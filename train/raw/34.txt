Bilingually motivated segmentation and generation of word translations using relatively small translation data setsAbstractOut-of-vocabulary (OOV) bilingual lexicon entries is still a problem for many applica- tions, including translation. We propose a method for machine learning of bilingual stem and suffix translations that are then used in deciding segmentations for new translations. Various state-of-the-art measures used to seg- ment words into their sub-constituents are adopted in this work as features to be used by an SVM based linear classifier for deciding appropriate segmentations of bilingual pairs, specifically, in learning bilingual suffixation.1 IntroductionOOV bilingual lexicon entries still remain an open problem and the approach proposed in this paper will contribute to solve this by machine learning of bilingual stem and suffix pairs using a very small English (EN)-Hindi (HI) bilingual lexicon. These bilingual segments are then used in deciding seg- mentations for unseen translations and also in gen- erating new ones. We examine a combination of commonly used segmentation measures as clues for bilingual suffixation of unseen translations in a min- imally supervised framework.No translation extraction technique guarantees the extraction of all possible translation pairs specially when not found or are infrequent in parallel cor- pora. Source-target asymmetry further adds to the problem for morphologically poor and rich language pairs, as is the case of English and Hindi. Noun, verb or adjective forms in English tend to have multi- ple translations in Hindi. Consider the English term ‘good’ with 3 possible translations: ‘acChA’, ‘ac- ChI’ and ‘‘acChe’ in Hindi. Each of these representvariants of the basic word form ‘acChA’, where ‘-A’ and ‘-I’ represent singular masculine and feminine, while ‘-e’ denotes a plural adjective suffix. As all the forms might hardly be seen in the training data, there is a need for identifying morphological similarities in the known example pairs1. In the referred exam- ple, the three word forms share the stem ‘acCh’ and differ in the endings ‘-A’, ‘-I’, ‘-e’. As these inflec- tions appear as endings for other words they serve in identifying word classes. Thus, the separation of morphological suffixes conflates various forms of a word, into a stem which is a crucial source of infor- mation. On the other hand, suffixes that occur fre- quently with words belonging to similar class, could be utilised for generating unknown forms. Hence, by using the morphological information, all possible forms can be inferred by combining different com- ponent morphemes from different mappings learnt using the example pairs in the translation lexicon.We discuss a generative approach for suggesting new translations based on the morphological simi- larities learnt from translation examples seen in the existing bilingual lexicon. The approach is distin- guishing as we rely on the frequent forms (suffixes) occurring in translations rather than on words in just one language. Fundamental to this generation strat- egy, we have 2 phases involving learning and clas- sification. Firstly, the bilingual approach to learn- ing morph-like units is used in preparing the training data (Mahesh et al., 2014). This involves identifica- tion and extraction of orthographically and seman- tically similar bilingual segments (as for instance, ‘good’ ⇔ ‘acCh’) occurring in known translation1Words consist of high-frequency strings (affixes) attached to low-frequency strings (stems) (Hammarstro ̈m, 2009) 
examples (‘acChA’, ‘acChI’ and ‘‘acChe’), together with their bilingual extensions constituting dissimi- lar bilingual segments (bilingual suffixes) (‘’ ⇔ ‘A’ | ‘e’ | ‘I’)2. The common part of translations that conflates all its bilingual variants3 represents a bilin- gual stem (‘good’ ⇔ ‘acCh’). The different parts of the translations contributing to various surface forms represent bilingual suffixes or bilingual morpholog- ical extensions (‘’ ⇔ ‘A’ | ‘e’ | ‘I’). Further, bilin- gual suffixes representing bilingual extensions for a set of bilingual stems form bilingual suffix classes4, hence allowing safer translation generalisation. The bilingual suffix classes thus learnt along with the bilingual lexicon constitutes the training data set for the classification phase. Upon identification of the segmentation boundary (by classification), depend- ing on the bilingual suffix and the stem surfaced for the given unseen translation, the bilingual pair is then classified into one of the bilingual suffix classes identified in the training phase. New translations are then suggested by simple concatenation of bilingual stems and suffixes belonging to the identified class.2 Related Work2.1 Monolingual ApproachesLexical inference or morphological processing tech- niques have been established for handling unknown terms that are variations of known forms. Moreover, learning suffixes and suffixation operations from the corpus or lexicon of a language allows new words to be generated. Such approaches are categorised as supervised (De ́jean, 1998), semi-supervised (Linde ́n et al., 2009) and unsupervised (Goldsmith, 2001; Creutz and Lagus, 2005; Monson et al., 2009).The state-of-the-art approaches to unsupervised morphology learning are overviewed and discussed with sufficient level of detail by Wicentowski and Yarowsky (2002) and Hammarstro ̈m and Borin (2011), respectively. A most recent work inte- grates orthographic and semantic view of words and models word formation in terms of morpholog- ical chains (Narasimhan et al., 2015). To address the morphological segmentation problem, Kirschen- baum (2015) suggests the use of segmentations de-2Note the null suffix in the English side corresponding to gender and number suffixes in the Hindi side.3Translations that are lexically similar.4A suffix class may or may not correspond to Part-of-Speech such as noun or adjective but there are cases where the same suffix class aggregates nouns, adjectives and adverbs.rived from words sharing similar distribution and form in analysing less frequent words.Partially supervised strategies for morphology learning may be viewed as classification tasks. The classifier trained on known paradigms classifies the unseen words into paradigms or induces new paradigms (Linde ́n et al., 2009).2.2 Bilingual Learning ApproachesSasaoka et al., proposed bilingual inductive learning mechanism for predicting translations for unknown words (Sasaoka et al., 1997). Common and differ- ent parts of strings between known words and their translations represent the example strings, referred as Piece of Word (PW) and Pair of Piece of Word (PPW). The bilingual pairs of these extracted exam- ple strings maintained as a Pair of Piece of Word (PPW) dictionary form the basis of the prediction process.Snyder and Barzilay (2008) proposed simultane- ous morphology learning for discovery of abstract morphemes using multiple languages. To boost the segmentation decisions, Poon et al. (2009), proposed discriminative log-linear model employing overlap- ping contextual features.In our previous work, we proposed an approach for learning bilingual suffixation operations by util- ising the translation lexicon as a parallel resource (Mahesh et al., 2014). As a pre-phase to transla- tion generation, bilingual morph-like units conflat- ing various translation forms are learnt and conse- quently clustered into bilingual suffix classes. Fre- quent forms occurring in translations rather than in word forms (in a language) are used in arriving at the segmentation decision. The ambiguities and com- plexities in decompositions are reduced as the trans- lation forms impose a restricted subset over the en- tire universe of word forms from which segmenta- tion decisions are made. Similar to the approach proposed by Sasaoka et al., (Sasaoka et al., 1997), our approach (Mahesh et al., 2014) that we adapt here for preparing the partial training data, allows identification of common (bilingual stems) and dif- ferent (bilingual suffixes) bilingual segments occur- ring in translation examples, which are then used in generating new translations.3 Proposed approachMuch of the research ranging from text analysis for acquisition of morphology, to learning suffixes and 
                                                                                         Term (EN) Term (HI)     Term (EN)   Term (HI)     process  ि या (prakriyA)     processes    ि याओं (prakriyAoM)     proof  माण (pramAN)     proofs    माण  (pramANoM)     plant    पौधा (paudhA)      plants      पौध  (paudhoM)    proceedingकाय वाही (kAryavAhI)  proceedings काय वािहय  (kAryavAhiyoM)     plan    योजना (yojanA)      plans      योजनाएं (yojanAeM)    prayer    ाथना (prArthanA)   prayers     ाथनाएँ (prArthanAeN)    promise        (vAd)   promises    वादे (vAde)    usualसामा  /साधारण(sAmAny/sAdharaN)  usually सामा तः /साधारणतः(sAmAnyatH/sAdharaNatH)     chief  धान (pradhAn)     chiefly    धानतः (pradhanataH)     rapid    शी  (shIghr)      rapidly      शी ता (shIghratA)    weak   दुब ल (durbal)   weakly    दुब लता (durbalatA)  suffixation operations for partially overcoming OOVbilingual entries and generating necessary trustablebilingual entries, is driven by the fact that word ismade up of high-frequency affixes attached to low-frequency stems (Hammarstro ̈m, 2009). Extend-ing this observation, we interpret a bilingual pairto be constituted by frequent bilingual suffixes at-tached to less frequent bilingual stems. The pro-posed approach operates in 2 stages: the learningphase for identifying bilingual suffix classes that     partially serves as the training data and the classi- fication phase for deciding segmentation.3.1 Learning PhaseLearning bilingual segments using translation vari- ants and their mapping into morphologically related classes closely follows the bilingual learning ap- proach and involves learning bilingual suffixes and suffixation operations (Mahesh et al., 2014) (refer Algorithm 1).Definitions Let L be a Bilingual Lexicon.Let L1, L2 be languages with alphabet set Σ1, Σ2. T={(wL1, wL2)|(wL1, wL2) ⊂ L} be set of valid bilingual pairs (translations) in L. S={piL1,siL1,piL2,siL2|piL1siL1 =wiL1;piL2 siL2 = wiL2 ; piL1 , siL1 εΣ1, piL2 , siL2 εΣ2} be the set of substrings of wiL1 , wiL2 , where piL1 siL1 denotes the concatenation of stem piL1 and suffix siL1 inlanguagesL1andL2.Let SSuffixPair be the set of bilingual suffix pairs and SStemP air be the set of bilingual stem pairs. Two translations (w1L1 , w1L2 ) and (w2L1 , w2L2 ) ∈ L are said to be similar if |lcp(w1L1 , w2L1 )| ≥ 3 and |lcp(w1L2 , w2L2 )| ≥ 3, where lcp is the longest com- mon prefix of the strings under consideration.  Input - Bilingual/Translation Lexicon (L):  Translation lexicon refers to a dictionary which contains a term (taken as a single word - any con- tiguous sequence of characters) in the first language  cross-listed with the corresponding term in the sec-  Table 1: Bilingual variants in EN-HI Lexiconinclude the list of bilingual stems (columns 3, 4 in Table 5) and suffixes (Table 4) with their observed frequencies in the training dataset. Sample bilingual stems include ‘plant’ ⇔ ‘paudh’, ‘boy’ ⇔ ‘laDak’. Sample bilingual suffixes are (‘’, ‘I’), (‘’, ‘A’), (‘ion’, ‘A’) and are attached to 10,743, 29,529 and 457 different bilingual pairs respectively. These lists aid in identifying bilingual stems and bilingual suffixes, given a new translation.Bilingual suffixes grouped by bilingual stems:This represents which set of bilingual suffixes attach to which bilingual stem. In Table 25, the bilingual suffixes, (‘s’, ‘oM’) and (‘ous’, ‘I’) attach to the same bilingual stem (‘mountain’, ‘pahAD’) yielding the surface forms ‘mountains’ ⇔ ‘pahADoM’ and ‘mountainous’ ⇔ ‘pahADI’.Total18, 10       Bilingual Stems Bilingual Suffixes               ('nation', 'रा ') : ('al', '◌ीय'), ('alism', '◌ीयता'), ('ality', '◌ीयता'), ('alist', ‘◌ीयतावादी’) ('nation', 'rAShTr') : ('al', 'Iya'), ('alism', 'IyatA'), ('ality', 'IyatA'), ('alist', ‘IyatAvAdI’)                 ('mountain', 'पहाड') : ('s', '◌ो◌ं '), ('ous', '◌ी') ('mountain', 'pahAD') : ('s', 'oM'), ('ous', 'I')     ond language such that they share the same mean- ing or are usable in equivalent contexts. In Ta- ble 1, sample entries illustrate bilingual variants: noun singular forms (columns 1, 2 in 1st 7 rows) – noun plural forms (column 3, 4 in 1st 7 rows) and adjective forms (columns 1, 2 in last 4 rows) – adverb forms (columns 3, 4 in last 4 rows).Output :List of Bilingual stem and suffix pairs: These   Bilingual Suffix Classes: A set of bilingual stemsthat share same suffix transformations form a clusterDescriptionTraining TestTable 2: Bilingual suffixes grouped by bilingual stemsBilingual Pairs Minimum Length (EN-HI) Maximum Length (EN-HI)58,04852K 6K 3, 3or a bilingual suffix class. In the 1st row of Table Term (EN) Term (HI) Term (EN) Term (HI)5, (‘’, ‘A’) and (‘s’, ‘oM’) represent bilingual suf- fixes that combine with bilingual stems, ‘plant’ ⇔ ‘paudh’, ‘boy’ ⇔ ‘laDak’ and many more. These allow new translation forms to be subsequently sug- gested upon identification of bilingual stems and suffixes in an unseen translation given as input.   52nd line in each row shows transliterations for HI terms
 Algorithm 1 Learning Bilingual Suffix Classes 1: 2: 3: 4: 5: 6: 7: 8:9: 10: 11: 12: 13:14: 15: 16: 17:18: 19:procedureLEARNBILINGUALSUFFIXCLASS for each translation (aL1, aL2) ∈ L doif ∃ (bL1, bL2) similar to (aL1, aL2), and (cL1, cL2) similar to (dL1, dL2) ∈ L, where p1L1 , p1L2 , p2L1 , p2L2 , s1L1 , s1L2 , s2L1 , s2L2 εS, and(aL1, aL2)=((p1L1 s1L1 ), (p1L2 s1L2 )); (bL1, bL2)=((p1L1 s2L1 ), (p1L2 s2L2 )), (cL1cL2)=((p2L1 s1L1 ), (p2L2 s1L2 )); (dL1, dL2)=((p2L1 s2L1 ), (p2L2 s2L2 )) thenadd (p1L1 , p1L2 ) to the list of bilingual stems SS temP air .add ((s1L1 , s1L2 ), (s2L1 , s2L2 )) to the list of bilingual suffixes SS uf f ixP air .foreachsuffixpair(siL1,siL2)εSSuffixPair doif ∃ m, n such that (msiL1 , nsiL2 ) ε SS uf f ixP air , u2 m = u1 , v2 n = v1and bilingual stem (u1,v1) and (u2,v2) ε SStemPair, thenreplace (u1, v1) by (u2, v2) and (siL1 , siL2 ) by (msiL1 , nsiL2 ) iff Strength(siL1 , siL2 ) or Strength(m, n) > Strength(msiL1 , nsiL2 ).for each stem pair (piL1 , piL2 )εSS temP air , where ((piL1 siL1 ), (piL2 siL2 ))= (wiL1 , wiL2 )εL do if (siL1 , siL2 ) is not in the list of bilingual suffixesassociated with the bilingual stem (piL1 , piL2 ) thenappend (siL1 , siL2 ) to the suffix list associated with (piL1 , piL2 ).Cluster the stem pairs sharing similar suffix transformations into bilingual suffix classes.endprocedure 3.2 ClassificationIn this section, we discuss the use of SVM based linear classifier6 (Fan et al., 2008) in predicting if a given segmentation option corresponds to a valid boundary or not.(p1L1 , p1L2 )(s1L1 , s1L2 ), (p2L1 , p2L2 )(s2L1 , s2L2 ), ...., (pnL1 , pnL2 )(snL1 , snL2 ) (1)In Equation 1, all possible bilingual stems and suffixes associated with a given bilingual word pair (wiL1 , wiL2 ) are represented, where (piL1 , piL2 )(siL1 , siL2 ) represents a candidate for the bilingual stem and suffix (a possible segmentation boundary). The principle of classification involves learning a function, to infer a binary decision for each split, given all possible segmentations compris- ing of bilingual stems and suffixes for any given un- seen translation.Each of the possible segmentations (constituting bilingual stem and bilingual suffixes) is a data in- stance, represented as a feature vector and a tar- get value indicating if the corresponding segmenta- tion is valid (+1), invalid (-1) or unknown (0). We train a binary classifier using the features identified from the training dataset made of the bilingual lexi- con and the clusters (bilingual suffix classes) identi- fied during the learning phase. Segmentation bound- aries identified for each of the bilingual pairs during the learning phase represent positive samples and all6http://www.csie.ntu.edu.tw/ cjlin/papers/liblinear.pdfother possible segmentation options for the bilingual pair represent negative samples. Given all possible splits for a new bilingual pair, the estimated model should predict if each of the candidate segmenta- tions represents a valid boundary (+1) or not (-1).3.2.1 Lexicon as Training DataThe measures discussed below, used in segment- ing words into substituent morphemes, are adopted in bilingual framework and are used to derive fea- tures to minimally supervise the segmentation.Stand-alone Bilingual Pair We use a binary val- ued feature indicating if each candidate bilingual stem appears as a stand-alone translation in the lexicon with respect to the candidate segmentation boundary. This knowledge is frequently used in sev- eral word-based models and in one of the best per- forming approaches selected by Hafer et al. (Hafer and Weiss, 1974). Instances of bilingual stems ap- pearing as stand-alone bilingual pairs in the lexicon are ‘mountain’ ⇔ ‘pahAD’ and ‘region’ ⇔ ‘kShetr’.Candidate Boundary Offset (BO) A pair of in- dex numbers indicating the position of the candi- date boundary relative to the beginning and end of the bilingual pair characterises the boundary points. Single-character suffixes, or generally short suffixes are often observed to be spurious than the long ones (Goldsmith, 2001). Index values have been used as multipliers in the function reflecting optimal split 
position to deal with the disparity with respect to the frequency of shorter stems and suffixes vs longer ones (Patel et al., 2010). Further, the index values have been used as features in correcting the prob- lem with predecessor variety values resulting from normalisation (C ̧o ̈ltekin, 2010). This knowledge is represented by 4 additional features:• A pair of integer-valued features corresponding to the offsets from the beginning of the bilingual pair (with respect to candidate boundary). For the bilin- gual pair, ‘boys’ ⇔ ‘laDakoM’, with a candidate bilingualstem‘boy’⇔‘laDak’,theoffsets7are3 and 3 EN and HI characters, respectively.• A pair of integer-valued features corresponding to the offsets from the end of the bilingual pair (with respect to candidate boundary). For the example above, the offsets are 1 and 1 EN and HI character, respectively.Normalised Successor Entropy (NSE) The suc- cessor entropy is calculated for each stem pair as :H(pL1,pL2) =−   f(pL1sL1,pL2sL2).(sL1 ,sL2 )∈succ(pL1 ,pL2 ) f (pL1 , pL2 )log f(pL1sL1,pL2sL2) (2)2 f(pL1,pL2)where, (pL1sL1, pL2sL2) is the bilingual string that is formed by concatenation of sL1 to pL1 and sL2 to pL2, f() represents the frequency of the bilingual pairs starting with the given bilingual stem (prefix pair), and succ() returns all bilingual suffixes (suffix pairs) for the given bilingual stem (pL1, pL2).NSE for a candidate stem pair is obtained by dividing the calculated entropy value by the ex- pected value (considering bilingual stems having same length as the candidate stem pair) correspond- ing to the split position.Normalized Predecessor Entropy (NPE) NPE for a candidate suffix pair is obtained by dividing the calculated predecessor entropy (PE) value by the ex- pected value (considering the bilingual suffixes hav- ing same length as the candidate suffix pair) with re- spect to the split position. PE can be obtained using the Equation 2 by replacing successor with prede- cessor and switching the concatenation order.7Transcription of HI characters to Latin ones is not character number conservative. But as we work with both character types, offsets must obey the character set in question.Normalized Successor Variety (NSV) and Nor- malized Predecessor Variety (NPV) We define successor variety as the number of distinct bilin- gual suffixes that follow a candidate bilingual stem. This count is calculated for each candidate bilin- gual stem in the training data set. The SV segmen- tation measure initially proposed by Harris (1970) is employed in numerous word-segmentation tasks (De ́jean, 1998; R. et al., 2005; Stein and Potthast, 2007; Bordag, 2008). Further, researches show how this measure could be utilised in improving the seg- mentationresults(HaferandWeiss,1974;C ̧o ̈ltekin, 2010).The variety values are normalised by dividing the calculated value by the expected value (based on the equi-lengthed bilingual stems) with respect to the split position. The NPV value for a candidate bilin- gual suffix may be calculated similarly. C ̧o ̈ltekin (2010) provide an elaborate analysis of the problems concerning SV values and the suggested improve- ments using normalized SV scores.Bilingual Morpheme Frequency (BMF) This measure quantifies a candidate bilingual morpheme by the number of distinct translations to which it at- taches in the bilingual lexicon.bmf(mL1, mL2) = Number of unique bilingualpairs (mL1, mL2) attaches to. (3)where (mL1,mL2) is the candidate bilingual mor- pheme (a bilingual stem or a bilingual suffix). This adds 2 features, corresponding to each candidate bilingual stem and the candidate bilingual suffix.Generative Strength (GS) Instead of placing same weight on each bilingual pair when scoring a morpheme, each bilingual pair might be assigned weight based on its generative strength (Dasgupta and Ng, 2007). The generative strength of a bilin- gual pair is estimated by calculating how many dis- tinct induced bilingual morphemes attach to that bilingual pair. The score of a bilingual morpheme is defined to be the sum of the strengths of the bilin- gual pairs to which it attaches.  gs(mL1, mL2) =  Strength(wiL1 , wiL2 ). (wiL1 ,wiL2 )(4) (wiL1 , wiL2 ) represents the bilingual pair to which the candidate bilingual morpheme (mL1 , mL2 ) attaches. The heuristic has been used in various word-based segmentation tasks to select from among multiple suffixes while stemming awhere 
word form (Pandey and Siddiqui, 2008; Zeman, 2008).Table 4 (columns 3 and 4) shows the scores for frequent bilingual suffixes using each of the above mentioned scoring functions.3.2.2 Clusters as Training DataThe clusters (bilingual suffix classes) generated in the learning phase is additionally used as training data to model the bilingual suffixes for classification.Cluster-based Bilingual Suffix Length (CBSL)This is calculated as the number of times a bilingual pair which is (l1, l2) characters contains an (sl1, sl2) character long bilingual suffix, normalized by the total number of bilingual pairs with length (l1,l2) (Brychc ́ın and Konop ́ık, 2015).Cluster-based Bilingual Suffix Probability (CBSP) This represents the probability that a candidate bilingual morphological extension is a correct bilingual suffix. The clusters generated in learning phase are used to estimate this and is calculated as the number of times the bilingual suffix (siL1,siL2) follows the bilingual stem of a translation (wiL1,wiL2) (for each bilingual pair in each cluster), divided by the number of all times (wiL1,wiL2) ends with (siL1,siL2) (Brychc ́ın and Konop ́ık, 2015).3.3 Suffix Class Determination and Translation GenerationGiven a new translation, upon identification of the segmentation boundary (after classification), we need to identify to which bilingual suffix class the surfaced bilingual suffix and hence the translation belongs. Depending on the bilingual suffix and the stem identified for the given translation, the bilin- gual pair is classified into one of the bilingual suffix classes identified in the training phase. This is ap- proached as a multi-label classification problem.SVM based tool namely LIBSVM8 was used to learn the multi-label classifier. A class is repre- sented as a set of features represented by a feature- value pair and a label. The features are bilingual suffixes that are representatives of a class. For any class, the value in a feature-value pair simply indi- cates whether the bilingual suffix is a representative of that class (if so, 1) or not (if not, 0).8 A library for SVMs - Software available at http://www. csie.ntu.edu.tw/ ̃cjlin/libsvmAfter the bilingual suffix class for a translation is determined based on the split, new translations are suggested by applying the suffix replacement rules to the identified bilingual stem. For example, given a new bilingual pair ‘dilemmas’ ⇔ ‘duvidhAein’ (Fig- ure 1), the bilingual suffix resulting from segmenta- tion is (‘s’, ‘Aein’). As (‘s’, ‘Aein’) is classified as belonging to the bilingual suffix class (‘’, ‘A’), (’s’, ’Aein’), the new translation is generated by replac- ing ‘s’ with ‘’ and ‘Aein’ with ‘A’, giving rise to the new bilingual variant ‘dilemma’ ⇔ ‘duvidhA’.      dilemmas ! दुिवधाएँ dilemmas ! duvidhAein New Translation (Bilingual pair) Segmentation(dilemma, दुिवध): ('s', '◌ाएं') (dilemma, duvidh): ('s', ‘Aein’) (Bilingual stem) : (Bilingual Suffix) Classification('', '◌ा'), ('s', '◌ाए'ं ) : ('plan', 'योजन'), ('meeting', 'सभ'), .... ('', 'A'), ('s', 'Aein') : ('plan', 'yojan'), ('meeting', 'sabh'), .... (Bilingual Suffix Class)Bilingual Suffix Replacement('s', '◌ाएं ') ⇒ ('', '◌ा') ('s', 'Aein') ⇒ ('', 'A')  Generationdilemma ! दुिवधा dilemma ! duvidhA(Suggested Translation -Bilingual pair) Figure 1: Sample generation            3.4Longest Bilingual Suffix Match (LBSM)The LBSM technique is used as baseline for iden- tifying bilingual suffixes. After the learning phase, we have different sets of bilingual stems that have been grouped according to their bilingual inflec- tional classes. We call such sets as Bilingual Suffix Classes. For each translation in the test set, we wish to determine their bilingual inflections (suffixes) and the associated bilingual suffix class. As baseline, we classify each new (unseen) translation in the test set into the class of longest matching bilingual suf- fix from the bilingual suffix list. For instance, the longest bilingual suffix matching the bilingual pair ‘conservative’ ⇔ ‘rakshAtmak’ is ‘ative’ ⇔ ‘Atmak’ yielding the bilingual stem ‘conserv’ ⇔ ‘raksh’.4 Experimental Results and Discussion 4.1 Data setWe used bilingual pairs taken from EN-HI bilingual lexicon representing single-word translations as the 
                                                                                                                                                Bilingual Suffixes     Suffix pair Co-occurrence Score*   Bilingual Stems   ('', '◌ा'), ('s', '◌ो◌ं ') ('', 'A'), ('s', 'oM')     27   ('plant', 'पौध') ('plant', 'paudh')   ('boy', 'ल क') ('boy', 'laDak')   ('', '◌ी'), ('s', '◌ो◌ं ') ('', 'I'), ('s', 'oM')     27   ('job', 'नौकर') ('job', 'naukar')   ('archer', 'धनुषधार') ('archer', 'dhanuShadhaar')   ('s', '◌ो◌ं '), ('ous', '◌ी') ('s', 'oM'), ('ous', 'I')       8      ('mountain', 'पव त') ('mountain', 'parvat')     ('mountain', 'पहाड') ('mountain', 'pahAD')   ('', '◌ा'), ('s', '◌ाएं ') ('', 'A'), ('s', 'AeM')    3    ('plan', 'योजन') ('plan', 'yojan')   ('meeting', 'सभ') ('meeting', 'saB')                     training data set. Approximately 90% of the entries in the lexicon were acquired from the dictionary9.                                            The bilingual suffixes (frequently undergoing trans- formations) recognised using the approach dis- cussed in Section 3.1 are shown in Table 4. Table 511 presents the bilingual suffix transformation rules which enable one translation form to be obtained us- ing the other. The grouping in row 1 implies that re- placing the suffix ‘s’ with ‘’ and the suffix ‘oM’ with ‘A’ in the bilingual pair ‘boys’ ⇔ ‘laDakoM’, yields its bilingual variant ‘boy’ ⇔ ‘laDakA’.The remaining (10%) entries were partly compiled m('natinonu',a'राl l्रy') a:nd('al',p'◌aीयr't),ia(l'allyismu','s◌iीयnतgा'),(t'ahliety',S'◌ीyयतmा'),m('aleist'r,i‘◌cीयCतावoादnी’)-Bilingual Stems Bilingual Suffixes('nation', 'rAShTr') : ('al', 'Iya'), ('alism', 'IyatA'), ('ality', 'IyatA'), ('alist', ‘IyatAvAdI’)ditional Probability based statistical measure from('test', 'परी ') : ('', '◌ा'), ('er', 'क'), 10 ('ers', 'क ')the aligned parallel corpora (Da Silva and Lopes, ('test', 'parIksh') : ('', ‘A'), ('er', 'k'), ('ers', 'koM')1999). The details are as shown in the Table 3.   Description   Total     Training   Test   Bilingual Pairs   58,048       52K      6K      Minimum Length (EN-HI) 3, 3     Maximum Length (EN-HI)      18, 10  4.2Table 3: Statistics of the Data setBilingual Learning and GenerationTable 5: Highly (top 2), less (bottom 2) frequent bilingual suffix replacement rulesto inflection classes result in distinct bilingual suffix classes some of which should be collapsed.We evaluate the bilingual segments and cluster- ing results indirectly by examining the applicability of induced segments in generating new translations. We first complete the translation lexicon with miss- ing bilingual pairs using bilingual stems and bilin- gual suffixes learnt using the known bilingual pairs. Generation of missing translation is purely concate- native and is done using the translations in the train- ing data for the chosen bilingual suffix classes (Ma- hesh et al., 2014). The generated translations are then evaluated. Table 6 shows the results of the learning phase. We calculate the precision for gen- erated translations as the fraction of correctly gener- ated bilingual pairs to total number of bilingual pairs generated. In completing the translation lexicon for missing forms, when both bilingual stems and bilin- gual suffixes are known, the precision achieved for translation generation reaches 86.52% when com- pared to the precision of 81.31% obtained using the bilingual learning approach (Mahesh et al., 2014).     Bilingual Suffixes Bilingual Suffixes (Hindi Suffixes transliterated)     Frequency (bmf)   Generative Strength (gs)     ('', '◌ी') (‘’, ‘I’)     10,743   11,240     ('', '◌ा') (‘’, ‘A’)     29,529   30,635     ('ion', '◌ा') (‘ion’, ‘A’)     457   567     ('er', '◌ा')    ('er', ‘A')      428      515    ('ity', '◌ा')   ('ity', ‘A')   286    340  Table 4: Bilingual Suffixes with frequent replacementsTo avoid over-segmentation, we perform the suf-fix containment check, looking for one candidatebilingual suffix enclosed within another. A truecompound bilingual suffix (a combination of mul-tiple candidate bilingual suffixes) is retained basedon the observation that the strength of a compoundbilingual suffix is less than the strengths of the bilin-   Learning Approach     Unique Bilingual Stem Count Unique Bilingual Suffix Count   Number of Clusters     Generation Precision   IDA2014 (Kavitha et al., 2014)     12,603 781   224     81.31   Proposed-Phase 1       10,224    426    143       86.52     Evaluation A few of the induced bilingual suffix class based morphological patterns are incomplete as not all the translation forms are seen in the lexi-gual suffixes composing it (Dasgupta and Ng, 2007).FeaturesPrecisionRecall47.32 52.54F-measure57.85 61.87con. Further, distinct surface translation forms dueNPE + NSE + BO + Stand-alone pair 70.14 57.22 63.02 BMWFe+GSc+aCtBeSgPo+rCiBsSeL+tBhOe+Stganed-naleonreaptaierd tr7a6.n21slati6o6.n24s int7o0.883  9http://sanskritdocuments.org/hindi/dict/eng-hin ̇unic.html , classes (separated by thick border) based on the de- gree of correctness. First 3 rows represent accept- able translations (Accept). The following row shows12Two bilingual suffixes are shown per class, though they range from 2 to 5Table 6: Clustering statisticsLongest Bilingual Suffix Match 74.41 NSV + NPV + BO + Stand-alone pair 75.23Table 712 shows suggested translation examples. www.dicts.info, hindilearner.com   10EMILLE Corpus - http://www.emille.lancs.ac.uk/   11*Number of times a bilingual suffix co-occurs with anotherbilingual suffix in the input lexicon (Mahesh et al., 2015) 
                                                                  translation errors (Reject) and the last row represents an inadequate translation (Inadequate). Mentioned errors are briefly explained below:Inadequate: The bilingual pair ‘Russians’ ⇔   ‘rUsiyoM’ (last row of the Table 7) is inadequate, as   in actual usage, both the singular and plural variants ‘Russian’ and ‘Russians’ are translated as ‘rUsI’. An alternate correct translation would be ‘rUs vAsI’.Unique UniqueLearning Bilingual Bilingual Suffix Number of Generationvarious features are shown in Table 8. When newApproach Stem Count Count Clusters Precisiontranslations are given as inputs, the best f-measureIDA201412,603 781 22481.31 86.52(Kavitha et al., 2014)of 70.88% is achieved.Proposed-Phase 110,224 426 143   Features   Precision     Recall   F-measure   Longest Bilingual Suffix Match   74.41     47.32   57.85   NSV + NPV + BO + Stand-alone pair     75.23       52.54      61.87   NPE + NSE + BO + Stand-alone pair 70.14  57.22 63.02   BMF + GS + CBSP + CBSL + BO + Stand-alone pair     76.21       66.24      70.88            Table 8: Results of minimally supervised learning Conclusion and Future Work     Generated Translations     Existing Lexicon Entry       Rule used      cleverly ! िनपुणता    cleverness ! िनपुणता    ('ly', 'ता'), ('ness', 'ता')     capitalist ! पूँजीवादी materialist ! भौितकवादीcapitalism ! पूंजीवाद materialism ! भौितकवाद   ('ism', 'वाद'), (‘ist’, 'वादी')      framework ! ढाँचा     frameworks ! ढाँचे       ('', '◌ा'), ('s', '◌े ')      world!लौक (lauk) weeks!सा ाह ' (sAptahoM) worldly!लौिकक (laukik) weekly!सा ािहक (sAptahik)  (‘ly’, ‘ि◌क), ('s', '◌ो◌ं ')      Russians! िसय ' (rUsiyoM)     Russian! सी (rUsI)       ('ian', '◌ी'), ('ians', ‘ि◌य ')                            Table 7: Generated TranslationsReject: Incorrect generations are a result of in- correct generalisations. Typical errors correspond to irregular translation forms, specifically, the stem changes before suffixation and misclassifications due to insufficient translation forms. An example for the former class of errors is the generated translation ‘world’ ⇔ ‘lauk’ (row 5), as the correct translated form should be ‘world’ ⇔ ‘lok’. The surface variant ‘worldly’ ⇔ ‘laukik’ is obtained from the stem pair ‘world’ ⇔ ‘lok’ by appending ‘ly’ ⇔ ‘ik’ at the end of the word pair ‘world’ ⇔ ’lok’. Further, the stem undergoes a change from ‘o’ to ‘au’.Our approach being purely bilingual suffixation based, does not handle irregular forms and does not capture stem changes prior suffixation.4.3 Minimally supervised learningThe results of segmentation by classification were indirectly evaluated by examining what the induced bilingual segments is expected to facilitate, specifi- cally, in suggesting or generating new translations. In evaluating the generated translations, the Preci- sion (P), Recall (R) and F-measure (Fm) are com- puted as given below:P =tp/(tp +fp), R=tp/(tp +fn),Fm =2∗P ∗R/(P +R) (5)where, tp denotes the number of times the generated translations were correct, fp denotes the number of times the generated translations were incorrect and fn denotes the number of times a possible correct translation suggestion was missed. The results forWe have discussed a minimally supervised approach for learning bilingual segments. The training data prepared using the bilingual learning approach par- tially serves as the basis for segmentation along with the bilingual lexicon (Mahesh et al., 2014). Various measures used in word segmentation tasks are used as features to represent a boundary/non-boundary condition in a bilingual framework. The segmen- tation boundary identified for a bilingual pair during the learning phase represent a positive sample and all other possible segmentation options for the bilin- gual pair represent negative samples. Experiments with distant language pairs and limited training data show that knowing both bilingual stems and bilin- gual suffixes, missing forms could be generated with the precision of 86.52%. For new translations, the precision falls by 10%.As future work, direct evaluations should be done by comparing the learned bilingual segments and suffix classes to those in the grammar descriptions for the language pairs under consideration. Learn- ing from bigram equivalents to predict translations for verb forms shall be addressed in the future work.AcknowledgementsK. M. Kavitha and Lu ́ıs Gomes acknowledge the Re- search Fellowship by FCT/MCTES with Ref. nos., SFRH/BD/64371/2009 and SFRH/BD/65059/2009, re- spectively, the funded research project ISTRION (Ref. PTDC/EIA-EIA/114521/2009) that provided other means for the research carried out. The authors thank NOVA LINCS, FCT/UNL for providing partial financial assistance to participate in PACLIC 2015, and ISTRION BOX - Translation & Revision, Lda., for providing the valuable consultation.5
ReferencesStefan Bordag. 2008. Unsupervised and knowledge-free morpheme segmentation and analysis. In Advances in Multilingual and Multimodal Information Retrieval, pages 881–891. Springer.Toma ́sˇ Brychc ́ın and Miloslav Konop ́ık. 2015. HPS: High precision stemmer. Information Processing & Management, 51(1):68–91.C ̧ag ̆rı C ̧o ̈ltekin. 2010. Improving successor variety for morphological segmentation. LOT Occasional Series, 16:13–28.Mathias Creutz and Krista Lagus. 2005. Unsuper- vised morpheme segmentation and morphology induc- tion from text corpora using Morfessor 1.0. Helsinki University of Technology.Joaquim Ferreira Da Silva and Gabriel Pereira Lopes. 1999. Extracting multiword terms from document col- lections. In Proceedings of the VExTAL: Venezia per il Trattamento Automatico delle Lingue, pages 22–24.Sajib Dasgupta and Vincent Ng. 2007. Unsupervised word segmentation for bangla. Proceedings of ICON, pages 15–24.Herve ́ De ́jean. 1998. Morphemes as necessary concept for structures discovery from untagged corpora. In Proceedings of the Joint Conferences on New Methods in Language Processing and Computational Natural Language Learning, pages 295–298. Association for Computational Linguistics.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. 2008. Liblinear: A library for large linear classification. The Journal of Machine Learning Research, 9:1871–1874.John Goldsmith. 2001. Unsupervised learning of the morphology of a natural language. Computational lin- guistics, 27(2):153–198.Margaret A Hafer and Stephen F Weiss. 1974. Word segmentation by letter successor varieties. Informa- tion storage and retrieval, 10(11):371–385.Harald Hammarstro ̈m and Lars Borin. 2011. Unsuper- vised learning of morphology. Computational Lin- guistics, 37(2):309–350.Harald Hammarstro ̈m. 2009. Unsupervised learn- ing of morphology and the languages of the world. Ph.D. thesis, Chalmers University of Technology and Go ̈teborg, Gothenburg, December.Zellig S Harris. 1970. From phoneme to morpheme. Springer.Amit Kirschenbaum. 2015. To split or not, and if so, where? Theoretical and empirical aspects of unsu- pervised morphological segmentation. In Computa- tional Linguistics and Intelligent Text Processing, vol- ume 9041 of LNCS, pages 139–150. Springer.Krister Linde ́n, Miikka Silfverberg, and Tommi Pirinen. 2009. HFST tools for morphology – An efficient open- source package for construction of morphological ana- lyzers. In State of the Art in Computational Morphol- ogy, volume 41 of CCIS, pages 28–47. Springer.Kavitha Karimbi Mahesh, Lu ́ıs Gomes, and Jose ́ Gabriel P Lopes. 2014. Identification of bilingual segments for translation generation. In Advances in Intelligent Data Analysis XIII, volume 8819 of LNCS, pages 167–178. Springer.Kavitha Karimbi Mahesh, Lu ́ıs Gomes, and Jose ́ Gabriel P Lopes. 2015. Learning clusters of bilin- gual suffixes using bilingual translation lexicon. In Mining Intelligence and Knowledge Exploration (Ac- cepted). Springer.Christian Monson, Jaime Carbonell, Alon Lavie, and Lori Levin. 2009. Paramor and morpho challenge 2008. In Evaluating Systems for Multilingual and Multimodal Information Access, volume 5706 of Lecture Notes in Computer Science, pages 967–974. Springer.Karthik Narasimhan, Regina Barzilay, and Tommi Jaakkola. 2015. An unsupervised method for uncovering morphological chains. ArXiv preprint arXiv:1503.02335.Amaresh Kumar Pandey and Tanveer J Siddiqui. 2008. An unsupervised hindi stemmer with heuristic im- provements. In Proceedings of the second workshop on Analytics for noisy unstructured text data, pages 99–105. ACM.Pratikkumar Patel, Kashyap Popat, and Pushpak Bhat- tacharyya. 2010. Hybrid stemmer for gujarati. In 23rd International Conference on Computational Lin- guistics, page 51.Hoifung Poon, Colin Cherry, and Kristina Toutanova. 2009. Unsupervised morphological segmentation with log-linear models. In Proceedings of Human Lan- guage Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 209–217. Associa- tion for Computational Linguistics.Al-Shalabi R., Ghassan Kannan, Iyad Hilat, Ahmad Ababneh, and Ahmad Al-Zubi. 2005. Experiments with the successor variety algorithm using the cutoff and entropy methods. Information Technology Jour- nal, 4(1):55–62.Hisayuki Sasaoka, Kenji Aaraki, Yoshio Momouchi, and Koji Tochinai. 1997. Prediction method of word for translation of unknown word. In Proceedings of the IASTED International Conference, Artificial Intel- ligence and Soft Computing, Banff, Canada, page 228. Acta Pr.Benjamin Snyder and Regina Barzilay. 2008. Unsuper- vised multilingual learning for morphological segmen- tation. ACL-08: HLT, page 737.
Benno Stein and Martin Potthast. 2007. Putting succes- sor variety stemming to work. In Advances in Data Analysis, pages 367–374. Springer.Richard Wicentowski and David Yarowsky. 2002. Mod- eling and learning multilingual inflectional morphol- ogy in a minimally supervised framework. Ph.D. the- sis, Ph. D. Thesis. Johns Hopkins University, Balti- more, Maryland.Daniel Zeman. 2008. Unsupervised acquiring of mor- phological paradigms from tokenized text. In Ad- vances in Multilingual and Multimodal Information Retrieval, pages 892–899. Springer.