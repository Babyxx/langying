A Constrained version of Latent Dirichlet AllocationAbstractText clustering is an important area of research which has tremendously grown in importance over the past few years. Extracting the under- lying hidden topics or concepts from unstruc- tured text is known as topic modeling. In this paper we first use the popular Latent Dirichlet Allocation (LDA) for identifying the underly- ing topics from a set of text documents. Next we improve the performance of LDA by in- serting constraints into it. We propose an im- provement over an existing constrained LDA method, which uses domain knowledge in the form of must link and cannot link constraints for improved performance. The improvement is in introducing a) non linearity in the change of importance of constraints, and b) the re- inforcement learning concept which both en- courages satisfaction of constraints and also takes care of violation of constraints. Through examples in two different domains, namely fi- nance and medicine, we show here in terms of normalized mutual information that the pro- posed method gives an improved performance for clustering text documents.1 IntroductionTopic modeling from text data is one of the most important areas in the domain of text mining. Topic modeling helps in identifying the underlying topics or concepts from the text. Latent Dirichlet Alloca- tion (LDA) (Blei et al., 2003) is one of the most popular topic modeling methods which is an unsu- pervised method. Constrained clustering is semi su- pervised clustering where constraints are used to im- prove the performance of the unsupervised method.Second AuthorAffiliation / Address line 1 Affiliation / Address line 2 Affiliation / Address line 3 email@domainIn constrained clustering the user may provide do- main knowledge to direct the clustering process. For example a set of financial news stories can be grouped according to the type of news ”Initial Pub- lic Offering”or ”Mergers and Acquisitions” etc. The same set of news stories may be grouped accord- ing to the sectors like ”Information Technology” or ”Banks” etc. Additional domain knowledge is a means to direct the clustering process in the desired direction. The domain knowledge can be given ei- ther in the form of labeled objects or in the form of Must Link (ML) and Cannot Link (CL) constraints. ML (CL) constraints specify that a pair of words be- long to the same topic (belong to two different top- ics) (Zhai et al., 2011). There has been research on incorporating domain knowledge into the LDA model in Zhai et al. (2011), Andrzejewski et al. (2009), Petterson et al. (2010), Andrzejewski and Zhu (2009), Wilson and Chew (2010), Xie et al. (2015) etc.2 Latent Dirichlet AllocationLatent Dirichlet Allocation (LDA) (Blei et al., 2003) is one of most popular methods in the area of topic modeling. The main idea of LDA is that the documents are probabilistic mixture of topics, where topics are defined to be distribution over words. The probability model for the LDA is given below.wi|zi, φ(zi) ∼ Discrete(φ(zi)) φ ∼ Dirichlet(β)zi|θ(di) ∼ Discrete(θ(di))θ ∼ Dirichlet(α)
Here di denotes the document where the ith term belongs to,φ is the topic-word distribution and θ is the document-topic distribution, α and β are hyper parameters, specifying the nature of the priors on θ and φ, zi the latent variable which denotes the topic from which the ith term wi is drawn.The in- put to LDA model is the term-document matrix and outputs are the document-topic and topic-word ma- trix. Applying Bayes theorem we can get (Griffiths, 2002)P(zi =j|z−i,w)∝P(wi|zi =j,z−i,w−i)P(zi =j|z−i) (1)here zi = j means the assignment of the ith term in a document to topic j, z−i denotes the assignment of all zk except i. Griffiths and Steyvers (2004) propose a statistical inference algorithm using Gibbs sampling for LDA. The notations used in this paper are same as Griffiths and Steyvers (2004).The first step for learning the topic-word dis- tribution and document-topic distribution is, scan- ning through each document and randomly assign- ing each term in the document to one of the topics in 1, 2, . . . , T . This random assignment gives the start- ing topic representations of all the documents and word distributions of all the topics. The main step here is updating the topic for each term in each doc- ument. When the topic assignment of the current term is updated it is assumed that the topic assign- ments for all the other terms except for the current term in question are correct. Topic for each term in each document is updated according to the proba- bilities calculated using equation 2. It is shown in Griffiths and Steyvers (2004) that from equation 1 we can derive equation 2.total number of terms in document di excluding the current ith term in question, W is the total number of word types, T is number of topics. After N itera- tions the document topic distribution and topic-word distribution are estimated as the equations below.3LDA is an unsupervised method. It does not use any domain knowledge for identifying the topics. Zhai et al. (2011) proposed a constrained LDA method, which incorporates domain knowledge into LDA. The constrained LDA suggested by Zhai et al. (2011) includes a multiplier q(zi = j) in the right hand side of equation 2.P(zi=j|z−i,w)∝q(zi =j) n−i,j +βn(w) + βφˆw= j (3) j n•j+Wβˆd n(d)+α θ=j (4) j n•j+TαConstrained Latent Dirichlet Allocation(wi )n(•) +Wβ ndi +Tα(di )n−i,j +α (5)  P(zi = j|z−i,w) ∝ (wi )n(wi)+β n(di) +α −i,j −i,jn(•) +Wβ ndi +Tα −i,j −i,•(2)The idea is to increase the probability of the ith term in any topic j, if there are other terms belong- ing to that topic, that have a ML constraint with this term. Similarly decrease the probability, if there are terms belonging to topic j that the current term is linked to by CL constraints. The constrained LDA method suggested in Zhai et al. (2011) re- vises the topic updating probabilities by a multiplier q(zi = j). Suppose the ith term wi has ML con- straint with terms M1, M2 and CL constraint with terms C1 and C2. The topics for these terms M1, M2, C1, C2 are found out from the last assignment from the LDA method. Every time there is a must link term which belongs to topic j, q(zi = j) is in- creased and every time there is a cannot link term which belongs to topic j, q(zi = j) is decreased.In this paper we carry the idea proposed by Zhai et al. (2011) one step further and introduce non lin- earity into the change in importance of the multiplier q(zi = j). As more and more must linked terms come the value of q(zi = j) increases by higherHere n−i,j denotes the number of times word wihas been assigned to topic j excluding the currentith term, n(di) denotes the number of times a term −i,jfrom document di has been assigned to topic j ex- cluding the current ith term, n(•) denotes the total−i,jnumber of times any term has been assigned to topicj excluding the current assignment zi, ndi is the −i,•−i,j −i,•  
1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14.15. 16.17. 18. 19. 20. 21. 22. 23. 24.25. 26.27. 28. 29.30. }Table 1: Algorithm for updating q(zi,j) values incLDA2 2.and higher values. In the two algorithms proposed here, {q(zi = j)|j = 1,2,...,T} is increased or decreased in a different way than suggested by Zhai et al. (2011). The methods suggested in this paper are named as cLDA2 1 and cLDA2 2 and the con- strained LDA method proposed in Zhai et al. (2011) is named as cLDA1. The notations used here are asfollows. The constraint sets ML and CL contain the set of must link and cannot link constraints. The input array Z contains the last topic assignments ob- tained from LDA. SM and SC denote the set of MLand CL constraints respectively where one term is′wi. The function m(l) and m (l) denote the first and second terms of the lth ML constraint. The functions c(l) and c′ (l) denote the first and second terms of the lth CL constraint. The variable otherTerm con- tains the other term in the lth ML constraint associ- ated with the term wi, and the array topicsML con- tains all the topics associated with otherTerm. Here weightML(wi,j) is the weight that wi should belong to topic j and all weightML values are initialized at 1 (see step4 in Table. 1). The multiplier q(zi = j) is initialized at 1. Let us assume word wi is associated with M1 and M2 by ML and with C1 and C2 with CL constraints. The topics assigned to M1 and M2 by LDA are found out. Say the topic 1 is assigned twice and topic 2 is assigned thrice to M1. Now the weightML (wi, 1) will be multiplied by (1 + λ)2 and weightML (wi , 2) will be multiplied by (1 + λ)3 (see step 14 in Table. 1). Next the topic allocations for M2 will be considered and similarly weightML will be adjusted. The method proposed in Zhai et al. (2011) instead of multiplying it by (1 + λ) adds λ to it. λ must be within 0 to 1. Similarly C1 and C2 are also considered but here rather than multi- plying weightCL by (1 + λ) we divide it by (1 + λ) (see step24 in Table. 1). This algorithm is named cLDA2 1. In Zhai et al. (2011) instead of dividing it by (1+λ), subtracts (1−λ) from it. The aim of the change suggested in our method is to introduce non linearity into the change in the importance of con- straints. In case of Zhai et al. (2011) this change is linear. We are assuming here if there are no must linked terms for topic1, one must linked term for topic2 and two must linked term for topic3, then, topic 3 should get the highest importance and the change in importance of topic3 over topic2 should be higher than topic2 over topic1.Apart from the change mentioned in cLDA2 1 we further suggest a change using the concept of rein- forcement. Here whenever any must linked object is assigned to some topic other than j, q(zi = j) is decreased. Here violation of constraints is penal- ized. So whenever M1 is not assigned to topic j, weightML(wi,j) is multiplied by 1/(1 + λ)ρ. TheInput : wi, Z, λ, constraint set ML and CL; Output : q(zi = j)|{j = 1,2,...,T};Initial all q(zi = j|{j = 1,2,...,T}to 1 Initial all weightML(wi, j)to 1, ∀jInitial all weightCL(wi, j)to 1, ∀j for each j ∈ T{SM ← {l|m(l) = wi} ∪ {l|m′ (l) = wi} SC ←{l|c(l)=wi}∪{l|c′(l)=wi}for each l ∈ SM{otherT erm ← {m(l) ∪ m′ (l)} \ {wi} topicsM L ← topics(otherT erm)f or each t ∈ topicsM L{if(topicsML[t] == j) {weightML(wi,j) = (1+λ)×weightML(wi,j)}else {weightML(wi,j) =(1/(1+λ)ρ)×weightML(wi,j)}} }for each l ∈ SC{otherT erm ← {c(l) ∪ c′ (l)} \ {wi}topicsCL ← topics(otherT erm) f or each t ∈ topicsC L{if(topicsCL[t] == j) {weightCL(wi, j) =(1/(1 + λ)) × weightCL(wi, j)}else{weightCL(wi, j) =((1 + λ)ρ) × weightCL(wi, j)}} }q(zi =j)=q(zi =j)× weightML(wi,j)×weightCL(wi,j)     
constant ρ must be within 0 to 1. The idea behind this is to lower weightML(wi,j), whenever M1 be- longs to some topic other than j. Basically when- ever a must linked object belongs to topic j we re- ward topic j and whenever a must linked object be- longs to some other topic we penalize topic j. Sim- ilarly whenever C1 belongs to some other topic, weightML(wi ,j) is increased by multiplying with (1 + λ)ρ. This algorithm is named cLDA2 2 and it is described in Table 1.If we remove steps 16 and 26 from cLDA2 2 it becomes cLDA2 1. If wi is not associated with any term by any ML or CL con- straint weightML(wi,j) remains at 1 for all the top- ics. Once the weightML(wi ,j) and weightCL(wi ,j) are found the q(zi = j) are calculated by multiply- ing with weightML(wi ,j) and weightCL(wi ,j). Next the q(zi = j) values are normalized and relaxed us- ing relaxation factor η in a way similar to Zhai et al. (2011).Normalizationq(zi = j) = (q(zi = j) − min)/(max − min) Relaxationq(zi =j)=q(zi =j)∗η+1−ηHere we explain with an example why cLDA2 1 and cLDA2 2 should work better than cLDA1. The algorithms cLDA2 1 and cLDA2 2 multiply weightML (wi, j) at each step by (1 + λ). Let us consider a simple three topic situation. If term1 and term2 are linked by a ML constraint and term 1 does not belong to topic 1, belongs to topic 2 once and topic 3 twice. Now while calculating the probabil- ity of term2 belonging to different topics we take into account the presence of constraints. So the probability of term2 belonging to topic 2 should go high and topic 3 should go higher. So the multiplier weightML should be 1 for topic 1, (1 + λ) for topic2 and (1 + λ)2 for topic3 in case of cLDA2 1. After normalization the values become 0, 1/(λ + 2) and 1 for topic1, topic2 and topic3 respectively. In case of cLDA1 instead of multiplying by (1 + λ) adds λ. So the weightML values become 0, λ, 2λ for topic1, topic2 and topic3 respectively. After normalization the values become 0,0.5 and 1 respectively. As we can see λ is a value greater than 0, 1/(λ + 2) is less than 0.5. So the difference in the weights betweentopic3 (topic with highest multiplier) and topic 2 (topic with the second highest multiplier) is higher for cLDA2 1 over cLDA1. So constraints are sat- isfied in a better manner in case of cLDA2 1 than cLDA1.Next let us consider the situation with the CL con- straints. Say term1 and term2 are linked by a CL constraint and term 1 belongs to topic2 once and topic3 twice. So the probability of term 2 belong- ing to topic 2 should go low and topic 3 should go lower. In case of cLDA2 1 the weightCL val- ues become 1, 1/(1+λ) and 1/(1 + λ)2 for topic1, topic2, and topic3 respectively. After normalization the weights are 1, 1/(λ + 2) and 0 respectively. In case of cLDA1 at each step instead of dividing by (1 + λ), (1 − λ) is subtracted. So the weights are 0, −(1 − λ) and −2(1 − λ) respectively. After normal- ization the values become 1, 0.5 and 0 respectively. Here also we can see that the difference between the weights between the topic with the highest mul- tiplier (i.e topic 1) and the topic with next highest multiplier (i.e topic 2) is higher in case of cLDA2 1 over cLDA1. So constraints are satisfied in a better manner in case of cLDA2 1 than cLDA1.4 Empirical EvaluationTwo datasets are chosen for this study. The first one is titles of financial news stories downloaded from Yahoo Finance website belonging to the four cate- gories (earnings, IPO, up/downgrade, mergers and acquisitions). The numbers of documents in the cat- egories are 50, 49, 53, and 55 respectively. The doc- ument term matrix is of dimension 207 X 732. The second dataset is a set of paper titles downloaded from MEDLINE. The dataset consists of total 203 documents belonging to three categories human, an- imals and yeast. There are 66, 68, 69 documents respectively. The dimension of the document term matrix for this dataset is 203 X 176. For both the datasets clusters are not well separated which in- creases the difficulty of the problem.The outputs from the constrained LDA are the document topic distribution and topic word distribu- tion. From the document topic distribution we ob- tain the topic probabilities for each document. We assign each document to that topic for which the probability is highest.             
The normalized mutual information (NMI) (Strehl et al., 2000) between the category labels and topic assignments of the documents from the algorithm is used as the evaluation metric. NMI measures how closely the algorithm is able to model the underlying category distribution of labels. The higher, the better. NMI lies between 0 to 1.The constraints given are as follows. For the Ya- hoo Finance dataset the four words earnings, IPO, downgrade, mergers were selected from the four categories respectively. Two other words moodys from the up/downgrade category and acquire from the mergers and acquisitions category were also cho- sen. So we have 13 CL and 2 ML constraints. In this way from the other dataset MEDLINE all total seven words were selected from the three categories and 16 CL and 4 ML constraints were formed. Here since domain expert has to pick up the words the number of constraints is limited. The output NMI values are plotted in Fig. 1. For the sake of comparison the output from the method proposed in Andrzejewski et al. (2009) has also been included. The algorithm proposed in Andrzejewski et al. (2009) is based on Dirichlet forest priors and has been termed DF LDA here in this paper. For all the experiments the param- eter ρ in cLDA2 2 was chosen to be 0.4 for both the datasets. Further research can be directed towards finding an optimum value for ρ.For cLDA1 the parameter λ gives the relative im- portance of CL and ML constraints. While exper- imenting with varying the number of clusters the λ has been fixed at 0.5, to put equal importance to both CL and ML constraints.The relaxation parameter η signifies the strength of the constraints. Since con- straints are chosen manually the constraints are of good quality, so the value of η has been fixed at 0.9.It can be observed from the results in Fig. 1. (a) and (b) that cLDA2 1 and cLDA2 2 both have per- formed better than cLDA1 and LDA. We also ran the algorithms varying the number of clusters, with λ = 0.1 and λ = 0.9. The results were found to be similar i.e. cLDA2 1 and cLDA2 2 worked better than both LDA and cLDA1 in most of the cases.Next we ran the experiments varying the parame- ter λ from 0.1 to 1 in steps of 0.1. In this case the number of clusters is fixed at the actual number of categories i.e. 4 and 3 for Yahoo Finance and MED- LINE respectively. The parameter η has been fixedat 0.9. Results given in Fig. 1. (c) and (d).Further the NMI values are plotted with varying the relaxation parameter η in Fig. 1. (e) and (f), keeping λ fixed at 0.5 and number of clusters fixed at 4 and 3 for Yahoo Finance and MEDLINE respec- tively. The parameter η signifies the strength of the constraints. It can be observed in most of the casescLDA2 1 and cLDA2 2 are better than cLDA1.Figure 1: NMI for (a)Yahoo Finance, (b)MEDLINE with varying number of clusters(k). NMI for (c)Yahoo Fi- nance (k=4) (d)MEDLINE (k=3) with varying parame- ter λ. NMI for e)Yahoo Finance and f)MEDLINE with varying parameter η.5 ConclusionIn this paper we propose two modified versions of the constrained LDA (Zhai et al., 2011) method and show experimentally that they work better than the existing constrained LDA methods proposed in Zhai et al. (2011) and Andrzejewski et al. (2009).ReferencesAlexander Strehl, Joydeep Ghosh and Raymond Mooney. 2000. Impact of similarity measures on web-page clustering. Workshop on Artificial Intelligence for Web Search , 58-64         
Andrew T. Wilson and Peter A. Chew. 2010. Term weighting schemes for Latent Dirichlet Allocation. Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the As- sociation for Computational Linguistics. Association for Computational Linguistics, 465-473David Andrzejewski and Xiaojin Zhu. 2009. La- tent Dirichlet Allocation with Topic-in-Set Knowl- edge. Proceedings of the NAACL HLT Workshop on Semi-Supervised Learning for Natural Language Pro- cessing. Association for Computational Linguistics,David Andrzejewski, Xiaojin Zhu and Mark Craven. 2009. Incorporating domain knowledge into topic modeling via Dirichlet forest priors. Proceedings of the 26th Annual International Conference on Machine Learning, 25-32David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet Allocation. The Journal of Ma- chine Learning Research, 3: 993–1022.James Petterson, Alex Smola, Tiberio Caetano, Wray Buntine and Shravan Narayanamurthy. 2010. Word Features for Latent Dirichlet Allocation. Ad- vances in Neural Information Processing Systems, 1921-1929Thomas L. Griffiths, Mark Steyvers. 2004. Finding Sci- entific Topics. Proceedings of the National Academy of Sciences of the United States of America, 101(1): 5228–5235.Tom Griffiths. 2002. Gibbs Sampling in the Generative model of Latent Dirichlet Allocation.Pengtao Xie, Diyi Yang, and Eric P. Xang. 2015. In- corporating Word Correlation Knowledge into Topic Modeling. The 2015 Annual Conference of the North American Chapter of the Association for Computa- tional Linguistics., 1921-1929Zhongwu Zhai, Bing Liu, Hua Xu and Pefia Jia. 2011. Constrained LDA for grouping product features in opinion mining. Advances in Knowledge Discovery and Data Mining, 448-459. Springer Berlin Heidel- berg.