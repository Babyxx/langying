Towards producing compact results in User-System interactions in a NLIDB systemAbstractUser-System interactions are a very important part of dialogue systems. Very often, a user does not mention complete information in his query. As a result, the system may give a large number of results, of which very few may be relevant to the user. In this paper, we propose a novel approach on how a system can reduce the size of results by prompting the user and give a compact set of answers. We experiment our approach in a small domain and discuss on how the proposed system can be useful in large real time database systems.1 IntroductionQuestioning a database in natural language is a user friendly way of searching databases rather than writ- ing and posing a question in the restricted pattern of S Q L syntax. A Natural Language Interface to Database (NLIDB) system (Androutsopoulos et al., 1995; Catalina Hallett and David Hardcastle, 2008; Pazos et al., 2002; Popescu et al., 2003; Giordani and Moschitti, 2009; Gupta et al., 2012) is a N L P application which takes a query in natural language (NL) from the user and generates a SQL query from it. The S Q L query retrieves the results based on the domain semantics and database schema and sends it back to the user.In NLIDB systems, the user asks a query and the system presents the user with few results accord- ingly. N L I D B systems can be extended to Dialogue systems,(Akula et al., 2013) wherein, instead of re- stricting the user to ask only a single question, the user can have a conversation with the system. InSecond AuthorAffiliation / Address line 1 Affiliation / Address line 2 Affiliation / Address line 3 email@domaineach question asked by the user, the system tries to convert these individual queries into SQL queries and retrieve answers from the database. Very of- ten, people do not give complete information while querying the system. Due to this unspecific nature of user queries, the system may output large num- ber of results. Going through a large number of re- sults would be quite difficult and uncomfortable for a user. In order to avoid this, the system has to give a compact set of results. For this, the system has to make the query more specific by interacting with the user. In this paper, we propose a system which tries to give a compact set of results to a user when the size of results is large.2 Related WorkSystem driven knowledge acquisition strategies have been proposed. In (Pappu et al., 2014), the authors propose three types of knowledge acquisition strate- gies (Query Driven, Personal and Show & Ask) and show that these strategies are helpful for the system to learn new slot-value pairs1. Our problem also requires system driven techniques to make a user query more specific. In (Akula et al., 2013) the au- thors propose user-system interaction models in a di- alogue process in the background of N L I D B systems. The authors also propose relationships between dia- logue units using the concept of entities, attributes and values in the Entity Relationship schema of the database. Identifying user system interaction mod- els is important to know the behaviour of a user. To1slot-value pair: A slot is similar to an attribute in Relational database. Eg. Person name: Smith, where Person name is slot and Smith is a value 
our knowledge, no work has been done on the lines of analysing the number of results to be presented to the user, until now. In this paper, we propose a system that minimizes the results of a user query when there are too many results. The system may require more information to reduce the results and thus prompts the user. In order to prompt the user, the system uses the concept of attributes from the database. Prompting the user with the ideal attribute helps in minimizing the results to be presented to the user. The system also ensures that while reducing the final set of results, the user does not miss any important information.The rest of this paper is organized as follows. In section 3, we discuss on nature of user queries. In section 4, we discuss types of user queries from a different perspective. Section 5 discusses on user- system interaction models. In Section 6, we discuss about prompting the user. Section 7 shows non- prompting heuristics to reduce the size of results. Section 8 discusses the experiments. We conclude in section 9.3 Specificity of a user queryWe categorize user queries into four types based on how specific a user is. They are:1. Strongly specific If the number of values in a query is more than one, then the user is said to be strongly specific. For example, Give me a good American restaurant on Fairgrounds Dr in Sunny- vale ?. Here the user is strongly specific as he men- tions two values (American, Fairgrounds Dr) in the query.2. Specific If there is exactly one value in a query, then the user is said to be specific. For example, List the restaurants in San Francisco. Here the user is specific as he mentions a value (San Francisco) in the query.3. Weakly specific If there are adjectival modi- fiers to an attribute in the query, then the user is said to be weakly specific. For example, List the good restaurants.4. Unspecific If there are no values in the query or no modifiers to an attribute, then the user is said to be unspecific. For example, List all the restaurants. Here, the user is unspecific as he wants the list of all restaurants.In case, the user is unspecific, the system prompts the user with an open question asking whether he would like to add any details regarding his query. If the user is again unspecific, then the system outputs all the results to the user. The same follows for other types of queries. This is done to ensure that there is no loss of information for the user.4 Types of a user queryAkula et al., (2013) categorize user-system interac- tions based on topic and goal. Similar to them, we categorize a user query based only on the goal of a user. We categorize a user query into the following types:1. Complete goal: In this type, the user has al- ready mentioned his goal completely in the query.2. Partial goal: In this type, the user mentions his goal partially and is expected to complete his goal during further interaction with the system.Knowing whether a user query is complete goal type or a partial goal type is essential for the system in order to prompt the user appropriately.5 Modeling User-system interactionsDepending on the way in which a user becomes spe- cific in a dialogue interaction with the system, we propose two models:1. Hierarchical Model: In this model of user- system of interaction, the user becomes specific in a hierarchical manner. In each dialogue , user adds values of attributes which are hierarchically related. For example, consider the attributes Region name, City name and Street name. The hierarchy between these three attributes is:Region name >City name >Street name.This is because a region consists of cities and a city consists of streets.Figure 1: An example of hierarchical interaction         U1: List the restaurants in Bay area.S1: There are many restaurants in Bay area. Can you be more specific?U2: List all Italian restaurants in Bay area.S2: Would you like to add anything more specific? U3: I’d like to eat SpaghettiS3: Restaurant 1, Restaurant 2,...Restaurant n 
Figure 1 shows an example of hierarchical user-system interaction. Each time the system prompts the user, the user adds values of attributes which are related hierarchi- cally. The hierarchical attributes/attribute-values in figure 1 are restaurant name (restaurant) in U1, cuisine name (Italian) in U2, dish name (Spaghetti) in U3. Linguisti- cally, the concept of hierarchy is similar to hypernymy and hyponymy. In Figure 1, restaurant and cuisine can be considered as hypernym and hyponym2 respectively. The user stops adding attributes hierarchically when he has reached his goal.2. Non-hierarchical Model: In a Non-Hierarchical model of user-system interaction, users do not add values of attributes in a hierarchical manner. We categorize non- hierarchical model interactions mainly into two types:a) Goal-related: In Goal-related interaction, when a user is prompted to become more specific, user adds at- tribute values related to the goal which he has already mentioned.b) Goal-unrelated: In Goal-unrelated interaction, when the user is prompted to become more specific, the user adds attribute values which are not related to the goal which he has already stated in his previous query. Here, the user adds something new which could actually be the beginning of a new goal as well.Figure 2: An example of Non-hierarchical interac- tion.In Figure 2, notice that in U2 and U3, the user adds attribute-values which are related to what is mentioned in U1. The user mentions his goal in U1 (list restaurants) and the information in U2 (time) and U3 (good ambience) are goal-related to U1. The information provided by the user in U2 and U3 just elevate information in U1 but do not make a new goal. Since in each interaction after U1, the user is not moving towards his goal (as the user has already mentioned his goal in U1), the example in Figure 2 is an example of Non-hierarchical user-system interac- tion.6 Prompting the userIn this section, we discuss on how a system should prompt a user to make a user query more specific in hi-2Hyponym is a word whose semantic field is present within another word, called hypernym.erarchical model of user-system interaction. Algorithm 1 shows the work flow of the system to reduce results de- pending on user-system interaction models.Algorithm 1 Algorithm showing on how the system switches to different user-system models for reduc- ing results     1: 2: 3: 4: 5: 6: 7: 8:9:10: 11: 12:13: 14:15: 16:17: 18: 19:20:21: 22: 23:24:25: 26: 27:28: 29:6.1procedureK ← Threshold value for size of results S ← size of results of U1d(Ui)← specificity degree of Ui.if S ≤ K thenoutput resultselseprompt the user with an open question to add more detailsif d (U2) == d(U1) then ◃ ensuring there is no loss of information for the user.output resultselseIdentify whether the user has moved hierarchically or non-hierarchically from U1 to U2if U1 → U2 ∈ Hierarchical then while Ui−1 → Ui ∈ Hierarchical   U1:Show all the restaurants in San Francisco. S1: Could you be little specific?U2: Show all the restaurants open till Midnight in San Francisco.S2: There seem to be many restaurants. You’d like to add anything?U3: Good ambience and 5 star rating.S3: Restaurant 1, Restaurant 2,...Restaurant nandS>K doprompt hierarchically S ← updateif S > K then while S > K doprompt non-S ← update output resultselseelse ◃IfU1 →U2 ∈ Non-hierarchicalwhile S > K doprompt non-hierarchically S ← updateoutput resultsendprocedurePrompting the user in Hierarchical Model hierarchicallyoutput results  If the list of hierarchical attributes are known to the sys- tem and the if the system identifies an interaction as hier-
 archical interaction, then the system can prompt the user with the appropriate attribute in the hierarchy. There are two ways to prompt a user in hierarchical model based on the number of attributes present in U1. They are:1. Single attribute: If there is only one attribute in a query, the system prompts the user according to the hier- archy of the attribute mentioned by the user in U1. Hi- erarchical list of attributes is maintained by the system separately.2. Multiple attributes: Here, the system starts prompting in a similar manner to single attribute type. Since there are more than one attributes, each having their own hierarchical list of attributes, the process is repeated for each attribute mentioned in U1. However, there is one constraint which the system follows in order to reduce the results quickly and effectively. A dialogue interaction can have more than one attribute values. Sometimes these attributes values may not be related to each other hierarchically. However, each attribute value can have its own hierarchy independent of the other other attribute value in the user system interaction. Figure 3 shows an example of such an interaction. Here, [cuisine, food] belong to one hierarchy and [California, San Diego, Eden street] belong to the second hierarchy. Note that in S2, instead of discussing further on hierarchy of food, the system prompts the user on the lines of the second hierarchy. It is important to maintain the balance between depths of different hierarchies in a interaction for two reasons. One, it becomes easier for the system to reduce the results in smaller number of steps and two, it is important that the system becomes specific in more than one way in order to benefit the user in terms of usefulness of the results.Figure 3: Example of user-system interaction with multiple hierarchical attributesWhen the system identifies a hierarchical model, it can prompt the user with attributes in the hierarchical list as discussed earlier. However, it is not necessary that the system should prompt with only one attribute in a prompt. The system can prompt with one or more than one at- tribute. We categorize system prompts based on the num- ber of attributes a system uses in a prompt. They are as follows:1. Strong prompt : If the system prompts a user with two or more than two attributes, the prompt is known asAlgorithm 2 Algorithm for prompting the user hier- archically 1: 2: 3: 4: 5: 6: 7: 8: 9:10:11: 12:13: 14:procedureK ← Threshold value for size of results S ← size of results of U1if S ≤ K thenoutput resultselsenum ← number of attributes in U1 if num = 1 thenpos ← position of attribute in U1 in its hierarchical chainlen ←length of hierarchical attribute chain to which attribute in Uwhile pos <len and S >K do prompt with attribute in the hier-archy chainpos ←pos + 1 S ← update◃ num > 1 prompt similar to single attribute butabs(pos(a1)−pos(a2)) is minimum end procedure15: else16: 17: a strong prompt.2. Moderate prompt : If the system prompts a user with only one attribute, the prompt is known as a moder- ate prompt.3. Weak prompt : If the system prompts the user without any prompt, then the prompt is known as a weak prompt. A weak prompt is more of a open question. Effect of a prompt on the reduction in the size of results: Strong prompt > Moderate prompt > Weak prompt. Depending on the following factors, the system prompts the user accordingly.a. Current results size: If the size of results is too large, then the system would preferably prompt strongly. If the size of results is not too high, the system would prompt moderately.b. Position of an attribute in its hierarchy: If the size of results is too high and the attribute in the current Ui is high in the hierarchy( that is, there are more attributes after the current attribute in the hierarchy or if the hierar- chical chain is too long), then the system would prompt the user strongly. This is an important part of a user- system interaction, as it helps in reducing the results in minimum number of steps according to various factors in the user-system interaction. If the results size is reduced with only one attribute, then the system will only prompt U1: List the restaurants in California.S1: Which cuisine are you looking for?U2: Italian Cuisine. Looking for good pasta. S2: Where do you live in California?U3: I live in Eden street, San Diego.S3: Restaurant 1, Restaurant 2...Restaurant n1
 moderately. The system limits itself to prompt at the most with two attributes. The system in no way tries to move along with the user towards his goal once the size of re- sults is less than the required threshold, K. The threshold K is discussed in section 8.In a non-hierarchical user-system interaction model, the system may need to prompt based on the various as- pects of the current goal presented by the user. The scope of new information is very vast and may vary from one user to other user. Currently, we do not address how the system can prompt a user non-hierarchically.When a user gives an input query, if the size of results is more than K, the system can prompt the user hierar- chically until the user moves non-hierarchically. Once the user is found to move non-hierarchically, the system can assume that the user has reached his goal and from there on prompt the user non-hierarchically until the size of results is less than K.7 Reducing results without prompting the userIn this section, we propose few heuristics which can be helpful in reducing the results without prompting a user. The heuristics are:1. Semantic knowledge Semantic knowledge helps the system in two ways. It helps in reducing the results without prompting the user and at the same time ,the sys- tem makes sure that these results are more relevant to the user. For example, in List some good restaurants, tokens like good imply that the attribute rating should be used. So, the system would now list restaurant whose rating is in the range 3-4 (out of 5). Here using the rating is help- ful in reducing the number of restaurants and at the same time it gives good restaurants. If the user had asked for the best restaurant, then the system gives the restaurant with maximum rating.2. Contextual knowledge Sometimes, it may not be clear for the system to choose an attribute for prompting the user. In such cases, the system tries to recognize the attribute which is frequently used by the user in the pre- ceding conversation. This information can also give the system an idea about user’s goal. Contextual knowledge helps in increasing the weights of the attributes, which is useful in database heuristics.3. Database Knowledge The system has to prompt the user with an attribute which gives minimum results. For this, the system follows a simple heuristic using the database.Attribute prompt=min{max(att[1]), max(att[2]), ..., max(att[n])}Here, att[1] is the number of results obtained for each value of attribute1. max(att[1]) is the worst case number of results obtained for choosing some value of attribute1.Algorithm 3 Algorithm for reducing size of results without prompting the user 1: 2: 3: 4: 5: 6: 7:8:9: 10: 11: 12: 13: 14: 15:16: 17:procedureK ← Threshold value for size of results S ← size of results of U1if S ≤ K thenoutput resultselseapply semantic knowledge or scaling of attributes if applicable to U1S ← updateif S ≤ K thenoutput resultselsewhile S > K docompute attribute prompt prompt with attribute prompt S ← updateoutput resultsendprocedure   n is the total number of attributes in the ER schema. Attribute prompt is the attribute the system uses to prompt the user. The system chooses an attribute having the minimum of all worst case number of results of all the attributes to present the minimum number of results to the user. But the above heuristic is not correct as the system is only looking to reduce the results without considering user’s requirement. Here, the output is solely dependent on the results stored in the database. To make the results more meaningful, system uses contextual knowledge. Thus, we modify the above heuristic using weights for each attribute. If an attribute is used by the user in the context of the current dialogue, weight of the attribute is increased by one. Initial weights of all the attributes are assumed to be one.Attribute prompt=min{w1*max(att[1]), w2*max(att[2]),..., wn*max(att[n])}4. Scaling of attribute values If the user asks for a good restaurant (rating between 3 and 4) and if there are too many restaurants in that range, then the system in- creases the rating to 3.5-4. That is, here the attribute value rating is scaled in order to decrease the size of results.   
8 Experiments and Discussions 8.1 Data and Experimental setupWe experiment our approach and heuristics on the REST- QUERY3 corpus which is a state-of-the-art corpus used for evaluating NLIDB systems. The total number of queries in the dataset was 251. We removed 83 queries from the above dataset. 39 of those queries had only one an- swer. An example of such query is How many bakeries are there in the Bay area ?. It can directly be seen that the answer for the above query would only be a num- ber. The size of results for such queries is only one and hence there is no scope for the system to reduce the size of results. The remaining 44 queries were found to have very low scope for reducing the size of results. An ex- ample of such a query is Give me the best bakery in Palo Alto ?. We repeated a few queries and also added un- specific queries as there were no unspecific queries in the standard dataset. The final size of the dataset was 300 queries. We conducted the experiment with 100 un- dergraduate CS students of our university. Each student was given 3 queries and was asked to make each query more specific by adding information. This was done un- der the assumption that there are large number of results for the given query which rightly serves the purpose of the experiment. This results in a dialogue process cover- ing topics like restaurants, locations, cuisines, restaurant timings etc,. We collected 300 dialogue processes. The users were prompted for a minimum of two times to add more information to the given query. The length of each dialogue process varied depending on the specificity of the given query.For each query, the system tries to reduce the results size using various heuristics. K is the threshold value of the size of results, based on which the system will decide whether it should try to reduce the size of results or not. We take K as the average number of results produced for a strongly specific query (with only two values) in the database. If the number of results is less than or equal to K, the system will not prompt the user. Therefore, the main aim of the system is to try and reduce the size of results to K or less than K. After a pilot set of experi- ments in the RESTQUERY dataset, we found that addition of even one or two values results in the size of results less than K. But this is not possible in large real time database systems. Hence, for the ease and betterment of the ex- perimentation we did not restrict users from adding more information.8.2 DiscussionsOut of the 300 dialogue processes, we found that 55.36% of the dialogue processes belonged to the Hierarchical3 http://www.cs.utexas.edu/users/ml/nldata.htmlmodel (more than we expected), 25.42% of the dialogue processes belonged to the Non-hierarchical model, 19.2% of the dialogue processes belonged to both hierarchical and non-hierarchical models. 15.53% (majority) out of the 19.2% processes see hierarchical followed by non- hierarchical. This shows that if a user has reached his goal and is still prompted to add new information, he moves non-hierarchically.We observe that whenever a user has already men- tioned his goal in the query (complete goal), the user in- teracts in a non-hierarchical manner. If a user has only partially mentioned his goal in the query (partial goal), then there is a possibility that a user can move towards his goal when prompted. In such cases, the user’s goal is definitely related to some of the attributes he has al- ready mentioned in previous queries. As all hierarchical attributes are related to each other in the context of a goal, we claim that when a user has not completely revealed his goal initially in an interaction, there is a possibility that the user may move hierarchically. It is also possible that when a system prompts a user regarding something, the user can actually make a new goal. In this case, the sys- tem should again prompt the user in a hierarchical fash- ion or in some manner in which attributes are related to each other. In our work, we only consider hierarchical relationships between attributes.We observed that length of dialogue process was higher when users were given unspecific or weakly spe- cific queries in comparison to strongly specific queries. Theoretically also, this is correct as the scope of adding more information increases with decrease in specificity of a query. However, this may not be true if a user starts a new goal.We applied the semantic knowledge heuristic to the RESTQUERY dataset. Semantic knowledge was found to be applicable for 40.47% of the queries in the dataset. The average size of the results size before applying se- mantic knowledge was found to be 196 and after apply- ing semantic knowledge the average results size was just 28. 16% of the 40.47% queries resulted in no results af- ter applying the semantic knowledge. 4% queries out of the 40.47% resulted in too many results even after apply- ing semantic knowledge. The semantic knowledge must make sure that some minimum number of results are re- turned and at the same time it has to make sure that not too many results are returned even after applying seman- tic heuristics. Such issues are handled by attribute value scaling. The attribute value scaling module tunes the se- mantic heuristics according to the size of the results. Se- mantic knowledge is generally very useful in the lesser specific queries.It is difficult for a user to express his goal with min- imal number of values. When the first user query(U1) is not strongly specific the results size is generally high. 
Thus, when the system prompts a user in case U1 is not strongly specific, it is very likely that the user will add values which make his goal more clear. Hence, the sys- tem always prompts the user hierarchically based on the attribute values in U1 during the initial stages of the dia- logue process. From the experiments, it shows that ma- jority of the users move hierarchically during the initial stages of the dialogue process. Hence the proposed ap- proach proves to be viable.9 Conclusion and Future WorkThis is a work in progress. We propose a system for re- ducing the size of results of a user query in NLIDB sys- tems. User queries are categorized based on number of values mentioned by a user. At a high level, we pro- pose two types of user-system interactions based on how a user interacts with the system. Depending on the model of user-system interaction, system prompts the user ac- cordingly, to reduce the size of results of a user query by making it more specific. User responses can be related in many ways. Our work focuses on user responses which are hierarchically related assuming that the user is mov- ing towards his goal. As our system is only concerned with the results of a NLIDB system, it can be coupled with any NLIDB system irrespective of the approach used in the NLIDB system. The generalized nature of the pro- posed user-system interaction models and the heuristics make the approach domain independent.We are currently working on non-hierarchical prompt- ing. There are two challenges in non-hierarchical prompting. One, the system should identify when a user is adding random information or information which is not related to previous user query. In other words, the sys- tem should be able to simultaneously address new goals (goal unrelated, as discussed in section 5) added by the user. The second challenge is, once the user completes his goal, when a user moves in a goal-related way, there is vastness in occurrence of new information. For example, consider List the restaurants in San Francisco. Assuming the user has mentioned his goal completely in the above query, lets say he would now move non-hierarchically in a goal-related way. Now the user can add new in- formation like: ”buffet restaurants, cost for two, ambi- ence, candle light dinner, open top restaurants, good mu- sic” etc. It is difficult to maintain such information in a database. However, we are trying to address such things using web sites like Zomato. In future, we would explore user-system interaction models in more detail. We would also work on computing the threshold value K in a more sophisticated manner which can be helpful in addressing the problem more effectively.ReferencesArjun R. Akula, Rajeev Sangal, Radhika Mamidi. 2013. A Novel Approach Towards Incorporating Context Processing Capabilities in NLIDB System. In Pro- ceedings of the International Joint Conference on Natural Language Processing (IJCNLP),pages 1216- 1222, Nagoya, Japan.Arjun R. Akula. 2015. A Novel Approach Towards Building a Generic, Portable and Contextual NLIDB System. International Institute of Information Tech- nology HyderabadIoannis Androutsopoulos, Graeme D. Ritchie, and Pe- ter Thanisch. 1995. Natural language interfaces to databases–an introduction. Natural language engi- neering,1(01), 29-81.Raffaella Bernardi and Manuel Kirschner. 2008. Context modeling for iqa: the role of tasks and entities. In Col- ing 2008: Proceedings of the workshop on Knowledge and Reasoning for Answering Questions, pages 25–32. Association for Computational Linguistics.Nuria Bertomeu, Hans Uszkoreit, Anette Frank, Han- sUlrich Krieger, and Brigitte Jorg. 2006. Contex- tual phenomena and thematic relations in database qa dialogues: results from a wizard-of-oz experiment. In Proceedings of the Interactive Question Answering Workshop at HLT-NAACL , pages 1-8 Association for Computational Linguistics.Joyce Y Chai and Rong Jin. 2004. Discourse struc- ture for context question answering. In Proceedings of the Workshop on Pragmatics of Question Answer- ing at HLT-NAACL, pages 23-30.Alessandra Giordani. 2008. Mapping Natural Language into SQL in a NLIDB. In Natural Language and In- formation Systems (pp. 367-371). Springer Berlin Hei- delbergAlessandra Giordani and Alessandro Moschitti. 2009. Syntactic structural kernels for natural language in- terfaces to databases. In Machine Learning and Knowledge Discovery in Databases, pages 391–406. Springer.Abhijeet Gupta, Arjun Akula, Deepak Malladi, Puneeth Kukkadapu, Vinay Ainavolu, and Rajeev Sangal. 2012. A novel approach towards building a portable nlidb system using the computational paninian gram- mar framework. In Asian Language Processing (IALP), 2012 International Conference on (pp. 93-96). IEEE.Catalina Hallett and David Hardcastle 2008. Towards a bootstrapping nlidb system In Natural Language and Information Systems, Springer, 2008, pp. 199-204.Aasish Pappu and Alexander I Rudnicky. 2014. Knowl- edge acquisition strategies for goal-oriented dialog
systems. In Proceedings of the 15th SIGDIAL Con-ference, pages 194-198.Ana-Maria Popescu, Oren Etzioni, and Henry Kautz.2003. Towards a theory of natural language interfaces to databases. In Proceedings of the 8th international conference on Intelligent user interfaces, pages 149- 157. ACM.Rodolfo A. Pazos Rangel , Alexander Gelbukh , J. Javier Gonza ́lez Barbosa , Erika Alarco ́n Ruiz , Alejandro Mendoza Mej ́ıa , and A. Patricia Dom ́ınguez Sa ́nchez 2002. Spanish Natural Language Interface for a Re- lational Database Querying System. In Sojka, P., Kopecˇek, I., Pala, K. (eds.) TSD 2002. LNCS (LNAI), vol. 2448, pp. 123-130. Springer, Heidelberg (2002) .