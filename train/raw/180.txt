 A Survey on Anaphora Resolution among Asian LanguagesAbstractAnaphora resolution identifies the relationship between two entities those refer to the same real world object. Almost all NLP applications such as machine translation, information extraction, automatic summarization, question answering and natural language generation requires successful identification and resolution of anaphora. Importance of this field in various regional languages is evident from numerous research results published recently in major journals and conferences. This article presents a comprehensive survey of approaches followed in various Asian languages including Arabic, Chinese, Hindi, Japanese, Tamil and Turkish, which covers the results of almost last twenty years of explore in this field. Various research issues faced including nature, special challenges, approaches selected, feature set, data sources and evaluation metrics of each language is discussed in detail. This aims to act as a preliminary aid for the beginners who delve into anaphora resolution for any non-English language.IntroductionOn one side this is a boon that human languages have evolved to include various shortcuts to refers the previously introduced entities in the discourse, on the other side this actually not a bane but really tough to teach computers the art of figuring, which short cut goes with which entity. Entities in natural language text are not identified with convenient unit ids, but rather with constantly changing descriptions.For an example,“David Ernest Duke (born July 1, 1950) is a former Grand Wizard of the Knights of the Ku Klux Klan an American activist and writer, and former Republican Louisiana State Representative. He was a candidate in the DemocraticDr. C. DeisyDept. Computer Science and Engineering Thiagarajar College of Engineering MaduraiIndia       cdcse@tce.edupresidential primaries in 1988 and the Republican presidential primaries in 1992.Duke has unsuccessfully run for the Louisiana State Senate, U.S. Senate, U.S. House of Representatives, and Governor of Louisiana.” [Pablon 2013].Here „David Emest Duke‟, „He‟ and „Duke‟ the three descriptions refer the same entity. It is essential to construct a system for automatic detection and collection of all textual descriptors that refer to the same entity within a co-reference chain either intra or inter documents. The problem of mapping linguistics expressions into these underlying entities is known as reference resolution. This can be used to find the complete information about an entity, even when referenced by a different name.Anaphora is the reference to an entity that has been previously introduced into the discourse. It describes an asymmetric relation between two linguistic expressions, an anaphor and an antecedent where, anaphor (He) is the referring expression and antecedent (David Emest Duke) is the one being referred [Denis 2007]. Both corefer each other. Anaphora expressions can be classified into two broad categories as nominal [Katja et al. 2003; Katja and Malvina 2005] and non-nominal anaphora. Reflexive (himself) [Sobha and Patnaik 1998; Petra et al. 2011; Li et al. 2010], pronoun (he, it) [Hobbs 1978; Bernan 1987; Mitkov 1998; Denis et al. 2007], definite (The book) [Vieira and Poesio 2000; Versley 2006; Naoyainoue et al. 2010] and demonstrative (That man) [Markert and Nissim 2005] are the subclasses of Nominal Anaphora and gapping(zero anaphora) [Yeh et al. 2004a and 2007; Seki et al. 2002; Iida et al. 2005; Chen and Yeh Chen 2005; Peng et al. 2009], temporal expressions and locative expressions are the subclasses of non-nominal anaphora. Most of the co reference research focus is done towards nominal anaphora as non-nominal anaphora is assumed to occur infrequently and comparatively resolving nominal anaphora has wider application   
 scope in many NLP tasks. But exceptionally possibility for the occurrence of zero anaphora is more in regional languages like Chinese [Yeh et al. 2004a and 2007; Chen and Yeh Chen 2005; Peng et al. 2009] and Japanese [Seki et al. 2002; Iida et al. 2005].For better understanding of the text, reference resolution is an unavoidable task to be accomplished. It plays a vital role in many NLP applications including information extraction [Wellner and McCallum 2004; Mykowiecka et al. 2009; Kameyama and Megumi 1997], question answering [Ahn et al. 2004; Lo and Lam 2006; Knott and Vlugter 2008], automatic summarization [Azzam et al. 1999; Bergler et al. 2003; Steinberger et al. 2007], Opinion Mining [Jakob et al. 2010], Topic identification [Chen and Yeh 2005], Machine Translation [Dutta et al. 2009] and natural language generation [Barzilay and Lapata 2006]. So reference resolution among various natural languages is another attention needed area for the NLP research community. This work has been initiated and achieved some encouraging results in various regional languages (apart from English) including Arabic [ Souha et al. 2009;Zitouni et al. 2009a, 2009b;Hammami et al. 2010], Chinese [Chen and Yi-Chun 2005; Peng et al. 2009; Wang et al. 2006; Yeh et al. 2004a, 2004b, 2007; Yeh and Ching-Long 1995; Li et al. 2010] , German [Hartrumpf 2001; Strube et al. 2002; Versley 2006; Klenner and Ailloud 2008], Hindi [Sobha 1999; Prasad and Strube 2000, 2003; Dutta et al. 2008, 2009, 2010, 2011; Triveni et al. 2012], Japanese[Murata and Nagao 1997; Seki et al. 2002; Sasano and Ryohei 2008; Naoya et al. 2010], Malayalam[Sobha and Patnaik 1998, 1999, 2002; Sobha 1999], Tamil [Narayana et al. 2007; Balaji et al. 2011; Akilandeswari et al. 2012] and Turkish [Tin and Akman 1992; Turan 1996; Kilicaslan et al. 2009]. This paper presents a shriveled view over the works that had been carried out for anaphora resolution among some of the Asian languages including Arabic, Chinese, Hindi, Japanese, Tamil and Turkish. A comprehensive view is provided that covers the additional challenges faced, PNG (Person, Number, Gender) agreement, list of additional features (apart from universal set of features) and data sources for each language with discussion about the methods and their results.This paper is organized as follows. Chapter 2 provides a overview of the area with definitions of important terms. Chapter 3 explains the three important approaches of anaphora resolution and common evaluation metrics. Chapter 4 surveys how these approaches are tuned to get adopted for some of the Asian languages. Chapter 5 describes some vital experimental aspects which were given additional care for each language. Finally the last chapter gives the summary of the article.ApproachesComputational approaches for reference resolution for the universal language, English has a quite long history since 1960. Based on the level of automation and resolution methods of various algorithms are classified under knowledge based, heuristic based and Machine learning based approaches. Figure 1 explains the hierarchical view of reference resolution algorithms of these approaches.Fig. 1. Hierarchical View of Reference Resolution Approaches.Knowledge based systemIn early days references were resolved by heuristic based approaches which need enormous knowledge about linguistic theory. Based on the linguistic knowledge best suitable antecedent is identified by reducing the size of antecedent set. These systems were developed from 60s through 80s with minimum amount of automation for the preprocessing steps. Most of such systems were originated a crowd of hand crafted rules to select the best suited antecedent for each anaphor. These constraints are described by various syntactic, semantic and pragmatic features. Hobbs et al. [1978] explained this approach by deepest-first search procedure on syntactic parse tree of a sentence to find the first candidate that satisfies a set of constraints and preferences. It makes use of 
 syntactic constraints while resolving pronouns. The search starts from the immediately dominating noun phrase of a pronoun.This approach can further be classified into three classes. First is the syntax based approach of Hobbs et al. [1976, 1978], that explains a Naïve algorithm for pronoun resolution. Here the constraints are derived by syntactic and morphological information. Though it showed a good performance up to 88%, its drawback is its need for the complete perfect parser, which is still a challenging task to achieve. Second one is the Discourse based approaches [Brennan et al. 1987, Grosz et al. 1995, Kehler [1997, 2002], Asher and Lascardies 2003 and Beaver 2004] are based on centering theory [Tetreault 2001] that model relationships among focus of attention, choice of referring expression and perceived coherence of utterances within a discourse. This approach focuses on the attention of the discourse participants. Third approach is a multi factor approach which is a mixture of previous two approaches. Here constraints and preferences are constructed based on the syntactic, semantic and pragmatic features [Carbonell and Brown 1988]. The main problem of this approach is recorded as, some conflicts between preferences are yet to be resolved. Building such system is difficult due to the need of strong linguistic knowledge and henceforth is expensive. And it is poor at portability to extend to other domains or languages.Heuristic Based ApproachesThe approaches of 90‟s that are capable of working with poor quality information with design simplicity and better robustness are also called as knowledge poor approaches. A salience based algorithm of Resolution Anaphora Procedure (RAP) was developed by Lappin and Leass [1994] to resolve third person pronouns. RAP algorithm operates based on salience measures derived from syntactic structure. To compute the salience measure this system needs a perfect morphological analyzer and a full syntactic parser. The system accuracy was recorded as 86%. Kennedy et al. [1996] proposed a extended RAP approach where the parse tree is substituted with a list of morphological features and the experimental result was about 75.4%. Baldwin [1997] uses noun phrase and clause chunking to determine mentionsby constructing high precision rules and uses shallow patterns to identify a small number of cases that can be reliably resolved. With hand annotated gender information Baldwin [1995] obtained 92% precision, at 60% recall for a corpus of three stories. Mitkov [1998] have proposed an approach used a wider list of different salience features that assign a score to antecedent candidates and subsequently select the highest scoring candidates. He evaluated his approach with a small corpus of technical manuals (223 pronouns) and achieved the performance as 89.7%.Machine Learning SystemsMore recently reference resolution research has given the focus towards the statistical and machine learning approaches due to their domain independence and extendibility to different languages. McCarthy and Lehnert [1995] developed the first machine learning approach, the Mention-Pair model based on decision tree algorithm trained with MUC-5 English Joint venture corpus on all possible pairs in the training set and showed a result better than the heuristic approaches. All possible markables in a training document are determined by a pipe-line of language processing modules, and training examples in the form of feature vectors are generated to appropriate pair of markables. These training examples are then given to a learning algorithm to build a classifier. For test document all markables are determined and potential pairs of coreferring markables are presented to the classifier, which decides whether the two markables actually corefer. This model was further extended with a set of twelve features by Soon et al. [2001], Ng and Carnie [2002] which is also a mention pair model that classifies whether two mentions are coreferent or not. Problem with their approach is its insufficient information to make an informed co-reference decision and each candidate antecedents is considered independently of the others. These models are called as single candidate model where a candidate is the antecedent of an anaphor. This only considers the candidates of an anaphor in isolation, which is incapable of effectively capturing the preference relation between candidates for its training.Next is twin candidate model [Connolly et al. 1997; Iida et al.2005; Luo. 2007] recast anaphora resolution as preference classification problem that
 determines the preference between two competing candidates for the antecedent of a given anaphor. That is positive and negative instances are created which makes the training even better. Denis and Balridge [2008] proposed a ranking model where the candidates are ordered based on their preference and the best one is the antecedent.Luo and Zitouni [2004] and Yang et al. [2008] explained entity mention model with improved expressiveness, that identifies whether a mention and a preceding possibly partially formed cluster are coreferent or not. This allows computation of cluster level features. Drawback of this system is each candidate cluster is considered independently of the others. Dennis and Baldridge [2007, 2008] proposed a Mention ranking model that imposes a ranking on a set of candidate antecedents. Parallelism is its strength, i.e. this considers all the candidate antecedents simultaneously. Main problem of such models is it has insufficient information to make an informed co-reference decision. Clustering based (unsupervised) approaches are selected because they take a more global view of constructing co-reference chains and are based either on constraint propagation [Klenner et al. 2008] or on probabilistic approach [ Kehler 1997; Culotta et al. 2007].Anaphora Resolution in Different LanguagesCo-reference resolution(CRR) has a quite long history for English documents. Other than English automation of CRR still has a long way to reach. Still some noteworthy approaches have been found for the languages like Spanish, Japanese, French and German. Though there are number of effective algorithms developed for co-reference resolution of the Universal language English, those systems cannot be applied directly over the regional languages due to various reasons. For an example in English number agreement can be detected through word inflection and part-of-speech tags. In the same way it is also possible in many Indo- European languages like Tamil. But there is no such simple rule in Chinese to distinguish whether a word is singular or plural. Proper names and abbreviations are identified by capitalization [Vieira and Poesio 1997, 2000] in English. But many of the Asian languages do not use capitalization. Word segmentation itself is a crucial problem in Chinese. For the past two decades thesealgorithms have been altered to get adopted for other regional languages including Japanese, Chinese, Arabic, Turkish, Spanish, Polish, etc. This paper is an attempt to survey the various algorithmic details of reference resolution for Asian languages. So that it may act as a preliminary aid to the researchers who are interested in developing a reference resolution system for any non- English language. Electronically-available resourcesArabicArabic has a complex and unusual morphology. As Arabic is highly inflected by its morphology, an important preprocessing step is segmentation because partial parts of the sentences are the mentions and is being segmented by WFST(Weighted Finite State Transducers) [Zitouni 2009a, 2009b]. Nouns in Literary Arabic have three grammatical cases (nominative, accusative, and genitive), three numbers(singular, dual and plural),two genders(masculine and feminine) and three states (indefinite, definite and construct). Pronouns in Literary Arabic are marked for person, number and gender. Zitouni and Florian [2009b] proposed a propagation approach for mention detection in low, medium or high resource languages that benefits from projecting the output of a system trained in a resource-rich language, such as English. It is possible to lend training data available in one resource-rich language (English) to another resource-poor language (Arabic) to build decently performing baseline mention detection system. This approach needs a mention detection system of resource-rich language and a machine translation system, both of which can be readily attained. As per the experiment done on ACE 2007 datasets among the four languages Arabic, Chinese, English and Spanish and according to the results, English is selected as the resource rich language. The main advantage is that the Arabic mention detection system is trained without the training data of Arabic.Zitouni et al. [2009a) have worked on the mention detection and chaining of Arabic co- references by the construction of statistical model based on maximum entropy. Bell tree [Luo 2004] is the approach selected for linking the mentions. It represents the search space of the co-reference resolution problem where each leaf node corresponds to a possible co-reference outcome.
 The two Bell tree models developed are linking and starting model and maximum entropy linking model. A binary entropy model is trained to compute the linking probability between a partial entity and a mention.Souha et al. [2009] proposed an anaphoric annotating tool for Arabic which aims to build a real corpus which will be used for anaphora resolution (i.e., either for system training or evaluation). Their system detects the Arabic pronouns automatically and allows the human annotator to select several anaphoric pronouns related to the same antecedent. The types of pronouns dealt are pronominal anaphora, lexical anaphora, comparative anaphora and verb anaphora.ChineseLack of morphological and orthographic clues makes the construction of Chinese co-reference resolution system difficult. Since Chinese has no inflection, conjugation, or case markers, the pronominal system is relatively simple. A third person pronoun can be used to replace and intersentential ZA (Zero Anaphora), except for first- and second- person pronouns, without changing the meaning of the sentence. Yeh [1995] presented a anaphora generating system. Yeh and Chen [2004a] proposed a anaphora resolution system by making use of a shallow parser. Chen [2009] developed the two-phase (occurrence detection, antecedent detection) model of zero anaphora resolution. Chinese linguistic knowledge is used for occurrence detection and centering model of local discourse were adopted for opt selection of the antecedent. Experiments were done for newspaper articles and showed precision rate of phase-I is 84% and recall rate of phase-II is 70%. Wang et al. [2006] proposed unsupervised approach for co-reference resolution. The system was evaluated on an annotated corpus TDT3 using MUC-7 scorer. Centering theory and constraint based approach of zero anaphora resolution in subject and object position was proposed by Yeh and Chen [2007]. This was evaluated with precision rate of 81% and recall rate of 70%. Peng and Araki [2009] proposed a learning classifier based on maximum entropy. Apart from the regular features (grammatical, lexical, positional and semantic) two more new features SEM-CONSI and SEM-RELA were introduced to extractadditional semantic information from web. SEM- CONSI is the rank of the semantic consistency of antecedent candidates. SEM-RELA is the semantic relations between the heads of the predicates in sentences containing ZA and antecedent candidates. This is obtained by querying the web using some patterns. An application of Chinese anaphora system topic identification was presented by Yeh and Chen [2004b].JapaneseF A convenient point with Japanese is there is a strict word order that a verb must be placed at the end of the sentence. As the basic structure is topic- comment, the topic of the sentence can easily be identified. An important critic in Japanese is that nouns have no grammatical number, gender or article aspect. Japanese pronouns can take modifiers as any other noun may. Here, pronouns are not used much; most anaphors are represented by proper noun phrases or common noun phrases or omitted phrases (zero anaphora). Murata and Nagao [1997] proposed a rule based reference resolution approach for determining the referents of noun phrases by using referential properties, modifiers and possessors and showed the experiment results with 78.7% of precision and 77.3% of recall for a corpus of Fairy tales. The famous machine learning approach was proposed by Iida et al. [2005] which is similar to the ML approach of Ng and Cardie. Here the experiments are done over a corpus of news paper articles and obtained results with 76.7% precision and 65.9% recallrates.Sasano [2008] presented a knowledge rich approach to Japanese co-reference resolution system. He has addressed proper noun co-reference and common noun co-reference by acquiring knowledge from large raw corpus and dictionary definition sentences. Articles play a major role in anaphoricity determination with the feature definite noun phrase and definite pronoun. But Japanese language has no articles. They designed a approach that uses information extraction patterns to identify contextual roles Bean and Riloff [2004]using supervised learning. This contextual knowledge improved co-reference performance for pronouns (not for noun phrases).Japanese is a language where arbitrary verb arguments may be realized as a zero pronoun (omitted pronoun) and the detection of zeroes is as
 challenging as their resolution. Seki et al. [2002] proposed a approach where the non-filled argument slot is filled by a zero pronoun by constructing preferences which are extracted from a large unannotated corpus by noting the co- occurrence of overt NPs. Their model is constructed based on probabilistic theory. Iida et al. [2003a, 2003b] presented a tournament model and a centering theory based salience model for zero anaphora resolution. Iida et al. [2005] developed classification-then-search model for noun-phrase resolution which inherits all the advantages of Ng and Cardie (2002). This model uses nonanaphoric occurrences along with anaphoric occurrences to build an anaphoricity classifier and determines the anaphoricity of a given NP taking the information of its most likely candidate antecedent into account. Iida et al. [2007] dealt the zero anaphora resolution as two subtask: intrasentential and intersentential. Here the syntactic patterns of the zero pronouns and their antecedents are the useful clues for intrasentential zero anaphora resolution. Each subtask is handled by selection-then-classification of Iida et al. [2005]. Experiments were done over NAIST text corpus developed by Iida et al. [2007]. Naoya et al. [2010] concentrated only on the definite pronouns of Japanese and showed an encouraging results.TurkishF Turkish is also a morphologically rich language. Special attention is needed as Turkish has no noun classes or grammatical gender. It is gender neutral by both pronouns and names. Turkish pronoun types are personal with six cases(absolute, accusative, dative, locative, ablative and genitive), demonstrative, interrogative, relative and reflexive pronouns. Probably the first contextual information based anaphora resolution system for Turkish was proposed by Tin and Akman[1992, 1994], offered a computation framework where the information oriented features of situation theory were used for resolving pronominal anaphora. Turan [1996] proposed a discourse level anaphoric relations system for Turkish by following the centering theory [Grosz et al. 1995].Kilicaslan et al. [2008] developed a learning model for pronoun resolution in Turkish and evaluated the classification performance of the learning models( NaiveBayes ,SVM, neural network and K-nearest classifiers) and shown that non-linear models behaves better. As Turkish frequently employed null pronouns and relatively less informative open pronouns, make reference resolution system of Turkish is more challenging than English. This system addresses four types of open pronouns namely personal, locative, reflexive and reciprocal. As there is no annotated corpus available for Turkish 20 different child stories (with 1149 pronouns – includes all the 4 types) were made involved in the experimentation and obtained the f-measure results from 64% to 74%. able 1: Font guideIndian LanguagesComputational models of anaphora resolution for many Indian languages like Bengali, Hindi, Malayalam, Sanskrit, Tamil and Telugu have almost fifteen years of history. Sobha and Patnaik [1998, 1999a] proposed algorithms for Malayalam Anaphora resolution. Sobha. and Patnaik [1999b] developed a multilingual [Luo 2005] system called VASITH for resolving anaphora in two different Indian languages, Malayalam and Hindi. Computational grammars of these two languages were explained in detail and syntactic rules have been formed to develop the rule based system. A major limitation of this system was that it uses only the syntactic knowledge and there was no incorporation of semantic or any form of real world knowledge. With a very short discourse the system showed success rate up to 96%. Most systems were developed on based syntactic nature of the language. In recent days semantic knowledge incorporated systems are started developing. Languages in India belong to two different categories Indo-Aryan and Indo Dravidian. In this paper for each category one language is selected (Hindi and Tamil) for surveying.1.1.1 HindiHindi has rich case system, though case marking is not obligatory. Pronouns are unmarked for gender and only partially marked for number. i.e., Hindi pronouns in first, second and third person do not have gender information. But the clue is in the verbal structure of the language. i.e., Hindi has verb agreement with the subject or the direct object. The agreement inflection is marked for person, number and gender. Rashmi and Michael
 [2000] proposed a system that interprets third personal pronouns to realize anaphoric relationships between noun phrases. This work followed two methodologies namely centering theory for mention detection and ranking model to resolve the mentions that are pronouns. This approach is experimented with two algorithms namely, BFP algorithm [Brennan et al. 1987] and S-list algorithm [Strube 1998] and justified a encouraging result. (comparing with a straightforward system-only centering theory and no ranking model).Sobha and Patnaik [2002] proposed a rule based approach of Hindi anaphora resolution system. Prasad and Strube [2000, 2003] are based on centering theory and salience factors were handled based on the grammatical nature of the language. The baseline system of pronominal (reflexive and possessive) resolution system for Hindi based on Hobb‟s algorithm was developed by Kamlesh et al. [2008]. The article of Triveni et al. [2012] describes the various issues and challenges involved with Hindi anaphora resolution system and surveyed various works addressing them. They mentioned the major issues as the need of an annotated corpus and need of grammatical structure to resolve ambiguity in gender identification. A comparative study with result analysis has been done on various approaches of anaphora resolution.1.1.2 TamilLike other Indo-Dravidian languages Tamil agglutinative language. Tamil words consist of a lexical root with one or more affixes attached. Most of the time by analyzing the morphemes of a noun phrase (NP) person, number, gender and many like agreement features can be identified. Tamil does not have a definite article. So the feature, definite pronoun agreement between the anaphor and antecedent can never be identified. Tamil has person, number and gender agreement. Murthi et al.[2007] proposed a salience measure approach and machine learning based algorithm for pronominal resolution in Tamil. This paper introduces a set of fine tuned salience factors and weights that more suitable for the relatively free word order languages. The system if experimented with a corpus from CIIL ( Central Institute of Indian Languages, Mysore, India) and got 86.32% of precision and 80.9% of recall rates forvarious cases of nominative, accusative, genitive, dative, locative and instrumental. Akilandeswari et al.[2012] proposed a machine learning system for the most common pronominals of Tamil discourse- avan, aval, athu and its suffixes. The five categories of features were word, POS, chunk, syntactic information, clause and NER information. These features were utilized to develop the system using conditional random field (CRF) model. The system was tested with a tourism domain data of 10000 sentences and showed encouraging results. An approach to resolve anaphors of persons, places, plurals and events in Tamil text was proposed by Balaji et al. [2012]. Most of the previous approaches were based on syntactic knowledge of the language, here is an approach that incorporates semantic information (by using Universal Networking Language) also. Their triggering tuple approach works with reduction of ambiguity while resolving. This system is evaluated with a corpus from tourism and news domain and achieved 84% accuracy and is compared with the previous rule based system.Experimental AspectsHere the language dependent additional issues and the tackling actions taken while implementing the systems were explained.General AlgorithmWhichever may be the language and whatever may be the approach selected, the outline or order of the steps remains almost the same [Denis 2007]. The way these steps are being carried out depends on the methodology and nature of the language. Keeping that in mind the simplified version of the general algorithm is presented in figure 2. Fig. 2. Architectural modules of anaphora resolution.
 Mention DetectionA series of preprocessing steps need to be taken to identity the exact list of mentions (for step 1 in generic algorithm). Common list of preprocessing that found in most of the papers are tokenization, segmentation, morphological processing, POS tagging, Noun Phrase identification, named entity recognition, nested noun phrase extraction semantic class determination [Soon et al. 2001]. Depending on the nature of a language mention detection may need additional actions. For Arabic text segmentation is an important step which is must in order to detect partial parts of a word as a mention. Most of the regional languages suffer from no capitalization, free word order, heavy conjugation, omitted pronouns etc. Special attention has to be given to handle these issues to resolve anaphors efficiently. Table 2 explains the special challenges that met in processing a regional language.Person, number and gender (PNG) agreement between the anaphora and antecedent are some of the important features to be analyzed. This task can directly be identified in some languages like Tamil (noun phrases are the indicators), in languages like Hindi verbal structures need to be analyzed and for languages like Japanese it is even more difficult, need for context based analysis. Table 3. explains the summary of PNG agreement analysis of theselanguages is explained.Table 3. PNG Agreement in Regional Languages     TableLanguag eArabicChineseHindiJapaneseTamilTurkish2. Specific Challenges met for Different LanguagesLanguage ArabicChineseHindi JapaneseTamil TurkishP-agreeNP analysisNP analysisNP analysis NP AnalysisNP analysis NP analysisN-agree G-agree NP analysis NPanalysisNP analysis NP analysisNP&VP analysis VP analysisNP analysis Context basedanalysisNP analysis NP analysisNP analysis Semantic analysis      Challenge/Complicatio nmorphological richnessmention as partial part of a wordlack of morphologic clueslack of orthographic cluesno case markersAmbiguity in gender identification Partially marked numbersPoor grammatical support for gender, number, article determinationAmbiguity at morphological level Ambiguity at semantic levelPartial free word ordermorphological richnessnull pronouns-more commonTackling Steps Segmentation character by character analyzationSemantic class determinationanalyzing verb/auxiliary verb phrase conjugationDictionary definition Context based analysis Morphologica l analysisExtracting semantical featuressyntactic structure study semantic discourse knowledgeReferenceImed et al.[2009]Peng and Araki[2009]Kamlesh et al. [2008] Triveni et al. [2012]Sasano [2008]Akilandeswar i et al. [2012] Balaji et al. [2011]Kilicaslan et al. [2009]P - Person N - Number G – Gender   Feature SetThere are some 8 [McCarthy and Lehnert, 1995] to 66 [Aone and Bennet,1995] features may be listed for better handling of anaphors. The most common categories of features are grammatical, lexical, positional and semantic classes[Kilicaslan 2009] which are called as universal set of features. Table 4 lists universal features between the anaphora and antecedent candidates that may be found in most of the papers. Feature Case agreementGrammati cal role Overtness Type Semantic type Person agreement Number agreement Gender agreement PositionTable 4. Universal Set of FeaturesDefinitionBoth nominative/accusative/dative/locative/genitive/ablative/i nstrumentalEither is a subject or objectOpen or zero pronounPronoun is personal/locative/reflexive/reciprocal Referent of a antecedent is animal/human being/a place/an abstract obhect/physical objectBoth first/second/thirdBoth with singular/plural Both male/female/neutral Distance between these two    
     There may be a slight variation in the selection feature set for a particular language depending on its grammatical support. For example in the languages like Hindi and Japanese there is really poor support for direct identification gender and number information. To identify this information in Hindi verbal structure is used and in Japanese semantic features is incorporated. Likewise figure 3 explains the recommended set of additional features for each language.Fig. 3. Special List of Features for each LanguageData SourcesAs most recent resolution approaches are based on machine learning methods, there is an extensive emerge for train and test data. And it is also important to work with the standard corpora so that the approach can be evaluated (correctness measure) and compared better. While English and many European language corpora have been created and made available recently, the number of publicly available Asian language corpora is very limited. Mitkov [2010] have listed the five issues that are being faced by anaphora resolving systems. One of the major issues is about corpus annotation. Most of the time evaluation is conducted against a corpus which is annotated by humans. Therefore reliable annotation is very important. In contrast to the wide variety of languages in Asia, the number of publicly available Asian language corpora is very limited. This situation needs to be improved. Table 5 explains the various referentially annotated corpora in different languages.ChineseJapaneseHindi, Tamil, TurkishOntoNotes 3.0ACE-2005 OntoNotes 3.0NAIST Text Corpus(so far) No public annotated Corpus200K words200K words 1224K words38K sentencesAuthors used different corpus of various sizesal.[2006] Weischedel et al.[2008]Walker et al.[2006] Weischedel et al.[2008]Iida et al. [2007] -     Table 5. Annotated CorpusLanguage Corpora Size (~) Arabic ACE-2005 100K wordsAnaphora resolution is an must focus topic for any regional language processing research groups as it has great scope in almost all natural language understanding applications. This offers an inclusive outlook of the last twenty years of focus on the computational dealing of anaphora resolution among various Asian languages (Arabic, Chinese, Hindi, Japanese, Tamil and Turkish) for the factors including additional challenges (nature of language), algorithms selected, features involved, corpus or dataset for evaluation and acquired results. No capitalization, morphological richness, free word order, semantic focus and heavy conjugations are some of the identified issues and were needed additional processing to resolve anaphors. Comparison among the results could not be evaluated properly due to the lack of corpus development. There are many more open issues are still need to be resolved effectively depending on the nature of a language, not only for anaphora resolution and also for the supporting tasks (POS tagger, Named entity recognizer) and corpus development.ReferencesA. KNOTT, P. VLUGTE. 2008. Multi-agent human–machine dialogue: issues in dialogue management and referring expression semantics. Artificial Intelligence. 172. 69–102.AHN, KISUH, JOHAN BOS, JAMES R. CURRAN, DAVE KOR, MALVINA NISSIM, BONNIE WEBBER. 2005. Question answering with QED at TREC-2005. In Proceedings of the Fourteenth Text REtrieval Conference, Gaithersburg, Md., 15–18 November.AKILANDESWARI, A AND SOBHA, LALITHA DEVI. 2012. Resolution for Pronouns in Tamil Using CRF. Proceedings of the Workshop on Machine Translation and Parsing in Indian Languages (MTPIL-2012), COLING 2012, Mumbai, December 2012. pages 103–112,Conclusions     Reference Walker et     
 AONE, C. AND BENNET, S.W.. 1995. Evaluating automated and manual acquisition of anaphora resolution rules. In Proceedings of ACL’ 95. PP 122-129.ASHER. NICHOLAS AND LASCARIDES. ALEX. 2003. Logics of Conversation. Cambridge University Press, Cambridge, UK.AZZAM. S, K. HUMPHREYS, R. GAIZAUSKAS. 1999. Using co- reference chains for text summarization. In Proceedings of the ACL Workshop on Co-reference and its Applications, College Park, MD.B. WELLNER, A. MCCALLUM, F. PENG, M. HAY. 2004. An integrated, conditional model of information extraction and co- reference with application to citation matching. In AUAI ’04: Proceedings of the 20th conference on Uncertainty in artificial intelligence, pages 593–601, Arlington, Virginia, United States. AUAI Press.BALAJI J, T V GEETHA, RANJANI PARTHASARATHI, MADHAN KARKY. 2011. Anaphora Resolution in Tamil using Universal Networking Language. IICAI 2011.1405-1415.BALAJI J, T V GEETHA, RANJANI PARTHASARATHI, MADHAN KARKY. 2012. Two-Stage Bootstrapping for Anaphora Resolution. Proceedings of COLING 2012: Posters, COLING 2012, Mumbai, December 2012. pages 507–516,BALDWIN, B. 1995. Cogniac: A discourse processing engine. Doctoral Dissertation, University of Pennsylvania.BARZILAY REGINA, LAPATA MIRELLA. 2006. Aggregation via set partitioning for natural language generation. In HLT-NAACL- 06, pages 359–366, New York City, USA.BEAN, D. AND E. RILOFF. 2004. Unsupervised learning of contextual role knowledge for co-reference resolution. In Proc. of NAACL.BEAN, DAVID AND ELLEN RILOFF. 1999. Corpus-based identification of non-anaphoric noun phrases. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, College Park, Md., 20–26 June.BEAVER. DAVID. 2004. The optimization of discourse anaphora. Linguistics and Philosophy. 27(1).BERGLER S. et al. 2003. Using Knowledge-poor Co-reference Resolution for Text Summarization. In Proceedings of Document Understanding Conference. May 31-June 1, NIST, USA, 85-92.BRENNAN, S.E., M.W. FRIEDMAN, AND C.J. POLLARD. 1987. A centering approach to pronouns. In Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics, Stanford, Cal., 6–9 July, pages 155–162.CARBONELL, JAIME G. AND BROWN, RALF D. Anaphora resolution: a multi-strategy approach. Proceedings of COLING, pages 96–101, 1988.CHEN. YI-CHUN. 2005. Chinese Zero Anaphora Resolution and Its Applications, Ph.D. Dissertation, Tatung University.CONNOLLY. DENNIS, BURGER. JOHN D. AND DAY. DAVID S. 1997. A machine learning approach to anaphoric reference. In D. B. Jones and H. L. Somers, editors, New Methods in Language Processing, pages 133–153. UCL Press.CULOTTA, ARON, MICHAEL WICK, AND ANDREW MCCALLUM. 2007. First-order probabilistic models for co- reference resolution. In Proceedings of Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics, Rochester, N.Y., 22–27 April, pages 81–88.DENIS P, BALDRIDGE J. 2008.Specialized models and ranking for co-reference resolution. In: Proceedings of the 2008 conference on empirical methods in natural language processing. Honolulu (HI): Association for Computational Linguistics. p. 660–9.DENIS, PASCAL AND JASON BALDRIDGE. 2007. A ranking approach to pronoun resolution. In Proceedings of the 20th International Joint Conference on Artificial Intelligence, Hyderabad, India, 6–12 January, pages 1588–1593.DENIS, PASCAL. 2007. New learning Models for Robust Reference Resolution. Doctoral Dissertation. University of Texas at Austin.DUTTA KAMLESH, NUPUR PRAKASH, AND SAROJ KAUSHIK. 2008. Resolving Pronominal Anaphora in Hindi using Hobbs‟Algorithm. Web Journal of Formal Computation and CognitiveLinguistics. Vol. 1. No. 10.DUTTA. K, PRAKASH. N, KAUSHIK. S. 2009. Application ofPronominal Divergence and Anaphora Resolution in English- Hindi Machine Translation. Research journal "POLIBITS" Computer Science and Computer Engineering with Applications, Issue 39, pp-55-58, 2009.DUTTA. K, PRAKASH. N, KAUSHIK. S. 2010. Probabilistic Neural Network Approach to the Classification of Demonstrative Pronouns for Indirect Anaphora in Hindi. Expert Systems with Applications: An International Journal, Volume 37, Issue 8, pp. 5607-5613, Elsevier.DUTTA. K, PRAKASH. N, KAUSHIK. S. 2011. Machine Learning Approach for the Classification of Demonstrative Pronouns for Indirect Anaphora in Hindi News Items. Prague Bulletin of Mathematical Linguistics. Versita, Vol. 95, pp. 33-50.GOOCH. P, A. ROUDSARI. 2012. Lexical patterns, features and knowledge resources for co-reference resolution in clinical notes. Journal of Biomedical Informatics. 45 901–912.GROSZ, B. J., JOSHI, A. K., AND WEINSTEIN, S. 1995. Centering: A framework for modeling the local coherence of discourse. Computa. Linguist., 21, 2, 203–226.HAMMAMI, S.M., SALLEMI, R., BELGUITH, L.H.: A BAYESIAN. 2010. classifier for the identification of non- referential pronouns in Arabic. In: INFOS, Special Track On Natural Language Processing and Knowledge Mining.HARTRUMPF, SVEN. 2001. Co-reference resolution with syntactico-semantic rules and corpus statistics. In Proceedings of the 3rd Conference on Computational Natural Language Learning, Toulouse, France, 6–7 July, pages 137–144.HIRST, G. 1981. Anaphora in Natural Language Understanding: A Survey. Lecture Notes in Computer Science 119. Berlin: Springer- Verlag.HOBBS JERRY. 1976. Pronoun resolution. Technical report. CUNY. HOBBS JERRY. 1978. Resolving pronoun references. Lingua. 44:339–352.HOBBS JERRY. 1979. Coherence and co-reference. Technical report. SRI International.HOBBS, J. 1978. Resolving pronoun references. Lingua 44, 311–338. IIDA, R., INUI, K., AND MATSUMOTO, Y. 2005. Anaphora Resolution by Antecedent Identification Followed by Anaphoricity Determination. ACM Trans. Asian Lang. Inf.Process. 4, 4, (December 2005), 18 pages-417-434.IIDA, R., INUI, K., AND MATSUMOTO, Y. 2007. Zero-anaphora resolution by learning rich syntactic pattern features. ACM Trans. Asian Lang. Inf. Process. 6, 4, Article 12 (December 2007), 22 pages. DOI = 10.1145/1316457.1316458.http://doi.acm.org/10.1145/1316457.1316458.IIDA, R., K. INUI, H. TAKAMURA, AND Y. MATSUMOTO.2003a. Incorporating contextual cues in trainable models for co- reference resolution. In Proc. EACL Workshop on the Computational Treatment of Anaphora.IIDA, RYU, KENTARO INUI, HIROYA TAKAMURA, AND YUJI MATSUMOTO. 2003b. Incorporating contextual cues in trainable models for co-reference resolution. In R. Dale, K. van Dempter, and R. Mitkov, eds., Proceedings of the EACL-03 Workshop on the Computational Treatment of Anaphora. Budapest.JAKOB, NIKLAS, IRYNA GUREVYCH. 2010. Using anaphora resolution to improve opinion target identification in movie reviews. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, Uppsala, Sweden, 11– 16 July, pages 263–268.KAMEYAMA, MEGUMI. 1997. Recognizing referential links: An information extraction perspective. In Proceedings of the ACL- Workshop on Operational Factors in Practical, Robust Anaphora Resolution for Unrestricted Texts, pages 46–53, Madrid.KAMP, H. 1979. Events, instant and temporal reference. In Semantics from Different Points of View . Springer-Verlag, pages 376–417.KEHLER ANDREW. 1997. Probabilistic co-reference in information extraction. In Proceedings EMNLP-97. pages 163–173. 
 KEHLER ANDREW. 2002. Coherence, Reference, and the Theory of Grammar. CSLI.KEHLER, ANDREW, LAURA KERTZ, HANNAH ROHDE, ANDJEFFREY ELMAN. 2008. Coherence and co-reference revisited.Journal of Semantics. 25(1):1–44.KENNEDY, CHRISTOPHER AND BRANIMIR BOGURAEV.1996. Anaphora for everyone: Pronominal anaphora resolution without a parser. In Proceedings of the 16th International Conference on Computational Linguistics, Copenhagen. Denmark, 5–9 August, vol. 1, pages 113–118.KILICASLAN YILMAZ, EDIP SERDER GUNER, SAVAS Y1LD1R1M. 2009. Learning-based pronoun resolution for Turkish with a comparative evaluation, Computer Speech and Language. 23. 311–331.KLENNER, MANFRED ETIENNE AILLOUD. 2008. Enhancing co- reference clustering. In Second Bergen Workshop on Anaphora Resolution (WAR II).KLENNER, MANFRED AND  ́ ETIENNE AILLOUD. 2008. Enhancing co-reference clustering. In Second sBergen Workshop on Anaphora Resolution (WAR II).LAPPIN, S. AND LEASS, H. J. 1994. An algorithm for pronominal anaphora resolution. Computa. Linguist. 20, 4, 535–561.LI, X.Q., ZHOU, X.L.2010. Who is Ziji? ERP Responses to the Chinese Reflexive Pronoun During Sentence Comprehension. Brain Research 1331, 96–104.LO, KA KAN, WAI LAM. 2006. Using semantic relations with world knowledge for question answering. In Proceedings of the Fifteenth Text REtrieval Conference, Gaithersburg, Md., 14–17 November.LUO, X. AND ZITOUNI, I. 2005. Multi-lingual co-reference resolution with syntactic features. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing. 660–667.LUO. XIAOQIANG, ITTYCHERIAH. ABE, JING. HOGYAN, KAMBHATLA. NANDA, AND ROUKOS. SALIM. 2004. A mention-synchronous co-reference resolution algorithm based on the bell tree. In Proceedings of ACL 2004. pages 135–142. Barcelona, Spain.LUO. XIAOQIANG. 2007. Co-reference or not: a twin model for co- reference resolution. In Proceedings of HLT-NAACL 2007. pages 73–80. Rochester, NY.MARKERT, KATJA, NISSIM MALVINA, NATALIA N. MODJESKA. 2003. Using the Web for nominal anaphora resolution. In Proceedings of the EACL Workshop on the Computational Treatment of Anaphora, pages 39–46, Budapest.MARKERT, KATJA, NISSIM MALVINA. 2005. Comparing Knowledge Sources for Nominal Anaphora Resolution. Association for Computational Linguistics, Volume 31, Number 3, 367-402.MCCARTHY, J. F. AND LEHNERT, W. G. 1995. Using decision trees for co-reference resolution. In Proceedings of the 14th International Joint Conference on Artificial Intelligence (IJCAI). 1050–1055.MITKOV, R. 2010. Outstanding issues in anaphora resolution. In Al. Gelbukh (Ed.). Computational Linguistics and Intelligent Text Processing, 110-125. Springer (keynote speech).MITKOV. RUSLAN. 1998. Robust pronoun resolution with limited knowledge. In Proceedings of COLING-ACL. pages 869–875. MURATA, M. AND NAGAO, M. 1997. Resolution of verb ellipsis inJapanese sentences using surface expressions and examples. InProceedings of 4th Natural Language Processing Pacific RimSymposium. 75–80.MYKOWIECKA AGNIESZKA, MAŁGORZATA MARCINIAK,ANNA KUPS ́C. 2009. Rule-based information extraction from patients‟ clinical data. Journal of Biomedical Informatics. 42 923–936.NAOYA INOUE, R., INUI, K., AND MATSUMOTO, Y. 2010. Resolving Direct and Indirect Anaphora for Japanese Definite Anaphora Pronouns . Journal of Natural Language processing.vol. 17 No. 1 (January 2010), 26 pages.NARAYANA MURTHI, K.N, SOBHA, L, MUTHUKUMARI, B. 2007. Pronominal Resolution in Tamil Using Machine Learning Approach. The First Workshop on Anaphora Resolution (WAR I),Ed Christer Johansson, Cambridge Scholars Publishing, 15 Angerton Gardens, Newcastle, NE5 2JA, UK pp.39-50NG, V. AND CARDIE, C. 2002. Improving machine learning approaches to co-reference resolution. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL). 104–111.PABLO N. MENDES. 2013. DBpedia People‟s Grammatical Genders. http://dbpedia.org/Datasets/NLP.PENG, JING AND ARAKI, KENJI. 2007. Zero-Anaphora Resolution in Chinese Using Maximum Entropy. IEICE Trans. INF. & SYST. VOL. E90-D.No.7.POESIO. MASSIMO, PAOLO. SIMONE PONZETTO, VERSLEY YANNICK. 2010. Computational models of anaphora resolution: A survey.PRADHEEP ELANGO. 2005. Co-reference Resolution: A Survey. Technical Report, University of WisconsinMadisonPRASAD R., AND STRUBE,M. 2003. Constraints on The Generationof Referring Expressions, With Special Reference To Hindi, APhD dissertation University of Pennsylvania.PRASAD R., AND STRUBE,M.. 2000. Discourse salience andpronoun resolution in Hindi. U. Penn Working Papers inLinguistics. Volume 6.3, pp. 189-208.RYOHEI SASANO, DAISUKE KAWAHARA, AND SADAOKUROHASHI. Improving Co-reference Resolution Using Bridging Reference Resolution and Automatically Acquired Synonyms , SpringerSASANO, RYOHEI. 2008. Japanese Anaphora Resolution Based on Automatically Acquired World Knowledge. Doctoral dissertation. December 2008.SASANO, RYOHEI., KAWAHARA, DAISUKE. AND KUROHASHI SADAO. 2007. Improving Co-reference Resolution Using Bridging Reference Resolution and Automatically Acquired Synonyms. SpringerLInk Anaphora: analysis, algorithms and applications. Vol. 4410. 125-136.SEKI, K., FUJII, A., AND ISHIKAWA, T. 2002. A probabilistic method for analyzing Japanese anaphora integrating zero pronoun detection and resolution. In Proceedings of the 19th Inter-national Conference on Computational Linguistics (COLING). 911–917.SOBHA L AND B.N. PATNAIK. 1998. An Algorithm for Pronoun and Reflexive Resolution in Malayalam. Proceedings of the International Conference on Computational Linguistics, Speech and Document processing. C63-66.SOBHA L AND B.N.PATNAIK. 1999. One-pronoun resolution in Malayalam. Indian Linguistics.SOBHA L. 1999. Anaphora Resolution In Malayalam and Hindi. Unpublished Doctoral dissertation. Mahatma Gandhi University, Kottayam , Kerala.SOBHA, L. AND PATNAIK,B.N. 2002. Vasisht” – An anaphora resolution system for Malayalam and Hindi, Symposium on Translation Support Systems, IIT Kanpur 15-17 March.SOON, W. M., NG, H. T., AND LIM, D. C. Y. 2001. A machine learning approach to co-reference resolution of noun phrases. Computa. Linguist. 27, 4, 521–544.SOUHA HAMMAMI, LAMIA BELGUITH, AND ABDELMAJID BEN HAMADOU. Arabic Anaphora Resolution: Corpora Annotation with Coreferential Links. The International Arab Journal of Information Technology, Vol. 6, No. 5, November 2009. 481-489.STEINBERGER, J., M. POESIO, M. KABADJOV, K. JEZEK. 2007. Two uses of anaphora resolution in summarization. Information Processing and Management. 43:1663– 1680.STRUBE, MICHAEL, STEFAN RAPP, CHRISTOPH M ̈ULLER. 2002. The influence of minimum edit distance on reference resolution. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, Philadelphia, Penn., 6– 7 July, pages 312–319.
 STRUBE, MICHAEL. 1998. Never look back: An alternative to Centering. In Proc. of the 17th Int. Conference on Computational Linguistics and 36th Annual Meeting of the Association for Computational Linguistics; Montr ́eal, Qu ́ebec, Canada. 10– 14 August 1998, 1251–1257.STRUBE,M. AND M ̈ULLER, C. 2003. A machine learning approach to pronoun resolution in spoken dialogue. In Proceedings of the 41st ACL. 168–175.TETREAULT. JOEL. 2001. A corpus-based evaluation of centering and pronoun resolution. Computational Linguistics. 27(4):507– 520.TIN E, Akman V. 1992. Anaphora in Turkish: a computational framework. In: Proceedings of Sixth International Turkish Linguistics Conference. Anadolu University, Eskis_ehir.TIN E, Akman V. 1994. Situated processing of pronominal anaphora. In: Proceedings of Second Conference for Natural Language Processing (KONVENS’94). University of Vienna, Austria, pp. 369–378.TRIVENI LAL PAL, KAMLESH DUTTA, PARDEEP SINGH. 2012. Anaphora Resolution in Hindi: Issues and Challenges. International Journal of Computer Applications. (0975 – 8887) Volume 42– No.18.TURAN U D. 1996. Null vs. Overt Subjects in Turkish Discourse: A Centering Analysis. PhD Dissertation, University of Pennsylvania.VERSLEY, YANNICK. 2006. A constraint-based approach to noun phrase co-reference resolution in German newspaper text. In Konferenz zur Verarbeitung Nat ̈urlicher Sprache (KONVENS 2006).VIEIRA, RENATA MASSIMO POESIO. 1997. Processing definite descriptions in corpora. In Corpus-based and Computational Approaches to Discourse Anaphora. UCL Press.VIEIRA, RENATA MASSIMO POESIO. 2000. An empirically based system for processing definite descriptions. Computational Linguistics 26(4):539–593.WALKER, CHRISTOPHER, STEPHANIE STRASSEL, JULIE MEDERO, AND KAZUAKI MAEDA. 2006.ACE 2005 multilingual training Corpus. LDC2006T06, Philadelphia, Penn.: Linguistic Data Consortium.WANG, CHI-SHING. AND NGAI, GRACE. 2006. A Clustering Approach for Unsupervised Chinese Co-reference Resolution, Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 40–47, Sydney, July 2006. c2006 Association for Computational Linguistics.WEISCHEDEL, RALPH, SAMEER PRADHAN, LANCE RAMSHAW, MARTHA PALMER, NIANWEN XUE, MITCHELL MARCUS, ANN TAYLOR, CRAIG GREENBERG, EDUARD HOVY, ROBERT BELVIN, AND ANN HOUSTON. 2008. Ontonotes release 2.0. LDC2008T04, Philadelphia, Penn.: Linguistic Data Consortium.YANG X, SU J, LANG J, TAN CL, LIU T, LI S. 2008. An entity- mention model for co-reference resolution with inductive logic programming. In Proceedings of ACL-08: HLT. Columbus (OH). Association for Computational Linguistics. p. 843–51.YANG, X., SU, J., AND TAN, C. L. 2005. Improving pronoun resolution using statistics-based semantic compatibility information. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL). 165–172.YEH, CHING-LONG AND CHEN, YI-CHUN, 2004a, Zero Anaphora Resolution in Chinese with Shallow Parsing, Journal of Chinese Language and Computing.YEH, CHING-LONG AND CHEN, YI-CHUN, 2004b, Topic Identification in Chinese Based on Centering Model. Proceedings of ACL Workshop on Reference Resolution and Its Applications, Barcelona, Spain.YEH, CHING-LONG, 1995, Generation of Anaphors in Chinese, Ph.D. thesis, University of Edinburgh.YEH, CHING-LONG. AND CHEN, YI-CHUN. 2007. Zero Anaphora Resolution in Chinese with Shallow Parsing. Journal of Chinese Language and Computing 17 (1): 41-56.ZHENG. JIAPING, CHAPMAN. W WENDY, CROWLEY. S REBECCA, SAVOVA. K GUERGANA. 2011. Co-reference resolution: A review of general methodologies and applications in the clinical domain. Journal of Biomedical Informatics 44 (2011) 1113–1122.ZITOUNI IMED, XIAOQIANG LUO, RADU FLORIAN. A Cascaded Approach to Mention Detection and Chaining in Arabic. IEEE Transactions on Audio, Speech and Language Processing, vol. 17, no. 5, 2009a.ZITOUNI, I. AND FLORIAN, R. 2009b. Cross language information propagation for Arabic mention detection. ACM Trans. Asian Lang. Inform. Process. 8, 4, Article 17 (December 2009), 21 pages. DOI = 10.1145/1644879.1644884. http://doi.acm.org/10.1145/1644879.1644884. 