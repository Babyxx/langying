Identifying Location Mentions in Tweets: An Iterative Approach Using Multiple Knowledge SourcesAbstractThis paper describes a strategy and results of a location mining system for Twitter messages. The task of location mining required us to identify the location mentions in 1003 Twit- ter test messages given a separate annotated training set of 2000 messages. We present an architecture that uses a basic named entity rec- ognizer in conjunction with various rule-based modules and knowledge infusion to achieve an average F score of 0.747. We used the pre-trained Stanford NER which gives us an F score of 0.532 and used an ensemble of other techniques to reach the 0.747 value. A major source of location resolver was the DBpedia location list which was used to identify a large percentage of locations with an individual F- score of 0.935.1 IntroductionSocial media has become so ubiquitous and per- vasive in our society that almost all organiza- tions nowadays use it for various types of strate- gic objectives such as marketing, campaigns, public- ity,information dissemination and information gath- ering. This has resulted in a flurry of research fo- cused specifically on processing social media texts because the tools and techniques designed for struc- tured texts have been found to fail miserably on so- cial media texts (Ritter et al., 2011). In order to be able to harness the enormous amounts of informa- tion embedded in social media texts there is a need for tools that can accurately extract the required in- formation. In this paper we present the results ofSecond AuthorAffiliation / Address line 1 Affiliation / Address line 2 Affiliation / Address line 3 email@domaintesting an information extraction tool that focuses on identifying location mentions on a very popular so- cial media platform, Tweeter. Tweeter is a a social media platform which allows 140 character mes- sages to be posted for general as well as closed group communication. It is used extensively to upload im- mediate news about events by users, hence has an enormous potential to be used as up to the minute information source. Among the various types of in- formation that can be mined from Twitter messages, location mining has attracted attention because of its application in identifying the geographical location of a topic in the Tweeter messages. For example tweets can be used to extract information on the lo- cation of an accident, a natural disaster, a concert and more recently, open invitation parties gone out of hand.Location mining is a special case of a generic NLP task called Named Entity Recognition (NER), which involves identifying and classifying entities into person, organization and location type entities. In its simplest form location mentions is a single to- ken such as “Auckland”, however it can also be com- pound nouns such as “South Auckland” and even short phrases such as “South West of Auckland”. Location mentions using single tokens can generally be identified by named entity recognizers trained on appropriate data. A typical NER tool such as the Stanford1 and OpenNLP2 identifies single word based locations. NER systems are typically able to identify 3 classes of named entities (for example: PERSON, LOCATION and ORGANIZATION). In1http://nlp.stanford.edu/software/CRF-NER.shtml 2 http://opennlp.apache.org 
most location mining tasks, we are interested in ex- tracting both geo-locations as well as points of in- terest (POI), hence both LOCATION ORGANIZA- TION classes need to be extracted from the output of an NER system. NER systems on their own have been proven to be ineffective for location mining from social media texts for two main reasons.1. The pre-trained NER systems perform poorly due to the inherent noise in social media texts. To overcome this problem, the authors in (Lin- gad et al., 2013) have attempted to retrain ex- isting NER systems and have reported F-scores of up to 0.9. We use the common definition of F-score throughout this paper:F = 2pr p+rwhere p is the precision and r is the recall. The experiments have been done with relatively small datasets (450 tweets), hence do not nec- essarily scale up with large datasets.2. NER systems identify single token locations. Locations embedded in compound nouns and short phrases either get entirely missed or need to be backward-constructed from the tokens identified by the NER system.The partitioned nature of location mentions in texts warrants an ensemble approach to resolve the different categories of locations in tweets. This pa- per presents the results of a location miner that was designed to take part in a location mining com- petition in the Australasian Language Technology Workshop 20143 which required identification of all forms of location mentions in tweeter messages. In addition to the locations identified by noun phrases, the task required the identification of specific loca- tions defined by short phrases such as “40km south of tenterfield2” and “100 mi from nations capital”.Our approach is using a parallel voting architec- ture. It combines several techniques including a NER system. We used the Conditional Random Field (CRF) based Stanford NER system because this delivers the highest accuracy on Twitter mes- sages according to (Lingad et al., 2013). Lingad et3ALTA2014: http://www.alta.asn.au/events/alta2014/al. (2013) reported that the retrained Stanford NER achieved an F-score of 0.902 compared to 0.576 for the pre-trained NER. We have found that re-training the Stanford NER with bare training data provided by the organizers delivered F scores around the 0.4 mark at token level compared to approximately 0.57 for the pre-trained model. Analysis of the errors for both models showed that due to loose capitalization in twitter messages, a lot of the locations could not be identified simply because they did not exist in the training data. Since the pre-trained model was trained with much larger training set it could de- tect a larger number of locations giving us a higher precision value. We tried incremental training of the Stanford NER, however ran into technical dif- ficulties with memory and computational time re- quired. Hence, we adopted the approach of an en- semble system consisting of a pre-trained Stanford NER, knowledge infusion, regular expression iden- tifier and the use of rules. Instead of a pipeline archi- tecture with no re-processing we adopted a parallel architecture to cater for the copious amount of noise in Tweets. The parallel architecture enables us to revisit previous decisions and correct them.The rest of the paper is organized as follows. Sec- tion 2 gives an overview of related works for lo- cation mining in Twitter messages as well as some generic NER works. Section 3 describes the task de- scription followed by our methodology. The results are detailed in Section 5 and Section 6 concludes this paper.2 Related WorksLocation Mining is a subtask of the more generic information extraction task of named entity recog- nition. This section gives an overview of recent works specifically in the informal domain of micro- blogging, mostly for “Twittersphere”.Ritter et. al. (2011) presented a NER system named T-NER, which uses Freebase as an informa- tion source to enhance supervision for the Stanford NER to classify entities into 10 classes, one of which was geo-location. Their system achieved an overall F-score of 0.66 and a geo-location F score of 0.77. Li et al. (2012) present a random walk model which exploits the gregarious properties associated with Tweets in addition to the textual content to deter-  
mine the named entities. The gregarious property is based on named entities mentioned together in me- dia other than Twitter. The authors used Microsoft N-Gram and Wikipedia as the corpus to compute the gregarious property value. This system attained an F-score of 0.419 on their data compared to 0.466 for the previously mentioned system and 0.423 for the Stanford NER on the same data.The task of location mining specifically from Twitter messages has attracted a lot of attention be- cause Twitter is current, up to the minute, hence can be used for information about uptodate events around the globe. One of its immediate use is for almost real time disaster detection so that services can be deployed as soon as possible. There are mul- tiple other uses for Twitter location mining such as location based advertising and geography based sen- timent mining. Lingad et al. (2013) present test re- sults for using 4 off-the-shelf NER’s to determine locations with varying degrees of granularity from Country, State, City, Area, Suburb to Point of In- terest. The results from this paper showed that the retrained Stanford NER was the best performer at 0.872 and the standard Stanford NER 4-class classi- fier attained a value of 0.691. Based on the results of this paper we have chosen a NER for our location miner.Twitter messages may also have meta data indi- cating the location from which a Tweet was sent. This is only present in Tweets sent from mobile de- vices equipped with GPS hardware. It is interest- ing that this feature can be turned off for privacy reasons by the user. Ikawa et al. (2012) present a model which exploits the GPS location as well as the textual content of the Tweet. This model uses as- sociations between locations and relevant keywords from past messages during training, which is then used to estimate where the new message was issued from. The identified location is then assigned to a geographical square and the errors were calculated based on the distance within 10 kilometers. The study reports a precision value of 0.45 with a dataset of 20,535 messages. A subset of 16,380 messages were used for training. A large number of errors oc- curred based on the fact that the location mentions in the text of the Tweet might not necessary corre- late with the location of the user.Mahmud et al. (2012) present a system for pre-dicting the home locations of Twitter users. Un- like the previous system, this paper uses an ensem- ble of statistical and heuristic classifiers to predict Google’s geo-coding bounding box for Twitter cor- responding to the Twitter users. The paper reports accuracies at various granularities which range from 0.54 to 0.78 for recall values.Sankaranarayanan et al. (2009) present a system which does location mining for a different purpose. The object of this work is to cluster Twitter mes- sages according to the news content based on geo- graphical locations. This work again uses ensemble learning, similar to our approach. It uses references to geographic locations in the text, called toponyms, to determine the coordinates which then used to re- solve using various techniques such as NER, POS tagging and a look up database containing countries, city, river etc. In addition to this, the textual content of the Tweet is extended using its metadata about the location of the Tweeter. The metadata information is added as textual content of the Tweet which is then treated similar to the rest of the message. The pa- per does not report any location specific accuracy, however illustrates a different use for location min- ing and the enforces the use of ensemble architecture for the purpose.The authors in (e.g., Kinsella et al., 2011; Li et al., 2011) have done work on location mining focused on either the location from where the Tweet was sent or the geographical location of the Tweeter. Those papers have in common that they apply a combi- nation of techniques rather than only one particular technique. We report in this paper about the results of a system with a similar architecture which uses an ensemble of techniques but the aim is slightly differ- ent. It is focused on location extraction from text and has nothing to do with the location of the Tweeter or the location from which the Tweet was sent. A Tweeter can tweet about a location without talking about his or her registered location or the current lo- cation.3 Task SpecificationThe training and test sets used for this research are based on ALTA-20144 shared task. The training set consisted of 2000 Twitter Id’s with identified loca-4 http://www.alta.asn.au/events/sharedtask2014/ 
tions and the test set consisted of another set of 1003 Twitter Id’s for testing.The overall goal of the research was to identify all mentions of locations in the text of a twitter mes- sage. This includes all single and contiguous word mentions such as “guatemala” and “new zealand” and similar mentions as abbreviations such as “nz” for New Zealand. The task also required to identify different mentions referring the same location. The following examples give an overview of the wider scope of the task.• “#eqnz” - location is “eqnz”In this case we need to check for location within strings, however extract the whole token if one is found.• “http:www.abc.net.au/melbourne/” - loca- tion is “http:www.abc.net.au/melbourne/”• “cork city...textbf#Cork” - locations - “cork city cork2”In this case locations such as city had to be identified and words in locations appearing more than once had to be tagged with the count.• “Morrison’s Island - S Terrace” - location is“morrisons island s terrace”Punctuations need to be removed leaving the strings as they appear in the text.• “U.S. EPA on Twitter” - location is “NONE” In this case “U.S.” is not a location, but a user.• “Our house” - location is “our house” Common nouns with possessive pronouns need to be identified since they are specific locations.• ‘‘Southwest towns of San Marcos” - location is “Southwest towns of San Marcos”In this case we need to retain the preposition “of”.• “60 miles east starting from Stamford CT” - location is “60 miles east Stamford CT” This involves removing the verb and the prepo- sition from the location.4 MethodologyThe schematic representation of the method is shown in Fig. 1. We utilized the parallel processing strategy with multiple modules to identify locations.The proposed location mining architecture is di- vided into the following of 9 major modules.I Cleaning Twitter text, this module is based on (Nand et al., 2014) in Twitter text mining that uses Hidden Markov Model (HMM) based tag- ging.II Location mining using NER, we have inte- grated the Stanford NER toolkit (Finkel and Manning, 2009) with MUC-3 class pre-trained model to locate cities and countries.III Phrase and dictionary chunking, the module chunks text based on a predefined rule set. This rule set uses LingPipe library 5.IV Regex Pattern miner, the module finds postal addresses and geo coordinates such as longitude and latitude in texts using regular expressions.V Location abbreviation miner, the module uses a location abbreviation lexicon list.VI Location specifier based identification, we used the ALTA training data to create a location spec- ifier list enriched with a set of location spec- ifiers extracted from a thesaurus. This list is used with a template based matching to identify whether an extracted phrase is a location. This module also selects locations which are prepo- sitional attachments using a set of templates.VII DBpedia based location mining, this module 6 uses the most extensive knowledge about loca- tions, DBpedia is a Linked Data resource which is built based on the Wikipedia7 text.VIII Merging module, this module presents a more informative location as the final result. This was accomplished using a text merging utility that takes the index of the each location mention and merge them to the same order of tokens appear- ing in the tweet text.5http://alias-i.com/lingpipe/index.html6 http://dbpedia.org/About 7http://en.wikipedia.org/wiki/Main Page  
 Figure 1: Schematic representation of the Twitter location mining framework IX Results formatter Formatting of the result as a comma separated file was accomplished by this module. In essence, the formatter was based on the following four rules:• remove all punctuations from the phrase• iflocationsarerepeatedinatweet,numberthem from the second occurrence• if there is no location for the tweet, thenmark it as NONE• lowercase all extracted location phrasesThe resulting phrases were converted to a Comma separated file with two fields; tweet id and the location phrases.5 ResultsOur location miner achieved an average F-score of 0.747. The F-score was calculated based on the “bag of words criteria” for each tweet as described in the Section 3. If a tweet did not contain any locations, the participants were required to label them with “NONE”. The overall results for the test dataset is shown in Table 5.The precision and recall values were computed for individual Tweets, which were then averaged to compute the overall F-score. Hence the preci- sion and recall values for a Tweet with no location mentions was taken as 1.0 for “NONE” to indicate no location. Any other strings instead of “NONE” were counted as false positives. Table 5 shows thatTest Data Property ValueNo. of Tweets 1003 No. of Location tokens 3179 No. NONE Tweets 115 Av. Recall 0.7279 Av. Precision 0.7905Table 1: Dataset details and Resultsthere were 115 Tweets (11.5%) with no locations. It should be noted that this strategy for accuracy ap- proximation will tend to boost the F-score if a large number of Tweets have no location mentions.Table 5 gives the number of the locations speci- fied by the individual modules of the ensemble sys- tem used for the task. The majority of false nega- tives were identified by the Location Specifier mod- ule which was primarily based around rules based on the use of the prepositions of place such as, “at”, “on” and “in”. The DBpedia miner module was able to identify a total of 1867 locations which is even higher than then the Stanford NER module. DBpe- dia miner has achieved the highest F- score of 0.935 compared to the other four modules.6 Conclusions and Future WorkThis paper showed the use of an ensemble architec- ture to solve the problem of location mention iden-  
 Module NumberStanford 1003NERPostal 6AddressMinerGeo coor- 8dinateLocation 607Abbre-viationMinerLocation 202SpecifierDBpedia 1867 MinerRelative F Score0.532 0.1670.242 0.7100.884 0.935Absolute F Score0.434 0.010.02 0.3970.126 0.682ion on World Wide Web - WWW ’12 Companion, page687, New York, New York, USA, April. ACM Press. Sheila Kinsella, Vanessa Murdock, and Neil O’Hare. 2011. ”I’m eating a sandwich in Glasgow”. In Proceedings of the 3rd international workshop on Search and mining user-generated contents - SMUC ’11, page 61, New York, New York, USA, October.ACM Press.Wen Li, Pavel Serdyukov, Arjen P. de Vries, CarstenEickhoff, and Martha Larson. 2011. The where in the tweet. In Proceedings of the 20th ACM international conference on Information and knowledge manage- ment - CIKM ’11, page 2473, New York, New York, USA, October. ACM Press.Chenliang Li, Jianshu Weng, Qi He, Yuxia Yao, An- witaman Datta, Aixin Sun, and Bu-Sung Lee. 2012. TwiNER. In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval - SIGIR ’12, page 721, New York, New York, USA, August. ACM Press.John Lingad, Sarvnaz Karimi, and Jie Yin. 2013. Loca- tion extraction from disaster-related microblogs. Pro- ceedings of the 22Nd International Conference on World Wide Web Companion, pages 1017–1020, May.Jalal Mahmud, Jeffrey Nichols, and Clemens Drews. 2012. Where Is This Tweet From? Inferring Home Locations of Twitter Users. In ICWSM.Parma Nand, Ramesh Lal, and Rivindu Perera. 2014. A HMM POS Tagger for Micro-Blogging Type Texts. In Proceedings of the 13th Pacific Rim International Conference on Artificial Intelligence (PRICAI 2014).Alan Ritter, Sam Clark, Mausam, and Oren Etzioni. 2011. Named entity recognition in tweets: an experi- mental study. pages 1524–1534, July.Jagan Sankaranarayanan, Hanan Samet, Benjamin E. Teitler, Michael D. Lieberman, and Jon Sperling. 2009. TwitterStand. In Proceedings of the 17th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems - GIS ’09, page 42, New York, New York, USA, November. ACM Press.  Table 2: The number of locations resolved by individual modules with respective F scoretification. We presented an ensemble architecture that uses a basic general purpose NER, with a com- bination of various rule based modules in conjunc- tion with DBpedia knowledge base to achieve an F -score of 0.747. A critical aspect of any ensem- ble architecture is how to combine the results at the end. This was also illustrated by the Merger module which takes outputs from the various ensemble mod- ules and combines them into a noun phrase location phrase as was required by the shared task specifica- tion. The design of the architecture enables us to exclude a class of location mentions and also to in- clude any new ones that a task at hand might dic- tate. The final results can also be easily modified to output single token locations or full noun phrase lo- cations. In future we intend to further improve the accuracy and to classify the locations into types such as country, site and address for specific applications.ReferencesJenny Rose Finkel and Christopher D Manning. 2009. Joint Parsing and Named Entity Recognition. In Pro- ceedings of the North American Association of Com- putational Linguistics (NAACL 2009).Yohei Ikawa, Miki Enoki, and Michiaki Tatsubori. 2012. Location inference using microblog messages. In Pro- ceedings of the 21st international conference compan-