Selecting_VBG Training_NNP Data_NNP for_IN Unsupervised_NNP Domain_NNP Adaptation_NNP in_IN Word_NNP Sense_NN Disambiguation_NNP Abstract_NNP This_DT paper_NN describes_VBZ a_DT method_NN of_IN do_VBP -_: main_JJ adaptation_NN ,_, which_WDT involves_VBZ adapting_VBG a_DT classifier_NN developed_VBD from_IN source_NN to_TO tar_NN -_: get_VB data_NNS ._.
We_PRP automatically_RB select_VBP the_DT train_NN -_: ing_NN data_NNS set_VBD that_DT is_VBZ suitable_JJ for_IN the_DT target_NN data_NNS from_IN the_DT whole_JJ source_NN data_NNS of_IN mul_NN -_: tiple_NN domains_NNS ._.
This_DT is_VBZ unsupervised_JJ do_VBP -_: main_JJ adaptation_NN for_IN Japanese_JJ word_NN sense_NN disambiguation_NN -LRB-_-LRB- WSD_NNP -RRB-_-RRB- ._.
Experiments_NNS re_SYM -_: vealed_VBD that_IN the_DT accuracies_NNS of_IN WSD_NNP im_SYM -_: proved_VBN when_WRB we_PRP automatically_RB selected_VBD the_DT training_NN data_NN set_NN using_VBG two_CD criteria_NNS ,_, the_DT degree_NN of_IN confidence_NN and_CC the_DT leave-one_NN -_: out_RP -LRB-_-LRB- LOO_NNP -RRB-_-RRB- -_: bound_VBN score_NN ,_, compared_VBN with_IN when_WRB the_DT classifier_NN was_VBD trained_VBN with_IN all_PDT the_DT data_NNS ._.
1_CD Introduction_NNP Classifiers_NNP in_IN standard_JJ supervised_JJ machine_NN learn_VBP -_: ing_NN have_VBP been_VBN trained_VBN for_IN data_NNS in_IN domain_NN A_DT using_VBG manually_RB annotated_VBN data_NNS in_IN domain_NN A_DT ,_, e.g._FW ,_, to_TO train_VB classifiers_NNS for_IN newswires_NNS using_VBG newswires_NNS ._.
How_WRB -_: ever_RB ,_, classifiers_NNS for_IN data_NNS in_IN domain_NN B_NN have_VBP some_DT -_: times_NNS been_VBN necessary_JJ when_WRB there_EX have_VBP been_VBN no_DT or_CC few_JJ manually_RB annotated_VBN data_NNS ,_, and_CC there_EX have_VBP only_RB been_VBN manually_RB annotated_VBN data_NNS in_IN domain_NN A_DT ,_, which_WDT has_VBZ been_VBN related_VBN to_TO domain_NN B._NNP Domain_NNP adapta_NN -_: tion_NN involves_VBZ adapting_VBG the_DT classifier_NN that_WDT has_VBZ been_VBN trained_VBN from_IN data_NNS in_IN domain_NN A_DT -LRB-_-LRB- source_NN domain_NN -RRB-_-RRB- to_TO data_NNS in_IN domain_NN B_NNP -LRB-_-LRB- target_NN domain_NN -RRB-_-RRB- ._.
This_DT has_VBZ been_VBN studied_VBN intensively_RB -LRB-_-LRB- see_VB Section_NN 2_LS -RRB-_-RRB- ._.
However_RB ,_, the_DT optimal_JJ method_NN of_IN domain_NN adap_SYM -_: tation_NN varied_VBD according_VBG to_TO the_DT properties_NNS of_IN the_DT data_NNS in_IN the_DT source_NN domain_NN -LRB-_-LRB- the_DT source_NN data_NNS -RRB-_-RRB- and_CC the_DT data_NNS in_IN the_DT target_NN domain_NN -LRB-_-LRB- the_DT target_NN data_NNS -RRB-_-RRB- when_WRB domain_NN adaptation_NN for_IN word_NN sense_NN disambiguation_NN -LRB-_-LRB- WSD_NNP -RRB-_-RRB- was_VBD carried_VBN out_RP -LRB-_-LRB- Komiya_NNP and_CC Okumura_NNP ,_, 2011_CD -RRB-_-RRB- ._.
In_IN other_JJ words_NNS ,_, the_DT optimal_JJ training_NN data_NNS varied_VBD ac_SYM -_: cording_NN to_TO the_DT properties_NNS of_IN the_DT source_NN and_CC tar_NN -_: get_VB data_NNS ._.
This_DT paper_NN proposes_VBZ automatic_JJ domain_NN adaptation_NN in_IN an_DT unsupervised_JJ manner_NN based_VBN on_IN a_DT comparison_NN of_IN multiple_JJ classifiers_NNS when_WRB Japanese_JJ WSD_NNP is_VBZ performed_VBN -LRB-_-LRB- see_VB Section_NN 3_LS -RRB-_-RRB- ._.
Our_PRP$ experi_SYM -_: ments_NNS -LRB-_-LRB- see_VB Sections_NNS 4_CD and_CC 5_CD -RRB-_-RRB- revealed_VBD that_IN the_DT av_SYM -_: erage_NN accuracy_NN of_IN WSD_NNP when_WRB the_DT training_NN data_NN set_NN that_WDT was_VBD automatically_RB determined_VBN was_VBD used_VBN was_VBD higher_JJR than_IN that_DT when_WRB all_PDT the_DT data_NNS were_VBD used_VBN col_SYM -_: lectively_NN -LRB-_-LRB- see_VB Section_NN 6_CD -RRB-_-RRB- ._.
We_PRP discuss_VBP the_DT results_NNS in_IN Section_NN 7_CD and_CC conclude_VBP this_DT paper_NN in_IN Section_NN 8_CD ._.
2_CD Related_JJ Work_NN The_DT domain_NN adaptation_NN problem_NN can_MD be_VB catego_NN -_: rized_VBN into_IN three_CD types_NNS depending_VBG on_IN the_DT informa_NN -_: tion_NN for_IN learning_VBG ,_, i.e._FW ,_, that_IN in_IN supervised_JJ ,_, semi_SYM -_: supervised_JJ ,_, and_CC unsupervised_JJ approaches_NNS ._.
Ac_SYM -_: cording_NN to_TO Daume_NNP ́_CD III_NNP et_FW al._FW -LRB-_-LRB- 2010_CD -RRB-_-RRB- ,_, a_DT classifier_NN in_IN a_DT supervised_JJ approach_NN is_VBZ developed_VBN from_IN a_DT large_JJ amount_NN of_IN labeled_VBN source_NN data_NNS and_CC a_DT small_JJ amount_NN of_IN labeled_VBN target_NN data_NNS with_IN the_DT aim_NN of_IN classify_VB -_: ing_NN target_NN data_NNS better_JJR than_IN a_DT classifier_NN developed_VBD from_IN only_RB the_DT target_NN data_NNS ._.
A_DT classifier_NN in_IN a_DT semi_NN -_: supervised_JJ approach_NN is_VBZ developed_VBN from_IN a_DT large_JJ amount_NN of_IN labeled_VBN source_NN data_NNS ,_, a_DT small_JJ amount_NN of_IN labeled_VBN and_CC a_DT large_JJ amount_NN of_IN unlabeled_JJ target_NN data_NNS with_IN the_DT aim_NN of_IN classifying_VBG target_NN data_NNS better_JJR than_IN a_DT classifier_NN developed_VBD from_IN only_RB the_DT source_NN data_NNS ._.
Fi_SYM -_: nally_RB ,_, a_DT classifier_NN is_VBZ developed_VBN from_IN a_DT large_JJ amount_NN of_IN labeled_VBN source_NN data_NNS and_CC unlabeled_JJ target_NN data_NNS with_IN the_DT aim_NN of_IN accurately_RB classifying_VBG target_NN data_NNS in_IN an_DT unsupervised_JJ approach_NN ._.
We_PRP focused_VBD on_IN the_DT un_NN -_: supervised_JJ domain_NN adaptation_NN for_IN Japanese_JJ WSD_NNP in_IN the_DT research_NN reported_VBD in_IN this_DT paper_NN ._.
Many_JJ researchers_NNS have_VBP investigated_VBN domain_NN adaptation_NN within_IN or_CC outside_IN the_DT area_NN of_IN natural_JJ language_NN processing_NN ._.
Chan_NNP and_CC Ng_NNP -LRB-_-LRB- 2006_CD -RRB-_-RRB- carried_VBD out_IN the_DT domain_NN adaptation_NN of_IN WSD_NNP by_IN estimating_VBG class_NN priors_NNS us_PRP -_: ing_VBG an_DT EM_NNP algorithm_NN ._.
Chan_NNP and_CC Ng_NNP -LRB-_-LRB- 2007_CD -RRB-_-RRB- also_RB conducted_VBD the_DT domain_NN adaptation_NN of_IN WSD_NNP by_IN es_SYM -_: timating_VBG class_NN priors_NNS using_VBG an_DT EM_NNP algorithm_NN ,_, but_CC this_DT was_VBD supervised_JJ domain_NN adaptation_NN using_VBG ac_SYM -_: tive_JJ learning_NN ._.
In_IN addition_NN ,_, Daume_NNP ́_CD III_NNP -LRB-_-LRB- 2007_CD -RRB-_-RRB- worked_VBD on_IN super_JJ -_: vised_VBN domain_NN adaptation_NN ._.
He_PRP augmented_VBD an_DT input_NN space_NN and_CC made_VBD triple_JJ length_NN features_NNS that_WDT were_VBD general_JJ ,_, source-specific_JJ ,_, and_CC target-specific_JJ ._.
This_DT was_VBD easy_JJ to_TO implement_VB ,_, could_MD be_VB used_VBN with_IN vari_NNS -_: ous_JJ domain_NN adaptation_NN methods_NNS ,_, and_CC could_MD easily_RB be_VB extended_VBN to_TO multi-domain_JJ adaptation_NN problems_NNS ._.
Daume_NNP ́_CD III_NNP et_FW al._FW -LRB-_-LRB- 2010_CD -RRB-_-RRB- extended_VBD the_DT earlier_JJR work_NN by_IN Daume_NNP ́_NNP -LRB-_-LRB- Daume_NNP ́_CD III_NNP ,_, 2007_CD -RRB-_-RRB- to_TO semi_SYM -_: supervised_JJ domain_NN adaptation_NN ._.
It_PRP inherited_VBD the_DT advantages_NNS of_IN the_DT supervised_JJ version_NN and_CC outper_NN -_: formed_VBD it_PRP by_IN using_VBG unlabeled_JJ target_NN data_NNS ._.
Agirre_NNP and_CC de_IN Lacalle_NNP -LRB-_-LRB- 2008_CD -RRB-_-RRB- worked_VBD on_IN semi_NNS -_: supervised_JJ domain_NN adaptation_NN for_IN WSD_NNP ._.
They_PRP ap_SYM -_: plied_VBD singular_JJ value_NN decomposition_NN -LRB-_-LRB- SVD_NNP -RRB-_-RRB- to_TO a_DT matrix_NN of_IN unlabeled_JJ target_NN data_NNS and_CC a_DT large_JJ amount_NN of_IN unlabeled_JJ source_NN data_NNS ,_, and_CC trained_VBD a_DT classifier_NN with_IN them_PRP ._.
Agirre_NNP and_CC de_IN Lacalle_NNP -LRB-_-LRB- 2009_CD -RRB-_-RRB- worked_VBD on_IN supervised_JJ domain_NN adaptation_NN using_VBG almost_RB the_DT same_JJ method_NN ,_, but_CC they_PRP used_VBD a_DT small_JJ amount_NN of_IN la_NNP -_: beled_VBD source_NN data_NNS instead_RB of_IN a_DT large_JJ amount_NN of_IN un_NN -_: labeled_VBN source_NN data_NNS ._.
Jiang_NNP and_CC Zhai_NNP -LRB-_-LRB- 2007_CD -RRB-_-RRB- demonstrated_VBD that_IN perfor_SYM -_: mance_NN increased_VBD as_IN examples_NNS were_VBD weighted_VBN when_WRB domain_NN adaptation_NN was_VBD applied_VBN ._.
This_DT method_NN could_MD be_VB used_VBN with_IN various_JJ other_JJ supervised_JJ or_CC semi-supervised_JJ domain_NN adaptation_NN methods_NNS ._.
In_IN addition_NN ,_, they_PRP tried_VBD to_TO identify_VB and_CC remove_VB source_NN data_NNS that_WDT misled_VBD domain_NN adaptation_NN ,_, but_CC they_PRP con_VBP -_: cluded_VBD that_IN it_PRP was_VBD only_RB effective_JJ if_IN examples_NNS were_VBD not_RB weighted_VBN ._.
Zhong_NNP et_FW al._FW -LRB-_-LRB- 2009_CD -RRB-_-RRB- proposed_VBD an_DT adaptive_JJ kernel_NN approach_NN that_WDT mapped_VBD the_DT marginal_JJ distribution_NN of_IN source_NN and_CC target_NN data_NNS into_IN a_DT common_JJ kernel_NN space_NN ._.
They_PRP also_RB conducted_VBD sample_NN selection_NN to_TO make_VB the_DT conditional_JJ probabilities_NNS between_IN the_DT two_CD domains_NNS closer_RBR ._.
Raina_NNP et_FW al._FW -LRB-_-LRB- 2007_CD -RRB-_-RRB- proposed_VBN self-taught_JJ learn_VBP -_: ing_NN that_WDT utilized_VBD sparse_JJ coding_NN to_TO construct_VB higher_JJR level_NN features_NNS from_IN unlabeled_JJ data_NNS collected_VBN from_IN the_DT Web_NNP ._.
This_DT method_NN was_VBD based_VBN on_IN unsupervised_JJ learning_NN ._.
Tur_NNP -LRB-_-LRB- 2009_CD -RRB-_-RRB- proposed_VBD a_DT co-adaptation_JJ algorithm_NN where_WRB both_DT co-training_NN and_CC domain_NN adaptation_NN techniques_NNS were_VBD used_VBN to_TO improve_VB the_DT performance_NN of_IN the_DT model_NN ._.
The_DT research_NN by_IN Blitzer_NNP et_FW al._FW -LRB-_-LRB- Blitzer_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- involved_VBN work_NN on_IN semi_NNS -_: supervised_JJ domain_NN adaptation_NN ,_, where_WRB they_PRP calcu_VBP -_: lated_VBD the_DT weight_NN of_IN words_NNS around_IN the_DT pivot_NN features_NNS -LRB-_-LRB- words_NNS that_WDT frequently_RB appeared_VBD both_DT in_IN source_NN and_CC target_NN data_NNS and_CC behaved_VBD similarly_RB in_IN both_CC -RRB-_-RRB- to_TO model_VB some_DT words_NNS in_IN one_CD domain_NN that_WDT behaved_VBD similarly_RB in_IN another_DT ._.
They_PRP applied_VBD SVD_NNP to_TO the_DT matrix_NN of_IN the_DT weights_NNS ,_, generated_VBD a_DT new_JJ feature_NN space_NN ,_, and_CC used_VBD the_DT new_JJ features_NNS with_IN the_DT original_JJ features_NNS ._.
McClosky_NNP et_FW al._FW -LRB-_-LRB- 2010_CD -RRB-_-RRB- focused_VBD on_IN the_DT problem_NN where_WRB the_DT best_JJS model_NN for_IN each_DT document_NN is_VBZ not_RB ob_SYM -_: vious_NN when_WRB parsing_VBG a_DT document_NN collection_NN of_IN het_NN -_: erogeneous_JJ domains_NNS ._.
They_PRP studied_VBD it_PRP as_IN a_DT new_JJ task_NN of_IN multiple_JJ source_NN parser_NN adaptation_NN ._.
They_PRP pro-_JJ posed_VBD a_DT method_NN of_IN parsing_VBG a_DT sentence_NN that_IN first_JJ pre_NN -_: dicts_NNS accuracies_NNS for_IN various_JJ parsing_NN models_NNS using_VBG a_DT regression_NN model_NN ,_, and_CC then_RB uses_VBZ the_DT parsing_NN model_NN with_IN the_DT highest_JJS predicted_VBD accuracy_NN ._.
Harimoto_NNP et_FW al._FW -LRB-_-LRB- 2010_CD -RRB-_-RRB- measured_VBN the_DT distance_NN between_IN domains_NNS to_TO conduct_VB domain_NN adaptation_NN using_VBG a_DT suitable_JJ corpus_NN in_IN parsing_NN ._.
In_IN addition_NN ,_, van_NN Asch_NNP and_CC Daelemans_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- reported_VBD that_IN per_IN -_: formance_NN in_IN domain_NN adaptation_NN could_MD be_VB predicted_VBN depending_VBG on_IN the_DT similarity_NN between_IN source_NN and_CC target_NN data_NNS using_VBG automatically_RB annotated_VBN corpus_NN in_IN parsing_NN ._.
They_PRP focused_VBD on_IN how_WRB corpora_NN were_VBD se_FW -_: lected_VBN for_IN use_NN as_IN source_NN data_NNS according_VBG to_TO the_DT dis_SYM -_: tance_NN between_IN domains_NNS ,_, Komiya_NNP and_CC Okumura_NNP -LRB-_-LRB- 2011_CD -RRB-_-RRB- and_CC Komiya_NNP and_CC Okumura_NNP -LRB-_-LRB- 2012b_JJ -RRB-_-RRB- determined_VBD an_DT optimal_JJ method_NN of_IN domain_NN adaptation_NN using_VBG decision_NN tree_NN learning_VBG given_VBN a_DT triple_JJ of_IN the_DT target_NN word_NN type_NN of_IN WSD_NNP ,_, source_NN data_NNS ,_, and_CC target_NN data_NNS ._.
They_PRP discussed_VBD what_WP features_NNS affected_VBD how_WRB the_DT best_JJS method_NN was_VBD deter_VB -_: mined_VBN ._.
Finally_RB ,_, the_DT closest_JJS work_NN to_TO ours_PRP is_VBZ that_IN by_IN Komiya_NNP and_CC Okumura_NNP -LRB-_-LRB- 2012a_JJ -RRB-_-RRB- who_WP determined_VBD the_DT optimal_JJ method_NN ,_, i.e._FW ,_, the_DT optimal_JJ training_NN data_NN set_NN ,_, for_IN each_DT instance_NN using_VBG the_DT degree_NN of_IN confidence_NN ,_, which_WDT was_VBD also_RB used_VBN in_IN this_DT paper_NN ,_, for_IN supervised_JJ domain_NN adaptation_NN in_IN WSD_NNP ._.
We_PRP found_VBD that_IN the_DT method_NN that_WDT Komiya_NNP and_CC Okumura_NNP -LRB-_-LRB- 2012a_JJ -RRB-_-RRB- proposed_VBN was_VBD also_RB effective_JJ for_IN unsuper_JJ -_: vised_VBN domain_NN adaptation_NN ._.
3_CD Automatic_NNP selection_NN of_IN training_NN data_NNS When_WRB we_PRP perform_VBP WSD_NNP on_IN the_DT target_NN data_NNS of_IN a_DT certain_JJ domain_NN ,_, we_PRP assume_VBP that_IN the_DT labels_NNS ,_, i.e._FW ,_, the_DT word_NN senses_NNS ,_, of_IN the_DT target_NN data_NNS are_VBP unknown_JJ ._.
If_IN we_PRP have_VBP the_DT source_NN data_NNS of_IN the_DT multiple_JJ domains_NNS ,_, we_PRP would_MD automatically_RB select_VB the_DT subset_NN of_IN the_DT train_NN -_: ing_NN data_NNS that_WDT is_VBZ suitable_JJ for_IN the_DT target_NN data_NNS from_IN the_DT whole_JJ set_NN of_IN the_DT source_NN data_NNS in_IN these_DT domains_NNS ._.
Komiya_NNP and_CC Okumura_NNP -LRB-_-LRB- 2012a_JJ -RRB-_-RRB- assumed_VBD that_IN the_DT optimal_JJ training_NN data_NN set_NN would_MD vary_VB according_VBG to_TO each_DT instance_NN ._.
However_RB ,_, Komiya_NNP and_CC Okumura_NNP -LRB-_-LRB- 2011_CD -RRB-_-RRB- and_CC Komiya_NNP and_CC Okumura_NNP -LRB-_-LRB- 2012b_JJ -RRB-_-RRB- deter_VBP -_: mined_VBD an_DT optimal_JJ method_NN of_IN domain_NN adaptation_NN for_IN each_DT word_NN type_NN ._.
Therefore_RB ,_, we_PRP investigate_VBP which_WDT is_VBZ better_RBR for_IN domain_NN adaptation_NN ,_, to_TO determine_VB the_DT optimal_JJ training_NN data_NNS set_VBN according_VBG to_TO the_DT word_NN type_NN or_CC the_DT instance_NN ._.
The_DT training_NN data_NN set_NN is_VBZ au_SYM -_: tomatically_RB determined_VBN for_IN each_DT word_NN type_NN or_CC each_DT instance_NN in_IN four_CD steps_NNS :_: -LRB-_-LRB- 1_LS -RRB-_-RRB- Select_NNP some_DT instances_NNS randomly_RB from_IN the_DT whole_JJ source_NN data_NNS and_CC create_VB multiple_JJ train_NN -_: ing_NN data_NNS sets_NNS ,_, -LRB-_-LRB- 2_LS -RRB-_-RRB- Train_NN multiple_JJ classifiers_NNS based_VBN on_IN the_DT training_NN data_NNS sets_NNS -LRB-_-LRB- in_IN -LRB-_-LRB- 1_LS -RRB-_-RRB- -RRB-_-RRB- and_CC apply_VB them_PRP to_TO the_DT target_NN data_NNS ,_, -LRB-_-LRB- 3_LS -RRB-_-RRB- Compare_VBP the_DT score_NN of_IN multiple_JJ classifiers_NNS -LRB-_-LRB- in_IN -LRB-_-LRB- 2_LS -RRB-_-RRB- -RRB-_-RRB- for_IN each_DT word_NN type_NN or_CC each_DT instance_NN ,_, and_CC -LRB-_-LRB- 4_LS -RRB-_-RRB- Employ_VB the_DT classifier_NN whose_WP$ score_NN is_VBZ the_DT high_JJ -_: est_NN for_IN the_DT word_NN type_NN or_CC the_DT instance_NN ._.
We_PRP use_VBP three_CD types_NNS of_IN scores_NNS for_IN classifiers_NNS and_CC compare_VB them_PRP :_: •_CD Confidence_NN -LRB-_-LRB- Komiya_NNP and_CC Okumura_NNP ,_, 2012a_CD -RRB-_-RRB- ,_, •_FW LOO_FW :_: LOO-bound_JJ score_NN ,_, which_WDT is_VBZ the_DT score_NN based_VBN on_IN the_DT LOO-bound_JJ -LRB-_-LRB- Vapnik_NNP and_CC Chapelle_NNP ,_, 2000_CD -RRB-_-RRB- ,_, •_FW Confidence_NN *_SYM LOO_NNP :_: The_DT product_NN of_IN the_DT two_CD scores_NNS above_IN ._.
As_IN Komiya_NNP and_CC Okumura_NNP -LRB-_-LRB- Komiya_NNP and_CC Okumura_NNP ,_, 2012a_CD -RRB-_-RRB- reported_VBD ,_, the_DT degrees_NNS of_IN confidence_NN are_VBP the_DT predicted_VBN values_NNS that_WDT indicate_VBP how_WRB confident_JJ clas_NNS -_: sification_NN is_VBZ and_CC these_DT are_VBP often_RB used_VBN to_TO select_VB in_IN -_: stances_NNS to_TO be_VB labeled_VBN in_IN active-learning_NN ._.
Since_IN the_DT classifier_NN outputs_VBZ the_DT degree_NN of_IN confidence_NN per_IN in_IN -_: stance_NN ,_, we_PRP use_VBP the_DT average_NN for_IN all_PDT the_DT instances_NNS in_IN the_DT training_NN data_NN set_NN of_IN each_DT word_NN type_NN when_WRB we_PRP determine_VBP the_DT optimal_JJ training_NN data_NNS for_IN each_DT word_NN type_NN ._.
In_IN other_JJ words_NNS ,_, the_DT score_NN is_VBZ an_DT averaged_VBN value_NN that_IN indicates_VBZ how_WRB confidently_RB a_DT classifier_NN classifies_VBZ the_DT whole_JJ target_NN data_NNS of_IN each_DT word_NN ._.
We_PRP use_VBP the_DT degree_NN of_IN confidence_NN per_IN instance_NN directly_RB when_WRB we_PRP determine_VBP the_DT optimal_JJ training_NN data_NNS for_IN each_DT instance_NN ._.
Komiya_NNP and_CC Okumura_NNP -LRB-_-LRB- 2012a_JJ -RRB-_-RRB- fo_SYM -_: cused_VBN on_IN the_DT fact_NN that_IN these_DT degrees_NNS of_IN confidence_NN are_VBP output_NN from_IN classifiers_NNS as_IN the_DT probability_NN ,_, and_CC they_PRP can_MD carry_VB out_RP ensemble_NN learning_NN by_IN compar_NN -_: ing_VBG them_PRP ._.
We_PRP use_VBP the_DT same_JJ method_NN for_IN unsuper_JJ -_: vised_VBN domain_NN adaptation_NN ._.
The_DT LOO-bound_JJ score_NN is_VBZ the_DT upper_JJ bound_VBN of_IN er_SYM -_: ror_NN for_IN the_DT leave-one-out_JJ estimation_NN of_IN SVM_NNP and_CC is_VBZ calculated_VBN as_IN :_: SVi_NNP LOOoriginal_NNP ,_, i_FW =_SYM TR_NNP ,_, -LRB-_-LRB- 1_LS -RRB-_-RRB- i_FW where_WRB LOOoriginal_NNP ,_, i_FW denotes_VBZ the_DT original_JJ LOO_NNP -_: bound_VBN score_NN of_IN each_DT -LRB-_-LRB- ith_NN -RRB-_-RRB- classifier_NN ,_, and_CC SVi_NNP and_CC TRi_NNP denote_VBP the_DT number_NN of_IN support_NN vectors_NNS and_CC training_NN data_NNS of_IN each_DT classifier_NN ,_, respectively_RB ._.
How_WRB -_: ever_RB ,_, when_WRB we_PRP select_VBP the_DT suitable_JJ classifier_NN from_IN multiple_JJ classifiers_NNS ,_, it_PRP is_VBZ necessary_JJ to_TO take_VB into_IN ac_SYM -_: count_NN the_DT numbers_NNS of_IN training_NN data_NNS of_IN each_DT classi_NNS -_: fier_NN because_IN they_PRP varies_VBZ a_DT great_JJ deal_NN ._.
Therefore_RB ,_, we_PRP use_VBP LOO-bound_JJ of_IN a_DT certain_JJ classifier_NN weighted_VBN by_IN the_DT number_NN of_IN training_NN data_NNS of_IN each_DT classifier_NN ._.
LOOselecting_NNP ,_, i_FW =_SYM T_SYM R1_CD LOOoriginal_JJ ,1_CD =_SYM SV1_CD ,_, T_NNP Ri_NNP T_NNP Ri_NNP -LRB-_-LRB- 2_LS -RRB-_-RRB- where_WRB LOOselecting_NNP ,_, i_FW denotes_VBZ the_DT LOO-bound_JJ for_IN selecting_VBG the_DT training_NN data_NN set_NN ,_, TR1_NNP and_CC SV1_NNP de_IN -_: note_VB the_DT number_NN of_IN training_NN data_NNS and_CC support_NN vec_NN -_: tors_NNS of_IN a_DT certain_JJ classifier_NN in_IN multiple_JJ classifiers_NNS developed_VBN in_IN step_NN -LRB-_-LRB- 2_LS -RRB-_-RRB- respectively_RB ,_, and_CC TRi_NNP de_IN -_: notes_VBZ the_DT number_NN of_IN training_NN data_NNS of_IN each_DT clas_NNS -_: sifier_NN ._.
Since_IN SV1_NNP is_VBZ constant_JJ for_IN every_DT classifier_NN ,_, LOOselecting_NN ,_, i_FW weights_NNS the_DT number_NN of_IN training_NN data_NNS of_IN each_DT classifier_NN ._.
In_IN addition_NN ,_, the_DT weight_NN is_VBZ based_VBN on_IN SV1_NNP ,_, i.e._FW ,_, the_DT number_NN of_IN support_NN vectors_NNS of_IN a_DT certain_JJ classifier_NN ._.
We_PRP use_VBP 1_CD −_CD LOOselecting_NN ,_, i_FW in_IN -_: stead_NN of_IN LOOselecting_NNP ,_, i_FW for_IN the_DT score_NN of_IN the_DT clas_NNS -_: sifiers_NNS since_IN the_DT LOO-bound_JJ is_VBZ the_DT error_NN rate_NN ._.
Fi_SYM -_: nally_RB ,_, we_PRP use_VBP the_DT following_JJ equation_NN to_TO avoid_VB ille_SYM -_: gal_NN division_NN because_IN the_DT number_NN of_IN training_NN data_NNS could_MD be_VB zero_CD when_WRB there_EX is_VBZ only_RB a_DT single_JJ word_NN sense_NN in_IN the_DT training_NN data_NN set_NN ;_: the_DT instances_NNS are_VBP ran_VBN -_: domly_JJ selected_VBN ._.
SV1_CD +_NN 0.5_CD LOOi_NNP =_SYM 1_CD −_CD TRi_NNP +_CD 0.5_CD ,_, -LRB-_-LRB- 3_LS -RRB-_-RRB- where_WRB LOOi_NNP denotes_VBZ the_DT LOO-bound_JJ score_NN of_IN each_DT classifier_NN ._.
We_PRP are_VBP able_JJ to_TO automatically_RB determine_VB the_DT best_JJS training_NN data_NNS set_VBN using_VBG ensemble_NN learning_VBG based_VBN on_IN the_DT classifier_NN score_NN for_IN each_DT word_NN type_NN or_CC each_DT in_IN -_: stance_NN ._.
Therefore_RB ,_, we_PRP expect_VBP the_DT average_JJ accu_NN -_: racy_JJ of_IN WSD_NNP ,_, when_WRB the_DT training_NN data_NN set_NN that_WDT is_VBZ automatically_RB determined_VBN is_VBZ used_VBN for_IN each_DT word_NN type_NN or_CC each_DT instance_NN ,_, to_TO be_VB higher_JJR than_IN when_WRB the_DT whole_JJ training_NN data_NNS are_VBP collectively_RB used_VBN ._.
Nav_SYM -_: igli_NNS -LRB-_-LRB- 2009_CD -RRB-_-RRB- introduced_VBN this_DT method_NN as_IN an_DT ensem_NN -_: ble_NN approach_NN to_TO WSD_NNP and_CC called_VBD it_PRP a_DT probability_NN mixture_NN ._.
We_PRP used_VBD the_DT probability_NN mixture_NN assum_NN -_: ing_NN that_IN each_DT classifier_NN is_VBZ trained_VBN for_IN each_DT training_NN data_NN set_NN ,_, rather_RB than_IN for_IN each_DT method_NN of_IN domain_NN adaptation_NN like_IN reported_VBN in_IN -LRB-_-LRB- Komiya_NNP and_CC Okumura_NNP ,_, 2012a_CD -RRB-_-RRB- or_CC each_DT method_NN of_IN WSD_NNP like_IN introduced_VBN in_IN -LRB-_-LRB- Navigli_NNP ,_, 2009_CD -RRB-_-RRB- ._.
4_CD Experiment_NN Libsvm_NNP -LRB-_-LRB- Chang_NNP and_CC Lin_NNP ,_, 2001_CD -RRB-_-RRB- ,_, which_WDT supports_VBZ multi-class_JJ classification_NN ,_, was_VBD used_VBN as_IN the_DT classifier_NN for_IN WSD_NNP ._.
We_PRP used_VBD the_DT -_: b_NN option_NN of_IN libsvm_NN to_TO train_VB a_DT model_NN to_TO estimate_VB probability_NN for_IN the_DT degree_NN of_IN confidence_NN ._.
We_PRP trained_VBD 100_CD classifiers_NNS for_IN a_DT word_NN type_NN of_IN a_DT domain_NN of_IN source_NN data_NNS and_CC employed_VBN the_DT classifier_NN with_IN the_DT highest_JJS degree_NN of_IN confidence_NN for_IN each_DT word_NN type_NN or_CC each_DT instance_NN ._.
We_PRP randomly_RB se_FW -_: lected_VBD the_DT number_NN of_IN instances_NNS in_IN one_CD training_NN data_NN set_NN ,_, from_IN one_CD to_TO the_DT number_NN of_IN all_PDT the_DT training_NN data_NN we_PRP could_MD use_VB ,_, for_IN each_DT word_NN type_NN ._.
Since_IN the_DT exper_NN -_: iments_NNS were_VBD greatly_RB affected_VBN by_IN the_DT randomness_NN of_IN the_DT setting_NN of_IN each_DT experiment_NN ,_, we_PRP performed_VBD the_DT experiments_NNS 10_CD times_NNS and_CC evaluated_VBD the_DT averaged_VBN accuracies_NNS ._.
A_DT linear_JJ kernel_NN was_VBD used_VBN according_VBG to_TO the_DT results_NNS obtained_VBN from_IN preliminary_JJ experiments_NNS ._.
Twenty_CD features_NNS were_VBD introduced_VBN to_TO train_VB the_DT clas_NNS -_: sifier_NN ._.
•_NNP Morphological_NNP features_NNS --_: Bag-of-words_NNS --_: Part-of-speech_JJ -LRB-_-LRB- POS_NNP -RRB-_-RRB- --_: Finer_JJR subcategory_NN of_IN POS_NNP •_CD Syntactic_NNP features_NNS --_: IfthePOSofatargetwordisanoun_NNP ,_, the_DT verb_NN that_IN the_DT target_NN word_NN modifies_VBZ --_: If_IN the_DT POS_NNP of_IN a_DT target_NN word_NN is_VBZ a_DT verb_NN ,_, the_DT case_NN element_NN of_IN `_`` ヲ_FW '_'' -LRB-_-LRB- wo_MD ,_, objective_NN -RRB-_-RRB- for_IN the_DT verb_NN •_NN Semantic_JJ feature_NN --_: Semantic_JJ classification_NN code_NN Morphological_JJ features_NNS and_CC a_DT semantic_JJ feature_NN were_VBD extracted_VBN from_IN the_DT surrounding_VBG words_NNS -LRB-_-LRB- two_CD words_NNS to_TO the_DT right_NN and_CC left_VBD -RRB-_-RRB- of_IN the_DT target_NN word_NN and_CC the_DT target_NN word_NN itself_PRP ._.
POS_NNP and_CC the_DT finer_NN subcate_NN -_: gory_NN of_IN POS_NNP could_MD be_VB obtained_VBN by_IN using_VBG a_DT morpho_NN -_: logical_JJ analyzer_NN ._.
We_PRP used_VBD ChaSen_NNP 1_CD as_IN a_DT morpho_NN -_: 1_CD http://sourceforge.net/projects/masayu-a/_NN logical_JJ analyzer_NN ,_, the_DT Bunruigoihyo_NNP thesaurus_NN -LRB-_-LRB- Na_SYM -_: tional_JJ Institute_NNP for_IN Japanese_JJ Language_NN and_CC Lin_NNP -_: guistics_NNS ,_, 1964_CD -RRB-_-RRB- for_IN semantic_JJ classification_NN codes_NNS -LRB-_-LRB- e.g._FW ._.
The_DT code_NN of_IN the_DT `_`` program_NN '_'' was_VBD 1.3162_CD ._. -RRB-_-RRB-
,_, and_CC CaboCha_NNP 2_CD as_IN a_DT syntactic_JJ parser_NN ._.
Five-fold_RB cross_VB validation_NN was_VBD used_VBN in_IN the_DT experiments_NNS ._.
5_CD Data_NNP Three_CD data_NNS that_WDT were_VBD the_DT same_JJ as_IN those_DT utilized_VBN by_IN Komiya_NNP and_CC Okumura_NNP -LRB-_-LRB- Komiya_NNP and_CC Okumura_NNP ,_, 2011_CD -RRB-_-RRB- and_CC -LRB-_-LRB- Komiya_NNP and_CC Okumura_NNP ,_, 2012a_CD -RRB-_-RRB- were_VBD used_VBN for_IN the_DT experiments_NNS :_: -LRB-_-LRB- 1_LS -RRB-_-RRB- the_DT sub-corpus_NN of_IN white_JJ papers_NNS in_IN the_DT Balanced_NNP Corpus_NNP of_IN Contem_NNP -_: porary_JJ Japanese_JJ -LRB-_-LRB- BCCWJ_NNP -RRB-_-RRB- -LRB-_-LRB- Maekawa_NNP ,_, 2008_CD -RRB-_-RRB- ,_, -LRB-_-LRB- 2_LS -RRB-_-RRB- the_DT sub-corpus_NN of_IN documents_NNS from_IN a_DT Q&A_NNP site_NN on_IN the_DT WWW_NNP in_IN BCCWJ_NNP ,_, and_CC -LRB-_-LRB- 3_LS -RRB-_-RRB- Real_JJ World_NNP Com_NNP -_: puting_NN -LRB-_-LRB- RWC_NNP -RRB-_-RRB- text_NN databases_NNS -LRB-_-LRB- newspaper_NN articles_NNS -RRB-_-RRB- -LRB-_-LRB- Hashida_NNP et_FW al._FW ,_, 1998_CD -RRB-_-RRB- ._.
Domain_NN adaptation_NN was_VBD conducted_VBN in_IN three_CD directions_NNS according_VBG to_TO differ_VB -_: ent_NN source_NN and_CC target_NN data_NNS ,_, i.e._FW ,_, one_CD data_NN in_IN three_CD was_VBD used_VBN for_IN the_DT target_NN data_NNS and_CC the_DT other_JJ two_CD data_NNS were_VBD used_VBN for_IN the_DT source_NN data_NNS in_IN one_CD setting_VBG 3_CD ._.
Word_NN senses_NNS were_VBD annotated_VBN in_IN these_DT corpora_NN ac_SYM -_: cording_NN to_TO a_DT Japanese_JJ dictionary_NN ,_, i.e._FW ,_, the_DT Iwanami_NNP Kokugo_NNP Jiten_NNP -LRB-_-LRB- Nishio_NNP et_FW al._FW ,_, 1994_CD -RRB-_-RRB- ._.
It_PRP has_VBZ three_CD levels_NNS for_IN sense_NN IDs_NNS ,_, and_CC we_PRP used_VBD the_DT fine-level_JJ sense_NN in_IN the_DT experiments_NNS ._.
Multi-sense_JJ words_NNS that_WDT appeared_VBD equal_JJ or_CC more_JJR than_IN 50_CD times_NNS in_IN all_PDT the_DT data_NNS were_VBD selected_VBN as_IN the_DT target_NN words_NNS in_IN the_DT ex_FW -_: periment_NN ._.
Twenty-two_CD word_NN types_NNS were_VBD used_VBN in_IN the_DT experiments_NNS ._.
Table_NNP 1_CD lists_NNS the_DT minimum_NN ,_, max_SYM -_: imum_NN ,_, and_CC average_JJ number_NN of_IN instances_NNS of_IN each_DT word_NN type_NN for_IN each_DT corpus_NN and_CC Table_NNP 2_CD summarizes_VBZ the_DT number_NN of_IN instances_NNS of_IN WSD_NNP for_IN each_DT corpus_NN ._.
Table_NNP 3_CD summarizes_VBZ the_DT list_NN of_IN target_NN words_NNS ._.
Komiya_NNP and_CC Okumura_NNP -LRB-_-LRB- Komiya_NNP and_CC Okumura_NNP ,_, 2011_CD -RRB-_-RRB- and_CC Komiya_NNP and_CC Okumura_NNP -LRB-_-LRB- Komiya_NNP and_CC Okumura_NNP ,_, 2012b_CD -RRB-_-RRB- found_VBD that_IN the_DT optimal_JJ method_NN of_IN domain_NN adaptation_NN varied_VBD depending_VBG on_IN each_DT `_`` case_NN '_'' -LRB-_-LRB- i.e._FW ,_, a_DT triple_JJ of_IN the_DT target_NN word_NN type_NN of_IN WSD_NNP ,_, the_DT source_NN data_NNS ,_, and_CC the_DT target_NN data_NNS -RRB-_-RRB- ._.
Komiya_NNP and_CC Okumura_NNP -LRB-_-LRB- Komiya_NNP and_CC Okumura_NNP ,_, 2012a_CD -RRB-_-RRB- assumed_VBD that_IN it_PRP varied_VBD according_VBG to_TO each_DT 2_CD http://sourceforge.net/projects/cabocha/_NN 3_CD Komiya_NNP and_CC Okumura_NNP -LRB-_-LRB- Komiya_NNP and_CC Okumura_NNP ,_, 2011_CD -RRB-_-RRB- and_CC Komiya_NNP and_CC Okumura_NNP -LRB-_-LRB- Komiya_NNP and_CC Okumura_NNP ,_, 2012a_CD -RRB-_-RRB- con_NN -_: ducted_VBN domain_NN adaptation_NN in_IN six_CD directions_NNS with_IN the_DT source_NN data_NNS from_IN one_CD domain_NN and_CC the_DT target_NN data_NNS from_IN another_DT do_VBP -_: main_JJ ._.
They_PRP used_VBD multi-sense_JJ words_NNS that_WDT appeared_VBD equal_JJ or_CC more_JJR than_IN 50_CD times_NNS in_IN both_DT the_DT source_NN and_CC target_NN data_NNS ,_, whereas_IN we_PRP used_VBD multi-sense_JJ words_NNS that_WDT appeared_VBD equal_JJ or_CC more_JJR than_IN 50_CD times_NNS in_IN the_DT two_CD source_NN data_NNS and_CC the_DT target_NN data_NNS ._.
Therefore_RB ,_, we_PRP used_VBD fewer_JJR target_NN word_NN types_NNS than_IN they_PRP did_VBD ._.
Target_NN words_NNS -LRB-_-LRB- in_IN Japanese_JJ -RRB-_-RRB- 場合_FW 自分_FW 事業_FW 情報_FW 地方_FW 社会_FW 思う_FW 子供_FW 考える_FW 含む_FW 技術_FW 関係_FW 時間_FW 一般_FW 現在_FW 今_FW 前_FW 持つ_FW 見る_FW 入る_FW 言う_FW 出る_FW Genre_NN BCCWJ_NNP white_JJ papers_NNS BCCWJ_NNP Q&A_NNP site_NN RWC_NNP newspaper_NN Min_NNP ._.
Max_NNP ._.
58_CD 7,610_CD 130_CD 13,976_CD 56_CD 374_CD Avg_NNP ._.
2,240.14_CD 2,741.95_CD 183.36_CD No_DT ._.
Sense_NN example_NN of_IN senses_NNS in_IN English_NNP 2_CD case_NN Table_NNP 1_CD :_: Minimum_NNP ,_, maximum_NN ,_, and_CC average_JJ num_NN -_: ber_NN of_IN instances_NNS of_IN each_DT word_NN type_NN for_IN each_DT corpus_NN self_NN 3_CD project_NN information_NN area_NN society_NN suppose_VB child_NN 4_CD think_VBP 5_CD contain_VBP technique_NN 6_CD connection_NN time_NN general_JJ present_JJ 7_CD now_RB 8_CD before_IN 10_CD have_VBP 12_CD see_VBP 14_CD enter_VBP Target_NNP data_NNS white_JJ paper_NN Q&A_NNP site_NN newspaper_NN Total_JJ No_UH ._.
of_IN instances_NNS 49,283_CD 60,323_CD 4,034_CD 232,116_CD Table_NNP 2_CD :_: No_UH ._.
of_IN instances_NNS of_IN WSD_NNP for_IN each_DT corpus_NN instance_NN ._.
Here_RB ,_, we_PRP investigate_VBP which_WDT is_VBZ better_RBR for_IN domain_NN adaptation_NN ,_, to_TO determine_VB the_DT optimal_JJ train_NN -_: ing_NN data_NNS set_VBN according_VBG to_TO the_DT word_NN type_NN or_CC the_DT in_IN -_: stance_NN ._.
6_CD Results_NNS Table_NNP 4_CD lists_NNS the_DT micro_NN -_: and_CC macro-averaged_JJ accu_NN -_: racies_NNS of_IN WSD_NNP for_IN the_DT whole_JJ data_NN set_NN according_VBG to_TO the_DT methods_NNS of_IN domain_NN adaptation_NN and_CC Table_NNP 5_CD summarizes_VBZ the_DT micro_NN -_: and_CC macro-averaged_JJ accu_NN -_: racies_NNS of_IN WSD_NNP according_VBG to_TO the_DT corpora_NN and_CC meth_NN -_: ods_NNS of_IN domain_NN adaptation_NN ._.
We_PRP tested_VBD Self_NNP ,_, which_WDT is_VBZ standard_JJ supervised_JJ learning_NN with_IN the_DT whole_JJ target_NN data_NNS by_IN five-fold_JJ cross_NN validation_NN ,_, assuming_VBG that_IN fully_RB annotated_VBN data_NNS were_VBD obtained_VBN and_CC could_MD be_VB used_VBN for_IN learn_VBP -_: ing_NN ,_, MFS_NNP ,_, which_WDT is_VBZ the_DT most_RBS frequent_JJ sense_NN of_IN the_DT target_NN corpus_NN ,_, Averaged_VBD ,_, which_WDT is_VBZ the_DT averaged_VBN ac_SYM -_: curacies_NNS of_IN the_DT supervised_JJ learning_NN with_IN the_DT source_NN data_NNS of_IN each_DT domain_NN ,_, Bigger_JJR ,_, which_WDT is_VBZ standard_JJ su_SYM -_: pervised_JJ learning_NN with_IN the_DT bigger_JJR source_NN data_NNS in_IN two_CD domains_NNS of_IN the_DT source_NN data_NNS ,_, and_CC All_DT ,_, which_WDT is_VBZ standard_JJ supervised_JJ learning_NN with_IN all_PDT the_DT source_NN data_NNS as_IN references_NNS ._.
When_WRB the_DT target_NN data_NNS were_VBD Q_NNP &_CC A_NNP sites_NNS and_CC the_DT source_NN data_NNS were_VBD white_JJ papers_NNS and_CC newswires_NNS ,_, for_IN example_NN ,_, Averaged_VBN would_MD be_VB the_DT averaged_VBN accu_NN -_: racy_JJ of_IN the_DT two_CD accuracies_NNS of_IN the_DT Q_NNP &_CC A_NNP sites_NNS :_: those_DT of_IN the_DT classifier_NN trained_VBN with_IN all_PDT the_DT white_JJ pa_NN -_: pers_NNS and_CC with_IN all_PDT the_DT newswires_NNS ._.
Bigger_JJR would_MD be_VB the_DT accuracy_NN of_IN the_DT classifier_NN trained_VBN with_IN all_PDT the_DT newswires_NNS because_IN the_DT number_NN of_IN instances_NNS in_IN the_DT newswires_NNS was_VBD greater_JJR than_IN that_DT in_IN the_DT white_JJ pa_NN -_: pers_NNS ._.
Finally_RB ,_, All_DT would_MD be_VB the_DT accuracy_NN of_IN the_DT Q_NNP say_VBP 16_CD 22_CD leave_NN Table_NNP 3_CD :_: List_NN of_IN target_NN words_NNS &_CC A_DT sites_NNS whose_WP$ classifier_NN was_VBD trained_VBN with_IN all_PDT the_DT source_NN data_NNS ,_, i.e._FW ,_, both_DT all_PDT the_DT white_JJ papers_NNS and_CC all_PDT the_DT newswires_NNS ._.
Self_NN was_VBD an_DT upper_JJ bound_VBN and_CC Averaged_VBN ,_, Bigger_JJR ,_, and_CC All_DT were_VBD baselines_NNS ._.
Confidence_NN -LRB-_-LRB- ty_NN -RRB-_-RRB- and_CC Con_NN -_: fidence_NN -LRB-_-LRB- in_IN -RRB-_-RRB- determined_VBD the_DT optimal_JJ training_NN data_NNS set_VBN using_VBG Confidence_NN score_NN for_IN each_DT word_NN type_NN and_CC each_DT instance_NN ,_, respectively_RB ._.
Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- ty_NN -RRB-_-RRB- and_CC Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- in_IN -RRB-_-RRB- determined_VBD the_DT optimal_JJ training_NN data_NNS set_VBN using_VBG Confidence_NN *_SYM LOO_NNP score_NN for_IN each_DT word_NN type_NN and_CC each_DT instance_NN ,_, respectively_RB ._.
LOO_NNP determined_VBD the_DT optimal_JJ training_NN data_NN set_VBD us_PRP -_: ing_NN LOO_NNP score_NN for_IN only_RB each_DT word_NN type_NN because_IN the_DT system_NN output_NN LOO_NNP for_IN each_DT word_NN type_NN ._.
The_DT highest_JJS accuracies_NNS except_IN for_IN Self_NN have_VBP been_VBN writ_SYM -_: ten_CD in_IN bold_JJ for_IN each_DT corpus_NN in_IN Tables_NNP 4_CD and_CC 5_CD ._.
7_CD Discussion_NNP First_NNP ,_, Table_NNP 4_CD indicates_VBZ that_IN the_DT micro-averaged_JJ ac_NN -_: curacy_NN of_IN Bigger_JJR is_VBZ higher_JJR than_IN that_DT of_IN All_DT and_CC Ta_SYM -_: ble_NN 5_CD shows_VBZ the_DT same_JJ when_WRB the_DT target_NN data_NNS were_VBD the_DT Q_NNP &_CC A_NNP sites_NNS ,_, which_WDT means_VBZ that_IN the_DT biggest_JJS training_NN data_NNS did_VBD not_RB always_RB provide_VB the_DT highest_JJS accuracy_NN ._.
96.07_CD %_NN Micro_NNP avg_NN ._.
White_NNP papers_NNS newswires_NNS Q_NNP &_CC A_NNP sites_NNS White_NNP papers_NNS 91.53_CD %_NN newswires_NNS 79.57_CD %_NN 91.93_CD %_NN 78.59_CD %_NN 78.74_CD %_NN 68.59_CD %_NN 76.74_CD %_NN 69.81_CD %_NN 73.54_CD %_NN 80.72_CD %_NN 81.80_CD %_NN 72.94_CD %_NN 74.86_CD %_NN 75.95_CD %_NN 79.95_CD %_NN 83.50_CD %_NN 82.11_CD %_NN 77.58_CD %_NN 71.23_CD %_NN 74.39_CD %_NN 74.91_CD %_NN 74.62_CD %_NN 74.01_CD %_NN 82.43_CD %_NN 81.92_CD %_NN 82.15_CD %_NN 73.64_CD %_NN 74.54_CD %_NN 76.10_CD %_NN 76.49_CD %_NN 76.06_CD %_NN 75.53_CD %_NN 76.03_CD %_NN 82.33_CD %_NN 82.91_CD %_NN 81.95_CD %_NN 70.80_CD %_NN 75.64_CD %_NN 76.91_CD %_NN 71.95_CD %_NN 72.12_CD %_NN 77.68_CD %_NN 77.31_CD %_NN 77.54_CD %_NN 72.59_CD %_NN 73.14_CD %_NN 75.17_CD %_NN 75.51_CD %_NN 75.17_CD %_NN Target_NNP data_NNS Self_NN MFS_NNP Averaged_VBD Bigger_JJR All_DT Confidence_NN -LRB-_-LRB- ty_NN -RRB-_-RRB- Confidence_NN -LRB-_-LRB- in_IN -RRB-_-RRB- Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- ty_NN -RRB-_-RRB- Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- in_IN -RRB-_-RRB- LOO_NNP Table_NNP 5_CD :_: Average_JJ accuracies_NNS of_IN WSD_NNP according_VBG to_TO corpora_VB and_CC methods_NNS of_IN domain_NN adaptation_NN Q_NNP &_CC A_NNP sites_NNS 87.80_CD %_NN 72.93_CD %_NN 71.57_CD %_NN 72.73_CD %_NN 75.76_CD %_NN 71.93_CD %_NN 72.73_CD %_NN 76.29_CD %_NN 76.23_CD %_NN 76.30_CD %_NN Macro_NNP avg_NN ._.
Micro_NNP avg_NN ._.
93.29_CD %_NN 77.32_CD %_NN 76.92_CD %_NN 81.99_CD %_NN 81.76_CD %_NN 75.07_CD %_NN 75.10_CD %_NN 82.15_CD %_NN 82.25_CD %_NN 81.83_CD %_NN Method_NNP Self_NNP 85.97_CD %_NN MFS_NNP 73.44_CD %_NN Averaged_VBD 71.20_CD %_NN Bigger_JJR 74.25_CD %_NN All_DT 75.86_CD %_NN data_NN set_NN ._.
However_RB ,_, it_PRP is_VBZ difficult_JJ to_TO deem_VB that_IN the_DT best_JJS classifier_NN is_VBZ that_IN trained_VBN with_IN only_RB one_CD training_NN instance_NN ,_, which_WDT means_VBZ that_IN the_DT degrees_NNS of_IN confi_NN -_: dence_NN are_VBP not_RB particularly_RB trustworthy_JJ when_WRB there_EX are_VBP few_JJ instances_NNS of_IN the_DT training_NN data_NN set_NN ._.
Moreover_RB ,_, Tables_NNP 4_CD and_CC 5_CD reveal_VBP that_IN the_DT ac_NN -_: curacies_NNS of_IN LOO_NNP outperformed_VBD those_DT of_IN the_DT three_CD baselines_NNS except_IN for_IN the_DT micro-averaged_JJ accura_NN -_: cies_NNS of_IN the_DT whole_JJ data_NN set_NN and_CC those_DT when_WRB the_DT tar_NN -_: get_VB data_NNS were_VBD the_DT Q_NNP &_CC A_NNP sites_NNS ._.
We_PRP think_VBP that_IN the_DT LOO-bound_JJ score_NN was_VBD effective_JJ for_IN selecting_VBG the_DT classifier_NN because_IN it_PRP weighted_VBD the_DT number_NN of_IN the_DT training_NN data_NNS and_CC therefore_RB the_DT score_NN indicated_VBD how_WRB trustworthy_JJ the_DT classifier_NN was_VBD ._.
However_RB ,_, the_DT micro-averaged_JJ accuracy_NN for_IN the_DT whole_JJ data_NN set_NN of_IN LOO_NNP could_MD not_RB outperform_VB that_DT of_IN Bigger_JJR because_IN the_DT micro-averaged_JJ accuracy_NN of_IN Bigger_JJR was_VBD higher_JJR than_IN that_DT of_IN LOO_NNP when_WRB the_DT target_NN data_NNS were_VBD Q_NNP &_CC A_NNP sites_NNS ._.
The_DT micro_NN -_: and_CC macro-averaged_JJ accuracies_NNS of_IN Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- ty_NN -RRB-_-RRB- or_CC Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- in_IN -RRB-_-RRB- ,_, on_IN the_DT other_JJ hand_NN ,_, were_VBD the_DT best_JJS except_IN for_IN Self_NN ,_, i.e._FW ,_, the_DT upper_JJ bound_VBN ,_, for_IN the_DT whole_JJ data_NN set_NN ,_, although_IN the_DT micro-averaged_JJ accuracy_NN could_MD not_RB outper_VB -_: form_NN that_IN of_IN Bigger_JJR when_WRB the_DT target_NN data_NNS were_VBD Q_NNP &_CC A_NNP sites_NNS ._.
Although_IN the_DT differences_NNS between_IN the_DT accuracies_NNS of_IN Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- ty_NN -RRB-_-RRB- and_CC Big_JJ -_: ger_NN were_VBD not_RB statistically_RB significant_JJ ,_, the_DT differ_VBP -_: ences_NNS between_IN the_DT micro-averaged_JJ accuracies_NNS of_IN Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- in_IN -RRB-_-RRB- and_CC Bigger_JJR ,_, those_DT of_IN Con_NN -_: fidence_NN *_SYM LOO_NNP -LRB-_-LRB- ty_NN -RRB-_-RRB- and_CC All_DT ,_, and_CC those_DT of_IN Confi_NNP -_: dence_NN *_SYM LOO_NNP -LRB-_-LRB- in_IN -RRB-_-RRB- and_CC All_DT were_VBD statistically_RB signif_NN -_: icant_JJ according_VBG to_TO a_DT chi-square_JJ test_NN ._.
The_DT level_NN of_IN significance_NN in_IN the_DT test_NN was_VBD 0.05_CD ._.
We_PRP think_VBP that_IN Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- ty_NN -RRB-_-RRB- and_CC Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- in_IN -RRB-_-RRB- Macro_NNP avg_NN ._.
Confidence_NN -LRB-_-LRB- ty_NN -RRB-_-RRB- Confidence_NN -LRB-_-LRB- in_IN -RRB-_-RRB- Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- ty_NN -RRB-_-RRB- Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- in_IN -RRB-_-RRB- LOO_NNP 72.16_CD %_NN 72.66_CD %_NN 76.38_CD %_NN 76.35_CD %_NN 76.34_CD %_NN Table_NNP 4_CD :_: Average_JJ accuracies_NNS of_IN WSD_NNP for_IN whole_JJ data_NNS set_VBN Second_NNP ,_, the_DT same_JJ tables_NNS reveal_VBP that_IN the_DT accu_NN -_: racies_NNS of_IN Confidence_NN -LRB-_-LRB- ty_NN -RRB-_-RRB- and_CC Confidence_NN -LRB-_-LRB- in_IN -RRB-_-RRB- are_VBP lower_JJR than_IN those_DT of_IN the_DT three_CD baselines_NNS ._.
This_DT is_VBZ different_JJ from_IN the_DT results_NNS obtained_VBN by_IN Komiya_NNP and_CC Okumura_NNP -LRB-_-LRB- Komiya_NNP and_CC Okumura_NNP ,_, 2012a_CD -RRB-_-RRB- who_WP found_VBD that_IN it_PRP was_VBD more_RBR effective_JJ to_TO select_VB the_DT method_NN of_IN domain_NN adaptation_NN ,_, i.e._FW ,_, the_DT training_NN data_NN set_NN ,_, using_VBG the_DT degree_NN of_IN confidence_NN for_IN each_DT instance_NN ._.
We_PRP think_VBP this_DT is_VBZ because_IN the_DT correct_JJ -_: ness_NN of_IN the_DT degree_NN of_IN confidence_NN decreased_VBN when_WRB there_EX were_VBD few_JJ instances_NNS of_IN the_DT training_NN data_NN set_NN ._.
Since_IN we_PRP randomly_RB determined_VBD the_DT number_NN of_IN the_DT instances_NNS of_IN the_DT training_NN data_NN set_NN ,_, the_DT classifiers_NNS were_VBD sometimes_RB trained_VBN with_IN a_DT small_JJ number_NN of_IN in_IN -_: stances_NNS and_CC this_DT affected_VBD the_DT decline_NN in_IN accuracies_NNS ._.
When_WRB the_DT training_NN data_NN set_NN included_VBD only_RB one_CD in_IN -_: stance_NN ,_, for_IN example_NN ,_, the_DT degree_NN of_IN confidence_NN was_VBD one_CD ,_, which_WDT was_VBD the_DT highest_JJS value_NN ,_, because_IN there_EX was_VBD no_DT other_JJ alternative_JJ word_NN sense_NN in_IN the_DT training_NN were_VBD the_DT best_JJS because_IN it_PRP selected_VBD the_DT most_RBS suitable_JJ classifier_NN for_IN each_DT target_NN data_NNS ._.
LOO_NNP returned_VBD the_DT same_JJ score_NN for_IN any_DT target_NN data_NNS if_IN the_DT training_NN data_NNS were_VBD the_DT same_JJ ,_, but_CC Confidence_NNP returned_VBD the_DT score_NN for_IN each_DT combination_NN of_IN the_DT training_NN data_NN set_NN and_CC each_DT instance_NN of_IN the_DT target_NN data_NNS ._.
Moreover_RB ,_, the_DT macro-average_JJ accuracies_NNS of_IN Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- ty_NN -RRB-_-RRB- ,_, Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- in_IN -RRB-_-RRB- ,_, and_CC LOO_NNP outperformed_VBD those_DT of_IN the_DT three_CD baselines_NNS al_SYM -_: though_IN the_DT differences_NNS were_VBD not_RB statistically_RB sig_NN -_: nificant_NN because_IN there_EX were_VBD few_JJ samples_NNS for_IN these_DT ._.
This_DT indicated_VBD that_IN these_DT criteria_NNS could_MD be_VB used_VBN to_TO select_VB a_DT better_JJR training_NN data_NNS set_VBN even_RB for_IN target_NN data_NNS with_IN fewer_JJR instances_NNS ._.
Next_JJ ,_, we_PRP investigate_VBP which_WDT is_VBZ better_RBR for_IN domain_NN adaptation_NN ,_, to_TO determine_VB the_DT optimal_JJ training_NN data_NNS set_VBN according_VBG to_TO the_DT word_NN type_NN or_CC the_DT instance_NN ._.
Ta_SYM -_: bles_NNS 4_CD and_CC 5_CD revealed_VBD that_IN the_DT best_JJS method_NN of_IN do_VBP -_: main_JJ adaptation_NN of_IN each_DT target_NN corpus_NN was_VBD Confi_NNP -_: dence_NN *_SYM LOO_NNP -LRB-_-LRB- ty_NN -RRB-_-RRB- or_CC Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- in_IN -RRB-_-RRB- except_IN for_IN the_DT micro_NN -_: and_CC macro-accuracies_NNS of_IN Q_NNP &_CC A_NNP sites_NNS ;_: the_DT best_JJS methods_NNS were_VBD Bigger_JJR and_CC LOO_NNP for_IN the_DT micro_NN -_: and_CC macro-accuracy_NN of_IN Q_NNP &_CC A_NNP sites_NNS ,_, respectively_RB ._.
The_DT same_JJ tables_NNS also_RB show_VBP that_IN the_DT differences_NNS amang_JJ accuracies_NNS of_IN Confi_NNP -_: dence_NN *_SYM LOO_NNP -LRB-_-LRB- ty_NN -RRB-_-RRB- ,_, Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- in_IN -RRB-_-RRB- ,_, and_CC LOO_NNP are_VBP not_RB so_RB big_JJ ._.
This_DT indicates_VBZ that_IN the_DT effect_NN of_IN Confidence_NN *_SYM LOO_NNP mainly_RB comes_VBZ from_IN LOO_NNP and_CC the_DT unit_NN for_IN selecting_VBG the_DT optimal_JJ training_NN data_NN set_NN ,_, i.e._FW ,_, the_DT word_NN type_NN or_CC the_DT instance_NN ,_, dose_NN not_RB affect_VB the_DT results_NNS so_RB much_RB although_IN the_DT effect_NN of_IN Confi_NNP -_: dence_NN did_VBD improved_VBN the_DT accuracies_NNS ._.
However_RB ,_, although_IN the_DT differences_NNS are_VBP not_RB so_RB big_JJ ,_, Table_NNP 5_CD indicates_VBZ that_IN the_DT best_JJS methods_NNS varies_VBZ according_VBG to_TO the_DT target_NN corpus_NN ;_: the_DT best_JJS method_NN is_VBZ Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- ty_NN -RRB-_-RRB- for_IN white_JJ papers_NNS and_CC it_PRP is_VBZ Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- in_IN -RRB-_-RRB- for_IN newswires_NNS ._.
We_PRP think_VBP that_IN it_PRP is_VBZ associated_VBN with_IN the_DT balance_NN of_IN the_DT senses_NNS in_IN the_DT target_NN corpus_NN ._.
As_IN Table_NNP 5_CD shows_NNS ,_, the_DT ratio_NN of_IN MFS_NNP for_IN white_JJ papers_NNS is_VBZ highest_JJS and_CC that_IN for_IN newswires_NNS is_VBZ the_DT lowest_JJS ._.
Therefore_RB ,_, we_PRP think_VBP that_IN Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- ty_NN -RRB-_-RRB- is_VBZ the_DT best_JJS for_IN white_JJ papers_NNS because_IN it_PRP is_VBZ better_JJR than_IN Confi_NNP -_: dence_NN *_SYM LOO_NNP -LRB-_-LRB- in_IN -RRB-_-RRB- when_WRB the_DT senses_NNS are_VBP biased_VBN ._.
Like_IN -_: wise_JJ ,_, we_PRP think_VBP that_IN Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- in_IN -RRB-_-RRB- is_VBZ the_DT best_JJS for_IN newswires_NNS because_IN it_PRP is_VBZ better_JJR than_IN Con_NN -_: fidence_NN *_SYM LOO_NNP -LRB-_-LRB- ty_NN -RRB-_-RRB- when_WRB the_DT senses_NNS are_VBP balanced_VBN ._.
It_PRP indicates_VBZ that_IN the_DT system_NN should_MD determine_VB the_DT op_SYM -_: timal_JJ training_NN data_NNS set_VBN according_VBG to_TO the_DT word_NN type_NN when_WRB the_DT senses_NNS of_IN the_DT target_NN corpus_NN are_VBP biased_VBN and_CC it_PRP should_MD determine_VB them_PRP according_VBG to_TO the_DT instance_NN when_WRB the_DT senses_NNS of_IN the_DT target_NN corpus_NN are_VBP balanced_VBN ._.
Finally_RB ,_, Table_NNP 4_CD demonstrates_VBZ that_IN Confi_NNP -_: dence_NN *_SYM LOO_NNP -LRB-_-LRB- in_IN -RRB-_-RRB- is_VBZ the_DT best_JJS for_IN micro-averaged_JJ ac_SYM -_: curacy_NN and_CC Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- ty_NN -RRB-_-RRB- is_VBZ the_DT best_JJS for_IN macro-averaged_JJ accuracy_NN for_IN the_DT whole_JJ data_NN set_NN ._.
We_PRP think_VBP this_DT is_VBZ because_IN the_DT method_NN that_WDT select_VBP training_NN data_NNS set_VBN for_IN each_DT word_NN type_NN ,_, i.e._FW ,_, Confi_NNP -_: dence_NN *_SYM LOO_NNP -LRB-_-LRB- ty_NN -RRB-_-RRB- ,_, improves_VBZ the_DT word_NN type_NN based_VBN accuracy_NN ,_, i.e._FW ,_, macro-averaged_JJ accuracy_NN and_CC the_DT method_NN that_WDT select_VBP training_NN data_NNS set_VBN for_IN each_DT in_IN -_: stance_NN ,_, i.e._FW ,_, Confidence_NN *_SYM LOO_NNP -LRB-_-LRB- in_IN -RRB-_-RRB- ,_, improves_VBZ the_DT instance_NN based_VBN accuracy_NN ,_, i.e._FW ,_, micro-averaged_JJ ac_SYM -_: curacy_NN ._.
8_CD Conclusion_NN This_DT paper_NN described_VBD how_WRB to_TO automatically_RB select_VB the_DT training_NN data_NN set_VBN by_IN using_VBG two_CD criteria_NNS ,_, the_DT degree_NN of_IN confidence_NN and_CC the_DT LOO-bound_JJ score_NN when_WRB there_EX were_VBD multiple_JJ domain_NN source_NN data_NNS for_IN unsupervised_JJ domain_NN adaptation_NN in_IN WSD_NNP ._.
We_PRP se_FW -_: lected_VBD a_DT suitable_JJ training_NN data_NNS set_VBN using_VBG the_DT degree_NN of_IN confidence_NN ,_, the_DT score_NN based_VBN on_IN a_DT LOO-bound_JJ ,_, and_CC their_PRP$ product_NN ._.
The_DT method_NN with_IN the_DT product_NN of_IN two_CD criteria_NNS demonstrated_VBD the_DT best_JJS micro_NN -_: and_CC macro-averaged_JJ accuracies_NNS ._.
We_PRP also_RB investigated_VBD which_WDT was_VBD better_JJR for_IN domain_NN adaptation_NN ,_, to_TO deter_VB -_: mine_NN the_DT optimal_JJ training_NN data_NNS set_VBN according_VBG to_TO the_DT word_NN type_NN or_CC the_DT instance_NN ._.
Although_IN the_DT differ_VBP -_: ences_NNS between_IN accuracies_NNS of_IN the_DT units_NNS for_IN selecting_VBG the_DT training_NN data_NN set_NN ,_, i.e._FW ,_, the_DT word_NN type_NN or_CC the_DT in_IN -_: stance_NN ,_, were_VBD not_RB so_RB big_JJ ,_, the_DT experimental_JJ results_NNS indicated_VBD that_IN the_DT system_NN should_MD determine_VB the_DT op_SYM -_: timal_JJ training_NN data_NNS set_VBN according_VBG to_TO the_DT word_NN type_NN when_WRB the_DT senses_NNS of_IN the_DT target_NN corpus_NN are_VBP biased_VBN and_CC it_PRP should_MD determine_VB them_PRP according_VBG to_TO the_DT in_IN -_: stance_NN when_WRB the_DT senses_NNS of_IN the_DT target_NN corpus_NN are_VBP bal_SYM -_: anced_VBN ._.
Finally_RB ,_, the_DT differences_NNS between_IN the_DT micro_NN -_: averaged_VBD accuracies_NNS of_IN the_DT proposed_VBN method_NN ,_, i.e._FW ,_, the_DT method_NN with_IN the_DT product_NN of_IN two_CD criteria_NNS for_IN the_DT instances_NNS ,_, and_CC three_CD baselines_NNS were_VBD significant_JJ ac_SYM -_: cording_NN to_TO a_DT chi-square_JJ test_NN ._.
References_NNS Eneko_NNP Agirre_NNP and_CC Oier_NNP Lopez_NNP de_IN Lacalle_NNP ._.
2008_CD ._.
On_IN robustness_NN and_CC domain_NN adaptation_NN using_VBG svd_NN for_IN word_NN sense_NN disambiguation_NN ._.
In_IN Proceedings_NNP of_IN the_DT 22nd_JJ International_NNP Conference_NNP on_IN Computational_NNP Linguistics_NNP ,_, pages_NNS 17_CD --_: 24_CD ._.
Eneko_NNP Agirre_NNP and_CC Oier_NNP Lopez_NNP de_IN Lacalle_NNP ._.
2009_CD ._.
Su_SYM -_: pervised_JJ domain_NN adaption_NN for_IN wsd_NN ._.
In_IN Proceedings_NNP of_IN the_DT 12th_JJ Conference_NN of_IN the_DT European_JJ Chapter_NN of_IN the_DT Association_NNP of_IN Computational_NNP Linguistics_NNP ,_, pages_NNS 42_CD --_: 50_CD ._.
John_NNP Blitzer_NNP ,_, Ryan_NNP McDonald_NNP ,_, and_CC Fernando_NNP Pereira_NNP ._.
2006_CD ._.
Domain_NN adaptation_NN with_IN structural_JJ coppe_NN -_: spondence_NN learning_NN ._.
In_IN Proceedings_NNP of_IN the_DT 2006_CD Conference_NN on_IN Empirical_JJ Methods_NNS in_IN Natural_JJ Lan_SYM -_: guage_NN Processing_NNP ,_, pages_NNS 120_CD --_: 128_CD ._.
Yee_NNP Seng_NNP Chan_NNP and_CC Hwee_NNP Tou_NNP Ng_NNP ._.
2006_CD ._.
Estimat_SYM -_: ing_NN class_NN priors_NNS in_IN domain_NN adaptation_NN for_IN word_NN sense_NN disambiguation_NN ._.
In_IN Proceedings_NNP of_IN the_DT 21st_CD Interna_NNP -_: tional_JJ Conference_NN on_IN Computational_NNP Linguistics_NNPS and_CC 44th_JJ Annual_JJ Meeting_VBG of_IN the_DT Association_NNP for_IN Compu_NNP -_: tational_JJ Linguistics_NNP ,_, pages_NNS 89_CD --_: 96_CD ._.
Yee_NNP Seng_NNP Chan_NNP and_CC Hwee_NNP Tou_NNP Ng_NNP ._.
2007_CD ._.
Domain_NN adaptation_NN with_IN active_JJ learning_NN for_IN word_NN sense_NN dis_SYM -_: ambiguation_NN ._.
In_IN Proceedings_NNP of_IN the_DT 45th_JJ Annual_JJ Meeting_VBG of_IN the_DT Association_NNP of_IN Computational_NNP Lin_NNP -_: guistics_NNS ,_, pages_NNS 49_CD --_: 56_CD ._.
Chih-Chung_NNP Chang_NNP and_CC Chih-Jen_NNP Lin_NNP ,_, 2001_CD ._.
LIBSVM_NNP :_: a_DT library_NN for_IN support_NN vector_NN machines_NNS ._.
Software_NNP available_JJ at_IN http://www.csie.ntu.edu.tw/_JJ cjlin/libsvm_NN ._.
Hal_NNP Daume_NNP ́_CD III_NNP ,_, Abhishek_NNP Kumar_NNP ,_, and_CC Avishek_NNP Saha_NNP ._.
2010_CD ._.
Frustratingly_RB easy_JJ semi-supervised_JJ domain_NN adaptation_NN ._.
In_IN Proceedings_NNP of_IN the_DT 2010_CD Workshop_NNP on_IN Domain_NNP Adaptation_NNP for_IN Natural_NNP Language_NNP Pro-_NNP cessing_NN ,_, ACL_NNP 2010_CD ,_, pages_NNS 23_CD --_: 59_CD ._.
Hal_NNP Daume_NNP ́_CD III_NNP ._.
2007_CD ._.
Frustratingly_RB easy_JJ domain_NN adap_SYM -_: tation_NN ._.
In_IN Proceedings_NNP of_IN the_DT 45th_JJ Annual_JJ Meeting_VBG of_IN the_DT Association_NNP of_IN Computational_NNP Linguistics_NNP ,_, pages_NNS 256_CD --_: 263_CD ._.
Keiko_NNP Harimoto_NNP ,_, Yusuke_NNP Miyao_NNP ,_, and_CC Jun_NN '_'' ichi_FW Tsu_SYM -_: jii_FW ._.
2010_CD ._.
Kobunkaiseki_NNP no_DT bunyatekiou_NN ni_NN okeru_NN seido_NN teika_FW youin_FW no_DT bunseki_NN oyobi_NN bunyakan_NN kyori_FW no_DT sokutei_NN syuhou_NN ,_, in_IN japanese_JJ ._.
In_IN Proceedings_NNP of_IN NLP2010_NNP -LRB-_-LRB- In_IN Japanese_JJ -RRB-_-RRB- ,_, pages_NNS 27_CD --_: 30_CD ._.
Koichi_NNP Hashida_NNP ,_, Hitoshi_NNP Isahara_NNP ,_, Takenobu_NNP Tokunaga_NNP ,_, Minako_NNP Hashimoto_NNP ,_, Shiho_NNP Ogino_NNP ,_, and_CC Wakako_NNP Kashino_NNP ._.
1998_CD ._.
The_DT rwc_NN text_NN databases_NNS ._.
In_IN Proceed_NNP -_: ings_NNS of_IN the_DT First_NNP International_NNP Conference_NNP on_IN Lan_NNP -_: guage_NN Resource_NNP and_CC Evaluation_NNP ,_, pages_NNS 457_CD --_: 461_CD ._.
Jing_VBG Jiang_NNP and_CC ChengXiang_NNP Zhai_NNP ._.
2007_CD ._.
Instance_NN weighting_NN for_IN domain_NN adaptation_NN in_IN nlp_NN ._.
In_IN Proceed_NNP -_: ings_NNS of_IN the_DT 45th_JJ Annual_JJ Meeting_VBG of_IN the_DT Association_NNP of_IN Computational_NNP Linguistics_NNP ,_, pages_NNS 264_CD --_: 271_CD ._.
Kanako_NNP Komiya_NNP and_CC Manabu_NNP Okumura_NNP ._.
2011_CD ._.
Auto_NN -_: matic_JJ determination_NN of_IN a_DT domain_NN adaptation_NN method_NN for_IN word_NN sense_NN disambiguation_NN using_VBG decision_NN tree_NN learning_NN ._.
In_IN Proceedings_NNP of_IN the_DT 5th_JJ International_NNP Joint_NNP Conference_NNP on_IN Natural_NNP Language_NNP Processing_NNP ,_, IJCNLP_NNP 2011_CD ,_, pages_NNS 1107_CD --_: 1115_CD ._.
Kanako_NNP Komiya_NNP and_CC Manabu_NNP Okumura_NNP ._.
2012a_NNS ._.
Au_SYM -_: tomatic_JJ domain_NN adaptation_NN for_IN word_NN sense_NN disam_NN -_: biguation_NN based_VBN on_IN comparison_NN of_IN multiple_JJ classi_NNS -_: fiers_NNS ._.
In_IN PACLIC_NNP 2012_CD ,_, pages_NNS 77_CD --_: 85_CD ._.
Kanako_NNP Komiya_NNP and_CC Manabu_NNP Okumura_NNP ._.
2012b_JJ ._.
Au_SYM -_: tomatic_JJ selection_NN of_IN domain_NN adaptation_NN method_NN for_IN wsd_NN using_VBG decision_NN tree_NN learning_NN ._.
Journal_NNP of_IN NLP_NNP -LRB-_-LRB- In_IN Japanese_JJ -RRB-_-RRB- ,_, 19_CD -LRB-_-LRB- 3_LS -RRB-_-RRB- :143_CD --_: 166_CD ._.
Kikuo_NNP Maekawa_NNP ._.
2008_CD ._.
Balanced_JJ corpus_NN of_IN con_NN -_: temporary_JJ written_JJ japanese_NN ._.
In_IN Proceedings_NNP of_IN the_DT 6th_JJ Workshop_NNP on_IN Asian_NNP Language_NNP Resources_NNP -LRB-_-LRB- ALR_NNP -RRB-_-RRB- ,_, pages_NNS 101_CD --_: 102_CD ._.
David_NNP McClosky_NNP ,_, Eugene_NNP Charniak_NNP ,_, and_CC Mark_NNP John_NNP -_: son_NN ._.
2010_CD ._.
Automatic_NNP domain_NN adaptation_NN for_IN pars_NNS -_: ing_NN ._.
In_IN Proceedings_NNP of_IN the_DT 2010_CD Annual_JJ Conference_NN of_IN the_DT North_JJ American_JJ Chapter_NN of_IN the_DT Association_NNP for_IN Computational_NNP Linguistics_NNP ,_, pages_NNS 28_CD --_: 36_CD ._.
National_NNP Institute_NNP for_IN Japanese_JJ Language_NN and_CC Linguis_NNP -_: tics_NNS ._.
1964_CD ._.
Bunruigoihyo_NNP ._.
Shuuei_NNP Shuppan_NNP ,_, In_IN Japanese_JJ ._.
Roberto_NNP Navigli_NNP ._.
2009_CD ._.
Word_NN sense_NN disambiguation_NN :_: A_DT survey_NN ._.
ACM_NNP Comput_NNP ._.
Surv._NNP ,_, 41_CD -LRB-_-LRB- 2_LS -RRB-_-RRB- :1_CD --_: 69_CD ._.
Minoru_NNP Nishio_NNP ,_, Etsutaro_NNP Iwabuchi_NNP ,_, and_CC Shizuo_NNP Mizu_NNP -_: tani_NNS ._.
1994_CD ._.
Iwanami_NNP Kokugo_NNP Jiten_NNP Dai_NNP Go_NNP Han_NNP ._.
Iwanami_NNP Publisher_NNP ,_, In_IN Japanese_JJ ._.
Rajat_NNP Raina_NNP ,_, Alexis_NNP Battle_NNP ,_, Honglak_NNP Lee_NNP ,_, Benjamin_NNP Packer_NNP ,_, and_CC Andrew_NNP Y._NNP Ng_NNP ._.
2007_CD ._.
Self-taught_JJ learn_VBP -_: ing_NN :_: Transfer_VB learning_VBG from_IN unlabeled_JJ data_NNS ._.
In_IN ICML_NNP '_POS 07_CD :_: Proceedings_NNP of_IN the_DT 24th_JJ international_JJ confer_VBP -_: ence_NN on_IN Machine_NN learning_NN ,_, pages_NNS 759_CD --_: 766_CD ._.
Gokhan_NNP Tur_NNP ._.
2009_CD ._.
Co-adaptation_NN :_: Adaptive_JJ co_SYM -_: training_NN for_IN semi-supervised_JJ learning_NN ._.
In_IN Proceed_NNP -_: ings_NNS of_IN the_DT IEEE_NNP International_NNP Conference_NNP on_IN Acous_NNP -_: tics_NNS ,_, Speech_NNP and_CC Signal_NNP Processing_NNP ,_, 2009_CD ._.
ICASSP_NNP 2009._CD ,_, pages_NNS 3721_CD --_: 3724_CD ._.
Vincent_NNP van_NNP Asch_NNP and_CC Walter_NNP Daelemans_NNP ._.
2010_CD ._.
Us_NNP -_: ing_NN domain_NN similarity_NN for_IN performance_NN estimation_NN ._.
In_IN Proceedings_NNP of_IN the_DT 2010_CD Workshop_NNP on_IN Domain_NNP Adaptation_NNP for_IN Natural_NNP Language_NNP Processing_NNP ,_, ACL_NNP 2010_CD ,_, pages_NNS 31_CD --_: 36_CD ._.
V._NNP Vapnik_NNP and_CC O._NNP Chapelle_NNP ._.
2000_CD ._.
Bounds_NNS on_IN error_NN ex_FW -_: pectation_NN for_IN support_NN vector_NN machines_NNS ._.
Neural_JJ Com_NNP -_: put._NN ,_, 12_CD -LRB-_-LRB- 9_CD -RRB-_-RRB- :2013_CD --_: 2036_CD ._.
Erheng_NNP Zhong_NNP ,_, Wei_NNP Fan_NNP ,_, Jing_NNP Peng_NNP ,_, Kun_NNP Zhang_NNP ,_, Jiang_NNP -_: tao_NN Ren_NNP ,_, Deepak_NNP Turaga_NNP ,_, and_CC Olivier_NNP Verscheure_NNP ._.
2009_CD ._.
Cross_NNP domain_NN distribution_NN adaptation_NN via_IN ker_NN -_: nel_NN mapping_NN ._.
In_IN Proceedings_NNP of_IN the_DT 15th_JJ ACM_NNP SIGKDD_NNP international_JJ conference_NN on_IN Knowledge_NN discovery_NN and_CC data_NNS mining_NN ,_, pages_NNS 1027_CD --_: 1036_CD ._.
