Trouble_NN information_NN extraction_NN based_VBN on_IN a_DT bootstrap_JJ approach_NN from_IN Twitter_NNP Abstract_NNP In_IN this_DT paper_NN ,_, we_PRP propose_VBP a_DT method_NN for_IN ex_FW -_: tracting_VBG trouble_NN information_NN from_IN Twitter_NNP ._.
One_CD useful_JJ approach_NN is_VBZ based_VBN on_IN machine_NN learn_VBP -_: ing_NN techniques_NNS such_JJ as_IN SVMs_NNS ._.
However_RB ,_, trou_SYM -_: ble_NN information_NN is_VBZ a_DT fraction_NN of_IN a_DT percent_NN of_IN all_DT tweets_NNS on_IN Twitter_NNP ._.
In_IN general_JJ ,_, imbalanced_JJ distribution_NN is_VBZ not_RB suitable_JJ for_IN machine_NN learn_VBP -_: ing_NN techniques_NNS to_TO generate_VB a_DT classifier_NN ._.
An_DT -_: other_JJ approach_NN is_VBZ to_TO extract_VB trouble_NN informa_NN -_: tion_NN by_IN using_VBG handwritten_JJ rules_NNS ._.
However_RB ,_, constructing_VBG high_JJ coverage_NN rules_NNS by_IN handwork_NN is_VBZ costly_JJ ._.
First_RB ,_, we_PRP verify_VBP these_DT problems_NNS in_IN a_DT preliminary_JJ experiment_NN ._.
Then_RB ,_, to_TO solve_VB these_DT problems_NNS ,_, we_PRP apply_VBP a_DT bootstrapping_NN method_NN to_TO our_PRP$ trouble_NN information_NN extraction_NN task_NN ._.
We_PRP introduce_VBP three_CD characteristics_NNS and_CC a_DT scoring_VBG method_NN to_TO the_DT bootstrapping_NN ._.
As_IN a_DT result_NN ,_, the_DT iteration_NN process_NN on_IN the_DT bootstrapping_NN in_IN -_: creased_VBD the_DT number_NN of_IN tweets_NNS and_CC patterns_NNS for_IN trouble_NN information_NN dramatically_RB ._.
1_CD Introduction_NNP The_NNP World_NNP Wide_NNP Web_NNP contains_VBZ a_DT huge_JJ number_NN of_IN on_IN -_: line_NN documents_NNS that_WDT are_VBP easily_RB accessible_JJ ._.
Analysis_NN of_IN the_DT documents_NNS has_VBZ an_DT important_JJ role_NN for_IN natural_JJ language_NN processing_NN ._.
One_CD of_IN the_DT important_JJ informa_NN -_: tion_NN for_IN business_NN companies_NNS is_VBZ trouble_NN information_NN of_IN a_DT product_NN as_IN the_DT risk_NN management_NN ._.
If_IN they_PRP can_MD mon_VB -_: itor_VB the_DT information_NN about_IN products_NNS and_CC the_DT troubles_NNS from_IN the_DT Web_NNP automatically_RB ,_, they_PRP might_MD be_VB able_JJ to_TO avoid_VB critical_JJ damages_NNS by_IN realizing_VBG the_DT risk_NN in_IN ad_NN -_: vance_NN ._.
Therefore_RB trouble_NN information_NN extraction_NN is_VBZ a_DT significant_JJ task_NN in_IN business_NN ._.
There_EX are_VBP many_JJ stud_NN -_: ies_NNS which_WDT handled_VBD news_NN articles_NNS -LRB-_-LRB- Sakai_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- ,_, review_NN documents_NNS -LRB-_-LRB- Ivanov_NNP and_CC Tutubalina_NNP ,_, 2014_CD -RRB-_-RRB- ,_, financial_JJ documents_NNS -LRB-_-LRB- Leider_NNP and_CC Schilder_NNP ,_, 2010_CD -RRB-_-RRB- ,_, daily_JJ reports_NNS -LRB-_-LRB- Kakimoto_NNP and_CC Yamamoto_NNP ,_, 2008_CD -RRB-_-RRB- ,_, a_DT failure_NN database_NN on_IN the_DT Web_NNP -LRB-_-LRB- Awano_NNP et_FW al._FW ,_, 2012_CD -RRB-_-RRB- and_CC so_RB on_IN ,_, as_IN the_DT target_NN data_NNS ._.
However_RB ,_, these_DT in_IN -_: formation_NN sources_NNS are_VBP not_RB usually_RB instantaneous_JJ and_CC exhaustive_JJ ._.
To_TO solve_VB this_DT problem_NN ,_, we_PRP focus_VBP on_IN Twit_NN -_: ter_NN ._.
It_PRP is_VBZ one_CD of_IN the_DT most_RBS famous_JJ microblogging_NN ser_NN -_: vices_NNS and_CC text-based_JJ posts_NNS of_IN up_RB to_TO 140_CD characters_NNS ._.
The_DT posted_VBN sentences_NNS are_VBP described_VBN as_IN ``_`` tweets_NNS ._. ''_''
We_PRP suppose_VBP users_NNS on_IN Twitter_NNP often_RB post_VBP tweets_NNS with_IN trou_SYM -_: ble_NN information_NN because_IN they_PRP tend_VBP to_TO post_VB tweets_NNS as_IN lifelog_NN data_NNS in_IN real_JJ time_NN ._.
Some_DT researchers_NNS focused_VBD on_IN the_DT characteristic_JJ -LRB-_-LRB- Aramaki_NNP et_FW al._FW ,_, 2011_CD ;_: Sakaki_NNP et_FW al._FW ,_, 2010_CD ;_: Shimada_NNP et_FW al._FW ,_, 2012_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, we_PRP propose_VBP a_DT method_NN to_TO extract_VB trou_SYM -_: ble_NN information_NN from_IN Twitter_NNP ._.
One_CD of_IN the_DT most_RBS com_NN -_: mon_NN approaches_NNS is_VBZ to_TO classify_VB an_DT input_NN into_IN trouble_NN information_NN and_CC non-trouble_JJ information_NN by_IN using_VBG a_DT machine_NN learning_VBG technique_NN ._.
However_RB ,_, most_JJS of_IN the_DT tweets_NNS do_VBP not_RB relate_VB to_TO trouble_NN information_NN ._.
In_IN other_JJ word_NN ,_, the_DT ratio_NN of_IN trouble_NN tweets_NNS and_CC non-trouble_JJ tweets_NNS is_VBZ biased_VBN ._.
Such_JJ biased_VBN data_NNS generally_RB gen_SYM -_: erate_VB a_DT unsuitable_JJ classifier_NN ._.
Another_DT approach_NN is_VBZ to_TO extract_VB trouble_NN information_NN by_IN using_VBG handwritten_JJ rules_NNS ._.
However_RB ,_, constructing_VBG high_JJ coverage_NN rules_NNS by_IN handwork_NN is_VBZ usually_RB a_DT difficult_JJ task_NN ._.
In_IN this_DT paper_NN ,_, we_PRP investigate_VBP these_DT problems_NNS through_IN a_DT preliminary_JJ experiment_NN ._.
On_IN the_DT basis_NN of_IN the_DT result_NN ,_, we_PRP intro_VBP -_: duce_VB a_DT bootstrapping_NN approach_NN to_TO our_PRP$ trouble_NN infor_NN -_: mation_NN extraction_NN task_NN ._.
Methods_NNS based_VBN on_IN bootstrap_NN -_: ping_NN techniques_NNS are_VBP one_CD of_IN the_DT effective_JJ approaches_NNS to_TO extract_VB information_NN -LRB-_-LRB- Riloff_NNP and_CC Jones_NNP ,_, 1999_CD ;_: Et_SYM -_: zioni_NNS et_FW al._FW ,_, 2004_CD -RRB-_-RRB- ._.
Riloff_NNP et_FW al._FW -LRB-_-LRB- 2013_CD -RRB-_-RRB- have_VBP pro-_JJ posed_VBD a_DT method_NN to_TO identify_VB sarcastic_JJ tweets_NNS by_IN using_VBG a_DT bootstrapping_NN algorithm_NN ._.
Ohmori_NNP and_CC Mori_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- have_VBP proposed_VBN a_DT method_NN based_VBN on_IN a_DT bootstrapping_NN approach_NN with_IN words_NNS and_CC phrases_NNS for_IN searching_VBG for_IN failure_NN cases_NNS among_IN products_NNS ._.
We_PRP focus_VBP on_IN trouble_NN expressions_NNS which_WDT indicate_VBP the_DT malfunction_NN and_CC fail_VB -_: ure_NN of_IN products_NNS ._.
We_PRP apply_VBP the_DT trouble_NN expressions_NNS as_IN seeds_NNS into_IN a_DT bootstrapping_NN approach_NN ._.
By_IN the_DT iter_NN -_: ation_NN process_NN ,_, our_PRP$ method_NN obtains_VBZ more_RBR trouble_NN ex_FW -_: pressions_NNS ,_, and_CC then_RB extracts_VBZ tweets_NNS with_IN trouble_NN in_IN -_: formation_NN ._.
2_CD Related_JJ work_NN Trouble_NN identification_NN is_VBZ one_CD category_NN in_IN sentiment_NN analysis_NN -LRB-_-LRB- Pang_NNP and_CC Lee_NNP ,_, 2008_CD -RRB-_-RRB- ._.
The_DT classification_NN into_IN trouble_NN or_CC non-trouble_JJ is_VBZ similar_JJ to_TO the_DT classi_NNS -_: fication_NN into_IN positive_JJ or_CC negative_JJ -LRB-_-LRB- Pang_NNP et_FW al._FW ,_, 2002_CD ;_: Turney_NNP ,_, 2002_CD -RRB-_-RRB- ._.
However_RB ,_, negative_JJ opinions_NNS are_VBP not_RB always_RB equal_JJ to_TO trouble_NN information_NN ._.
For_IN example_NN ,_, ``_`` I_PRP do_VBP n't_RB like_VB this_DT product_NN ''_'' is_VBZ a_DT negative_JJ opinion_NN ,_, but_CC not_RB trouble_NN information_NN ._.
Therefore_RB ,_, they_PRP should_MD be_VB distinguished_VBN ._.
Saeger_NNP et_FW al._FW -LRB-_-LRB- 2008_CD -RRB-_-RRB- have_VBP proposed_VBN a_DT method_NN to_TO extract_VB object-trouble_JJ relations_NNS from_IN the_DT Web_NNP ._.
They_PRP acquired_VBD trouble_NN expressions_NNS by_IN an_DT unsupervised_JJ method_NN ,_, and_CC then_RB classify_VBP them_PRP by_IN using_VBG SVMs_NNS ._.
Gupta_NNP -LRB-_-LRB- 2011_CD -RRB-_-RRB- has_VBZ proposed_VBN a_DT method_NN to_TO extract_VB prob_SYM -_: lem_NN information_NN using_VBG a_DT machine_NN learning_VBG technique_NN from_IN Twitter_NNP ._.
As_IN the_DT two_CD papers_NNS mentioned_VBN ,_, the_DT trou_NN -_: ble_NN descriptions_NNS in_IN the_DT training_NN data_NNS were_VBD rare_JJ ,_, less_JJR than_IN 10_CD %_NN ._.
In_IN other_JJ words_NNS ,_, the_DT ratio_NN of_IN positive_JJ and_CC negative_JJ instances_NNS for_IN this_DT task_NN tends_VBZ to_TO be_VB biased_VBN ._.
Therefore_RB ,_, machine_NN learning_NN approaches_NNS are_VBP not_RB al_SYM -_: ways_NNS suitable_JJ for_IN this_DT task_NN ._.
Solovyev_NNP and_CC Ivanov_NNP -LRB-_-LRB- 2014_CD -RRB-_-RRB- have_VBP proposed_VBN a_DT dictionary-based_JJ problem_NN phrase_NN extraction_NN from_IN product_NN reviews_NNS ._.
It_PRP was_VBD based_VBN on_IN a_DT simple_JJ pattern_NN matching_VBG with_IN their_PRP$ dictionaries_NNS ._.
In_IN -LRB-_-LRB- Ivanov_NNP and_CC Tu_NNP -_: tubalina_NN ,_, 2014_CD -RRB-_-RRB- ,_, they_PRP incorporated_VBD a_DT clause_NN feature_NN ,_, but-conjunction_NN ,_, with_IN the_DT dictionary-based_JJ method_NN ._.
Kakimoto_NNP and_CC Yamamoto_NNP -LRB-_-LRB- 2008_CD -RRB-_-RRB- have_VBP proposed_VBN a_DT method_NN based_VBN on_IN syntactic_JJ pieces_NNS for_IN extracting_VBG trou_SYM -_: bles_NNS ._.
The_DT basic_JJ idea_NN in_IN these_DT studies_NNS is_VBZ similar_JJ to_TO our_PRP$ method_NN ._.
However_RB ,_, these_DT approaches_NNS did_VBD not_RB contain_VB an_DT iteration_NN process_NN like_IN bootstrapping_NN ._.
Although_IN bootstrapping_VBG methods_NNS often_RB generate_VBP noise_NN seeds_NNS for_IN the_DT next_JJ process_NN and_CC the_DT wrong_JJ seeds_NNS lead_VBP to_TO the_DT decrease_NN of_IN the_DT precision_NN rate_NN ,_, namely_RB semantic_JJ drift_NN ,_, the_DT iteration_NN process_NN is_VBZ vital_JJ to_TO obtain_VB the_DT high_JJ recall_NN rate_NN ._.
Although_IN there_EX are_VBP studies_NNS based_VBN on_IN a_DT bootstrap_NN -_: ping_NN approach_NN such_JJ as_IN -LRB-_-LRB- Leider_NNP and_CC Schilder_NNP ,_, 2010_CD ;_: Ohmori_NNP and_CC Mori_NNP ,_, 2010_CD -RRB-_-RRB- ,_, the_DT targets_NNS are_VBP not_RB Twitter_NNP ._.
Riloff_NNP et_FW al._FW -LRB-_-LRB- 2013_CD -RRB-_-RRB- have_VBP handled_VBN tweets_NNS and_CC used_VBD a_DT bootstrapping_NN approach_NN for_IN their_PRP$ task_NN ._.
However_RB ,_, the_DT purpose_NN is_VBZ to_TO generate_VB a_DT sarcasm_NN recognizer_NN ._.
3_CD Trouble_NN information_NN In_IN this_DT section_NN ,_, we_PRP explain_VBP the_DT target_NN trouble_NN infor_NN -_: mation_NN in_IN this_DT paper_NN ._.
Here_RB we_PRP introduce_VBP two_CD words_NNS ;_: trouble_NN sentences_NNS -LRB-_-LRB- TS_NNP -RRB-_-RRB- and_CC trouble_NN expressions_NNS -LRB-_-LRB- TE_NNP -RRB-_-RRB- ._.
The_DT TSs_NNP are_VBP our_PRP$ target_NN in_IN the_DT extraction_NN process_NN ._.
They_PRP are_VBP tweets_NNS with_IN trouble_NN information_NN about_IN a_DT product1_NN ._.
The_DT TEs_NNP are_VBP phrases_NNS which_WDT indicate_VBP trou_SYM -_: ble_NN situation_NN ,_, failure_NN and_CC so_RB on_IN ._.
TS_NNP :_: Why_WRB ?_.
My_PRP$ smartphone_NN is_VBZ n't_RB powered_VBN on_IN ..._: TE_NNP :_: not_RB powered_VBN on_IN In_IN this_DT paper_NN ,_, a_DT TS_NNP needs_VBZ to_TO contain_VB a_DT prod_VB -_: uct_NN name/information_NN and_CC TE_NNP -LRB-_-LRB- s_PRP -RRB-_-RRB- ._.
In_IN other_JJ words_NNS ,_, we_PRP do_VBP not_RB handle_VB any_DT tweets_NNS without_IN a_DT product_NN name/information_NN ._.
In_IN the_DT above_JJ instance_NN ,_, ``_`` smart_JJ -_: phone_NN ''_'' is_VBZ the_DT product_NN name/information_NN ._.
For_IN TEs_NNS ,_, we_PRP admit_VBP figurative_JJ phrases_NNS ,_, emoticons_NNS and_CC Internet_NNP slangs_NNS ._.
For_IN example_NN ,_, ``_`` My_PRP$ phone_NN is_VBZ dead_JJ ''_'' and_CC ``_`` The_DT home_NN button_NN on_IN iPhone_NNP is_VBZ wroooooong_JJ -LRB-_-LRB- ToT_NNP -RRB-_-RRB- ._. ''_''
4_CD Preliminary_JJ experiment_NN In_IN this_DT section_NN ,_, we_PRP describe_VBP some_DT problems_NNS of_IN a_DT sim_NN -_: ple_NN machine_NN learning_VBG approach_NN and_CC a_DT rule-based_JJ ap_NN -_: proach_NN through_IN an_DT experiment_NN ._.
4.1_CD Machine_NN learning_VBG based_VBN We_PRP constructed_VBD a_DT classification_NN model_NN based_VBN on_IN SVM_NNP -LRB-_-LRB- Vapnik_NNP ,_, 1995_CD -RRB-_-RRB- ._.
We_PRP used_VBD SVMlight_NNP -LRB-_-LRB- Joachims_NNP ,_, 1998_CD -RRB-_-RRB- for_IN the_DT implementation_NN ._.
Although_IN we_PRP utilized_VBD some_DT features_NNS about_IN emoticons_NNS ,_, Internet_NNP slang_NN dic_SYM -_: tionaries_NNS and_CC so_RB on_IN ,_, they_PRP were_VBD not_RB effective_JJ ._.
There_EX -_: fore_NN ,_, we_PRP used_VBD only_RB the_DT bag-of-words_NNS features_NNS for_IN SVM_NNP ._.
We_PRP prepared_VBD 900_CD tweets_NNS for_IN the_DT training_NN data_NNS ;_: 450_CD positive_JJ and_CC 450_CD negative_JJ instances_NNS ._.
We_PRP evaluated_VBD 1The_JJ actual_JJ tweets_NNS in_IN the_DT experiment_NN are_VBP written_VBN in_IN Japanese_JJ ._.
Recall_VB Precision_NNP F_NN 0.88_CD 0.98_CD 0.93_CD #_# of_IN EXT_NNP #_# of_IN COR_NNP Precision_NNP 474_CD 444_CD 0.94_CD Table_NNP 1_CD :_: The_DT experimental_JJ result_NN on_IN the_DT leave-one-out_JJ cross-validation_NN ._.
Table_NNP 2_CD :_: The_DT experimental_JJ result_NN for_IN a_DT realistic_JJ situation_NN ._.
the_DT machine_NN learning_VBG based_VBN method_NN with_IN the_DT leave_NN -_: one-out_JJ cross-validation_NN ._.
Table_NNP 1_CD shows_VBZ the_DT exper_NN -_: imental_JJ result_NN ._.
The_DT method_NN produced_VBD high_JJ recall_NN and_CC precision_NN rates_NNS for_IN the_DT cross-validation_NN ._.
How_WRB -_: ever_RB ,_, most_JJS of_IN real_JJ tweets_NNS are_VBP non-trouble_JJ informa_NN -_: tion_NN ._.
In_IN other_JJ words_NNS ,_, this_DT situation_NN is_VBZ not_RB on_IN the_DT real_JJ world_NN ._.
Therefore_RB ,_, we_PRP also_RB evaluated_VBD our_PRP$ method_NN trained_VBN by_IN 900_CD tweets_NNS with_IN 30,000_CD tweets_NNS that_WDT ex_FW -_: tracted_VBN from_IN Twitter_NNP randomly_RB ,_, as_IN an_DT opened_VBN test_NN set_NN ._.
This_DT is_VBZ an_DT real_JJ situation_NN ,_, namely_RB unbalance_JJ data_NNS ._.
We_PRP judged_VBD the_DT correctness_NN of_IN the_DT outputs_NNS of_IN SVM_NNP ._.
Table_NNP 2_CD shows_VBZ the_DT experimental_JJ result_NN for_IN the_DT unbalance_NN data_NNS ._.
The_DT EXT_NNP and_CC COR_NNP in_IN the_DT table_NN denote_VBP the_DT number_NN of_IN tweets_NNS extracted_VBN by_IN SVM_NNP and_CC the_DT num_NN -_: ber_NN of_IN tweets_NNS extracted_VBN correctly_RB ,_, respectively_RB ._.
From_IN the_DT table_NN ,_, the_DT machine_NN learning_VBG based_VBN method_NN was_VBD not_RB suitable_JJ for_IN this_DT task_NN because_IN the_DT precision_NN rate_NN on_IN the_DT realistic_JJ data_NN set_NN dramatically_RB decreased_VBD ._.
4.2_CD Rule-based_JJ We_PRP also_RB constructed_VBD a_DT rule-based_JJ method_NN with_IN a_DT sim_NN -_: ple_NN matching_VBG approach_NN ._.
We_PRP prepared_VBD trouble_NN ex_FW -_: pressions_NNS -LRB-_-LRB- TEs_NNS -RRB-_-RRB- by_IN handwork_NN ._.
Although_IN trouble_NN sentences_NNS -LRB-_-LRB- TSs_NNP -RRB-_-RRB- always_RB contain_VBP TE_NNP -LRB-_-LRB- s_PRP -RRB-_-RRB- ,_, all_DT sentences_NNS with_IN TEs_NNS are_VBP not_RB always_RB TSs_NNP ._.
Therefore_RB ,_, we_PRP also_RB prepared_VBD NG_NNP phrases_NNS for_IN the_DT rule-based_JJ method_NN ._.
For_IN example_NN ,_, ``_`` ca_MD n't_RB charge_VB ''_'' is_VBZ a_DT TE_NNP for_IN mobile_JJ phones_NNS ._.
However_RB ,_, ``_`` I_PRP ca_MD n't_RB charge_VB my_PRP$ phone_NN because_IN I_PRP do_VBP n't_RB have_VB a_DT charger_NN now_RB ''_'' is_VBZ not_RB a_DT TS_NNP because_IN it_PRP is_VBZ not_RB trouble_NN information_NN about_IN a_DT product_NN ._.
To_TO solve_VB this_DT problem_NN ,_, we_PRP need_VBP to_TO add_VB a_DT NG_NNP phrase_NN ``_`` because_IN I_PRP do_VBP n't_RB have_VB a_DT charger_NN ._. ''_''
We_PRP evaluated_VBD our_PRP$ rule-based_JJ method_NN with_IN 30,000_CD tweets_NNS in_IN Section_NN 4.1_CD ._.
Table_NNP 3_CD shows_VBZ the_DT experimen_NNS -_: tal_JJ result_NN ._.
We_PRP obtained_VBD high_JJ precision_NN rate_NN by_IN using_VBG the_DT rule-based_JJ method_NN ,_, as_IN compared_VBN with_IN the_DT ma_FW -_: chine_NN learning_VBG method_NN -LRB-_-LRB- See_VB Table_NNP 2_CD ._. -RRB-_-RRB-
On_IN the_DT other_JJ Table_NNP 3_CD :_: The_DT experimental_JJ result_NN of_IN the_DT rule-based_JJ method_NN on_IN the_DT same_JJ situation_NN with_IN SVM_NNP ._.
hand_NN ,_, the_DT number_NN of_IN tweets_NNS extracted_VBN correctly_RB was_VBD reduced_VBN almost_RB by_IN half_NN -LRB-_-LRB- 720_CD vs._FW 444_FW -RRB-_-RRB- ._.
As_IN a_DT re_NN -_: sult_NN ,_, the_DT simple_JJ rule-based_JJ method_NN faced_VBN with_IN an_DT -_: other_JJ problem_NN for_IN this_DT task_NN ._.
4.3_CD Discussion_NNP The_DT problem_NN of_IN the_DT machine_NN learning_VBG method_NN is_VBZ caused_VBN by_IN the_DT number_NN of_IN tweets_NNS and_CC the_DT ratio_NN of_IN pos_NNS -_: itive_JJ and_CC negative_JJ instances_NNS in_IN the_DT training_NN data_NNS ._.
The_DT training_NN data_NNS with_IN 900_CD instances_NNS was_VBD insufficient_JJ in_IN terms_NNS of_IN the_DT size_NN for_IN machine_NN learning_NN ,_, especially_RB the_DT coverage_NN of_IN non-trouble_JJ information_NN ._.
Besides_IN ,_, a_DT classifier_NN in_IN this_DT situation_NN often_RB generates_VBZ a_DT poor_JJ result_NN because_IN the_DT distribution_NN of_IN the_DT training_NN data_NNS differs_VBZ from_IN that_DT of_IN the_DT real_JJ data_NNS ._.
One_CD intuitive_JJ solution_NN is_VBZ to_TO add_VB new_JJ tweets_NNS as_IN positive/negative_JJ instances_NNS ._.
However_RB ,_, collecting_VBG tweets_NNS with_IN posi_NNS -_: tive/negative_JJ by_IN handwork_NN is_VBZ costly_JJ ._.
Moreover_RB ,_, the_DT concrete_JJ definition_NN of_IN non-trouble_JJ tweets_NNS is_VBZ essen_SYM -_: tially_RB difficult_JJ ._.
Since_IN the_DT realistic_JJ situation_NN contains_VBZ many_JJ non-trouble_JJ tweets_NNS as_IN compared_VBN with_IN trou_SYM -_: ble_NN tweets_NNS ,_, the_DT training_NN data_NNS should_MD contain_VB many_JJ non-trouble_JJ tweets_NNS ._.
However_RB ,_, combined_VBN with_IN the_DT difficulty_NN of_IN the_DT concrete_JJ definition_NN of_IN non-trouble_JJ tweets_NNS ,_, collecting_VBG non-trouble_JJ tweets_NNS with_IN high_JJ cov_NN -_: erage_NN is_VBZ also_RB a_DT difficult_JJ task_NN ._.
Therefore_RB ,_, machine_NN learning_NN approaches_NNS are_VBP not_RB appropriate_JJ for_IN our_PRP$ task_NN ._.
The_DT rule-based_JJ method_NN obtained_VBD the_DT high_JJ preci_NN -_: sion_NN rate_NN ._.
The_DT reason_NN was_VBD that_IN we_PRP could_MD focus_VB on_IN the_DT trouble_NN expressions_NNS in_IN the_DT method_NN as_IN compared_VBN with_IN the_DT machine_NN learning_VBG method_NN ._.
Although_IN we_PRP natu_SYM -_: rally_NN needed_VBD to_TO prepare_VB NG_NNP phrases_NNS ,_, the_DT effort_NN for_IN the_DT rule-based_JJ method_NN was_VBD less_JJR than_IN that_DT for_IN the_DT ma_FW -_: chine_NN learning_VBG method_NN ._.
Therefore_RB ,_, rule-based_JJ meth_NN -_: ods_NNS are_VBP essentially_RB appropriate_JJ for_IN our_PRP$ task_NN ._.
How_WRB -_: ever_RB ,_, the_DT recall_NN rate_NN was_VBD a_DT critical_JJ problem_NN for_IN the_DT method_NN ._.
One_CD solution_NN is_VBZ to_TO increase_VB the_DT number_NN of_IN TEs_NNP for_IN the_DT extraction_NN process_NN ._.
On_IN the_DT other_JJ hand_NN ,_, constructing_VBG TEs_NNS with_IN high_JJ coverage_NN by_IN handwork_NN is_VBZ costly_JJ ._.
Therefore_RB ,_, we_PRP need_VBP to_TO extract_VB TEs_NNS from_IN tweets_NNS automatically_RB ._.
#_# of_IN EXT_NNP #_# of_IN COR_NNP Precision_NNP 3,742_CD 720_CD 0.19_CD 5_CD Proposed_VBN method_NN TE_NNP :_: broken_JJ On_IN the_DT basis_NN of_IN the_DT discussion_NN in_IN the_DT previous_JJ sec_NN -_: tion_NN ,_, we_PRP expand_VBP our_PRP$ rule-base_JJ method_NN with_IN a_DT boot_NN -_: strapping_VBG approach_NN ._.
The_DT bootstrapping_NN approach_NN leads_VBZ to_TO the_DT improvement_NN of_IN the_DT coverage_NN of_IN the_DT orig_NN -_: inal_JJ rule-based_JJ method_NN ._.
5.1_CD Outline_NN For_IN extracting_VBG various_JJ types_NNS of_IN trouble_NN sentences_NNS ,_, TSs_NNP ,_, it_PRP is_VBZ necessary_JJ to_TO acquire_VB new_JJ trouble_NN expres_VBZ -_: sions_NNS ,_, TEs_NNP ,_, automatically_RB ._.
In_IN general_JJ ,_, some_DT TEs_NNS of_IN -_: ten_CD appear_VBP in_IN one_CD TS_NNP ._.
We_PRP focus_VBP on_IN this_DT characteristic_NN ._.
Figure_NN 1_CD shows_VBZ an_DT example_NN ._.
Here_RB ,_, ``_`` broken_JJ ''_'' is_VBZ a_DT TE_NNP ,_, a_DT seed_NN for_IN a_DT bootstrapping_NN approach_NN ._.
Assume_VB that_IN the_DT TE_NNP and_CC the_DT phrase_NN ``_`` not_RB make_VB a_DT call_NN ''_'' often_RB co_SYM -_: occur_VBP in_IN tweets_NNS ._.
From_IN this_DT observation_NN ,_, our_PRP$ method_NN obtains_VBZ the_DT phrase_NN ``_`` not_RB make_VB a_DT call_NN ''_'' as_IN a_DT new_JJ TE_NNP ,_, and_CC then_RB extract_VB a_DT new_JJ TS_NNP by_IN the_DT new_JJ TE_NNP ._.
The_DT outline_NN of_IN our_PRP$ method_NN is_VBZ shown_VBN in_IN Figure_NN 2_CD ._.
First_RB ,_, we_PRP create_VBP seed_NN words_NNS with_IN strong_JJ trouble_NN meanings_NNS for_IN a_DT target_NN product_NN by_IN hand_NN ._.
By_IN using_VBG the_DT initial_JJ seeds_NNS ,_, namely_RB TEs_NNP ,_, our_PRP$ method_NN extracts_VBZ TSs_NNP from_IN a_DT tweet_NN corpus_NN ._.
For_IN the_DT TS_NNP extraction_NN process_NN ,_, we_PRP judge_VBP the_DT presence_NN of_IN TEs_NNP in_IN each_DT sen_NN -_: tence_NN ._.
As_IN exceptional_JJ treatment_NN ,_, we_PRP prepare_VBP some_DT non-extraction_JJ rules_NNS ._.
The_DT non-extraction_JJ rules_NNS con_VBP -_: tain_NN hearsay_NN expressions_NNS such_JJ as_IN ``_`` someone_NN told_VBD me_PRP that_WDT ''_'' and_CC non-factual_JJ expressions_NNS such_JJ as_IN ''_'' feel_VB like_IN ._. ''_''
We_PRP do_VBP not_RB extract_VB sentences_NNS matching_VBG with_IN the_DT non_NN extraction_NN rules_NNS as_IN TSs_NNP ._.
Next_JJ ,_, our_PRP$ method_NN extracts_VBZ TE_NNP candidates_NNS from_IN the_DT extracted_VBN TSs_NNP ._.
For_IN the_DT can_MD -_: didates_NNS ,_, we_PRP apply_VBP a_DT scoring_VBG method_NN for_IN computing_VBG a_DT confidence_NN measure_NN as_IN new_JJ TEs_NNS ._.
We_PRP acquire_VBP only_RB TEs_JJ with_IN high_JJ confidence_NN values_NNS as_IN new_JJ TEs_NNS ._.
Fi_SYM -_: nally_RB ,_, we_PRP add_VBP the_DT new_JJ TEs_NNS to_TO the_DT previous_JJ seeds_NNS ._.
Our_PRP$ method_NN iterates_VBZ these_DT processes_NNS until_IN it_PRP fulfills_VBZ certain_JJ conditions_NNS ._.
In_IN this_DT paper_NN ,_, we_PRP set_VBD two_CD condi_NNS -_: tions_NNS ;_: -LRB-_-LRB- 1_LS -RRB-_-RRB- if_IN the_DT iteration_NN is_VBZ repeated_VBN at_IN 5_CD times_NNS or_CC -LRB-_-LRB- 2_LS -RRB-_-RRB- if_IN the_DT method_NN does_VBZ not_RB acquire_VB new_JJ TEs_NNS ._.
5.2_CD TE_NNP acquisition_NN TE_NNP extraction_NN is_VBZ based_VBN on_IN surface_NN and_CC part-of-speech_NN tags_NNS patterns_NNS ._.
We_PRP focus_VBP on_IN the_DT following_JJ character_NN -_: istics_NNS for_IN the_DT extraction_NN ._.
Specific_JJ adverbs_NNS Adverbs_NNS are_VBP closely_RB related_VBN to_TO trouble_NN information_NN ._.
Murakami_NNP and_CC Nasukawa_NNP Automatic_NNP extraction_NN TS_NNP :_: My_PRP$ iPhone_NN was_VBD broken_VBN ..._: I_PRP ca_MD n't_RB make_VB a_DT call_NN !_.
This_DT sucks_VBZ !_.
Automatic_NNP acquisition_NN New_NNP TE_NNP :_: not_RB make_VB a_DT call_NN Automatic_NNP extraction_NN New_NNP TS_NNP :_: Suddenly_RB ,_, I_PRP found_VBD my_PRP$ iPhone_NN was_VBD n't_RB able_JJ to_TO make_VB a_DT call_NN ._.
Figure_NN 1_CD :_: An_DT example_NN of_IN the_DT extraction_NN process_NN ._.
Seeds_NNS TSs_NNP TE_NNP candidates_NNS New_NNP TEs_NNP Tweet_NNP corpus_VBZ TE_NNP acquisition_NN Scoring_NNP Figure_NNP 2_CD :_: The_DT outline_NN of_IN our_PRP$ method_NN ._.
-LRB-_-LRB- 2011_CD -RRB-_-RRB- have_VBP proposed_VBN a_DT method_NN to_TO detect_VB po_SYM -_: tential_JJ problems_NNS from_IN documents_NNS ._.
They_PRP fo_SYM -_: cused_VBN on_IN adverbs_NNS ,_, such_JJ as_IN ``_`` suddenly_RB ''_'' and_CC ``_`` ar_SYM -_: bitrarily_NN ''_'' ,_, to_TO detect_VB the_DT nouns_NNS and_CC verbs_NNS that_WDT de_FW -_: scribed_VBD the_DT actual_JJ problems_NNS ._.
This_DT is_VBZ a_DT language_NN -_: independent_JJ characteristic_JJ ._.
We_PRP also_RB extract_VB phrases_NNS with_IN the_DT specific_JJ adverbs_NNS as_IN TEs_NNS ._.
Imperfective_JJ forms_NNS The_DT target_NN tweets_NNS in_IN this_DT pa_NN -_: per_IN are_VBP written_VBN in_IN Japanese_JJ ._.
As_IN one_CD Japanese_JJ characteristic_NN ,_, TSs_NNP often_RB contain_VBP the_DT imperfec_NN -_: tive_JJ form_NN of_IN a_DT verb_NN with_IN negation2_CD ._.
We_PRP extract_VBP phrases_NNS with_IN this_DT pattern_NN as_IN TEs_NNS ._.
Negative_JJ words_NNS As_IN we_PRP mentioned_VBD in_IN Section_NN 2_CD ,_, negative_JJ opinions_NNS are_VBP closely_RB related_VBN to_TO trouble_NN information_NN ._.
Tweets_NNS with_IN negative_JJ expressions_NNS have_VBP high_JJ potentiality_NN for_IN TEs_NNP and_CC TSs_NNP ._.
On_IN the_DT other_JJ hand_NN ,_, as_IN we_PRP also_RB mentioned_VBD in_IN Sec_NNP -_: tion_NN 2_CD ,_, negative_JJ opinions_NNS are_VBP not_RB always_RB equal_JJ 2E_NNP ._.
g._NN ,_, ``_`` 動か_FW ない_FW -LRB-_-LRB- not_RB work_VB -RRB-_-RRB- ''_'' and_CC ``_`` 起動し_FW ない_FW -LRB-_-LRB- not_RB start_VB -RRB-_-RRB- ._. ''_''
to_TO trouble_NN information_NN ._.
Utilizing_VBG general_JJ senti_NNS -_: ment_NN dictionaries_NNS is_VBZ not_RB always_RB suitable_JJ for_IN this_DT task_NN because_IN they_PRP contain_VBP many_JJ negative_JJ words_NNS not_RB related_VBN to_TO trouble_NN information_NN ._.
In_IN this_DT paper_NN ,_, we_PRP prepare_VBP negative_JJ words_NNS related_VBN to_TO trouble_NN in_IN -_: formation_NN about_IN a_DT target_NN product_NN ,_, such_JJ as_IN ``_`` bad_JJ ''_'' ,_, ``_`` wrong_JJ ''_'' and_CC ``_`` failure_NN ''_'' ,_, as_IN a_DT negative_JJ word_NN set_NN ._.
We_PRP extract_VBP phrases_NNS with_IN the_DT negative_JJ words_NNS ._.
5.3_CD Scoring_NNP A_NNP bootstrapping_VBG approach_NN uses_VBZ the_DT previous_JJ outputs_NNS from_IN the_DT system_NN as_IN the_DT inputs_NNS for_IN the_DT system_NN in_IN the_DT next_JJ step_NN ._.
If_IN the_DT precision_NN of_IN the_DT outputs_NNS is_VBZ low_JJ ,_, it_PRP leads_VBZ to_TO the_DT decrease_NN of_IN the_DT precision_NN of_IN the_DT next_JJ out_IN -_: puts_VBZ ._.
The_DT accuracy_NN deterioration_NN by_IN the_DT change_NN of_IN the_DT meaning_NN of_IN seeds_NNS is_VBZ well-known_JJ as_IN ``_`` Semantic_JJ drift_NN ''_'' -LRB-_-LRB- Curran_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ._.
To_TO solve_VB this_DT problem_NN ,_, we_PRP need_VBP to_TO keep_VB high_JJ precision_NN in_IN the_DT iteration_NN pro-_JJ cess_NN ._.
In_IN other_JJ words_NNS ,_, we_PRP need_VBP to_TO reject_VB noise_NN TEs_NNS in_IN candidate_NN TEs_NNS ._.
Therefore_RB ,_, we_PRP need_VBP to_TO estimate_VB a_DT confidence_NN measure_NN of_IN each_DT candidate_NN TE_NNP ._.
One_CD of_IN the_DT most_RBS successful_JJ approaches_NNS is_VBZ the_DT Espresso_NNP algorithm_NN -LRB-_-LRB- Komachi_NNP et_FW al._FW ,_, 2008_CD ;_: Pantel_NNP and_CC Pennacchiotti_NNP ,_, 2006_CD -RRB-_-RRB- ._.
The_DT algorithm_NN was_VBD based_VBN on_IN recursive_JJ definition_NN of_IN pattern-instance_NN scoring_NN metrics_NNS ._.
It_PRP computed_VBD the_DT pointwise_NN mutual_JJ informa_NN -_: tion_NN between_IN each_DT pattern_NN and_CC instance_NN recursively_RB ._.
The_DT method_NN in_IN this_DT paper_NN does_VBZ not_RB handle_VB any_DT pat_NN -_: terns_NNS for_IN the_DT bootstrapping_NN process_NN ._.
Therefore_RB ,_, we_PRP can_MD not_RB incorporate_VB this_DT algorithm_NN into_IN our_PRP$ method_NN directly_RB ._.
We_PRP introduce_VBP another_DT scoring_VBG method_NN for_IN a_DT con_NN -_: fidence_NN measure_NN in_IN the_DT bootstrapping_NN process_NN ._.
First_RB ,_, we_PRP compute_VBP confidence_NN values_NNS of_IN nouns_NNS ,_, verbs_NNS and_CC adjectives_NNS in_IN TSs_NNP ._.
Then_RB ,_, we_PRP estimate_VBP the_DT confidence_NN value_NN of_IN each_DT TE_NNP on_IN the_DT basis_NN of_IN the_DT confidence_NN val_NN -_: ues_NNS ._.
The_DT confidence_NN measure_NN is_VBZ based_VBN on_IN the_DT follow_VB -_: ing_NN hypothesis_NN :_: •_CD if_IN a_DT word_NN frequently_RB appears_VBZ in_IN TSs_NNP ,_, the_DT TE_NNP likelihood_NN of_IN the_DT word_NN is_VBZ high_JJ ._.
•_NN words_NNS appearing_VBG near_IN a_DT product_NN name3_CD contain_VBP high_JJ TE_NNP likelihood_NN ._.
3It_JJ denotes_NNS not_RB only_RB concrete_JJ product_NN names_NNS ,_, such_JJ as_IN ``_`` iPhone_NNP ''_'' ,_, but_CC also_RB product_NN categories_NNS ,_, such_JJ as_IN ``_`` smartphone_NN ._. ''_''
The_DT value_NN of_IN a_DT word_NN w_NN is_VBZ computed_VBN as_IN follows_VBZ :_: ∑_SYM 1_CD WSw_NNP =_SYM disti_NNS -LRB-_-LRB- w_NN -RRB-_-RRB- -LRB-_-LRB- 1_LS -RRB-_-RRB- i_FW ∈_FW I_PRP where_WRB i_FW and_CC I_PRP are_VBP a_DT sentence_NN and_CC sentences_NNS includ_SYM -_: ing_VBG a_DT product_NN name_NN ,_, respectively_RB ._.
disti_NNS -LRB-_-LRB- w_NN -RRB-_-RRB- is_VBZ the_DT distance_NN between_IN a_DT product_NN name_NN and_CC w_NN in_IN i_FW ._.
The_DT confidence_NN measure_NN of_IN a_DT TEt_NNP is_VBZ the_DT average_JJ value_NN of_IN WSw_NNP intheTE_NNP ._.
1_CD ∑_CD TEscoret_NNP =_SYM N_NNP WSw_NNP -LRB-_-LRB- 2_LS -RRB-_-RRB- w_FW w_FW ∈_FW TEt_FW where_WRB Nw_NNP is_VBZ the_DT number_NN of_IN words_NNS in_IN TEt_NNP ._.
If_IN a_DT TE_NNP contains_VBZ frequent_JJ words_NNS with_IN the_DT high_JJ W_NNP Sw_NNP ,_, it_PRP ob_SYM -_: tains_NNS high_JJ T_NNP Escore_NNP ._.
After_IN computation_NN of_IN T_NNP Escore_NNP ,_, we_PRP extract_VBP phrases_NNS in_IN the_DT top_JJ N_NNP %_NN as_IN the_DT new_JJ seeds_NNS for_IN the_DT next_JJ iteration_NN ._.
If_IN the_DT phrases_NNS in_IN the_DT current_JJ top_JJ N_NNP %_NN are_VBP the_DT same_JJ as_IN the_DT phrases_NNS in_IN the_DT previous_JJ step_NN ,_, the_DT iter_NN -_: ation_NN is_VBZ terminated_VBN ._.
6_CD Experiment_NN In_IN this_DT section_NN ,_, we_PRP evaluate_VBP our_PRP$ method_NN with_IN real_JJ tweets_NNS ,_, and_CC then_RB discuss_VB the_DT results_NNS ._.
6.1_CD Result_NN The_DT target_NN product_NN was_VBD cellphones_NNS ._.
We_PRP collected_VBD 100,000_CD tweets_NNS about_IN cellphones_NNS as_IN the_DT data_NN set_NN ._.
These_DT tweets_NNS contained_VBD words_NNS that_IN related_VBN to_TO cell_NN -_: phones_NNS ._.
As_IN initial_JJ seeds_NNS ,_, we_PRP set_VBP the_DT following_VBG seven_CD words_NNS ;_: 壊れる_CD -LRB-_-LRB- broken_VBN -RRB-_-RRB- ,_, おかしい_FW -LRB-_-LRB- wrong_JJ -RRB-_-RRB- ,_, 異常_FW -LRB-_-LRB- defect_NN -RRB-_-RRB- ,_, 故障_FW -LRB-_-LRB- defect_NN -RRB-_-RRB- ,_, フリース_FW -LRB-_-LRB- freeze_NN -RRB-_-RRB- and_CC ハ_CD ク_NN -LRB-_-LRB- bug_NN -RRB-_-RRB- ._.
We_PRP applied_VBD the_DT seeds_NNS to_TO the_DT data_NN set_NN ,_, and_CC then_RB obtained_VBD TEs_NNP and_CC TSs_NNP by_IN using_VBG the_DT proposed_VBN bootstrapping_NN method_NN ._.
In_IN this_DT experiment_NN ,_, the_DT total_JJ number_NN of_IN iterations_NNS was_VBD 5_CD ._.
More_RBR properly_RB speaking_VBG ,_, when_WRB the_DT number_NN of_IN iteration_NN was_VBD 5_CD ,_, our_PRP$ method_NN did_VBD not_RB obtain_VB new_JJ TEs_NNS ._.
In_IN other_JJ words_NNS ,_, both_DT of_IN the_DT two_CD conditions_NNS in_IN Section_NN 5.1_CD were_VBD fortuitously_RB fulfilled_VBN in_IN this_DT iteration_NN ._.
Figure_NN 3_CD shows_VBZ the_DT result_NN of_IN the_DT precision_NN rate_NN and_CC the_DT number_NN of_IN extracted_VBN TSs_NNP on_IN the_DT iteration_NN ._.
Our_PRP$ method_NN increased_VBD the_DT number_NN of_IN TSs_NNP in_IN the_DT second_JJ step_NN by_IN using_VBG new_JJ TEs_NNS extracted_VBN in_IN the_DT first_JJ step_NN ._.
Despite_IN the_DT increase_NN of_IN TSs_NNP ,_, our_PRP$ method_NN maintained_VBD a_DT high_JJ precision_NN rate_NN in_IN the_DT second_JJ step_NN ._.
After_IN the_DT third_JJ step_NN ,_, our_PRP$ method_NN obtained_VBD a_DT small_JJ increase_NN in_IN Precision_NNP 0.85_CD 0.84_CD 0.83_CD 0.82_CD 0.81_CD 0.80_CD 0.79_CD 0.78_CD 0.77_CD 0.76_CD 0.75_CD 1_CD TS_NNP 勝手に電源か_CD つく_NN -LRB-_-LRB- turn_VB on_RP arbitrarily_RB -RRB-_-RRB- 電源か_SYM つかない_CD -LRB-_-LRB- not_RB turn_VB on_RP -RRB-_-RRB- 急に電源か_CD 落ちる_CD -LRB-_-LRB- power_NN off_IN suddenly_RB -RRB-_-RRB- 電源か_SYM 落ちない_CD -LRB-_-LRB- not_RB power_NN off_RP -RRB-_-RRB- ホ_SYM タンか_SYM 押せない_CD -LRB-_-LRB- not_RB push_VB the_DT button_NN -RRB-_-RRB- 勝手にスヒ_CD ーカーか_CD ミュートになる_NN -LRB-_-LRB- put_VB the_DT speaker_NN on_IN mute_JJ arbitrarily_RB -RRB-_-RRB- Table_NNP 4_CD :_: Extracted_VBN TEs_NNS ._.
Table_NNP 5_CD :_: The_DT number_NN of_IN extracted_VBN TSs_NNP on_IN several_JJ data_NNS sets_NNS ._.
The_DT third_JJ row_NN is_VBZ the_DT same_JJ as_IN Section_NN 6.1_CD ._.
propriate_NN TEs_NNS ._.
It_PRP probably_RB leads_VBZ to_TO the_DT increase_NN of_IN the_DT number_NN of_IN TSs_NNS with_IN non-trouble_JJ information_NN and_CC the_DT decrease_NN of_IN the_DT precision_NN ._.
We_PRP investigated_VBD our_PRP$ method_NN with_IN the_DT different_JJ size_NN of_IN data_NNS sets_NNS ._.
Table_NNP 5_CD shows_VBZ the_DT result_NN ._.
For_IN smaller_JJR data_NN set_NN ,_, namely_RB 10,000_CD and_CC 50,000_CD tweets_NNS ,_, the_DT number_NN of_IN extracted_VBN TSs_NNP decreased_VBD dramatically_RB ._.
In_IN these_DT data_NNS sets_NNS ,_, the_DT number_NN of_IN outputs_NNS in_IN the_DT first_JJ iteration_NN was_VBD insuffi_JJ -_: cient_NN ._.
As_IN a_DT result_NN ,_, our_PRP$ method_NN could_MD not_RB obtain_VB TSs_NNP and_CC new_JJ TEs_NNS in_IN the_DT next_JJ process_NN ._.
Thus_RB ,_, our_PRP$ method_NN needs_VBZ an_DT adequate_JJ amount_NN of_IN tweets_NNS for_IN the_DT TE_NNP ac_SYM -_: quisition_NN process_NN ._.
For_IN a_DT larger_JJR data_NN set_NN ,_, 500,000_CD tweets_NNS ,_, the_DT predicted_VBN number_NN of_IN TSs_NNP was_VBD approxi_SYM -_: mately_FW 13,0004_CD ._.
The_DT actual_JJ number_NN of_IN extracted_VBN TSs_NNP in_IN the_DT larger_JJR data_NN set_NN was_VBD 9,088_CD ._.
The_DT result_NN indi_SYM -_: cates_VBZ that_IN our_PRP$ method_NN controlled_VBN noise_NN TEs_NNP appro_NN -_: priately_RB in_IN the_DT bootstrapping_NN process_NN ._.
In_IN addition_NN ,_, our_PRP$ method_NN extracted_VBD different_JJ types_NNS of_IN TEs_NNS from_IN the_DT larger_JJR data_NN set_NN ,_, such_JJ as_IN 勝手にアフ_CD リか_CD 起動す_CD る_NN -LRB-_-LRB- an_DT app_NN starts_VBZ arbitrarily_RB -RRB-_-RRB- カート_CD を読み込まな_CD い_NN -LRB-_-LRB- not_RB recognize_VB a_DT card_NN -RRB-_-RRB- and_CC 時計進まない_CD -LRB-_-LRB- clock_NN not_RB work_VB -RRB-_-RRB- ._.
Our_PRP$ method_NN was_VBD robust_JJ to_TO the_DT increase_NN 4_CD It_PRP was_VBD 13_CD ,_, 115_CD =_SYM 2_CD ,_, 623_CD ×_NN 5_CD by_IN simple_JJ arithmetic_NN ._.
2_CD terms_NNS of_IN the_DT number_NN of_IN TSs_NNP and_CC also_RB held_VBD the_DT high_JJ precision_NN rate_NN ._.
This_DT result_NN denotes_VBZ that_IN the_DT scoring_VBG method_NN in_IN Section_NN 5.3_CD was_VBD effective_JJ for_IN the_DT boot_NN -_: strapping_VBG in_IN terms_NNS of_IN the_DT noise_NN reduction_NN from_IN can_MD -_: didate_NN TEs_NNS ._.
The_DT experimental_JJ result_NN shows_VBZ the_DT ef_NN -_: fectiveness_NN of_IN our_PRP$ method_NN ,_, as_IN compared_VBN with_IN a_DT non_NN -_: bootstrapping_VBG method_NN ,_, because_IN the_DT result_NN in_IN the_DT sec_NN -_: ond_JJ step_NN ,_, namely_RB bootstrapping_NN ,_, outperformed_VBD that_IN in_IN the_DT first_JJ step_NN ,_, non-bootstrapping_JJ ._.
6.2_CD Analysis_NN and_CC discussion_NN Our_PRP$ method_NN extracted_VBD TSs_NNS with_IN a_DT high_JJ precision_NN rate_NN through_IN the_DT iteration_NN in_IN the_DT bootstrapping_NN ._.
Table_NNP 4_CD shows_NNS instances_NNS of_IN TEs_NNS extracted_VBN by_IN the_DT method_NN ._.
These_DT TEs_NNP related_VBN to_TO the_DT category_NN ``_`` cellphones_NNS ''_'' and_CC were_VBD suitable_JJ for_IN the_DT extraction_NN of_IN TSs_NNP ._.
Our_PRP$ method_NN correctly_RB extracted_VBD some_DT phrases_NNS with_IN the_DT opposite_JJ meaning_NN ,_, such_JJ as_IN ``_`` turn_NN on_IN automatically_RB ''_'' and_CC ``_`` not_RB turn_VB on_RP ._. ''_''
These_DT TEs_NNS were_VBD distinguished_VBN by_IN adverbs_NNS ;_: ``_`` arbitrarily_RB ''_'' and_CC ``_`` suddenly_RB ._. ''_''
It_PRP is_VBZ difficult_JJ to_TO extract_VB these_DT TEs_NNS by_IN using_VBG only_RB general_JJ sentiment_NN dictionar_NN -_: ies_NNS ._.
We_PRP also_RB obtained_VBD domain_NN specific_JJ TEs_NNS ,_, such_JJ as_IN ``_`` put_VBD the_DT speaker_NN on_IN mute_JJ arbitrarily_RB ._. ''_''
Our_PRP$ method_NN extracted_VBD various_JJ types_NNS of_IN TEs_NNS by_IN using_VBG the_DT boot_NN -_: strapping_VBG method_NN ._.
Next_JJ ,_, we_PRP discuss_VBP the_DT size_NN of_IN the_DT target_NN data_NNS and_CC the_DT accuracy_NN ._.
If_IN the_DT data_NNS size_NN is_VBZ small_JJ ,_, our_PRP$ method_NN might_MD not_RB extract_VB sufficient_JJ TEs_NNS ._.
As_IN a_DT result_NN ,_, it_PRP leads_VBZ to_TO the_DT decrease_NN of_IN the_DT number_NN of_IN TSs_NNP ._.
If_IN the_DT data_NNS size_NN is_VBZ large_JJ ,_, our_PRP$ method_NN might_MD extract_VB many_JJ inap_NN -_: 3_CD #_# of_IN iterations_NNS 4_CD 2750 2500 2250 2000_CD 1750_CD 5_CD 1500_CD Figure_NN 3_CD :_: The_DT precision_NN and_CC the_DT number_NN of_IN TSs_NNP in_IN each_DT #_# of_IN tweets_NNS #_# of_IN TSs_NNP 10,000_CD 50,000_CD 100,000_CD 500,000_CD 121_CD 623_CD 2,623_CD 9,088_CD iteration_NN ._.
Precision_NN #_# of_IN extracted_VBN tweets_NNS -LRB-_-LRB- TS_NNP -RRB-_-RRB- of_IN target_NN data_NNS and_CC could_MD extract_VB new_JJ TEs_NNS and_CC TSs_NNS efficiently_RB ._.
Finally_RB ,_, we_PRP explain_VBP the_DT results_NNS of_IN TSs_NNP ._.
The_DT follow_VBP -_: ing_VBG sentences_NNS are_VBP tweets_NNS extracted_VBN from_IN our_PRP$ method_NN :_: •_SYM 充電切れるわケータイ熱くなっちゃって充電_SYM て_SYM きないわ勝手に電源切れるわ最悪て_CD す_NN -LRB-_-LRB- My_PRP$ cellphone_NN ran_VBD out_IN of_IN charge_NN ,_, too_RB hot_JJ to_TO charge_VB the_DT battery_NN and_CC power_NN off_IN automatically_RB ..._: This_DT sucks_VBZ !_. -RRB-_-RRB-
•_FW てか携帯画面真っ黒になって電池ハ_FW ック抜い_FW て電源入れようとしても電源つかないんた_FW け_FW と_FW -LRB-_-LRB- The_DT display_NN of_IN my_PRP$ cellphone_NN blacked_VBD out_RP ,_, I_PRP removed_VBD the_DT battery_NN ,_, and_CC then_RB I_PRP powered_VBD on_IN it_PRP ,_, but_CC it_PRP is_VBZ n't_RB turned_VBN on_RP ._. -RRB-_-RRB-
Although_IN these_DT tweets_NNS did_VBD not_RB contain_VB direct_JJ expres_NNS -_: sions_NNS to_TO trouble_NN information_NN ,_, such_JJ as_IN 壊れた_CD -LRB-_-LRB- bro_NN -_: ken_NN -RRB-_-RRB- ,_, our_PRP$ method_NN correctly_RB extracted_VBD them_PRP with_IN ac_SYM -_: quired_VBD TEs_NNP ,_, such_JJ as_IN 勝手に電源か_CD 落ちる_CD -LRB-_-LRB- power_NN off_IN automatically_RB -RRB-_-RRB- and_CC 電源か_CD つかない_CD -LRB-_-LRB- not_RB turn_VB on_RP -RRB-_-RRB- ._.
The_DT following_JJ sentence_NN is_VBZ an_DT incorrect_JJ output_NN TS_NNP from_IN our_PRP$ method_NN ._.
•_FW iPhone_FW の充電ケーフ_FW ル壊れた_FW -LRB-_-LRB- ;_: ́Д_NNP `_`` -RRB-_-RRB- 充_SYM 電て_SYM きない_CD -LRB-_-LRB- ;_: ́Д_NNP `_`` -RRB-_-RRB- -LRB-_-LRB- The_DT charging_VBG cable_NN of_IN my_PRP$ iPhone_NN was_VBD broken_VBN ..._: I_PRP ca_MD n't_RB charge_VB the_DT battery_NN ._. -RRB-_-RRB-
This_DT tweet_NN is_VBZ trouble_NN information_NN about_IN accessories_NNS ,_, but_CC not_RB a_DT TS_NNP for_IN a_DT cellphone_NN itself_PRP ._.
In_IN this_DT experi_NN -_: ment_NN ,_, we_PRP regarded_VBD this_DT kind_NN of_IN outputs_NNS as_IN negative_JJ results_NNS ._.
This_DT is_VBZ a_DT difficult_JJ problem_NN in_IN trouble_NN infor_NN -_: mation_NN extraction_NN ._.
One_CD solution_NN is_VBZ to_TO add_VB NG_NNP rules_NNS to_TO the_DT extraction_NN process_NN ._.
However_RB ,_, we_PRP can_MD not_RB solve_VB a_DT problem_NN of_IN the_DT following_JJ sentence_NN ,_, which_WDT is_VBZ also_RB a_DT negative_JJ result_NN ,_, by_IN addition_NN of_IN NG_NNP rules_NNS ._.
•_SYM と_SYM したんやろーなんかあったんかな_CD -LRB-_-LRB- ・_FW ́_FW ω_FW ・_FW `_`` -RRB-_-RRB- iPhone_NNP 壊れたんかな_NNP -LRB-_-LRB- An_DT accident_NN had_VBD hap_SYM -_: pened_VBN -LRB-_-LRB- to_TO him/her_VB -RRB-_-RRB- ?_.
..._: -LRB-_-LRB- his/her_NN -RRB-_-RRB- iPhone_NN might_MD be_VB broken5_NNS ._. -RRB-_-RRB-
This_DT tweet_NN contained_VBD a_DT trouble_NN expression_NN ,_, but_CC it_PRP is_VBZ not_RB a_DT TS_NNP for_IN a_DT cellphone_NN ._.
It_PRP implied_VBD that_IN a_DT user_NN was_VBD 5Note_JJ that_IN the_DT question_NN mark_NN and_CC the_DT word_NN ``_`` might_MD ''_'' in_IN the_DT English_NNP translation_NN do_VBP n't_RB appear_VB explicitly_RB in_IN the_DT original_JJ Japanese_JJ sentence_NN ._.
worried_JJ about_IN someone_NN ._.
This_DT problem_NN is_VBZ more_RBR dif_SYM -_: ficult_NN because_IN we_PRP need_VBP deep_JJ analysis_NN including_VBG se_FW -_: mantics_NNS to_TO solve_VB it_PRP ._.
Handling_VBG metaphor_NN and_CC Internet_NNP slangs_NNS appropriately_RB is_VBZ also_RB important_JJ future_NN work_NN ._.
In_IN the_DT experiment_NN ,_, we_PRP evaluated_VBD our_PRP$ method_NN in_IN terms_NNS of_IN the_DT precision_NN rate_NN because_IN it_PRP is_VBZ difficult_JJ to_TO measure_VB the_DT recall_NN rate_NN ._.
Although_IN we_PRP obtained_VBD more_RBR TSs_JJ by_IN using_VBG our_PRP$ method_NN ,_, the_DT number_NN of_IN TSs_NNP might_MD be_VB insufficient_JJ ,_, namely_RB the_DT low_JJ recall_NN rate_NN ._.
To_TO im_SYM -_: prove_VB this_DT problem_NN is_VBZ the_DT most_RBS important_JJ issue_NN for_IN our_PRP$ method_NN ._.
We_PRP judged_VBD the_DT correctness_NN of_IN the_DT extracted_VBN TSs_NNP in_IN Figure_NNP 3_CD with_IN one_CD annotator_NN ._.
We_PRP prepared_VBD a_DT man_NN -_: ual_NN for_IN the_DT annotation_NN ,_, such_JJ as_IN the_DT definition_NN of_IN trou_NN -_: ble_NN information_NN ,_, in_IN advance_NN ._.
However_RB ,_, for_IN more_JJR cor_NN -_: rect_NN and_CC reliable_JJ annotation_NN ,_, we_PRP need_VBP to_TO annotate_VB TSs_NNS with_IN several_JJ annotators_NNS and_CC compute_VB the_DT agreement_NN among_IN them_PRP ._.
This_DT is_VBZ also_RB important_JJ future_NN work_NN ._.
7_CD Conclusions_NNS In_IN this_DT paper_NN ,_, we_PRP proposed_VBD a_DT bootstrapping_NN method_NN to_TO extract_VB trouble_NN information_NN from_IN Twitter_NNP ._.
As_IN a_DT preliminary_JJ experiment_NN ,_, we_PRP evaluated_VBD a_DT simple_JJ ma_NN -_: chine_NN learning_VBG method_NN based_VBN on_IN SVM_NNP and_CC a_DT sim_NN -_: ple_NN rule-based_JJ method_NN ._.
Although_IN the_DT SVM-based_JJ method_NN worked_VBD well_RB for_IN the_DT cross-validation_NN about_IN a_DT small_JJ data_NN set_NN ,_, the_DT precision_NN rate_NN dramatically_RB de_IN -_: creased_VBN for_IN a_DT real_JJ and_CC unknown_JJ tweet_NN data_NN set_NN ._.
The_DT rule-based_JJ method_NN obtained_VBD a_DT high_JJ precision_NN rate_NN as_IN compared_VBN with_IN SVM_NNP ._.
However_RB ,_, TSs_VBZ extracted_VBN cor_SYM -_: rectly_NN were_VBD reduced_VBN almost_RB by_IN half_NN ._.
The_DT main_JJ prob_NN -_: lems_NNS of_IN these_DT methods_NNS were_VBD -LRB-_-LRB- 1_LS -RRB-_-RRB- biased_VBN data_NNS ,_, -LRB-_-LRB- 2_LS -RRB-_-RRB- cov_SYM -_: erage_NN about_IN non-trouble_JJ information_NN and_CC -LRB-_-LRB- 3_LS -RRB-_-RRB- a_DT lim_NN -_: ited_VBD number_NN of_IN trouble_NN expressions_NNS -LRB-_-LRB- TEs_NNS -RRB-_-RRB- ._.
To_TO solve_VB the_DT problems_NNS ,_, we_PRP applied_VBD a_DT bootstrap_NN -_: ping_NN approach_NN to_TO the_DT trouble_NN information_NN extraction_NN ._.
By_IN using_VBG a_DT small_JJ seed_NN set_NN and_CC the_DT bootstrapping_NN approach_NN ,_, our_PRP$ method_NN increased_VBD the_DT number_NN of_IN ex_FW -_: tracted_NN trouble_NN sentences_NNS -LRB-_-LRB- TSs_NNP -RRB-_-RRB- by_IN 50_CD %_NN with_IN a_DT high_JJ precision_NN rate_NN ._.
We_PRP used_VBD three_CD characteristics_NNS in_IN the_DT TE_NNP acquisition_NN ;_: specific_JJ adverbs_NNS ,_, imperfective_JJ forms_NNS and_CC negative_JJ words_NNS ._.
In_IN addition_NN ,_, we_PRP introduced_VBD a_DT scoring_VBG method_NN to_TO avoid_VB the_DT semantic_JJ drift_NN prob_SYM -_: lem_NN ._.
The_DT scoring_VBG was_VBD based_VBN on_IN the_DT distance_NN between_IN product_NN information_NN and_CC each_DT word_NN ._.
We_PRP verified_VBD the_DT effectiveness_NN of_IN our_PRP$ method_NN with_IN different_JJ size_NN of_IN data_NNS sets_NNS ._.
Our_PRP$ method_NN was_VBD robust_JJ to_TO the_DT increase_NN of_IN target_NN data_NNS and_CC could_MD extract_VB new_JJ TEs_NNS and_CC TSs_NNS efficiently_RB ._.
In_IN the_DT discussion_NN part_NN of_IN this_DT paper_NN ,_, we_PRP explained_VBD some_DT problems_NNS through_IN the_DT extracted_VBN TSs_NNP ._.
A_DT sim_NN -_: ple_NN solution_NN to_TO improve_VB the_DT accuracy_NN is_VBZ to_TO expand_VB rules_NNS for_IN the_DT TE_NNP acquisition_NN ._.
In_IN addition_NN ,_, we_PRP need_VBP to_TO introduce_VB more_JJR deep_JJ analysis_NN ,_, such_JJ as_IN semantic_JJ analysis_NN ,_, for_IN the_DT difficult_JJ problem_NN described_VBN in_IN Sec_NNP -_: tion_NN 6.2_CD ._.
We_PRP have_VBP obtained_VBN many_JJ tweets_NNS with_IN trou_SYM -_: ble_NN information_NN by_IN our_PRP$ method_NN ._.
Deeper_JJR trouble_NN min_SYM -_: ing_NN from_IN the_DT tweets_NNS ,_, such_JJ as_IN risk-prone_JJ analysis_NN ,_, and_CC visualization_NN of_IN the_DT trouble_NN information_NN are_VBP our_PRP$ im_SYM -_: portant_JJ future_JJ work_NN ._.
Torisawa_NNP et_FW al._FW -LRB-_-LRB- 2008_CD -RRB-_-RRB- have_VBP re_SYM -_: ported_VBD a_DT system_NN based_VBN on_IN graph_NN drawing_NN as_IN a_DT web_NN search_NN directory_NN ._.
It_PRP mapped_VBD a_DT topic_NN that_IN a_DT user_NN in_IN -_: putted_VBN and_CC the_DT related_JJ keywords_NNS ._.
This_DT approach_NN is_VBZ useful_JJ to_TO find_VB and_CC understand_VB potential_JJ troubles_NNS from_IN the_DT extracted_VBN TSs_NNP ._.
Another_DT useful_JJ visualization_NN ap_SYM -_: proach_NN is_VBZ TreeMap_NNP styles_NNS -LRB-_-LRB- Johnson_NNP and_CC Shneider_NNP -_: man_NN ,_, 1991_CD -RRB-_-RRB- ._.
Carenini_NNP et_FW al._FW -LRB-_-LRB- 2006_CD -RRB-_-RRB- have_VBP proposed_VBN an_DT interactive_JJ multimedia_NNS summarization_NN system_NN based_VBN on_IN a_DT text_NN summary_NN and_CC a_DT visual_JJ summary_NN ._.
Shimada_NNP et_FW al._FW -LRB-_-LRB- 2010_CD -RRB-_-RRB- have_VBP reported_VBN an_DT interactive_JJ multime_NN -_: dia_NN summarization_NN method_NN with_IN the_DT Tree-Map_NNP and_CC fisheye-like_JJ styles_NNS for_IN clustered_VBN sentences_NNS ._.
The_DT sum_NN -_: marization_NN and_CC visualization_NN of_IN the_DT extracted_VBN TSs_NNP are_VBP interesting_JJ future_NN work_NN ._.
References_NNS Eiji_NNP Aramaki_NNP ,_, Sachiko_NNP Maskawa_NNP ,_, and_CC Mizuki_NNP Morita_NNP ._.
2011_CD ._.
Twitter_NNP catches_VBZ the_DT flu_NN :_: Detecting_VBG influenza_NN epi_SYM -_: demics_NNS using_VBG twitter_NN ._.
In_IN Proceedings_NNP of_IN Conference_NNP on_IN Empirical_NNP Methods_NNPS in_IN Natural_NNP Language_NNP Processing_NNP ,_, pages_NNS 1568_CD --_: 1576_CD ._.
Yuki_NNP Awano_NNP ,_, Qiang_NNP Ma_NNP ,_, and_CC Masatoshi_NNP Yoshikawa_NNP ._.
2012_CD ._.
Cause_NN analysis_NN of_IN new_JJ incidents_NNS by_IN using_VBG failure_NN knowledge_NN database_NN ._.
In_IN Proceedings_NNP of_IN the_DT 23rd_JJ Inter_NNP -_: national_JJ Conference_NN on_IN Database_NNP and_CC Expert_NNP Systems_NNPS Applications_NNS -LRB-_-LRB- DEXA_NNP 2012_CD -RRB-_-RRB- ,_, pages_NNS 88_CD --_: 102_CD ._.
Giuseppe_NNP Carenini_NNP ,_, Raymond_NNP T._NNP Ng_NNP ,_, and_CC Adam_NNP Pauls_NNP ._.
2006_CD ._.
Interactive_JJ multimedia_NNS summaries_NNS of_IN evalua_NN -_: tive_JJ text_NN ._.
In_IN Proceedings_NNP of_IN Intelligent_NNP User_NNP Interfaces_NNP -LRB-_-LRB- IUI_NNP -RRB-_-RRB- ,_, pages_NNS 124_CD --_: 131_CD ._.
James_NNP R._NNP Curran_NNP ,_, Tara_NNP Murphy_NNP ,_, and_CC Bernhard_NNP Scholz_NNP ._.
2007_CD ._.
Minimising_VBG semantic_JJ drift_NN with_IN mutual_JJ exclu_NN -_: sion_NN bootstrapping_NN ._.
In_IN Proceedings_NNP of_IN the_DT 10th_JJ Con_NN -_: ference_NN of_IN the_DT Pacific_NNP Association_NNP for_IN Computational_NNP Linguistics_NNP -LRB-_-LRB- 2007_CD -RRB-_-RRB- ,_, pages_NNS 172_CD --_: 180_CD ._.
Oren_NNP Etzioni_NNP ,_, Michael_NNP Cafarella_NNP ,_, Doug_NNP Downey_NNP ,_, Stanley_NNP Kok_NNP ,_, Ana-Maria_NNP Popescu_NNP ,_, Tal_NNP Shaked_NNP ,_, Stephen_NNP Soder_NNP -_: land_NN ,_, Daniel_NNP S._NNP Weld_NNP ,_, and_CC Alexander_NNP Yates_NNP ._.
2004_CD ._.
Web-scale_JJ information_NN extraction_NN in_IN knowitall_NN -LRB-_-LRB- prelim_SYM -_: inary_JJ results_NNS -RRB-_-RRB- ._.
In_IN Proceedings_NNP of_IN the_DT 13th_JJ international_JJ conference_NN on_IN World_NNP Wide_NNP Web_NNP -LRB-_-LRB- WWW2004_NNP -RRB-_-RRB- ,_, pages_NNS 100_CD --_: 110_CD ._.
Narendra_NNP K._NNP Gupta_NNP ._.
2011_CD ._.
Extracting_VBG descriptions_NNS of_IN problems_NNS with_IN product_NN and_CC service_NN from_IN twitter_NN data_NNS ._.
In_IN Proceedings_NNP of_IN the_DT 3rd_CD Workshop_NNP on_IN Social_NNP Web_NNP Search_NNP and_CC Mining_NNP -LRB-_-LRB- SWSM2011_NNP -RRB-_-RRB- ._.
Vladimir_NNP Ivanov_NNP and_CC Elena_NNP Tutubalina_NNP ._.
2014_CD ._.
Clause_NN -_: based_VBN approach_NN to_TO extracting_VBG problem_NN phrases_NNS from_IN user_NN reviews_NNS of_IN products_NNS ._.
In_IN Analysis_NN of_IN Images_NNS ,_, So_RB -_: cial_JJ Networks_NNP and_CC Texts_NNP ,_, AIST_NNP 2014_CD ,_, pages_NNS 229_CD --_: 236_CD ._.
Thorsten_NNP Joachims_NNP ._.
1998_CD ._.
Text_NN categorization_NN with_IN sup_NN -_: port_NN vector_NN machines_NNS :_: Learning_NNP with_IN many_JJ relevant_JJ features_NNS ._.
In_IN European_JJ Conference_NN on_IN Machine_NN Learn_NNP -_: ing_NN -LRB-_-LRB- ECML_NNP -RRB-_-RRB- ,_, pages_NNS 137_CD --_: 142_CD ._.
Brian_NNP Johnson_NNP and_CC Ben_NNP Shneiderman_NNP ._.
1991_CD ._.
Treemaps_NNP :_: A_NNP space-filling_JJ approach_NN to_TO the_DT visualization_NN of_IN hi_SYM -_: erarchical_JJ information_NN structures_NNS ._.
In_IN Proceedings_NNP of_IN the_DT 2nd_CD International_NNP IEEE_NNP Visualization_NNP Conference_NNP ,_, pages_NNS 284_CD --_: 291_CD ._.
Yoshifumi_NNP Kakimoto_NNP and_CC Kazuhide_NNP Yamamoto_NNP ._.
2008_CD ._.
Extracting_VBG troubles_NNS from_IN daily_JJ reports_NNS based_VBN on_IN syn_NN -_: tactic_NN pieces_NNS ._.
In_IN Proceedings_NNP of_IN PACLIC_NNP 22_CD ,_, pages_NNS 411_CD --_: 417_CD ._.
Mamoru_NNP Komachi_NNP ,_, Taku_NNP Kudo_NNP ,_, Masashi_NNP Shimbo_NNP ,_, and_CC Yuji_NNP Matsumoto_NNP ._.
2008_CD ._.
Graph-based_JJ analysis_NN of_IN se_FW -_: mantic_JJ drift_NN in_IN espresso-like_JJ bootstrapping_NN algorithms_NNS ._.
In_IN Proceedings_NNP of_IN EMNLP_NNP 2008_CD ,_, pages_NNS 1011_CD --_: 1020_CD ._.
Jochen_NNP L._NNP Leider_NNP and_CC Frank_NNP Schilder_NNP ._.
2010_CD ._.
Hunting_NN for_IN the_DT black_JJ swan_NN :_: Risk_NNP mining_NN from_IN text_NN ._.
In_IN Proceedings_NNP of_IN ACL2010_NNP System_NNP Demonstration_NNP ,_, pages_NNS 54_CD --_: 59_CD ._.
Takuma_NNP Murakami_NNP and_CC Tetsuya_NNP Nasukawa_NNP ._.
2011_CD ._.
De_NNP -_: tecting_VBG potential_JJ issues_NNS based_VBN on_IN typical_JJ problem_NN de_IN -_: scription_NN -LRB-_-LRB- in_IN Japanese_JJ -RRB-_-RRB- ._.
In_IN IEICE_NNP ,_, SIG-NLC_NNP ,_, 111_CD ,_, pages_NNS 31_CD --_: 35_CD ._.
Nobuyuki_NNP Ohmori_NNP and_CC Tatsunori_NNP Mori_NNP ._.
2010_CD ._.
Novel_NN ap_SYM -_: proach_NN for_IN test_NN methods_NNS automatic_JJ selection_NN in_IN prod_VB -_: uct_NN reliability_NN --_: improved_VBN method_NN for_IN acquiring_VBG part_NN -_: whole_JJ relation_NN --_: ._.
In_IN Proceedings_NNP of_IN International_NNP Conference_NNP on_IN Machine_NN Learning_NNP and_CC Application_NNP -LRB-_-LRB- ICMLA_NNP 2010_CD -RRB-_-RRB- ,_, pages_NNS 834_CD --_: 839_CD ._.
Bo_NNP Pang_NNP and_CC Lillian_NNP Lee_NNP ._.
2008_CD ._.
Opinion_NN mining_NN and_CC sentiment_NN analysis_NN ._.
Foundations_NNS and_CC TrendsR_NNP in_IN Infor_NNP -_: mation_NN Retrieval_NNP ,_, 2_CD ._.
Bo_NNP Pang_NNP ,_, Lillian_NNP Lee_NNP ,_, and_CC Shivakumar_NNP Vaithyanathan_NNP ._.
2002_CD ._.
Thumbs_NNS up_IN ?_.
sentiment_NN classification_NN using_VBG ma_SYM -_: chine_NN learning_VBG techniques_NNS ._.
In_IN Proceedings_NNP of_IN the_DT Con_NN -_: ference_NN on_IN Empirical_JJ Methods_NNS in_IN Natural_JJ Language_NN Processing_NNP -LRB-_-LRB- EMNLP_NNP -RRB-_-RRB- ,_, pages_NNS 79_CD --_: 86_CD ._.
Patrick_NNP Pantel_NNP and_CC Marco_NNP Pennacchiotti_NNP ._.
2006_CD ._.
Espresso_NN :_: leveraging_VBG generic_JJ patterns_NNS for_IN automatically_RB harvest_NN -_: ing_NN semantic_JJ relations_NNS ._.
In_IN Proceedings_NNP of_IN the_DT 44th_JJ annual_JJ meeting_NN of_IN the_DT Association_NNP for_IN Computational_NNP Linguistics_NNP ,_, pages_NNS 113_CD --_: 120_CD ._.
Ellen_NNP Riloff_NNP and_CC Rosie_NNP Jones_NNP ._.
1999_CD ._.
Learning_NNP dictionar_NN -_: ies_NNS for_IN information_NN extraction_NN by_IN multi-level_JJ bootstrap_NN -_: ping_NN ._.
In_IN Proceeding_VBG of_IN AAAI_NNP 99_CD ,_, pages_NNS 474_CD --_: 479_CD ._.
Ellen_NNP Riloff_NNP ,_, Ashequl_NNP Qadir_NNP ,_, Prafulla_NNP Surve_NNP ,_, Lalindra_NNP De_NNP Silva_NNP ,_, Nathan_NNP Gilbert_NNP ,_, and_CC Ruihong_NNP Huang_NNP ._.
2013_CD ._.
Sar_SYM -_: casm_NN as_IN contrast_NN between_IN a_DT positive_JJ sentiment_NN and_CC neg_NN -_: ative_JJ situation_NN ._.
In_IN Proceedings_NNP of_IN EMNLP_NNP 2013_CD ,_, pages_NNS 704_CD --_: 714_CD ._.
Stijn_NNP De_NNP Saeger_NNP ,_, Kentaro_NNP Torisawa_NNP ,_, and_CC Jun_NN '_'' ichi_FW Kazama_FW ._.
2008_CD ._.
Looking_VBG for_IN trouble_NN ._.
In_IN Proceedings_NNP of_IN COL_NNP -_: ING_NNP 08_CD ,_, pages_NNS 185_CD --_: 192_CD ._.
Hiroyuki_NNP Sakai_NNP ,_, Shouji_NNP Umemura_NNP ,_, and_CC Shigeru_NNP Ma_NNP -_: suyama_NN ._.
2006_CD ._.
Extraction_NN of_IN expressions_NNS concerning_VBG accident_NN cause_NN contained_VBN in_IN articles_NNS on_IN traffic_NN accidents_NNS -LRB-_-LRB- in_IN Japanese_JJ -RRB-_-RRB- ._.
Journal_NNP of_IN Natural_NNP Language_NNP Process_NNP -_: ing_NN ,_, 13_CD -LRB-_-LRB- 2_LS -RRB-_-RRB- :99_CD --_: 123_CD ._.
Takeshi_NNP Sakaki_NNP ,_, Makoto_NNP Okazaki_NNP ,_, and_CC Yutaka_NNP Matsuo_NNP ._.
2010_CD ._.
Earthquake_NN shakes_VBZ twitter_NN users_NNS :_: real-time_JJ event_NN detection_NN by_IN social_JJ sensors_NNS ._.
In_IN Proceedings_NNP of_IN the_DT 19th_JJ international_JJ conference_NN on_IN World_NNP Wide_NNP Web_NNP -LRB-_-LRB- WWW2010_NNP -RRB-_-RRB- ,_, pages_NNS 851_CD --_: 860_CD ._.
Kazutaka_NNP Shimada_NNP ,_, Masahi_NNP Yamaumi_NNP ,_, Ryosuke_NNP Tadano_NNP ,_, Masashi_NNP Hadano_NNP ,_, and_CC Tsutomu_NNP Endo_NNP ._.
2010_CD ._.
Inter_NNP -_: active_JJ aspect_NN summarization_NN using_VBG word-aspect_JJ rela_NN -_: tions_NNS for_IN review_NN documents_NNS ._.
In_IN Proceedings_NNP of_IN the_DT 5th_JJ International_NNP Conference_NNP on_IN Soft_NNP Computing_NNP and_CC Intelligent_NNP Systems_NNPS and_CC 11th_JJ International_NNP Symposium_NNP on_IN Advanced_NNP Intelligent_NNP Systems_NNP -LRB-_-LRB- SCIS_NNP &_CC ISIS_NNP 2010_CD -RRB-_-RRB- ,_, pages_NNS 183_CD --_: 188_CD ._.
Kazutaka_NNP Shimada_NNP ,_, Shunsuke_NNP Inoue_NNP ,_, and_CC Tsutomu_NNP Endo_NNP ._.
2012_CD ._.
On-site_JJ likelihood_NN identification_NN of_IN tweets_NNS for_IN tourism_NN information_NN analysis_NN ._.
In_IN Proceedings_NNP of_IN 3rd_CD IIAI_NNP International_NNP Conference_NNP on_IN e-Services_NNPS and_CC Knowledge_NNP Management_NNP -LRB-_-LRB- IIAI_NNP ESKM_NNP 2012_CD -RRB-_-RRB- ,_, pages_NNS 117_CD --_: 122_CD ._.
Valery_NNP Solovyev_NNP and_CC Vladimir_NNP Ivanov_NNP ._.
2014_CD ._.
Dictionary_NNP -_: based_VBN problem_NN phrase_NN extraction_NN from_IN user_NN reviews_NNS ._.
In_IN Proceedings_NNP of_IN TSD_NNP 2014_CD ,_, LNAI_NNP 8655_CD ,_, pages_NNS 225_CD --_: 232_CD ._.
Kentaro_NNP Torisawa_NNP ,_, Stijn_NNP De_NNP Saeger_NNP ,_, Yasunori_NNP Kakizawa_NNP ,_, Jun_NNP '_POS ichi_JJ Kazama_NNP ,_, Masaki_NNP Murata_NNP ,_, Daisuke_NNP Noguchi_NNP ,_, and_CC Asuka_NNP Sumida_NNP ._.
2008_CD ._.
Torishiki-kai_NNP ,_, an_DT autogen_NN -_: erated_JJ web_NN search_NN directory_NN ._.
In_IN Proceedings_NNP of_IN the_DT Sec_NNP -_: ond_NN International_NNP Symposium_NNP on_IN Universal_NNP Communi_NNP -_: cation_NN -LRB-_-LRB- ISUC_NNP 2008_CD -RRB-_-RRB- ,_, pages_NNS 179_CD --_: 186_CD ._.
Peter_NNP D._NNP Turney_NNP ._.
2002_CD ._.
Thumbs_NNS up_IN or_CC thumbs_NNS down_IN ?_.
:_: Semantic_JJ orientation_NN applied_VBD to_TO unsupervised_JJ classi_NNS -_: fication_NN of_IN reviews_NNS ._.
In_IN Proceedings_NNP of_IN the_DT 40th_JJ An_DT -_: nual_JJ Meeting_VBG on_IN Association_NNP for_IN Computational_NNP Lin_NNP -_: guistics_NNS ,_, ACL_NNP '_POS 02_CD ,_, pages_NNS 417_CD --_: 424_CD ._.
Vladimir_NNP N._NNP Vapnik_NNP ._.
1995_CD ._.
The_DT Nature_NN of_IN Statistical_NNP Learning_NNP Theory_NNP ._.
Springer-Verlag_NNP New_NNP York_NNP ,_, Inc._NNP ._.
