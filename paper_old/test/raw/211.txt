Learning Sentential Patterns of Various Rhetoric Moves for Assisted Academic WritingAbstractWe introduce a new method for extracting rep- resentative sentential patterns from a corpus for the purpose of assisting ESL learners in academic writing. In our approach, sentences are transformed into patterns for statistical analysis and filtering, and then are annotated with relevant rhetoric moves. The method in- volves annotating every sentence in a given corpus with part of speech and base phrase information, converting the sentence into for- mulaic patterns, and filtering salient patterns for key content words (verbs and nouns). We display the patterns in the interactive writing environment, WriteAhead, to prompt the user as they type away.1 IntroductionThe British Council estimated that roughly a billion people are learning and using English around the world (Graddol, 1997), mostly as a second language, and the number has been growing. For advanced learners in university, English for Academic Pur- poses (EAP) plays an important role in English Spe- cific Purposes (ESP) study. More and more Com- puter Assisted Language Learning (CALL) systems have been developed to help learners in academic writing, including concordancers, grammar check- ers, and essay raters. Typical CALL systems assist learners before and after the writing process by pro- viding corpus-based reference services, or returning a grade and corrective feedback (e.g., Cambridge English Write & Improve).However, researchers have shown that non-native student writers may have difficulties in compos-ing sentences and lack knowledge at discourse level (Hinds, 1990; Swales, 1990 or Connor,1996) in aca- demic writing. For example, (Antony, 2003) indi- cated that many Japanese scientists and engineers lack sufficient knowledge of commonly used struc- tural patterns at the discourse level.The rhetorical organization has been considered to be one of the most effective strategies of teach- ing technical writing and reading. The American National Standard Institute (ANSI) recommends ed- itors or writers to state the purpose, methods, results, and conclusions in the document (Weil, 1970). That is, an article usually begins with a description of background information, and is followed by the tar- get problem, solution to the problem, evaluation of the solution, and conclusion, by analyzing annotated dictionary examples and automatically tagged sen- tences in a corpus. As will be described in Section 4, we used the information on collocation and syntax (ICS) for example sentences from online Macmillan English Dictionary, as well as in the Citeseer x cor- pus, to develop WriteAhead. Along the same line, the second edition of the Macmillan English Dictio- nary provides a 29-page Improve your Writing Skills Writing Section with instruction on how to write flu- ently by : adding information, comparing and con- trasting, exemplifying, expressing cause and effect, expressing personal opinions, possibility and cer- tainty, introducing a concession or introducing top- ics, listing items, paraphrasing or clarifying, quot- ing and reporting, summarizing and concluding.Although there are much information (such as dictionary examples) that could help to write a pa- per, learners may fail to generalize from examples
 Figure 1: Example WriteAhead session where an user typed ”pp”.and apply to their own situations. Often, there are too many examples to choose from and to adapt to match the need of the learner writers. Learn- ers could be more effectively assisted with a tool that provides concise, relevant, genre-specific sug- gestions as learners type away, when writing a draft. In our research, we automatically extract rhetorical patterns to assist learners in academic writing. For example, in Figure 1, the learner has already typed a sentence describing the background and problem, and then the learner types the move tag AIM.Figure 2 shows the implementation of WriteA-head in the Google Doc environment. With thisGoogle Docs Add-on, the user can conveniently ac-cess the WriteAhead functionalities, as well as com-mon editing functions. According to the informa-tion, WriteAhead displays the appropriate sententialpatterns and examples for the ”method” extractedfrom a corpus, to help the learner continue writing: • Our ALGORITHM be BASE on (Our ap-proach/method is based on),• We ILLUSTRATE the ALGORITHM (Weillustrate the approach/method/technique),• The ALGORITHM be BASE on (Themethod/approach/model is base on).In this paper, we present a prototype system, WriteAhead, that extracts patterns that cover exten- sively most semantic categories in academic writ- ing (e.g. Teufel, 2000) from an academic corpus.Writing suggestions are given to assist student writ- ers. WriteAhead extracts these sentential patterns and examples automatically by tagging and analyz- ing sentences in a corpus. As will be described in Section 3, we used the Citeseerx corpus as our source to extract sentential patterns.These patterns are then used at run-time in WriteAhead for assisted writing. WriteAhead takes the move tag the user types in, and then retrieves, and displays patterns related to the tag to help the user write or edit a draft (Figure 1). We present a new methodology for automatically deriving pat- terns. WriteAhead is also the first interface that sug- gests patterns for learners while they type.The rest of the paper is organized as follows. The related work is reviewed in the next section. Then we present our method for automatically extracting sentential patterns and examples (Section 3). As part of our evaluation, we measured the accuracy rate of suggestions generated by WriteAhead using pub- lished research papers unrelated to the training data (Section 4). Section 5 reports on the experiment re- sults and we summarize our conclusion in Section 6.2 Related WorkResearchers have shown that non-native student writers may have difficulties in composing sentences
     and lack knowledge at discourse level (Connor, 1996 & 1999) in academic writing.English for Academic Purposes (EAP) plays an important role in Specific Purposes (ESP) study, focusing on English of academic writing (EAW). EAW consists in numerous academic genres, includ- ing grant proposal (Connor, 1999), research articles (Swales, 1990), and reviews, which involve manual structure analysis in the academic texts for teach- ing academic writing. Among them, research ar- ticles (RAs) play the most significant role. In our work, we use RAs as our corpus to generate senten- tial patterns, which can assist learners in academic writing. We also adopt a set of semantic categories to generate patterns, which were manually identified in Teufel (1999).2.1 Analysis of the Structure of Research ArticlesMore specifically, we focus on the structure of re- search articles, namely, automatically analyzing the abstracts based on series of moves. The sentences are classified to match the predefined structure. The most related body analyzing research article was Hill et al. (1982). The scheme he proposed was a starting-point for the analysis of the macrostructure of research articles. The graphical illustration of his proposed structure is like an hourglass.Several research indicate that RAs, defined by Swales (1990), have a simpler and more clear pictureof the organizational pattern – the IMRD structure: Introduction, Method, Results and Discussion. Ad- ditionally, Swales (1981, 1990) proposed the CARS model (”Create a Research Space”) which describes the structure of the typical introductions of scientific articles according to prototypical rhetorical building plans.The unit of analysis is the argumentative move, which represents ”a semantic unit related to the writer’s purpose”, typically, one clause or sentence long. There is a finite number of such moves, and they are subdivided into ”steps”. The model is schematically depicted in Figure 3. The model has been used extensively by discourse analysis and re- searchers in the field of discourse structure. Many studies adopted his theory to analyze the introduc- tion section (e.g. Cooper, 1985; Hopkins, 1985; Crookes, 1986; Samraj, 2002, 2005). Additionally, Thompson (1993) applied it to analyze the result section while others applied it to investigate the dis- cussion section (e.g. Hopkins and Dudley-Evans, 1994). More researches have been done to study RAs in recent years.2.2 Identifying Moves for Text ClassificationIn the search area of automatic analysis of the dis- course structure of research articles, in recent years, much work has been done viewing the task as a text classification problem that determines a label (move name) for each sentence. Various classi-Figure 2: WriteAhead implementation for Google Doc.
 Figure 3: Structure of research article introduction (Swales, 1990)fiers were applied to text categorization, including Naive Bayesian Model (NBM) (Teufel and Moens, 2002, 2004, 2006; Anthony 2003), Support Vector Machines (SVM) (McKnight and Arinivasan, 2003; Shimbo et al., 2003; Yamamoto and Takagi, 2005), Hidden Markov Model (HMM) (Lin et al., 2006), and Conditional Random Fields (CRFs) (Hirohata et al. 2008). Table 1 summarizes these approaches.Table 1 shows the set of labels commonly used in most studies: background (B), objective (O), pur- pose(P), gap (G), method (M), result (R),and con- clusion (C). We did not compare directly the perfor- mances of these studies, which used a different set of classification labels and evaluation data.Anthony (2003) has developed a system which could offer a move analysis to assist students in writ- ing and reading. He used the CARS model to an- alyze the abstracts of RA, using hand tagged RA abstracts. Shimbo et al. (2003) presented an ad- vanced text retrieval system for MEDLINE that pro- vides zone search specific sections in abstracts. The system classifies sentences in each Medline abstract into four sections: objective, method, results, and conclusion. Each sentence is represented by words, word bigrams, and contextual information of the sentences (e.g., class of the previous sentence, rela- tive location of the current sentence). They reported 91.9% accuracy (per-sentence basis) and 51.2% ac- curacy (per-abstract basis) for the classification with the best feature set for quadratic SVM.Similarly, Yamamoto and Takagi (2005) devel- oped a system to classify abstract sentences into five moves, background, purpose, method, result, and conclusion. They trained a linear-SVM classifierwith features of unigram, subject-verb, verb tense, relative sentence location, and sentence score. Hiro- hata et al (2008) presented another system for Med- line abstracts into four moves. They trained a CRF classifier with features of n-grams, sentence loca- tion, and features from previous/next sentences.3 MethodWriting academic paper by referencing examples (e.g., We illustrate the method ...) often does not work very well, because learners may fail to general- ize from examples and apply them to their own situa- tions. Often, there are too many examples to choose from and to adapt to match the need of the learner writers. To help the learner in writing, a promising approach is to extract a set of representative senten- tial patterns consisting of keywords and categories that are expected to assist learners to write better.3.1 Problem StatementWe focus on the extracting process of sentential pat- terns for various rhetoric functions: identifying a set of candidate patterns with keywords and categories. These candidate patterns are then statistically ana- lyzed, filtered and finally returned as the output of the system. The returned patterns can be directly ex- amined by the learner, alternatively they can be used to annotate rhetoric moves. Thus, it is crucial that the extracted patterns cover all semantic categories of interest. At the same time, the set of extracted patterns of a semantic category cannot be too large that it overwhelms the writer or the tagging process of the subsequent move. Therefore, our goal is to re- turn a reasonable-sized set of sentential patterns that, at the same time, must cover all rhetoric moves. We now formally state the problem that we are address- ing.Problem Statement: We are given a raw corpus CORP (e.g., Citeseerx) as well as an annotated cor- pus TAGGED-CORP in a specific genre and domain, and a list of semantic categories (e.g., PAPER = { paper, article}, PRESENT = { present, describe, in- troduce }). Our goal is to retrieve a set of tagged sen- tential patterns, p1 , ... , pm, consisting of keywords and categories from CORP. For this, we convert all sentences in CORP and TAGGED-CORP into can- didate patterns (e.g., In this PAPER, we PRESENT
Table 1: Approaches of previous studies ResearchersMacmillan English DictionaryTeufel and Moens (2002, 2004, 2006) Anthony (2003)McKnight and Srinivasan (2003) Shimbo et al. (2003)Yamamoto and Takagi (2005)Wu et al. (2006)Lin et al. (2006)Hirohata et al. (2008)Model—Naive BayesNaive BayesSupport Vector Machine Support Vector Machine Support Vector Machine Hidden Markov Model Hidden Markov Model Conditional Random FieldMoves12 moves+7 moves+ BPGMRC OMRC OMRC BPMRC BPMRC OMRC OMRCDatageneral writing scientific papers scientific papers MEDLINE MEDLINE MEDLINE Citeseer MEDLINE MEDLINE  * ADD, COMPARE, EXAM, CAUSE, OPIONION, HEDGE, TOPIC, LIST, REPHRASE, REPORT, SUM-UP + AIM, TEXTUAL, OWN, BACKGROUND, CONTRAST, BASIS and OTHER————————————————————————— - Procedure ExtractPatterns(Sent, Categories, Corpus)1. ExtractcandidatepatternsfromsentencesinCORP(Sec- tion 3.2.1)2. Grouppatternsbysemanticcategoriesinthegivencorpus (Section 3.2.2)3. Generatesententialpatternsbystatisticallyanalyzingand filtering candidate patterns (Section 3.2.3)4. Outputcharacteristicpatternsforeachcategory —————————————————————————Figure 4: Outline of the pattern extraction processWORK), such that these candidates can be statisti- cally analyzed and filtered to generate common and representative patterns.In the rest of this section, we describe our solu- tion to this problem. First, we define a strategy for transforming sentences from academic corpora into candidate patterns (Section 3.2.1). This strategy re- lies on a set of candidate patterns derived from sen- tences of patterns (which we will describe in detail in Section 3.2.3). In this section, we also describe our method for extracting the most representative of the candidate patterns for each semantic category of interest. Finally, we show how WriteAhead displays patterns at run-time (Section 3.3).3.2 Transforming Sentences into PatternsWe attempt to find transformations from sentences into patterns, consisting of keywords and categories expected to characterize rhetoric moves in academic writings. Our learning process is shown in Figure 4.———————————————————- Procedure SPs&Examples (Sentences, Templates)(1) taggedCorpus = ChunkParser(Sentences)(2) candidates = GenPatternCandidate(taggedCorpus)(3) patternInstances = ReplaceTeufel(candidates)(4) Pats, Categories, Instances = GroupByCate-gory(patternInstances)(5) Pats, Counts = Counter(Patterns, Instances)(6) Avg, STD = CalStatics(Pats, Counts)For each Pat, Count pair in (Pats, Counts)If Count > Avg + MinSTDThreshold × STD(7) Emit Tuple = (Word, Pat, PatTuples)(8) Pats = Annotate(Word, Pat, PatTuples)———————————————————-Figure 5: Process for extracting SPs and examples.3.2.1 Extracting Candidate Patterns.In the first stage of the extracting process (Step (1) in Figure 5), we tokenize sentences in the given corpus, and assign to each word its syntactic infor- mation including lemma, part of speech, and phrase group (represented using the B-I-O notation to mark the beginning, inside, and outside of some phrase group).See Table 2 for an example of tagged sentence. In order to identify the head of a phrase, we convert the B-I-O notation to I-H-O notation with H denoting the headword of a phrase. Using the I-H-O nota- tion allows us to directly identify the headword of a phrase chunk. Then, we convert every word in a sentence into elements of a candidate pattern. The
Table 2: A tagged sentence, pattern elements for each word, and anchored pattern candidates Word LemmaIn Inthis this report report, ,we we propose propose a a method methodPOS B-I-O I-H-O ElementIN B-PP I-PP inDT B-NP H-NP thisNN I-NP H-NP PAPER, O O ,PRP B-NP I-NP weVBP B-VP H-VP PRESENT DT B-NP I-NP ()NN I-NP H-NP WORKPattern candidate anchored at each word(In)(In this)(In this PAPER)(In this PAPER ,)(In this PAPER , we)(In this PAPER , we PRESENT) (InthisPAPER,wePRESENT )(In this PAPER , we PRESENT   WORK)    Table 3: Example Teufel category of sentential patternsFor example, in Table 2, the sentence ”In this pa- per, we propose a method that accurately reports timing information by accounting for intrusion in- troduced by monitoring.” will be transformed into the candidate pattern ”In this PAPER, we PRESENT WORK”.The input to this state is a set of sentences. These sentences constitute the data for generating the can- didate patterns, that can be used in the next step.The output of this stage is a set of candidate pat- terns that can be statistically analyzed and filter in a later step. See Table 4 for example candidate pat- terns extracted from some sentences.3.2.2 Grouping Patterns by Categories.In the second stage of the process (Step (4) in Fig- ure 5), we filter candidate patterns to generate rep- resentative patterns. Once patterns and instances are generated, they are sorted and grouped by category.Then, we count the number of instances of each pattern within the category (in Step (5)), and the av- erage and standard deviation of these counts for each category (in Step (6)).In Step (7), we select patterns with an in- stance count exceeding the average count by Min- STDThreshold standard deviation.Consider the partial sentence ”In this paper, we propose a method” Table 2 shows elements of each word, pattern candidates anchored each word. Note that the candidate (e.g., In this PAPER, we PRESENT WORK associated with the instance of In this paper, we propose a method) are valid pat- terns. Teufel categoryPAPER WORK PURPOSE DEVELOP PRESENT EVALUATEGloss and examplesarticle, draft, paper, project, report, ... analysis, approach, method, ...aim, goal, purpose, task, theme, topic, ... accomplish, achieve, answer, prove, ... describe, introduce, present, propose, ... compare, compete, evaluate, test, ...  elements consist of three types of information:• Semantic categories (See Table 3) : typical do-main specific concepts and words,• Lexical symbols: a list of common preposi-tions, pronouns, adverbs, and determinants,• Noun phrase and verb phrase: head wordsthat are not classified in a category are repre- sented as something or do.Note that determinants (e.g., the, an, a) or adjec- tives need to be represented in a pattern. For those words, we add ” ” (ignored) to the element list. The ignored elements will be deleted before patterns are analyzed and filtered (as shown in Table 2). We de- sign the scope of extracted patterns, as from the be- ginning of the sentence, to the object phrase after the main verb.Finally, we combine elements for a sentence to generate pattern candidates (Step (2) in Figure 5). Table 2 shows those elements associated with words and how they combine to form pattern candidates.In Step (3), we use semantic categories to gener- alize words and generate formulaic patterns. As will be described in Section 4, we used a Teufel manually analyzed research article to device a set of categories of words (Teufel, 1999). 
Table 4: Ranked patterns based on CORP and TAGGED-CORP statistics AZ Pattern CountExampleIn this paper , we present/propose/introduce In this paper , we describeIn this paper we present/propose/introduce In this paper we describe/discussThe purpose/aim/goal of this paperThe aim/purpose of this studyIn this paper , we investigate/examine/identify In this paper , we analyze AIM In this PAPER , we PROPOSE AIM In this PAPER we PROPOSEAIM The AIM of this PAPERAIM In this PAPER , we INVESTIGATE3.2.3 Ranking and Annotating Patterns.In the third and final stage (Step (8) in Figure 5), we count, sort, and filter patterns, essentially using the frequency counts from CORP with the tags in TAGGED-CORP (See Tables 4). Figure 5 shows the algorithm for ranking a set of corresponding senten- tial patterns for all semantic categories. See Table 6 for an example of the move tag AIM and its corre- sponding sentential patterns.3.3 Run-TimeOnce the patterns and examples are automatically extracted for each category in the given corpus, they are stored and indexed by category that can be annotated with corresponding rhetoric moves. At run-time in a writing session, WriteAhead detects a rhetoric move tag Move in the text box. With the tag as a query, WriteAhead retrieves and sorts all rele- vant patterns and examples (Pattern and Example) by frequency, aiming to display the most common information toward the top.4 Implementation and SettingIn this section, we describe the implementation and experiments of the method presented in Section 3. First, we retrieved computer science abstracts from the digital library website, CiteSeer (citeseerx. ist.psu.edu, a collection of bibliographies of scientific literature in computer science from various sources). We obtained about four million computer science abstracts. Before extracting patterns, we use GeniaTagger as a simple toolkit for analyzing and parsing English sentences and outputting the base forms, part-of-speech tags, chunk tags and namedentity tags. Tsuruoka et al. (2005) develop this tools, specifically tuned for biomedical text. Then, we use this tagger for tagging sentences to obtain the part-of-speech tags, lemma, chunks for training the model. After tagging, we applied our method to extract patterns from CiteSeer x.We used manually compiled semantic categories and words (Teufel, 1999) to generalize word and generate formulaic patterns. There are 66 categories with some 900 nouns, verbs, and adjectives.For example, in Table 2, the sentence ”In this pa- per, we propose a method that accurately reports timing information by accounting for intrusion in- troduced by monitoring.” will be transformed into the candidate pattern ”In this PAPER, we PRESENT WORK”. As will be described in Section 4, we used a Teufel manually analyzed research article to derive a set of categories of words (Teufel, 1999).We also used the Argumentative Zoning corpus (available at www.cl.cam.ac.uk/ ̃sht25/ AZ_corpus.html), created and annotated by Teufel (2010) and collaborators. The dataset con- sists of 80 AZ-annotated conference articles in the research area of computational linguistics, hosted in the academic archive of Cmplg arXiv. The set of AZ tags include AIM (purpose), BAS (basis), BKG (background), CTR (contrast), OTH (previous work), OWN (own method and results), TXT (tex- tual references).To provide user interface for accessing WriteA- head, we have implemented two versions of the sys- tem: (1) browser-based proof-of-concept (POC) in- terface and a Google Docs add-on. (2) To prove the feasibility of the concept, the browser version (with-100,607 48,354 20,725 16,872 
out the common editing functions) was implemented in Python and within the Flask Web framework. We stored the suggestions in JSON format using Post- greSQL for a faster access. The WriteAhead server obtains client input from a popular browser (Safari, Chrome, or Firefox) dynamically with AJAX tech- niques. For uninterrupted service and ease of scal- ing up, we chose to host WriteAhead on Heroku, a cloud-platform-as-a-service (PaaS) site.The WriteAhead add-on for Google Docs was im- plemented in Google App Script (GAS) with HTML and JavaScript. WriteAhead add-on obtains client input from documents using built-in methods in GAS, and obtains the suggestions by sending re- quests to the WriteAhead server through our API. To start the add-on, the user click ”Add-ons > WriteA- head > Start” after installation, and a sidebar will appear. The suggested patterns and examples are shown in the sidebar.5 EvaluationThe proposed system was designed to automatically extract patterns and examples for each correspond- ing rhetoric move. A preliminary evaluation was done on a set of real formula labeled with moves. We compared our patterns with the Teufel formula and evaluated the precision in different experimen- tal settings. In this Section, we first describe how we compared patterns (Section 4). Then, Section 5.1 introduces the evaluation metrics for evaluating the experimental results.5.1 Evaluation MetricsThe output of our method is an automatically tagged pattern, which can either be shown to the user di- rectly, or be used in academic writing, e.g., in teach- ing academic writing, teachers can use those tagged patterns to help tag the sentences in a given RA with moves.To evaluate our approach, we compare our senten- tial patterns with Teufel Formula. We extract three categories PAPER, WORK, and PRESENT to in- spect that if there are some patterns in common.We compare Teufel formulas and our extracted sentential patterns under three specific categories, PAPER, WORK, and PRESENT. In PAPER cate- gory, there are 76 formula and 5 patterns, amongthese, 18 formula and 5 patterns are in common. Similar in WORK category, there are 153 formula and 16 patterns, among these, 30 formula and 16 patterns are in common. And in PRESENT cate- gory, there are 15 formula and 13 patterns, among these, 7 formula and 5 patterns are in common.In comparison, our sentential patterns are longer and more complete than Teufel’s original formulas serving as features for classification. It is clear that, our sentential patterns tend to be more complete and indicative of rhetoric moves, since we use the stop- ping condition to extract patterns all the way up to the object of the main verb. As it turns out, the pat- terns generate by a computer using a very large scale academic corpus are more consistent, complete, and relevant to academic writing.6 Conclusion and Future WorkMany avenues exist for future research and improve- ment of our system. For example, the method for extracting patterns could be discussed further and be evaluated separately, using different formula to cal- culate a threshold, and generate different patterns. Additionally, an interesting direction to explore is to expand the word categories and obtain more fine- grain patterns. Yet another direction of this research would be applied to the model of different sections of RAs, and more disciplines.In summary, we have presented a new method for extracting patterns in a scholar big dataset for var- ious moves in academic writing. The method in- volves patterns with all semantic categories of in- terest. The experimental results show that our auto- matically extracted patterns reflect different rhetoric moves and purposes.ReferencesAnthony, Laurence and Lashkia, George V.Mover: A machine learning tool to assist in the read- ing and writing of technical papers. Transactions on Professional Communication, IEEE. Vol 46,3, pages 185–193, IEEE.Connor, Ulla. 1996. Contrastive rhetoric: Cross-cultural aspects of second language writing. Cambridge Uni- versity Press.Connor, Ulla and Mauranen, Anna. 1999. Linguistic analysis of grant proposals: European Union research2003.
grants. English for specific purposes. Vol. 18, 1, pages47–62, Elsevier.Cooper, Catherine. 1985. Aspects of article introduc-tions in IEEE publications. Unpublished master’s the-sis, University of Aston, Birmingham, England.Crookes, Graham. 1986. Towards a validated analysis of scientific text structure. Applied linguistics, Am Asso- ciation of Applied Linguistics. Vol. 7, 1, pages 57–70.Dudley-Evans, Tony. 1994. Genre analysis: An ap- proach to text analysis for ESP. Advances in written text analysis. Vol. 219, page 228.Graddol, David. 1997. The future of English?: A guide to forecasting the popularity of the English language in the 21st century. British Council.Hill, Susan S and Soppelsa, Betty F and West, Gre- gory K. 1982. Teaching ESL Students to Read and Write Experimental-Research Papers. TESOL quar- terly. Vol. 16, 3, pages 333–347, Wiley Online Library.Hinds, John. 1990. Inductive, deductive, quasi- inductive: Expository writing in Japanese, Korean, Chinese, and Thai. Coherence in writing: Research and pedagogical perspectives, pages 87–110.Hirohata, Kenji and Okazaki, Naoaki and Ananiadou, Sophia and Ishizuka, Mitsuru and Biocentre, Manch- ester Interdisciplinary. 2008. Identifying Sections in Scientific Abstracts using Conditional Random Fields. IJCNLP, pages 381–388.Hopkins, Andy. 1985. An investigation into the orga- nizing and organizational features of published confer- ence papers. Unpublished MA dissertation, University of Birmingham.opkins, Andy and Dudley-Evans, Tony. 1988. A genre- based investigation of the discussion sections in arti- cles and dissertations. English for Specific Purposes. Vol. 7, 2, pages 113–121, Elsevier.Lin, Jimmy and Karakos, Damianos and Demner- Fushman, Dina and Khudanpur, Sanjeev. 2006. lin2006generative. Association for Computational Linguistics, pages 65–72.McKnight, Larry and Srinivasan, Padmini. 2003. Cat- egorization of sentence types in medical abstracts. American Medical Informatics Association Annual Symposium Proceedings 2003, page 440.Ruiying, Yang and Allison, Desmond. 2003. Research articles in applied linguistics: Moving from results to conclusions. English for Specific Purposes. Vol. 22, 4, pages 365–385.Samraj, Betty. 2002. Introductions in research articles: Variations across disciplines. English for specific pur- poses. Vol. 21, 1, pages 1–17, 2002. Elsevier.Shimbo, Masashi and Yamasaki, Takahiro and Mat- sumoto, Yuji. 2003. Using sectioning information for text retrieval: a case study with the medline abstracts.Proceedings of Second International Workshop on Ac-tive Mining (AM’03).Swales, John. 1990. Genre analysis: English in aca- demic and research settings. Cambridge University Press.Teufel, S., Carletta, J. & Moens, M. 1999. An annotation scheme for discourse-level argumentation in research articles. EACL.Teufel, Simone. 2000. Argumentative zoning: Informa- tion extraction from scientific text. Diss. University of Edinburgh.Teufel, Simone and Moens, Marc. 2002. Summariz- ing scientific articles: experiments with relevance and rhetorical status. Computational linguistics. Vol.28, pages 409–445. MIT Press.Teufel, Simone. 2010. The Structure of Scientific Ar- ticles: Applications to Citation Indexing and Sum- marization (Center for the Study of Language and Information-Lecture Notes). Center for the Study of Language and Inf.Thompson, Dorothea K. 1993. Arguing for Experimen- tal Facts in Science A Study of Research Article Re- sults Sections in Biochemistry. Written communica- tion. Vol. 10, 1, pages 106–128, Sage Publications.Tsuruoka, Yoshimasa and Tateishi, Yuka and Kim, Jin- Dong and Ohta, Tomoko and McNaught, John and Ananiadou, Sophia and Tsujii, Junichi. 2005. De- veloping a robust part-of-speech tagger for biomed- ical text. Advances in informatics, pages 382–392, Springer.Weil, Ben H. 1970. Standards for writing abstracts.Journal of the American Society for Information Sci-ence. Vol. 1, 5,pages 351–357, Wiley Online Library. Yamamoto, Yasunori and Takagi, Toshihisa. 2005. A sentence classification system for multi biomedical lit- erature summarization. Data Engineering Workshops, 2005. 21st International Conference on BiomedicalData Engineering, pages 1163–1163, IEEE.