 Stance Classification on PTT CommentsAbstractWith the development of social media and online forums, users have grown accustomed to expressing their agreement and disagreement via short texts. Elements that reveal the user’s stance or subjectivity thus becomes an important resource in identifying the user’s position on a given topic. In the current study, we observe comments of an online bulletin board in Taiwan for how people express their stance when responding to other people’s post in Chinese. A lexicon is built based on linguistic analysis and annotation of the data. We performed binary classification task using these linguistic features and was able to reach an average of 71 percent accuracy. A linguistic analysis on the confusion caused in the classification task is done for future work on better accuracy for such task.1 IntroductionThe wide spread of social media has given organizations and individuals new channels to understanding public opinion. Opinions are expressed via public debate forums and on various platforms, such as Facebook, Twitter, and even Youtube. These opinions reveal how users feel about an event, a person, or any focus of discussion. One expression in Taiwan, 測風向 cè fēngxiàng “to test the direction of the wind” is used by netizens when an article online inquires how the public feels about a topic. The phrase perfectly demonstrates how online discussions reflect the public’s reaction to certain event or certain individual, often a political figure. In Taiwan, the mass media often resort to online forums as a source of understanding how the public respondsShukai HsiehGraduate Institute of Linguistics National Taiwan University shukaihsieh@ntu.edu.twto political events like new policy and candidates running for elections.Online discussion forums and social media give citizens an easier access to information and more power in shaping what information or idea gets passed on. Users of these online forums participate in a process of framing discussions and forming opinions. As Walker et al. (2012) pointed out, these debates involve not only the expression of opinions but also the formation of opinions. Through posting articles online, users talk about their beliefs on what is true or not, what is important, and what should be done. Their shared opinions thus stimulate more discussions. These users play an important role on how the discussions are framed and shape the form of the arguments.One characteristics of these forums is that users usually have to express their position in a very short text. This implies that stance classification on short text would be different from identifying stance on a document level. Thus, we find it important to identify “elements” that reveal user’s subjectivity in these short texts. Such resources would assist in identification or classification of attitudes and is applicable in all tasks that involves differentiating between factual information and opinionated utterances.In the current study, we observe stance-taking language and arguing behavior from online comments and from previous studies in both English and Mandarin. The hope is to provide linguistic patterns and analysis that would assist in automated classification on stance. In the following sections, we will introduce previous works done on related topic of interest, discuss our work on tagging and classifying PTT comments, present the result of our classification task, and an analysis on classification errors that could shed light on future tasks on short text stance classification.
 2 Related workThe importance of social media has been captured in Shirky’s study on the political power of social media. He asserts that regular citizens, nongovernmental organizations, firms, and governments are all actors in social media. Social media has become an active part in political movements all over the world (Shirky, 2011).This increasing importance and the accessibility of online data have triggered interests in related research to achieve automated methods in understanding affections and opinions. Previous research has made efforts on differentiating factual information from opinionated information. Opinionated information reveals a person’s private states through the use of subjective language. Private state is a term that covers a person’s overall attitude, including opinions, evaluations, emotions, and speculations (Quirk et al., 1985). Identifying these cues could assist automatic tasks on detecting attitudes online by providing resources (Wiebe et al., 2005).Wiebe et al. (2004) extracted subjective cues by combining manually annotated subjective elements and expanding it with collocations and clustering method. Somasundaran et al. (2007) inspected dialogues in meetings to detect arguing and sentiment. In the annotated data, sentiment includes emotions, evaluations, judgements, feelings, and stances. Arguing refers to cues that indicate the speaker’s attempt to convince one another.The extracted subjective cues are utilized in classification of texts online for users’ stance, defined as “an overall position held by a person toward an object, idea, or proposition” (Somasundaran et al., 2009). Stance classification deals with two sided debates and seeks an automated approach to categorization whether a person is for or against the topic discussed (Hasan and Ng, 2013).In Somasundaran and Wiebe’s study in 2010, they tested a combined feature set of arguing based features and sentiment based features. Arguing based features included arguing trigger expressions and modal verbs. Sentiment lexicon compiled by Wilson et al. in 2005 was used as sentiment based features. They reached an average accuracy of 64 percent classifying online debates based on the lexicon.Anand et al. (2011) combined the feature set with metalinguistic features like word length and number of characters and approach arguing language with dependency parsers that capture words and its modifying targets. An average accuracy of 65 was reached. Hasan and Ng (2013) takes into account features like the author’s position towards other issues and the stance of the immediate preceding post as predictors for stance classification and raised the accuracy up to 74%.Faulkner (2014) incorporated generalized stance proposition subtrees and “Wikipedia Link-based Measure” to capture the relations between topics. The combined feature set was able to achieve an average accuracy of 80 percent on students’ argumentative essays.Although previous studies on stance classification has proven that classifier trained on unigrams could be a baseline that is hard to defeat and that identification on stance could be difficult for human annotators, adjustment according to the nature of the data set could help improve the results of the classification. Previous studies have mainly focused on document-level stance (Faulkner, 2014) or online debate forums (Anand et al., 2011; Hasan and Ng, 2013). Less attention has been placed on short text comments. However, we believe subjective elements is important in these texts full of sarcasm, typing errors, and colorful use of language (Malouf and Mullen, 2008). The aim of the current study is to establish related resources in Mandarin from short text comments online and to examine whether these linguistic cues assist in stance classification.3 Methodology 3.1 Data collectionThe corpus in the current study was collected from an online forum used in Taiwan, PTT. PTT is the most popular online bulletin board in Taiwan (Shea, 2006). It allows users to share their opinion by posting articles and responding to other’s posts. The platform is divided into boards with different topics. Each board is centered on certain field of discussion. For example, the board “Boy_Girl” is a board users discuss relationships between boys and girls.In PTT, users give response to other users’ posts with comments. Comments are tagged by the users
 with their own attitude, whether towards the issue discussed, the author of the post, or previous responses comments left by other users. Three tags are available, including “push”, “boo”, and “arrow”. “Push” indicates that the author has a positive attitude towards either the original post or previous comments; “boo” is used when expressing a negative or opposing view; “arrow” is used when no certain attitude is chosen.The data collected are extracted from three boards that are popular on PTT, including “Gossiping”, “Boy_Girl”, and “WomenTalk”. The boards are chosen with consideration to the amount of data and to the nature of discussion. Some of the boards, though popular enough, may only allow “push” and “arrow” comments or may not be discussion-oriented. In order to identify the patterns used in push comments and boo comments, boards with more opinionated discussions are preferred.Each line of comment in PTT is limited to 27 Chinese characters. Comments that exceeds 27 characters would be shown in a second line with an automatically assigned “arrow” at the beginning of the line. As a result, for comments that lasts more than one line, only the beginning line would be shown with the original tag while the rest of the lines would begin with an arrow. Since comments are extracted line by line with its tag at the beginning of each line and categorized as such, we cannot distinguish comments tagged with “arrows” by the original user from comments that exceeds one line. In order to avoid confusion between opinionated comments over one line and neutral comments that are originally tagged with arrows, the current study extracts only comments that are tagged with “push” and “boo” and focus on binary classification on opinionated sentences. Table 1 shows the details of the corpus used in the study.           Number of comments     Number of tokens   Number of token types Gossiping (6 months)         Push 3786034     28341656   11538420     Boo    1222735      9000728      493926   Boy_Girl (12 months)    Push998327  10006638 462780     Boo    53376      508778      66186     WomenTalk (12 months)      Push167473  1655771 121794     Boo    36381      354672      47904  3.2 Annotation criteriaSince comments on these forums are used as a way for users to express their opinion, to oppose to others’ ideas, and to justify their reasons for believing in or not believing in something (Wilson and Wiebe, 2005; Wilson, 2008; Somasundaran et al., 2007), the lexicon used in the classifier is compiled with a set of categories that are related to stance-taking and arguing. Following previous studies, we look for linguistic cues that indicate the author’s opinion or position on the discussed topic. The following are categories included in the annotation. In the tagging process, the identified “element” is not restricted to the word level. Considering the fact that subjectivity is often revealed in a common phrase or expression, function words are also included in the tagged set. For example, expression like 最好是 zuìhǎoshì“it’d better be” is treated as an element used to reject other people’s opinion.3.2.1 Arguing cuesPhrases and syntactic patterns that are indicative of opinionated sentences are manually identified from 5000 random comments tagged with push and boo, individually. Reynolds and Wang’s (2014) categorized comments on PTT into 9 categories, including questions, reply, clarification, interpretation, etc. We narrowed the categories down to 6 categories, including question- answering, confirmation, counterargument, clarification, suggestion, and encouragement. Expressions that carry one of these six functions would be included as an arguing cue. The annotated outcome is combined with the sixteen categories of arguing cues in MPQA opinion corpus (Wiebe et al., 2005; Somasundaran et al., 2007) as features for arguing cues.Table 1. Corpus information
 Neutral question answering usually happens when users enquire information on something and is often non-opinionated. It often contains only a proper noun and with no specific cues. Sometimes users would include example-giving as part of their answer. Markers used at such circumstances would include phrase like 像 是 xiàngshì “like”. Confirmation contains expressions used to agree with previous propositions, such as 同意 tóngyì “agree”. Counterargument is used when the user opposes to or challenges either the original post or previous comments. An example cue of counterargument would be 你怎麼知道 nǐ zěnme zhīdào “how do you know”. Clarification is used when the focus of the comments shifts from one part to another and is sometimes used for similar purpose as a counterargument. An example of a comment used to clarify is shown in example (1) below, with the arguing cue underlined.meaning that it can subjective in a certain context. Most of the words included are noun phrases and verb phrases that are evaluative, including both explicit subjective elements and expressive subjective elements (Wiebe et al., 2005; Wilson, 2008). Criticism and appraisal are given as tags to each of the phrases, indicating positive and negative evaluation.Explicit subjective elements refer to phrases that explicitly show the attitude of the speaker, such as 討厭 tǎoyàn “hate” and 反對 fǎnduì “against”. Expressive subjective elements refer to expressions that reveal one’s attitude without explicitly naming that attitude. For example, in the sentence “the report is full of absurdities”, the phrase full of absurdities is used to express negative evaluation on the report (Wiebe et al., 2005).In this category, expressive subjective elements are considered more interesting because some of the words might not be negative when it occurs individually or in other contexts. However, users on PTT form their habitual use of language to express their attitudes towards something without directly giving an evaluation. For example, the original definition of the word 公主 gōngzhǔ “princess” refers to a member in the royal family, but in PTT, it is a negative evaluation which refers to girls who rely on their boyfriends to take perfect care of them, cater to their every need, and gets mad over trivial matters. These expressions involve users’ world knowledge and is often used in sarcasm and irony (Wiebe et al., 2005). Identifying these elements would help us identify whether a comment or an evaluation towards the posted article contains positive or negative attitude.3.2.3 Metadiscourse markersMetadiscourse has been included in previous studies (Vande Kopple, 1985; Hyland, 1998; Hyland, 2002; Hyland and Tse, 2004; Dafouz- Milne, 2008) as a crucial part of persuasive writing. It reveals the author’s strategic arrangement of the text base on his intention to persuade and his understanding of the potential readers. According to Halliday (1973), the three macrofunctions of language include ideational function, interpersonal function, and textual function. The categorization of metadiscourse markers corresponds to two of the three functions, interpersonal and textual. Textual metadiscourse refers to the structure of the(1) 你 爸爸 nǐ bàbayour father錢奴 ,qián nú ,這樣是zhèyàngshìthis is不是bùshì  miser企業家 ...qǐyèjiāentrepreneur“Your father is a miser, not anentrepreneur.”Suggestion is used when the user provides a solution or advice for the poster or other users. It is similar to neutral question answering but it usually involves more personal point of view. A typical cue in this category would be 建 議 jiànyì “suggest”. Encouragement refers to the expressions of sympathy and support, which is very common on some boards. Users may use cues like 拍拍 pāipāi “patting” or 加油 jiāyóu “cheer up” to show their understanding of what the poster is going through.3.2.2 Subjective elementsFollowing previous studies, words that are indicative of the author’s stance on the discussed topic are included in the lexicon. Our definition of subjective elements is similar to the one brought up by Wiebe in 1994, which identifies a subjective element as an element that is potentially subjective,not
 text. How the author arranges his text might affect the readability persuasiveness of the text. Interpersonal metadiscourse, on the other hand, refers to how the author positions himself in the text and how he includes his readers. Following Hyland’s study (1998), ten categories are includedas metadiscourse markers: logical connectives, frame markers, endophoric markers, evidentials, code glosses, hedges, emphatics, attitude markers, relational markers, and person markers. Examples and definition of each category is given in the following table.     Textual Metadiscourse    Logical connectives Express semantic relation between main clauses    所以suǒyǐ ‘therefore’    Frame markers   Explicitly refer to discourse acts or text stages     先xiān ‘first’    Endophoric markersRefer to information in other parts of the text  我剛才說的 wǒ gāngcái shuō de ‘what I just said’    Evendentials Refer to source of information from other texts    指出 zhǐchū ‘pointed out (in the show)’    Code glosses   Help readers grasp meanings of identical material    換言之 huànyánzhī ‘in other words’     Interpersonal Metadiscourse    Hedges Withhold writer’s full commitment to statements    可能 kěnéng ‘possibly’    Emphatics   Emphasize force or writer’s certainty in message     絕對juéduì‘definitely’    Attitude markersExpress writer’s attitude to prepositional content  同意 tóngyì‘agree’    Relational markers   Explicitly refer to or build relationship with reader     你 nǐ ‘you’    Person markersExplicit reference to author(s)   我們 wǒmen ‘we’During the annotation process, we find that there may be overlapping categories for arguing and for metadiscourse. One element could also have more than one function in comments. Our approach is to keep all categorization as part of the resources. Examples showing the arrangement of the data can be found in Table 3. The second column shows its category in metadiscourse, and the third column shows its category in MPQA arguing lexicon. Thefourth column shows its category in the six types of comments. The fifth column shows its annotated prior subjectivity, which is the polarity of the word when it stands alone. The last column show its polarity in the extracted corpus, which is acquired by comparing the element’s relative frequency in push and boo comments. The combined annotated lexicon includes a total of 4582 entries.Table 2. Categories of Metadiscourse Markers   entry  metadiscourse     arguing   commenting     prior sub     calculated sub    感覺  assessmentquestion-answering; encouragement  neu pos   不然 logical connectives    conditional counterargument; suggestion    neu   pos   當然 emphatics    emphasis confirmation; counterargument    neu   pos   好像   hedges        counterargument     neu     pos  3.3 Building the classifierTable 3. Examples of the subjective lexiconidentifying the stance of comments. In the current study, three sets of features are used in building the classifier. The first set of featuresThe combined lexicon is used as feature set for contains subjective elements acquired through
 manually annotating the data. For subjective elements, we assume negative evaluation reflects negative attitudes that more likely occur in boo comments while positive evaluation is associated with push comments. The second set of features includes the C- LIWC wordlist of positive and negative emotions (Huang, 2012). In this set, positive emotion words are associated with push comments while negative emotions are associated with boo comments. As for the rest of the cues, which may occur in both positive and negative context, we use relative frequency as a way of deciding whether it is representative for a certain position or not. Using the following calculations, if the number is higher than 0.70, the expression (which could be a subjective element, an entity, or even a disclaimer) would be judged as a feature for identifying that particular stance.Relative frequency of the segment in boo/push commentsRelative frequency of the segment in all commentsThe calculation is done after all of the scarce words are removed from the data. We used the third quantile of frequency as the threshold for scarce words. Thus, in all three sets of data, words that occur only once are removed. Relative frequency of data from each board is calculated individually. The combined wordlist is then used as features for an SVM classifier1.4 Result and discussionIn order to make a comparison, a baseline was done using segmented words as features for the SVM classifier. The feature set raises the accuracy on WomenTalk from 55 percent to 75 percent. The classification on Boy_Girl data also improved by 13 percent. What’s worth noticing is that the1 The classifier used here is released by CLiPS, Computational Linguistics and Psycholinguistics Research Center and is available on http://www.clips.ua.ac.be/pages/pattern- vector#classificationaccuracy of Gossiping data dropped by 2 percent. Table 3 shows the results of the classifier.Table 3. Results using the combined feature setThe numbers show that the feature set can successfully assist in the classification of texts in Boy_Girl and WomenTalk. However, the accuracy of classification on Gossiping data perform two percent lower than baseline. There are a few possibilities to why there would be a difference between these three sets of data.1. The degree of diversity of the topicsThe three boards, though all discussion oriented, involves the exchange of information in different topics. For Boy_Girl board, most of the topic is centered on romantic relationships. As for WomenTalk board, most of the discussions focus on things that girls care about, such as products for women, boyfriends, etc. These two boards might have a clearer group of users than Gossiping, where all kinds of questions could be relevant. The topics cover from debates on international political events to opinions on superhero characters. In previous studies in English (Hasan and Ng, 2013; Hasan and Ng, 2014; Faulkner, 2014), domains are usually selected and separated so that the classification is performed on one central idea, such as gay rights or death penalty. The variety of topics might be a reason why classification on Gossiping data is less accurate than the others.2. Different language use due to the different culture of the boardSince each board on PTT has its own purpose of discussion, every board attracts different group of users and forms its unique “culture”. In general, speakers on Gossiping board is more direct and more quick to criticize than users on the other two boards, as indicated by the different proportions of push comments and boo comments in the three boards. The difference might suggest that boo comments on WomenTalk and Boy_Girl would      Baseline   SVM Classifier  Gossiping     0.69     0.67   Boy_Girl  0.57 0.70  WomenTalk    0.55   0.75  Average     0.60     0.71      
 have a higher degree of disagreement than the ones on Gossiping, which makes it harder to differentiate push and boo comments on Gossiping. Other than possible differences among the boards, error analysis is also done by randomly selecting comments that are mistakenly tagged by the classifier. The result shows that the following mistakes are most common.1. Context dependent commentsSince comments on PTT are usually left very short so that people can grasp the idea at a quick glance, a lot of words are often omitted in comments. The other users would have to judge the stance of the comment by combing the information they get from the original post and the self-tagged stance. Thus, two kinds of confusion might arise when we have to judge the stance of the comment without its context, including the original post and previous comments.First type of error occurs when the target of the comment is not the original poster but the person or event of which the poster is attacking. For example, when a boyfriend complains about his girlfriend who always threatens to break up with him whenever they have a fight, other users might leave comments criticizing that girlfriend. But since they agree with the original poster’s position, which is a negative attitude towards the girlfriend’s behavior, the tags they give to their comments are usually “push”. For our classifier, this would cause confusion because the linguistic behavior corresponds to negative evaluation, which is usually associated with “boo” comments. As a result, these comments would be categorized as “boo” comments. The following is an example of this type of error.Confusion may result because the target of the comment could be the person the original post was criticizing or it could be the original poster him/herself. That target could only be identified with consideration of what was originally written in the post.The second type of error involves comments that are very short and give very little clue on their stance. The expressions that occur in these comments can be either positive or negative, depending on the speaker’s intention. An example of this type of expression would be 天啊 tiān a “Oh my goodness”, which could be used to express surprise in both positive or negative context. Since we cannot examine “how” the user says it in his/her mind and can only rely on the relative frequency of these phrases in comments, it also results in confusion.2. Sarcastic commentsIt is not uncommon for users to use sarcasm to express their stance online. On PTT, users might use very positive sentences and give it a negative tag to indicate that the comment was sarcastic. These negative comments might be mistaken by the classifier as “push” comments. The following example illustrates how a negative comment might be mistakenly tagged as “push” comment.(3) 當了 鄉民 這麼 多 dāngle xiāngmín zhème duō be PTT.user this many 年,我終於 搶到(2) 很 不 hěn bùvery not婚前hūnqiánso touchedbefore.marriage already say後 怎樣怎樣hòu zěnyàngzěnyàng喜歡 那種xǐhuān nàzhǒnglike those.kind就在說離婚jiùzài shuōlíhūndivorce的人de rénafter how DE“I really don’t like those people who already starts talking about what would happen when they get a divorce before even getting married”In example (2), the comment expresses a negative attitude towards people who appears to be planning their divorce before even getting married.peoplenián wǒyear I頭噓tóu xūfirst.booLE“After being a PTT user for so many years, I am finally the first one to leave a boo comment in an article! I am so touched.”The comment includes the emotion 好感動 hǎo gǎndòng “so touched”, which appears to be a positive emotion. But human readers would be able to tell that the comment was sarcastic because of the mention of 頭噓 tóuxū, which is used in PTT to refer to the first boo comment in an article. Thus, this comment was tagged with “push” by the classifier.3. Intentionally vague commentsOn PTT, in order to avoid directly referring to a person name or avoid directly saying swear wordszhōngyú qiǎngdàofinally get了好 感動le hǎo gǎndòng
 or negative expressions, users sometimes use characters that have similar pronunciation or similar form to replace the original characters. These would result in segmentation errors and it would be very difficult to categorize because each user might has his/her own choice of characters and there isn’t an exhaustive list of such words. They may also use underlines or spaces to replace the original negative expressions when the rest of the sentence makes it clear what the word should be in that position. This omission would also make it harder to categorize the comment.Example (4) includes the phrase 甘 吟 釀 gānyínniàng, which does not exist in Chinese vocabulary but the sounds of these words are similar to the swear words 幹拎娘 gànlīnniáng “you mother fucker”. The person who left this comment chose to use these words instead of the conventional characters. Other users, when reading this comment, would still be able to judge what the comment intends to express. However, the classifier might judge this new “word” to be a proper noun and this may cause some mistakes.In example (5), the underlined part is an omission of the original word 中二 zhōng èr. This term is used as a negative representation for juvenile behavior and mindset common among teenagers. The word could not be identified by the classifier because the omission results in segmentation error.Sometimes it is very difficult to identify why the original poster would choose certain tag. This could be a result of the user’s own tagging mistake, or it could also be individual differences. In example (6), the comment was tagged with “boo” while the beginning of the sentence is the word push. Both the classifier and human readers would consider this sentence to be a push comment rather than a boo comment. This could be a result of the user’s own tagging error. Thus would not be considered a very important issue in the current study.(4) 甘吟釀 gānyínniànggānyínniàng 噓~~~xūboo(5) 圍巾 醜 wéijīn chǒu scarf ugly___的 欠de qiànDE asking.for原 POyuán PO original poster 二結案èr jié'àntwo case.close(underline)The other type of vague comments are produced because of the structure of PTT comments, users sometimes try to complete other people’s comments by positioning their comments at certain position. These comments would only make sense when processed in combination with the rest of the comments, also known as “floors” on PTT.4. Others(6) 推tuī tóubìshì nǚyǒupush coin-op girlfriend“I agree with coin-operated girlfriend”To further improve the classifier, the following approaches could be taken into consideration. According to Riloff and Wiebe (2003), it is important to incorporate large amount of data because infrequent words can sometimes be strong subjective clue. Thus, it might be helpful to expand the coverage of annotated data. Context of the comments should also be taken into account. If the classifier is able to capture the relationship between the target and the comment being given, the errors caused by context dependent comments could be solved.5 ConclusionThe purpose of this study is to compile lexical resources in Mandarin on arguing and stance- taking and to test the applicability of these resources in machine training on stance classification. We explored related linguistic categories on how users express their stance in online comments and established three sets of features that we believe reveals speaker’s subjectivity. An experiment on classifying online comments shows that the annotated wordlist could assist in the classification by raising up to 20 percent of accuracy. In order to further improve automatic classification, an analysis on the errors of our classification task in provided. Possible linguistic issues such as identifying the targets of the comments, the overall culture on the boards discussed, sarcastic comments, and problems resulting from vague comments requires further studies.投幣式 女友
 ReferencesAnand, P.; Walker, M.; Abbott, R.; Tree, J. E. F.; Bowmani, R. & Minor, M. (2011). Cats rule and dogs drool!: Classifying stance in online debate. Proceedings of the Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, 1-9.Dafouz-Milne, E. (2008). The pragmatic role of textual and interpersonal metadiscourse marker in the construction and attainment of persuasion: A cross- linguistic study of newspaper discourse. Journal of Pragmatics, 40, 95-113.Faulkner, A. (2014). Automated classification of stance in student essays: An approach using stance target information and the Wikipedia link-based measure. In Proceedings of the 27th International Florida Artificial Intelligence Research Society Conference, 174-179.Halliday, M. A. K. (1973). Explorations in the functions of language. London: Edward Arnold.Hasan, K. S. & Ng, V. (2013). Stance classification of ideological debates: Data, models, features, and constraints. Proceedings of International Joint Conference on Natural Language Processing, 1348- 1356.Hasan, K. S. & Ng, V. (2014). Why are you taking this stance? Identifying and classifying reasons in ideological debates. Proceedings of the Conference on Empirical Methods in Natural Language Processing, 751-762.Hyland, K. (1998). Persuasion and context: The pragmatics of academic metadiscourse. Journal of Pragmatics, 30, 437-455.Hyland, K. (2002). Authority and invisibility: Authorial identity in academic writing. Journal of Pragmatics, 34, 1091-1112.Hyland, K. & Tse, P. (2004). Metadiscourse in academic writing: A reappraisal. Applied Linguistics, 25, 156-177.Malouf, R., & Mullen, T. (2008). Taking Sides: User Classification for Informal Online Political Discourse. Internet Research, 18(2), 177-190.Quirk, R.; Greenbaum, S.; Leech, G. & Svartvik, J. (1985). A comprehensive grammar of the English language. New York: Longman.Reynolds, B. L. & Wang, S. (2014). An investigation of the role of article commendation and criticism in Taiwanese university students' heavy BBS usage. Computers and Education, 78, 210-226.Riloff, E. & Wiebe, J. (2003). Learning extraction patterns for subjective expressions. Proceedings of the Conference on Empirical Methods in Natural Language Processing, 105-112.Shea, D. (2006). What is PTT? Retrieved from http://www.ptt.cc/index/htmlShirky, C. (2011). The political power of social media: Technology, the public sphere, and political change. Foreign Affairs, 90, 28-41.Somasundaran, S.; Namata, G.; Wiebe, J. & Getoor, L. (2009). Supervised and unsupervised methods in employing discourse relations for improving opinion polarity classification. Proceedings of the Conference on Empirical Methods in Natural Language Processing, 170-179.Somasundaran, S.; Ruppenhofer, J. & Wiebe, J. (2007).Detecting arguing and sentiment in meetings.Proceedings of the SIGdial Workshop on Discourse and Dialogue.Somasundaran, S. & Wiebe, J. (2010). Recognizing stances in ideological on-line debates. Proceedings of the NAACL HLT Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, 116-124.Vande Kopple, W. J. (1985). Some exploratory discourse on metadiscourse. College Composition and Communication, 36, 82-93.Walker, M. A.; Anand, P.; Abbott, R. & Grant, R. (2012). Stance classification using dialogic properties of persuasion. Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 592-596.Wiebe, J. (1994). Tracking point of view in narrative. Computational Linguistics, 20, 233-287.Wiebe, J.; Wilson, T.; Bruce, R.; Bell, M. & Martin, M. (2004). Learning subjective language. Computational Linguistics, 30, 277-308.Wiebe, J.; Wilson, T. & Cardie, C. (2005). Annotating expressions of opinions and emotions in language. Language Resources and Evaluation, 39, 165-210.Wilson, T. (2008). Annotating subjective content in meetings. Proceedings of LREC.Wilson, T.; Hoffmann, P.; Somasundaran, S.; Kessler, J.; Wiebe, J.; Choi, Y.; Cardie, C.; Riloff, E. & Patwardhan, S. (2005). Opinion finder: A system for subjectivity analysis. Proceedings of HLT/EMNLP Demonstration Abstracts, 34-35. 
 黃金蘭、Chung, C. K.、Hui, N.、林以正、謝亦泰、 程威詮、Lam, B.、Bond. M., 及 Pennebaker, J. W. (2012):〈中文版語文探索與字詞計算字典之 建立〉。中華心理學刊,54,185-201。