Identification of Sympathy in Free ConversationAbstractDialog systems are generally categorized into two types: task oriented and non task oriented systems. Recently, the study of non task ori- ented dialog systems or chat systems becomes more important since robotic pets or nursing care robots are paid much attention in our daily life. In this paper, as a fundamental tech- nique in a chat system, we propose a method to identify if a speaker displays sympathy in his/her utterance. Our method is based on su- pervised machine learning. New features are proposed to train a classifier for identifying the sympathy in user’s utterance. Results of our experiments show that the proposed features improve the F-measure by 3-4% over a base- line.1 IntroductionDialog systems could be broadly divided into two categories. One is a task oriented dialog system. It focuses on a specific task such as guidance on sight- seeing, hotel reservation or promotion of products, and communicates with a user to achieve a goal of the task. The other is a non task oriented dialog sys- tem or chat system. It does not suppose any spe- cific tasks but can handle a wide variety of topics to freely chat with the user. Most of the past re- searches focus on task oriented dialog systems. In recent years, however, non task oriented dialog sys- tems become more important since robotic pets or nursing care robots are paid much attention (Libin and Libin, 2004).One of important characteristics in free conver- sation is sympathy of a speaker for the topics inthe conversation (Anderson and Keltner, 2002; Hi- gashinaka et al., 2008). The topics in free conver- sation are not fixed but could be changed by the speakers at any time. To make the conversation nat- ural and smooth, however, a non task oriented dia- log system can not arbitrarily change the topics. It is uncomfortable for the user if the system would suddenly change the topic when the user wants to continue to talk on the current topic, or if the sys- tem would keep the same topic when the user is bored and does not want to talk on the topic any more. If the system fails to shift the topic at ap- propriate time, the user may break the conversation. The sympathy of the user is one of the useful clues to guess good timing for changing the topic. If the user shows the sympathy for the current topic, the sys- tem should continue the conversation with the same topic. On the other hand, if the user does not display the sympathy, the system should provide other top- ics. Therefore, it is essential for the chat system to guess the sympathy of the user.This paper proposes a method to automatically judge whether the user displays the sympathy in his/her utterance as a fundamental technique in a non task oriented dialog system. In this paper, we define ‘sympathetic utterance’ as the utterance where the speaker expresses the sympathy or ap- proval especially when he/she replies to subjective utterance of the other participant. Note that the utter- ance just showing agreement is not defined as sym- pathetic. Various kinds of clues could be applicable for identification of the sympathy, such as facial ex- pressions, gesture or the contents of the utterance. Since we focus on a text based chat system, our
method only considers the content and detects the user’s sympathy in a transcript of the utterance. In addition to ordinary n-gram features, new features for the sympathy identification are introduced. The effectiveness of our proposed features will be proved via empirical evaluation.The remaining parts of this paper are organized as follows. Section 2 discusses related work for the sympathy identification. Section 3 presents our pro- posed method. Section 4 reports results of evalua- tion experiments. Finally, Section 5 concludes the paper.2 Related workA considerable number of studies have been made on an automatic tagging of utterance in a dialog cor- pus. That is, each utterance in the dialog is auto- matically annotated with some useful information such as dialog acts. Hereafter we call it ‘dialog tag’. Supervised machine learning is often used for auto- matic identification of dialog tags. Since the sym- pathy of the speaker is also regarded as a kind of dialog tags, we introduce several related work au- tomatically classifying utterance into dialog tags in- cluding the sympathy1.Xioa et al. (2012) proposed a method to esti- mate the sympathy speech using the language model learning tool SRILM (Stolcke, 2002). In their method, n-gram of words were used as the features to classify if the utterance indicated the sympathy of the speaker. They reported that bi-gram was the most effective feature and the accuracy of the sym- pathy identification was around 60%.A set of 29 dialog acts including ‘empathy’ was proposed toward an open-ended dialog system (Mi- nami et al., 2012). They performed the automatic recognition of them using a weighted finite-state transducer with the words in the utterance.Sekino et al. (2010) tried to identify the dia- log acts using Conditional Random Fields (CRF). SWBD-DAMSL tag set (Jurafsky et al., 1997) were used as a set of dialog acts. Note that the tag ‘sym- pathy’ is included in SWBD-DAMSL. The features used for training CRF were the tag of the previous utterance, the number of content words in the utter-ance, the length of the utterance and so on.To identify the dialog acts of the sentences in microblogging, semantic category patterns were in- troduced as the feature of Support Vector Machine (SVM) classifier (Meguro et al., 2013). The words in the utterance were converted into their semantic categories (or abstract concepts) using a thesaurus, then n-gram of not words but semantic categories is used as the feature. Results of this study showed that n-gram of the semantic categories was more ef-fective than word n-gram.This study also applies supervised learning for au-tomatic identification of the sympathy. Especially, we investigate what are the useful features to infer the sympathy in the utterance. Therefore, we fo- cus on identification of the sympathy only, although many previous work handled the sympathy as one of the dialog acts. Several studies reported that charac- teristics of the sympathy could be found in an ex- pression at the end of the utterance (Itoh and Na- gata, 2007; Huifang, 2009). In addition, there might be more linguistic features indicating the sympathy of the speaker. The main contribution of the pa- per is that new features for the sympathy identifica- tion are proposed through manual analysis of a free conversation corpus. Furthermore, the effectiveness of these features is empirically evaluated by experi- ments. Note that the target language in this study is Japanese.3 Proposed methodOur system accepts a text of utterance in free conver- sation as an input, then guesses whether it indicates the speaker’s sympathy. Support Vector Machine (SVM) (Chih-Chung and Chih-Jen, 2001) is applied to train a binary classifier to judge if the given utter- ance is sympathetic 2.3.1 FeatureWe design the following 9 features for sympathy identification. Note that all features are binary, that is, the weight in the feature vector is 1 if it is present in the utterance, 0 otherwise.Fng: Word n-gram2Memory-based learning (TiMBL) (Daelemanset al., 2010) is also applied in our preliminary experiment, but SVM slightly outperformed TiMBL.  1ance, some of the related papers are written in Japanese.Since we focus on the methods that handle Japanese utter-
The word n-gram (n=1,2,3) is used as the fea- ture, since it represents the content of the utter- ance. This is the basic feature widely used for identification of the dialog tags in the previous work. Since the content of the previous utter- ance is also important, we use the word n-gram of both the current and previous utterance.Flen: Length of utteranceSince the sympathetic utterance tends to be short, the length of the utterance (the number of characters) is considered. In the simple ap- proach, the length feature is defined according to intervals, such as ‘1 ∼ 5’, ‘6 ∼ 10’ and ‘more than 10’. However, it is rather difficult to deter- mine the optimum intervals. In this study, the length features are defined as in (1) and (2)We introduce a feature indicating if the same word appears in the current and previous utter- ance.Frw2: Repetition of word (2)Repetition of the words does not always indi- cates the sympathy. Let us consider the follow- ing example.A: 海草類 / 嫌い /な/の/? (seaweed) (dislike)(Do you dislike seaweed?)B:そう/で/も/ない/よ/、/ 海草 (so) (not) (seaweed)(Not so much, seaweed.)The speaker B repeats the word ‘海草 (sea- weed)’, but his/her utterance does not show the sympathy.This feature is similar to Frw1, but more strictly checks the presence of repetition of the content words. The feature Frw2 is activated if either condition below is fulfilled:• The last predicative word in the previous utterance is also found in the current ut- terance.• There is only one content word in the cur- rent utterance and it also appears in the previous utterance.Frc1: Repetition of semantic class (1)Repetition of not words but semantic classes is considered in this feature. In the following ex- ample, no content word is overlapped in two ut- terance, but the speaker B express his/her sym- pathy by saying ‘楽しかっ(fun)’ whose mean- ing is similar to ‘面白かっ(interesting)’ in the speaker A’s utterance.A: あの/ 映画 /は/ 面白かっ /た (that) (movie) (interesting)(That movie was interesting.)B: 楽しかっ/た/ね (fun)(It was fun.)This feature is activated if the same seman- tic class appears in both current and previous utterance. A Japanese thesaurus ‘Bunruigoi- hyo’ (National Institute for Japanese Language(i) flen :iflu isin[i−2,i+2] (1)(long)flen : iflu≥20(2) , where lu stands for the length of the utterance.We use 17 length features f(i) (3 ≤ i ≤ 19) as lenwell as an extra feature f(long) indicating the lenutterance is long. This approach enables us to incorporate the information of the length of ut- terance into SVM more flexibly.Ftu: Turn takingIn our conversation corpus, the speakers may give two or more utterance in one turn. This feature indicates the presence of turn taking, i.e. whether the speaker of the current and pre- vious utterance is the same.Frw1: Repetition of word (1)The speakers often show their sympathy by re- peating a word in a previous utterance of the other. For example, in the simple conversation below 3, the speaker B repeats the word ‘傑作 (fine work)’ to agree with A’s comment.A:あの/ 映画 /は/ 傑作 /だ (that) (movie) (fine work) (be)(That movie is a fine work.)B: 傑作 /だ/ね (fine work) (be)(It is a fine work.) 3Note that ‘/’ stands for the word segmentation, and a word or a sentence in parentheses is an English translation. The words without translations are function words that have no meaning.
and Linguistics, 2004) is used to obtain the se- mantic classes of the words. If one word has two or more semantic classes in the thesaurus, all of them are used to check repetition in two utterance. That is, we build the lists of all pos- sible semantic classes of all content words in the current and previous utterance, and check if there is an overlap between them.Frc2: Repetition of semantic class (2)Similar to Frw2, repetition of the semantic classes are strictly checked as follows:• The semantic class of the last predica- tive word in the previous utterance is also found in the current utterance.• There is only one content word in the cur- rent utterance and its semantic class also appears in the previous utterance.Fda: Dialog actDialog act is also a useful feature to identify the sympathy. When we hear the other’s asser- tion or opinion, we sometimes show our sym- pathy with it. However, we seldom express the sympathy for a simple yes-no question. In this study, we define a set of dialog acts in free con- versation as in Figure 1.Figure 1: Dialog actWe manually annotate the conversation corpus with the dialog acts and use them as the fea- tures. In future, the dialog acts should be auto- matically identified to derive this feature.Fend: End of sentenceThe speakers often show their sympathy in an expression at the end of their utterance. For example, in Japanese, “だ [da] / ね [ne]” or “よ [yo] / ね [ne]”4 at the end of the sentence strongly indicates the sympathetic mood of the4Parentheses show pronunciation of each word. ‘/’ stands for word segmentation. Note that these words are particles and have no meaning.speaker. Based on the above observation, the expression at the end is introduced as the fea- ture. In this paper, it is represented by a se- quence of function words at the end of each sentence in the utterance.3.2 Combination featuresIn the preliminary experiment, we investigated sev- eral types of kernels of the SVM classifier: linear kernel, polynomial kernel, radial basis function and so on 5. We found that the kernels except for the linear kernel performed very poorly on our data set. Therefore, we chose the linear kernel. However, the individual features are regarded as independent each other in the SVM with the liner kernel, although the dependency between the features should be consid- ered.To tackle this problem, we introduce a feature composed by combination of the existing features. When a feature set F = {...fi ...} is derived from one utterance, where fi is one of the features de- scribed in Subsection 3.1, all possible pairs of fea- tures [fi, fj ] (i ̸= j) are also added to the feature set. Hereafter, [fi , fj ] is referred to as a combination feature. The combination features enable the clas- sifier to consider the dependency between two fea- tures. Since the number of this feature are increased combinatorially, feature selection is applied as de- scribed in the next subsection.3.3 Feature selectionA simple feature selection procedure is introduced. We apply the feature selection only for the word n-gram feature (Fng) and the combination feature, since the numbers of these features are extremely high.The correlation between a sympathy class and a feature fi is measured by χ2 value. The features are discarded when χ2 value is less than a threshold. We denote the threshold of χ2 value for the n-gram and combination feature as Tng and Tcomb, respectively. In the experiment in Section 4, these thresholds will be optimized with a development data.3.4 Filtering of negative samplesIn supervised machine learning, it is inappropriate that the numbers of positive and negative samples in5 self-disclosure, question(yes-no), question(what), response(yes-no), response(declarative), backchannel, filler, confirmation, request  We used LIBSVM (Chih-Chung and Chih-Jen, 2001).
the training data are extremely imbalanced, since the trained classifier may display strong bias for the ma- jority class. In general, however, the sympathetic ut- terance does not frequently appear in free conversa- tion. Actually, the ratio of the sympathetic utterance is 1.1% in our conversation corpus as will be shown in Table 1. To tackle this problem, a filtering pro- cess to remove the negative samples is introduced to correct imbalance of the training data.The basic idea of our filtering method is that we try to remove redundant negative samples. Here ‘re- dundant’ sample stands for a sample that is similar to other samples in the training data. Similar neg- ative samples might be redundant and could be re- moved from the training data without any significant loss of the classification performance. The similar- ity between two samples (utterance) is measured by cosine similarity of the vector consisting of the word n-gram feature only.It is time consuming to calculate the similarity be- tween all possible pairs of the utterance in the train- ing data. Instead, we reduce the computational cost by constructing clusters of the utterance as the pre- possessing. First, the clusters are constructed from the set of the negative samples. A fast clustering algorithm ‘Repeated Bisections’ is used, where the number of the cluster is set to 10006.For each cluster, the redundant negative samples are detected by Algorithm 1. Given a set of utter- ance in a cluster U, the algorithm divides the utter- ance into a set of non-redundant utterance Uk to be kept and redundant utterance Ud to be deleted. For each utterance ui, if the similarity between ui and the rest of the utterance uj is greater than the thresh- old Sfil, uj is added to the set Ud. Then ui is added to Uk. Intuitively, if several similar utterance are found, only the first appeared one is remained in the training data. Note that the threshold Sfil controls the number of the removed negative samples. It is optimized on a development data.4 EvaluationThis section reports experiments to evaluate our pro- posed method. In this experiment, the systems are evaluated and compared by the precision, recall and6We used the clustering tool CLUTO. http://glaros .dtc.umn.edu/gkhome/views/clutoInput : U = {u1,u2,· · ·,un} Output: Uk, UdUk←∅, Ud←∅ for i ← 1 to n doif ui ∈ Ud then nextendfor j ← i + 1 to n dosim ← cos(ui,uj) if sim ≥ Sfil thenUd ← Ud ∪ {uj } endendUk ← Uk ∪ {ui} endAlgorithm 1: Search for redundant negative sam- plesF-measure of the identification of sympathetic utter- ance.4.1 DataMeidai conversation corpus 7 is used to train and evaluate our proposed method. It is a collection of transcription of actual conversation or chat in Japanese. Two to four participants joined free con- versation. Dialogs where the number of the partic- ipants is two are chosen from the corpus, then each utterance is manually annotated with ‘sympathy tag’ indicating whether it expresses the sympathy of the speaker or not8 .We randomly divide the conversation corpus into three sets: 80% training, 10% development and 10% test set. Table 1 shows the number of the dialogs, sympathetic utterance (sym) and non-sympathetic utterance (non-sym) in each data. The ratio of the positive and negative samples stands at 1 to 86, that is, the number of sympathetic utterance is much fewer than non-sympathetic. A balanced data in-7   https://dbms.ninjal.ac.jp/nuc/index.php?mode=viewnuc8Each dialog in the corpus is annotated by one person. To measure inter-annotator agreement, another annotator put sym- pathy tags to only three dialogs. Cohen’s kappa was 0.27. It indicates the difficulty of the sympathy identification task. In future, the definition of sympathetic utterance should be more clarified to make a better annotation guideline for consistent an- notation.      
Table 1: Statistics in the conversation corpuson the test data, while Table 3 shows the results on the balanced test data. In these tables, the fil- tering of the negative samples is not applied. Our proposed method outperformed the baseline on the whole, although the precision was comparable on the balanced data. In the imbalanced test data, the F-measure was not so high. This is because the sym- pathetic utterance does not frequently appear in the conversation corpus. Since the participants of some dialogs were strangers, they might hesitate to ex- press their sympathy. On the other hand, in the bal- anced test data, the results were reasonably high. If our method is applied for the conversation between close friends where they frequently show their sym- pathy, it will achieve better performance than the re- sults in Table 2.  data dialog training 77 development 10 test 10sym non-sym 861 73378 103 888299 8598     cluding the same number of the positive and nega- tive samples is also used for evaluation. It is made by keeping all positive samples and randomly choos- ing the equal number of the negative samples in the training, development and test data. We repeat to construct the balanced data five times, and evaluate the systems in these five data sets. Note that the re- sults on the balanced data shown below are the aver- age precision, recall and F-measure of five trials.4.2 Results and discussion 4.2.1 Parameter optimizationFirst, the parameter Tng for selection of n-gram feature was optimized on the development data. Fig- ure 2 shows a change in precision(P), recall(R) and F-measure(F) on the development data. We chose Tng = 0.9 as the best parameter where the precision, recall and F-measure were the highest. In this case, 4378 features, which are 1% of all n-gram features, were selected.Figure 2: Optimization of TngAnother parameters Tcomb and Sfil were also op-timized. The details will be reported later.4.2.2 ResultsWe define the baseline as the classifier with the word n-gram feature only. Table 2 reveals the per- formance of the baseline and our proposed methodTable 2: Results on the imbalanced test data PRF   Baseline (Fng) Proposed method   0.28Table 3: Results on the balanced test data PRFBaseline (Fng)Proposed method   0.81 0.76 0.80Effectiveness of features0.23 0.11 0.15 0.13 0.18    0.80 0.73 0.76 4.2.3 Next, to investigate the effectiveness of our pro- posed features, the models with several feature sets are compared. We train the classifiers with the ba- sic word n-gram feature and one of the other fea- tures (denoted as Fng + F∗), and compared it with the baseline model (Fng ). We also compare the clas- sifier with all features (denoted as FALL). Table 4 and 5 show the results on the imbalanced and bal- anced test data. Note that the combination features are not used in this experiment.On the imbalanced test data, adding the feature Flen, Frc2, Fda and Fend caused a decline of the F- measure. Furthermore, the classifier using all fea- tures were comparable with the baseline. However, on the balanced data, almost all types of the features contributed to gain the F-measure. In addition, pre- cision, recall and F-measure of FALL were better than the baseline.From the results in Table 4 and 5, turn taking (Ftu)
Table 4: Effectiveness of the features on the imbalanced test dataTable 6 and 7 compare the classifiers with and without the combination feature in the imbalanced and balanced test data, respectively. In Table 6, the combination feature improves both precision and re- call in FALL feature set. While, combination of the n-gram features increases the precision but de- creases recall and F-measure. Therefore, the combi- nation of our proposed features worked well, but the combination of n-gram not.In the balanced test data (Table 7), the models with and without the combination feature are com- parable.Comparing Fng+COMB and FALL+COMB in Table 6, incorporation of the proposed features im- proved the F-measure with a loss of the precision. In the same comparison in Table 7, all three crite- ria were improved by using the proposed features. Therefore, it can be concluded that our proposed fea- tures are effective for identification of the sympathy, especially when the dependency between two fea- tures is considered.Table 6: Evaluation of the combination feature on the im- balanced test data  Feature setFng   0.23 0.11 0.15P R F  Fng + FlenFng + FtuFng + Frw1Fng + Frw2Fng + Frc1Fng + Frc2Fng + FdaFng + FendFALL   0.240.18 0.08 0.11 0.25 0.12 0.160.25 0.11 0.150.26 0.11 0.150.23 0.11 0.15 0.21 0.10 0.14 0.19 0.08 0.11 0.19 0.10 0.13       0.11 0.15Table 5: Effectiveness of the features on the balanced test data   Feature setP R F0.80 0.73 0.760.81 0.73 0.770.81 0.75 0.78 0.81 0.73 0.77 0.81 0.73 0.77 0.81 0.72 0.76 0.81 0.73 0.77 0.81 0.73 0.770.74 0.78 0.77 0.80and repetition of word (Frw1 and Frw2) seem the most effective features. Since the increase or de- crease caused by adding one feature is inconsistent for several features on the imbalanced and balanced data, however, the effectiveness of them are rather unclear.4.2.4 Effectiveness of combination featureIn this subsection, we evaluate the combination feature. Two sets of the features are investigated: the word n-gram feature Fng and all proposed features FALL. For each feature set, the combination features are added to the feature vector of the utterance.Recall that we introduce feature selection for the combination feature. The parameter Tcomb was op- timized on the development data. Tcomb was set as 140 for both feature sets Fng and Fall on the imbal- anced data. While, it was set as 280 and 260 for Fng and Fall on the balanced data, respectively.  FngFng + FlenFng + FtuFng + Frw1Fng + Frw2Fng + Frc1Fng + Frc2Fng + FdaFng + Fend   0.82 FALL   0.83Feature Set P Fng 0.23 Fng+COMB 0.31 FALL 0.24 FALL+COMB 0.28R F 0.11 0.15 0.09 0.14 0.11 0.15 0.13 0.18                 Table 7: Evaluation of the combination feature on the bal- anced test data  Feature Set P Fng 0.80 Fng+COMB 0.80 FALL 0.83 FALL+COMB 0.81R F 0.73 0.76 0.73 0.77 0.77 0.80 0.76 0.80       4.2.5 Evaluation of filtering of negative samplesThe method of negative sample filtering was eval- uated using the imbalanced data set. First, the pa- rameter Sfil was optimized as 0.5 that achieved the highest F-measure on the development data.Three methods are compared in this experiment: a model without the negative sample filtering (w/o Filtering), a model with the filtering by our proposed method (Proposed Filtering) and a model where the
negative samples are randomly removed (Random Filtering). In Proposed Filtering, 25,174 negative samples were removed from the training data. In Random Filtering, the same number of the negative samples were randomly removed. We repeated the training of the classifier with random filtering five times and compared the average with the other meth- ods.Table 8: Evaluation of filtering methods PRFRandom FilteringTable 8 reveals the results of three methods. By the filtering, the recall was improved, while the pre- cision declined. It is natural because the classifier tends to judge the utterance as sympathetic (posi- tive) when the number of the negative samples in the training data is reduced. Since F-measure was im- proved, the filtering of the negative samples seems to contribute toward improvement of the performance. However, our proposed filtering method was worse than the random sampling. It is still uncertain why the idea to remove the redundant negative samples is inappropriate in this task. In future, we will in- vestigate the reason and refine the algorithm of the negative sample filtering.4.3 Error AnalysisWe have conducted an error analysis to find major causes of the errors. First, we found many false positives (the sympathetic utterance is wrongly clas- sified as non-sympathetic) and false negatives (the non-sympathetic utterance is wrongly classified as sympathetic) when the previous utterance was long. In such cases, the previous utterance consisted of many sentences, but only one sentence was usually related to the current utterance. Although many fea- tures were derived from the previous utterance, the most of them were irrelevant. Such noisy features might cause the classification error. To overcome this problem, the coherence between the current and previous utterance should be considered. In other words, it is required to introduce a method to choose only the sentence relevant to the current utterancefrom long previous utterance.Many errors were also found when both the cur-rent and previous utterance were too short. We guessed that the classification errors were caused by the lack of the features. Due to the feature selection, even the word n-gram feature was sometimes not ex- tracted from short utterance. One of the solutions is to apply feature selection only for bi-gram and tri- gram while remaining all uni-gram features, in order to prevent from extracting no n-gram feature.We also found that several false negatives were caused by the feature Fend. Some of the expressions at the end of the sentence indicate the speaker’s sym- pathy, but not always. Let us suppose such an ex- pression appeared in non-sympathetic utterance and the lengths of both current and previous utterance were short. In such cases, since only a few fea- tures were extracted, the end of the sentence feature strongly worked to classify the utterance as the sym- pathetic. The way to incorporate the end expression into the classifier should be refined.5 ConclusionThis paper proposed a method to identify the sym- pathetic utterance in the free conversation. The main contribution of the paper is to propose novel features for sympathy identification. Results of the experi- ments indicate that (1) the proposed features are ef- fective, especially when the pairs of these features are considered as the additional features, (2) among the proposed features, turn taking and repetition of the content words show strong correlation with the sympathetic utterance, and (3) the filtering of nega- tive samples is important to improve the F-measure.F-measure of the proposed method was still low in the extremely imbalanced positive and negative sample data. We proposed the filtering method to remove the redundant negative samples, but it was worse than the random filtering. However, since the results on the balanced data were promising, we be- lieve that the filtering of negative samples is a right way to improve the performance. In future, we will continue to explore a better way of negative sample filtering.   w/o FilteringProposed Filtering   0.23 0.16 0.190.28 0.13 0.18 0.25 0.18 0.22  
ReferencesAlexander V. Libin and Elena V. Libin 2004. Person- Robot Interactions From the Robopsychologists’Point of View: The Robotic Psychology and Robotherapy Approach. Proceedings of the IEEE 92, pp. 1789– 1803.Ryuichiro Higashinaka, Kohji Dohsaka and Hideki Isozaki. 2008. Effects of self-disclosure and empa- thy in human-computer dialogue. Spoken Language Technology Workshop, pp. 109–112.Anderson, C. and Keltner, D. 2002. The role of empa- thy in the formation and maintenance of social bonds. Behavioral and Brain Sciences 25 (1), pp. 21–22.Bo Xiao, Dogan Can, Panayiotis G. Georgiou, David Atkins and Shrikanth S. Narayanan. 2012. Analyzing the Language of Therapist Empathy in Motivational Interview based Psychotherapy. Proceedings of Asia- Pacific Signal and Information Processing Association Annual Summit and Conference.Andreas Stolcke. 2002. SRILM – An Extensible Lan- guage Modeling Toolkit. Proceedings of International Conference on Spoken Language Processing 2, pp. 901–904.Yasuhiro Minami, Ryuichiro Higashinaka, Kohji Dohsaka, Toyomi Meguro, Akira Mori and Eisaku Maeda. 2012. POMDP Dialogue Control Based on Predictive Action Probability Obtained from Dialogue Act Trigram Sequence (in Japanese). The Transac- tions of the Institute of Electronics, Information and Communication Engineers A,Vol. 95, No. 1,pp. 2–15.Takahiro Sekino,Masashi Inoue. 2010. Tagging Ex- tended Conversation Tag to Utterance (in Japanese). Tohoku-Section Convention of Information Process- ing Society of Japan, 10-6-B3-2.D. Jurafsky, E. Shriberg, D. Biasca. 1997. Switchboard SWBD-DAMSL Shallow-Discourse-Function Anno- tation Coders Manual Draft 13, University of Col- orado, Institute of Cognitive Science, Tech. Rep, pp. 97-102.Toyomi Meguro, Ryuichiro Higashinaka, Hiroaki Sugiyama, Yasuhiro Minami 2013. Dialogue act tagging for microblog utterances using semantic category patterns (in Japanese). IPSJ SIG Technical Report, Vol. 2013-SLP-98, No. 1,pp. 1–6.Huifang Zhang. 2009. The Semantic Type and Ex- pression Function of YONE in Natural Dialogue (in Japanese). TSUKUBA WORKING PAPERS IN LIN- GUISTICS,No.2,pp. 17–32.Masako Itoh and Ryota Nagata. 2009. Rhetorical Func- tion of a Sentence-Final Particle for Constructing In- teraction in Discourse (in Japanese). Cognitive stud- ies: bulletin of the Japanese Cognitive Science Soci- ety,Vol. 14, No. 3,pp. 282–291.Chang, Chih-Chung and Lin, Chih-Jen.C.-C. Chang and C.-J. Lin. 2001. LIBSVM: A library for support vector machines. Software available at http://www.csie.ntu.edu.tw/ ̃cjlin/libsvm.Daelemans, W., Zavrel, J., Van der Sloot, K., and Van den Bosch, A. 2010. TiMBL: Tilburg Memory Based Learner, version 6.3, Reference Guide. Technical Re- port ILK 03-10, Tilburg University, ILK.National Institute for Japanese Language and Linguistics. 2004. Bunruigoihyo. Dainippon tosho.