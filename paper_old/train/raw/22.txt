Incorporating DBpedia for Tweet Retrieval and RankingAbstractThis paper presents an unsupervised architec- ture for retrieving and ranking conceptually related tweets which can be used in real time. We discuss an option for ranking tweets with respect to topic relevance in order to improve the accuracy of information extraction.The proposed architecture uses concept en- richment from a knowledge source in order to expand the concept beyond the search key- words. The enriched concept is used to de- termine similarity levels between tweets and the given concept followed by a ranking of those tweets based on different similarity val- ues. Tweets above a certain similarity thresh- old are considered as useful for providing rele- vant information (this is not part of this paper).A set of 1400 downloaded tweets related to the 2014 national elections in New Zealand was used to test our approach. Cosine Sim- ilarity performs best with an F-value of 0.61 and a precision of 0.81 compared to six other tested similarity measures. Our experiments have shown that a combination of persistent knowledge and dynamic temporal knowledge improves retrieving and ranking tweets rele- vant to a topic.1 IntroductionIn recent times a significant proportion of informa- tion dissemination has been taken over by social me- dia platforms instead of the conventional news or- ganizations. Social media platforms (SMP) such as Facebook and Twitter contain information createdSecond AuthorAffiliation / Address line 1 Affiliation / Address line 2 Affiliation / Address line 3 email@domainby ordinary, non-journalist, users although more re- cently even news organizations have started using social media for their purpose of news dissemina- tion. This “crowd-sourcing” ability of social media makes the information extremely current and a rich source of information which captures the pulse of the society. The large volume of texts and embedded knowledge on social media platforms has created the need for information extraction by automating con- stituent tasks such as collection, aggregation, cate- gorization, summarization and visualization. How- ever, the information contained in SMP texts is dis- organized, incomplete, abbreviated and contains a high degree of redundancy. Hence, the majority of the NLP tools that are available for processing texts fail miserably when applied on social media texts due to their informal structure. This has prompted a flurry of research in recent times aimed specifi- cally at unstructured texts from social media. Some of these researches have focussed on understanding the structure of social medial texts from linguistic point of view, eg., (Monojit Choudhury, Rahul Saraf, Vijit Jain, Sudeshna Sarkar et al., 2007; Cooper et al., 2005; Finin et al., 2010), while others such as (Gimpel et al., 2011; Ritter et al., 2010; Barbosa and Feng, 2010; Soderland et al., 1999) try to use vari- ous types of computational techniques for informa- tion extraction.Twitter, as a SMP, has been the subject of ex- tensive number of studies for two reasons. Firstly, Twitter is used for posting short public messages rather than group or person to person postings. It is designed for users to post messages with com- mon interests, for example information about poli-
tics, events, products, people inter alia. This makes Twitter a unique and rich repository of knowledge on both public, and private aspects of society. The other major reason is that it is easy to retrieve tweets and use them as data for research.The Tweeter platform by design is meant for post- ing short, frequent blurbs. It has a size limita- tion of 140 characters, which is meant to encour- age more frequent postings, especially by users on the move using mobile devices with limited typ- ing facilities. The size limit, however has resulted in Twitter users employing clever ways of express- ing their ideas which often involves the use of non- standard language. This combination of short mes- sages and non-standard language requires extensive retraining of existing Natural Language Processing (NLP) tools as well as a change of strategies for most of the language processing tasks.The Twitter API1 allows real time retrieval of tweets based on keywords and other limited criteria such as posting time, tweets from specific accounts and topic popularity. The most common technique to retrieve tweets on a topic is to use a logical com- bination of keywords or phrases, which will retrieve all tweets containing the keywords. In most cases, this will also download a large amount of unrelated tweets, since the keywords could have been used in a different context and/or used with a different sense. In order to be able to filter out the irrelevant tweets, there has been substantial efforts to re-rank the re- trieved tweets from the Twitter API according their appropriateness to the topic.There are also a number of third party search en- gines which allow additional features that can be used to select tweets and rank them. CrowdEye2, for example, uses content relevance and author influ- ence factors, which rely on the number of followers and re-tweet count. Tweetfind3 and Twitority4 rank tweets according to the authority of authors, which depends on how popular, relevant and active an au- thor is. The ranking from these search engines are based on gregarious features which are unrelated to the content of the tweet.Several AI researchers have exploited the social1Twitter API: https://dev.twitter.com/ 2CrowdEye: http://www.crowdeye.com/ 3Tweefind: http://www.tweefind.com/ 4Twitority: http://www.twitority.com/media attributes of tweets as features to train ma- chine learning algorithms in attempts to rank them according to topic appropriateness. (Zhunchen Luo, Miles Osborne, Sasˇa Petrovic ́, 2012) define Twit- ter Building Blocks (TBBs) as structural blocks in a Twitter message and use these for higher level infor- mational characteristics. As an example, tweets with the same structure as BBC news tweets are likely to be news tweets. The TBBs consist of non-content features such as neighbour TBB type, TBB count, TBB length and OOV (out of vocabulary words). Other works such as (Duan et al., 2010) and (Nag- moti et al., 2010) also exploit generic social media as well as Twitter specific features to rank tweets re- trieved from the Twitter API using a keyword based query. Some sample features used in these works are the presence or absence of a URL, author au- thorities, whether the current tweet is a repost(re- tweet), number of re-tweets, hash tag score, whether the current tweet is a reply-tweet and the ratio of OOV words to total number of words. In addition to the social media structural features Duan et. al., also use a content feature. They compute the cosine sim- ilarity between each pair of tweets and then use this score in combination with Term Frequency Inverse Document Frequency (TF-IDF) to rank the individ- ual tweets retrieved by the query.In this paper we present a language model which uses concept enrichment to retrieve and rank tweets by capturing the dynamics of a given topic on a micro-blogging platform (MBP). The model is based on the fact that a trending topic on a MBP con- sists of two components; a persistent component and a dynamic component. The model uses the informa- tion content of the tweets for dynamic component and an external knowledge base, DBpedia, for the persistent component. The model was tested on data from Twitter, however the model can be translated on any MBP since it is based entirely on content, rather than MBP-specific structure related features.In summary this paper makes the following con- tributions:• Presents a language based model that can be used to retrieve and rank micro-blogs in real time.• Presents the results of testing the model on tweet data. 
• Makes the model and the annotated data avail- able for research purposes.2 BackgroundPrevious works that have dealt with the task of twit- ter ranking can be categorized into those that make use of a machine learning algorithm and those that use some form of similarity measure. The work in (Zhunchen Luo, Miles Osborne, Sasˇa Petrovic ́, 2012) presents a model which uses a fifteen dimen- sion feature vector to train a SVM (Support Vec- tor Machine) model by using a corpus of 2000 hu- man tagged tweets. Each tweet is split into Twit- ter Building Blocks (TBBs) consisting of the tokens with at least one TBB containing the query term used to search the tweets. The other TBBs contain structural features such as whether the TBB is an URL, whether there are followers of the author and whether the current tweet was retweeted. The paper ((Duan et al., 2010)) presents a very similar model using 3 sets of features; content relevance, twitter specific features and account authority. This study concludes that account authority and the length of tweets are the best conjunction as features for learn- ing to rank tweets. (Nagmoti et al., 2010) present another model, however this is completely based on structural features. This study affirms the conclu- sions from (Duan et al., 2010), however emphasize that the presence of URL is a stronger feature rele- vant to ranking.The focus of this study is to be able to retrieve and rank tweets corresponding to a topic in real time. The ranked tweets can then be used to extract infor- mation for a particular purpose and present an anal- ysis as a web service. This can be effectively used for opinion mining for popularity of sports teams, political parties and newly released products. Some works have also demonstrated applications in min- ing requirements in disaster situations such as earth- quakes (eg. (Lingad et al., 2013)). Apart from these there can be numerous other Social Science appli- cations of information extracted from tweets as it is very extensively used (350,000 tweets per minute5), hence is a good reflection of the sentiment of the so- ciety at a particular time.5Twitter statistics: http://www.internetlivestats.com/twitter- statistics/The topic can be diverse and corresponding tweets can have equally diverse structures, the use of a pre- trained model can not be expected to perform well if the corpus is significantly different from the training data.Unlike above papers, we focus on ranking tweets based entirely on the content of the message rather than other unrelated structural features. The pro- posed model is similar to the one presented in (Michel Krieger, 2010). In this work the authors use TF-IDF for ranking new tweets based on a back- ground corpus consisting of 150,000 Twitter mes- sage corpus. The ranked messages are then merged into topic clusters using Jaccard similarity exceed- ing 65%. The limitation in O’Connor et. al’s model is that the ranking is biased by a static corpus, hence is not completely realtime. (Massoudi et al., 2011) present a model which mitigates this limitation by capturing the dynamics of the topics using query expansion. The authors of this work build a back- ground corpus by selecting messages posted closer to the query time using the original query terms. The rationale for this is that messages temporally closer to the query time are more relevant compared to older messages. A weighted mixture of the origi- nal query and top n terms from the generated corpus is then used to expand the query to retrieve further messages and rank them. Our model is an extension of the notion of query expansion from (Massoudi et al., 2011).The rationale for query expansion is that tweets about an entity can be expressed by a wide a set of keywords rather than a single or a couple of key- words. When a user wishes to search for tweets per- taining to a topic, he would normally enter either a single or a very small logical combination of key- words resulting in selecting tweets which directly contain the keywords. This would leave out a large proportion of texts which use other keywords rele- vant to the topic.A topic on a MBP can be broken down into a persistent and a dynamic component. The dy- namic component accounts for the current conversa- tion about an entity and this can rapidly change over time. The persistent component consists of conver- sation about the more static attributes of the topic. In order to be able to identify a balanced set of tweets one would need to use some combination of the dy- 
namic and the persistent components. We propose a model which uses knowledge infusion from DBpe- dia to account for the persistent component and the MBP itself for the dynamic component. The infor- mation from these sources is combined to form word vectors followed by using a selection of similarity calculators in order to rank the messages. The archi- tecture and the experiments are described in detail in the next section.3 Model description and ExperimentThe proposed query expansion model uses DBpe- dia6 as the knowledge source, however any other knowledge source such as the Google search may be effective as well. DBpedia provides persistent knowledge of about 4.0 million entities, categorized under 529 classes (person, organization, places, etc.). The knowledge is organized as predicates called triples, approximately consisting of a sub- ject, predicate and object. For example the triple “⟨New Zealand National Party, leader, John Key⟩” contains the information about the party leader and similarly “⟨New Zealand National Party, type, Liberal-conservativeParties⟩” contains information about the type of party. DBpedia knowledge base is organized into pages corresponding to the pages in Wikipedia, however Wikipedia may contain slightly more information as free text which might not have been structured in the DBpedia knowledge base. DBpedia is a relatively rich and an uptodate source of knowledge, the drawback is that the query interfaces that exist for DBpedia, such as SPARQL, does not support free text queries. This problem was solved by implementing a Google custom search module for Wikipedia which was then translated into a DBpedia search as both have the same resource sharing convention. As an illustration, the Wikipedia page http://www. en.wikipedia.org/wiki/NewZealandNationalParty corresponds to http://www.dbpedia.org/resource/ /NewZealand National Party.Information was extracted from DBpedia by ex- tracting the predicates Resource Description Frame- work (RDF) files. The predicates objects and sub- jects were then extracted from the predicates and sent through a pre-processing module. This mod-6DBPedia: http://www.dbpedia.orgule cleaned the noun phrases by removing non En- glish characters, numbers, URLS, punctuations, du- plicates and noun phrases which were longer than 50 tokens. The resulting noun phrases was tokenized and the tokens were used to construct the the persis- tent component of the topic vector.The dynamic component of the word vector was constructed using a set of seed tweets. The set of seed tweets is constructed by retrieving the first 100 tweets using only the noun phrase corresponding the topic entity using the Twitter API. The tweets re- trieved from the Twitter API was first filtered for lo- cality compatibility. In the case of a location men- tion in the content of a tweet, we used the location miner from (Nand et al., 2014b) to eliminate tweets which did not belong to the locality of the topic, which was New Zealand for this project, extracted from the query terms. This gives us locality spe- cific tweets that are directly related to the topic en- tity, however, will also contain other related entities that are typical at the time of the retrieval. The seed tweets were POS tagged using a HMM POS tagger from (Nand et al., 2014a) which is able to identify the syntactical components as well as tweeter spe- cific components such as hash tags URLs, and user mentions. The data details from the POS tagger is shown in Table 1.Experiments were conducted using tokens from two sets of word vectors derived from the tagged seed tweets. The first was using all the words from noun phrases as identified by a noun phrase chun- ker which uses the tags identified by the tagger. The chunker was based approximately on the implemen- tation of a phrase chunker in LingPipe7 but modi- fied for tweet messages. The implementation uses combinations of POS tags to identify chunks which can be defined for various constructs such as noun and verb phrases. The algorithm works by itera- tively defining sets of higher level tag sets using the basic POS tags which can be associated with vari- ous constructs such as noun phrases. For example a noun phrase can be defined using a ADJECTIVE as the beginning tag followed by a START NOUN, AD- VERB or a PUNCTUATION tag. The START NOUN tag enables one to iterated multiple times in order to find multiple word chunks. The extracted noun7Lingpipe: http://alias-i.com/lingpipe      
phrases from the chunker were then cleaned by re- moving some of the tags such as determiners and some categories of adjectives. The remaining words were collated for all seed tweets and sorted. The top n words were then combined with the top n hash tags to form the dynamic component of the word vector. The persistent and the dynamic word vectors were combined in various proportions and tested with a selection of similarity calculators to rank the tweets in the dataset.Table 1: Dataset Details as identified by the HMM POS TaggerNo. of Tweets: 1400 Nouns: 3318 Proper Nouns: 2668 Verbs: 2221 Hash: Tags 234 @ mentions: 520 Babble: 174 Verb Phrases: 2266 Noun Phrases: 4250We downloaded a set of 1400 tweets before the New Zealand general elections at the end of 2014 for a larger research project on the influence of social media on party popularity.The tweets were download using the keywords pertaining to New Zealand elections such as “John Key”, “National Party” and “NZ elections”. This re- sulted in a wide variety of tweets belonging to the wider topic of elections in NZ. The objective for the experiment was to rank the tweets that are relevant to the “National Party” which could be used later for downstream tasks such as sentiment detection. The tweets were manually annotated by a group of 15 post-graduate NLP students as being relevant to Na- tional Party or not. The annotators were instructed to take into account the topics relevant directly to National Party as well as the evolving topic tempo- rally relevant to National Party. A selection of 100 tweets were annotated by 4 different annotators with a Cohens Kappa coefficient of 0.87. The annotators classified a total of 291 out of 1400 tweets belonging to the topic of “National Party in New Zealand”The word vector consisting of the persistent and dynamic components were tested with variousweights for similarity calculations. We used the following similarity measures: Cosine Similarity, Euclidean Distance, MongeElkan Similarity, Lev- enshtein Similarity, JaroWinkler Distance, Jaccard Distance and TFIDF Distance. Similarity algo- rithms were implemented as described in (Russell and Cohn, 2012). Various components of POS com- ponents were tested in the similarity computations, the best performance was achieved using combina- tions of nouns, proper nouns and hash tags, hence all the results reported in this paper are based on to- kens corresponding to these three tags. The tagging used in the ranking computations were directly from the POS tagger, hence the ranking results incorpo- rate the propagated errors to all upstream tasks such as tokenization, tagging and chunking.4 Ranking Results and DiscussionIinitial experiments were done to determine the best similarity algorithm. We applied 50% weight for the persistent and the same for the dynamic components using a word vector size of 100. The static compo- nent words were chosen based on the first 50 tokens from DBpedia triples. The 50 words for the per- sistent component were chosen from the top, most frequent set comprising of tokens from the noun phrases and hash tags. This topic word vector was then compared with the tweet word vector consist- ing only noun phrases and hash tags. Experiments including other components such as @mentions and verb phrases did not yield good results. Table 2 sum- marizes the results of the similarity computations.The results show that Cosine similarity was a clear winner with an F-value of 0.61 for selecting the top 250 ranked tweets from the corpus of 1400. Jaccard distance also had a relatively high F-value of 0.57 compared to the rest of the algorithms which had F-values less then 0.4. The rest of the experi- ments were done using the best performing similar- ity calculator, Cosine Similarity.The cosine similarity for text matching two at- tribute vectors are usually based on token frequency vectors of the two documents being compared. The value of cosine similarity is always between 0 and 1. Although cosine similarity does document length normalization, the vast difference between the length of the topic vector (approx. 100 words),  
 Figure 1: Results for Retrieving Relevant Tweets with Persistent Topics Word Vector Figure 2: Results for Retrieving Relevant Tweets with Dynamic Topics Word Vector
 Figure 3: Results for Retrieving Relevant Tweets with Equal Proportions of Persistent and Dynamic Topics in the Word VectorTable 2: Performance Comparison of Similarity Algo- rithms for top 250 ranked TweetsAlgorithmAccuracy Precision Recall F-valuephrases and hash tags from the seed tweets. The comparison vector for the tweets was constructed using tokens from the noun phrases, proper nouns and hash tags. Use of other components such as verb phrases and @mentions significantly deterio- rated the performance values. The graphs in Fig- ures 1, 2 and 3 show the results for retrieving top n tweets from 10 up to 200 from a total of 291 relevant tweets. The tweets were ranked using the amplified cosine similarity values above an arbitrary threshold value of 100. The accuracy, precision, recall and F- values were computed for top tweets ranging from 10, in steps of 10 up a total of 200. The first ex- periment was done by using a topic vector of only persistent topics consisting of 100 words from the DBpedia page for the New Zealand National Party. The graph in Figure 1 shows that up to 40 tweets the precision was 1, however the recall is substan- tially low at 0.14. Beyond 40 tweets the precision starts declining down to 0.7 and at this point the re- call value plateaus at 0.48. For this experiment the best result in terms of the F-value is for 190 tweets with an F-value of 0.58, recall of 0.48 and a preci-  Cosine 0.85 Jaccard 0.83 Euclid 0.77 Mongee 0.73 Levins 0.71 Jarowr 0.71 TFIDF 0.690.66 0.57 0.61 0.61 0.53 0.57 0.43 0.37 0.40 0.33 0.28 0.30 0.28 0.24 0.26 0.28 0.24 0.26 0.21 0.18 0.20 and the length of the tweet vector (approx. 4 words) results in values which are very small. Hence for practical purposes, the similarity values were ampli- fied by 1000 which gave us values ranging from 0 to approximately 450.Tweeter ranking was done by using various com- binations of topic vectors and various tweet compo- nents. The best results were obtained using about half of the topic vector from the persistent topics from DBpedia and the other half from the noun
 Figure 4: Results for Retrieving Relevant Tweets with 50% Persistent Topics and 50% Dynamic Topic extracted from Proper Nouns Onlysion of 0.73. After 200 tweets the cosine similarity fell below the threshold of 100, hence not reported in the results. The Figure in 2 shows the correspond- ing experiment done with the dynamic topic consist- ing of tokens from the noun phrases and hash tags. The highest precision for this was 0.9 and the high- est F-value obtained was 0.32. The graph in Figure 3 shows the best results obtained with equal propor- tion of topic s from both persistent and dynamic top- ics. The highest F-value obtained was 0.64, a preci- sion value of 0.81 and a recall value of 0.53 for 190 tweets. The next best result was for persistent only topics with values 0.58, 0.73 and 0.48 respectively. The graph in Figure 4 shows the results of an ad- ditional experiment done using only proper nouns and hash tags for both dynamic topic and compar- ison vectors. The highest F-value in this case was 0.53, precision of 0.65 and a recall value of 0.45.The results show that external infusion of knowl- edge for downloading and ranking tweets signifi- cantly increases the accuracy. Our proposed lan- guage model uses the fact that tweets relevant to a topic would revolve partly around the persistenttopic and partly around evolving temporal topics current at the time of retrieval. Model tests show that the best results are achieved when a combina- tion of both persistent topics derived from an ex- ternal knowledge source and dynamic topic derived from a set of seed tweets are combined.5 Conclusion and Future WorkWe presented a non-learning language model which can be used to retrieve ranked tweets relevant to a topic of interest. The model divides a topic into knowledge around more persistent aspects and those that are transient and temporally relevant. We used DBpedia for the persistent component and a small set of seed tweets for the dynamic component. The dynamic and the persistent combined word vector used with cosine similarity calculator gave an F- value of 0.64 with a precision of 0.81 with a sample size of 1400 tweets. We also tested a total of 7 sim- ilarity calculators and showed that cosine similarity achieves an F-value of 0.61 followed by Jaccard dis- tance with an F-value of 0.57 while all the other ones
tested had F-values below 0.4.The presented model uses a single knowledgesource, DBpedia, hence it is restricted to only top- ics belonging to entities that exist in DBpedia. We are currently working on integrating and extracting knowledge from other knowledge sources such as Google search API. We are also doing tests on a wider range of topic types in order to validate the results for a variety of entity types from DBpedia.ReferencesLuciano Barbosa and Junlan Feng. 2010. Robust Sen- timent Detection on Twitter from Biased and Noisy Data. In Proceedings of the 23rd International Confer- ence on Computational Linguistics: Posters, COLING ’10, pages 36–44, Stroudsburg, PA, USA. Association for Computational Linguistics.Richard Cooper, Sajjad Ali, and Chenlan Bi. 2005. Ex- tracting Information from Short Messages. In Andre ́s Montoyo, Rafael Muoz, and Elisabeth Me ́tais, editors, Natural Language Processing and Information Sys- tems, volume 3513 of Lecture Notes in Computer Sci- ence, pages 388–391. Springer Berlin Heidelberg.Yajuan Duan, Long Jiang, Tao Qin, Ming Zhou, and Heung-Yeung Shum. 2010. An empirical study on learning to rank of tweets. Proceedings of the 23rd In- ternational Conference on Computational Linguistics, pages 295–303, August.Tim Finin, Will Murnane, Anand Karandikar, Nicholas Keller, Justin Martineau, and Mark Dredze. 2010. An- notating Named Entities in Twitter Data with Crowd- sourcing. In Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk, CSLDAMT ’10, pages 80–88, Stroudsburg, PA, USA. Association for Computational Linguistics.Kevin Gimpel, Nathan Schneider, Brendan O’Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A Smith. 2011. Part-of-speech tagging for Twitter: annotation, features, and experiments. In Proceedings of the 49th Annual Meeting of the Asso- ciation for Computational Linguistics: Human Lan- guage Technologies: short papers - Volume 2, HLT ’11, pages 42–47, Stroudsburg, PA, USA. Association for Computational Linguistics.John Lingad, Sarvnaz Karimi, and Jie Yin. 2013. Loca- tion extraction from disaster-related microblogs. Pro- ceedings of the 22Nd International Conference on World Wide Web Companion, pages 1017–1020, May.Kamran Massoudi, Manos Tsagkias, Maarten de Rijke, and Wouter Weerkamp. 2011. Incorporating query ex- pansion and quality indicators in searching microblog posts. Proceedings of the 33rd European Conference on Advances in Information Retrieval, pages 362–367, April.David Ahn Michel Krieger. 2010. TweetMotif: ex- ploratory search and topic summarization for Twitter.Anupam Basu Monojit Choudhury, Rahul Saraf, Vijit Jain, Sudeshna Sarkar, Monojit Choudhury, Rahul Saraf, Vijit Jain, Sudeshna Sarkar, and Anupam Basu. 2007. Investigation and modeling of the structure of texting language. In In Proceedings of the IJCAI Workshop on ”Analytics for Noisy Unstructured Text Data, pages 63–70.Rinkesh Nagmoti, Ankur Teredesai, and Martine De Cock. 2010. Ranking Approaches for Microblog Search. In 2010 IEEE/WIC/ACM International Con- ference on Web Intelligence and Intelligent Agent Technology, volume 1, pages 153–157. IEEE, August.Parma Nand, Ramesh Lal, and Rivindu Perera. 2014a. A HMM POS Tagger for Micro-Blogging Type Texts. In Proceedings of the 13th Pacific Rim International Conference on Artificial Intelligence (PRICAI 2014).Parma Nand, Rivindu Perera, Anju Sreekumar, and He Lingmin. 2014b. A Multi-Strategy Approach for Location Mining in Tweets: AUT NLP Group Entry for ALTA-2014 Shared Task. In Proceedings of the Australasian Language Technology Association Workshop 2014, pages 163–170, Brisbane, Australia, November.Alan Ritter, Colin Cherry, and Bill Dolan. 2010. Un- supervised Modeling of Twitter Conversations. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10, pages 172–180, Stroudsburg, PA, USA. Association for Computational Linguistics.J Russell and R Cohn. 2012. Simmetrics. Tbilisi State University.Stephen Soderland, Claire Cardie, and Raymond Mooney. 1999. Learning Information Extraction Rules for Semi-structured and Free Text. In Machine Learning, pages 233–272.Ting Wang Zhunchen Luo, Miles Osborne, Sasˇa Petrovic ́. 2012. Improving twitter retrieval by exploiting struc- tural information. AAAI, Proceeding:22–26.