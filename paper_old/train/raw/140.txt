Clustering Bilingual Documents via Different Clustering StrategiesAbstractLarge amount of documents on the websites are written in different languages. Though there have been many studies on multilingual document clustering of document representa- tion, clustering algorithm or clustering strate- gies. There are no systematic investigations about comparing different strategies and doc- ument representation on bilingual documents clustering. In this paper, different strategies are compared based on their performances in parallel documents clustering. Translations are made to transfer bilingual documents set into monolingual documents set. When represent- ing documents, vector space model and topic model are used while similarities are meas- ured correspondingly with cosine distance and Jensen-Shannon divergence. Experimental re- sults show that: 1) Traditional vector space model performs better than topic model among all the strategies. 2) With the help of translation technique, monolingual documents set in English shows better performance than documents set in Chinese.1 IntroductionWith globalization of Internet environment, there are a tremendous amount of documents on the websites which are written in different languages. Apparently, large quantities of bilingual documents are parallel corpora or comparable corpora. When hot press comes out, news and reports in different languages are available on the Internet rapidly. These documents sets are so-called comparable corpora without translations to each other, but they are about the same topic. For some bilingual socie- ties or many international websites, they appear to[name][address1] [address2] [address3][email]release information in different language editions which are translations to each other and these are parallel corpora. Organizing multilingual infor- mation helps to improve the performance of infor- mation retrieval and provide people more specific multilingual information, such as the multilingual documents summarization (Evans, Klavans, & McKeown, 2004; Montalvo, Fresno, & Martínez, 2012).Multilingual document clustering aims to clus- ter documents in different languages into groups with the same topic or subtopic. Considering ap- proaches based on translation technique, two strat- egies are employed: translate the whole document into target language (Evans, et al., 2004) or trans- late certain features of document (e.g. cognate named entities) (Montalvo, Martinez, Casillas, & Fresno, 2006). Without translation, documents can be represented using translation independent fea- tures (Denicia-Carral, Montes-Gómez, Villaseñor- Pineda, & Aceves-Pérez, 2010). Obviously, per- formances of clustering will be affected by the quality of translations. After translating, first step of clustering is to represent each document. So far, several models have been proposed, like vector space model (VSM) (Salton, Wong, & Yang, 1975), latent semantic indexing (LSI) (Papadimitriou, Tamaki, Raghavan, & Vempala, 1998), probabilistic latent semantic indexing (PLSI) (Hofmann, 1999) and latent dirichlet allocation (LDA) which has many extensions nowadays to find latent topics of documents (Blei, Ng, & Jordan, 2003; Porteous et al., 2008). Meanwhile, clustering methods have also been studied, typical existing techniques include K-means (Wagstaff, Cardie, Rogers, & Schrödl, 2001), hierarchical ag- glomerative clustering (Zhao, Karypis, & Fayyad, 2005), density based algorithms, and graph based
algorithms (Frey & Dueck, 2007) etc. Though there have been many studies on document repre- sentation methods, clustering algorithms or cluster- ing strategies. There are no systematic investigations about comparing these methods or strategies on bilingual documents clustering.In this paper, we compare clustering strategies and document representation methods using the parallel corpora. Eliminating the difference and noise of language expression in comparable corpo- ra, parallel corpora are more suitable for detecting evidences of strategies effects. Basically, we have two strategies during experiments, one is using monolingual corpora which are translated from parallel corpora, and another one is using original corpora. Secondly, documents are represented by vector space model and topic model respectively. Referring to strategy using monolingual corpora, we cluster documents set twice comparing with clustering once. According to experimental results, we find that traditional VSM performs stably among all the strategies and performs better than the topic model. After translating parallel docu- ments into monolingual documents, corpora in English show better performance than corpora in Chinese.This paper is structured as follows: we will give an overview of previous works in the next section. Section 3 will present methodology of our research. Section 4 describes the experimental results and analysis. The conclusion and future work will be given in Section 5.2 Related worksIn the task of multilingual documents clustering, there have been many studies on clustering strate- gies, document representation methods or cluster- ing algorithms and so on.When referring to the clustering strategies, tra- ditional methods can take advantages of translation technique, such as using automatic translation sys- tem (Wang, Qian, & Davidson, 2012) or some bi- lingual thesaurus and dictionaries (Evans, et al., 2004). It transfers bilingual documents clustering into monolingual documents clustering. In some studies, documents were translated in the whole length (Leftin, 2003) and some documents were just translated in specific words (Chen & Lin, 2000) or chosen some features which reach a given weight threshold (Yang & Pedersen, 1997). Anoth-er main method is independent of translation. Named entities are used to represent documents (Montalvo, et al., 2012), and pairs of words ortho- graphically or thematically related (Pham, Bern- hard, Diallo, Messai, & Simonet, 2007). There were also re-searchers utilizing other knowledge (Kumar, Santosh, & Varma, 2011) or using new modeling to avoid the altering of original docu- ment semantics (Romeo, Tagarelli, & Ienco, 2014).Except clustering strategies, attentions have been paid to documents representation methods for further computing for a long time. Totally, repre- senting models can be categorized into five types: set-theoretic; algebraic; probabilistic; graph-based and hybrid models (Huang & Kuo, 2010). Set- theoretic model represents documents as sets of terms; algebraic model represents documents as vectors, tuples, or matrices; probabilistic model treats the process of document retrieval as a proba- bilistic inference (Huang & Kuo, 2010). Among all the models, vector space model (Salton, et al., 1975) is the most classical one while it will lose some semantic information. To solve this problem, LDA model (Blei, et al., 2003) is proposed. Many studies about the documents clustering based on the topic model are still going ahead (Sun, 2014) and some even integrated document clustering and topic modeling together (Xie & Xing, 2013). Moreover, topic models also deal with multilingual documents clustering; many extensions of LDA models are developed, such as MuTo (Boyd- Graber & Blei, 2009), PLTM (Mimno, Wallach, Naradowsky, Smith, & McCallum, 2009), etc. Vulic & Tang et al. defined the multilingual prob- abilistic topic modeling (MuPTM) and chose a natural extension of the omnipresent LDA model to multilingual settings called bilingual LDA (BiLDA) (Vulić, De Smet, Tang, & Moens, 2015).Researchers also care about computation meth- ods of document similarity (Forsyth & Sharoff, 2014; Sharoff, 2013). For instance, widely used cosine coefficient (Salton, et al., 1975) is to meas- ure the angle between two document vectors. Jen- sen-Shannon divergence between words probability distributions of two documents were also used in order to measure textual coherence (Boyack et al., 2011).From previous works, various strategies on multilingual document clustering have own limita- tions in some ways. We can find that translation quality and missing semantic information will def-
initely affect the clustering performance. So we try to find out the better clustering strategy and docu- ment representation method for bilingual docu- ments clustering.3 MethodologyIn this study, three different strategies are conduct- ed for bilingual documents clustering. We choose the parallel corpora as test data. Different from comparable corpora, each pair of parallel docu- ments can be considered as a piece of document representing in two different languages. Taxono- my of clustering strategies for parallel corpus is shown in figure 1. To compare the influences made by translation, strategies are firstly divided into two types, one is using translation technique and another one is using original documents. We de- note the former strategy as ‘I’ and the latter strate- gy as ‘II’. In the strategy I, after translation, two corpora are in the same language. We can combine each piece of parallel documents into one docu- ment and then cluster them, or we cluster the two documents sets in the parallel corpora separately and then combine the identified clusters to achieve our goal. Strategy with documents combination first is marked as ‘I-DC’. Strategy without combi- nation first is marked as ‘I-NC’.Figure 1.Taxonomy of Clustering Strategies for Bilin- gual Documents3.1 Bilingual Document Clustering StrategiesFrom previous studies, we find that performance of bilingual documents clustering is partly affected by the quality of translation. In this experiment, we compare the strategies with or without translations. (1) Clustering Strategy with Translation (Strategy I) Firstly, Microsoft machine translation API Bing1 is used to do translating works. Obviously, differ- ences between documents after translating are1 http://www.microsoft.com/translator/api.aspxcaused by the quality of translation. {𝑇1 , 𝑇2 , ⋯ , 𝑇𝑚 } and {𝑆1, 𝑆2, ⋯ , 𝑆𝑚} represent the two documents sets of parallel corpora in two different languages, target language T and source language S respec- tively.{𝑇1′,𝑇2′,⋯,𝑇𝑚′ }represents documents set in language T after translation. Two strategies, name- ly documents combination (‘I-DC’), and no com- bination (‘I-NC’) are used to preprocess the documents sets {𝑇1,𝑇2,⋯,𝑇𝑚} and{𝑇1′,𝑇2′,⋯𝑇𝑚′ }, respectively. The flowchart of Strategy I-DC is shown in figure 2.Parallel CorporaDoc Set in target language Doc Set in source language{𝑇,𝑇,⋯,𝑇 } {𝑆,𝑆,⋯,𝑆 } 12𝑚 12𝑚      Translation DocSet{𝑇,𝑇,⋯,𝑇 }′ ′ ′ DocSet{𝑇,𝑇,⋯,𝑇 } 1 2𝑚12𝑚   Document Combination Doc Set {𝑇 𝑇′,𝑇 𝑇′,⋯,𝑇 𝑇′ } 1122 𝑚𝑚  Doc representationSimilarity calculation Clustering algorithmDoc clustering resultsFigure 2.The flowchart of Clustering Strategy I-DCStrategy I-DC is that we combine document 𝑇1 and translated document 𝑇1′ into one document, two documents are all in target language, same combination for the other documents. Then, whole corpora are organized like {𝑇1𝑇1′, 𝑇2𝑇2′, ⋯ , 𝑇𝑚𝑇𝑚′ }. Additionally, features of nth document will be rep- resented based on new combined document 𝑇𝑛𝑇𝑛′. Instead of orderly arranging the features, we re- count features of the new documents as a whole. Clustering steps in this study include document representation, similarity calculation and clustering with affinity propagation [9]. Detailed information will be described in section 3.2.Strategy I-NC is the strategy about clustering for twice. Flowchart of it is shown in figure 3. Firstly, documents set {𝑇1, 𝑇2, ⋯ , 𝑇𝑚}and translat- ed documents set {𝑇1′,𝑇2′,⋯,𝑇𝑚′ } are clustered apart. We get the first clustering results of each. In order to combine the identified clusters, we use the center vector to represent each cluster and cluster these center vectors again. So, based on identified clusters, center vectors {𝑇1′′, 𝑇2′′, ⋯ , 𝑇𝑚′′} of all clus-       Bilingual Documents Clustering     Clustering Strategy IClustering Strategy II     Clustering Strategy I-DCClustering Strategy I-NC 
ters are computed. Here we use formula 1 to obtain center vectors.∑𝑁𝑙=1 𝑑𝑜𝑐𝑙(𝑤1,𝑤2,⋯,𝑤j,⋯,𝑤𝑘) 𝐶𝑖(𝑤1,𝑤2,⋯,𝑤𝑘)= 𝑁 (1)Where the C (𝑤 ,𝑤 ,⋯,𝑤 ) represents center i12 𝑘vector of identified cluster i, N is the number of documents in cluster i, docl(𝑤1,𝑤2,⋯,𝑤j,⋯,𝑤𝑘) is vector of document l in cluster i while wj is the weighted TF*IDF of word j.Then, we calculate similarities between all the center vectors and a second clustering is conducted based on these similarities to achieve the goal of clustering bilingual documents.Parallel CorporaDoc Set in target language Doc Set in source language{𝑇,𝑇,⋯,𝑇 } {𝑆,𝑆,⋯,𝑆 } 12𝑚 12𝑚and q is features count of document Ti and docu- ment Si . Methods of similarity computation and clustering are the same as Strategy I-DC.Parallel CorporaDoc Set in target language Doc Set in source language{𝑇,𝑇,⋯,𝑇 } {𝑆,𝑆,⋯,𝑆 } 12𝑚 12𝑚Document CombinationDocSet{𝑇𝑆,𝑇𝑆,⋯,𝑇 𝑆 } 1122 𝑚𝑚Doc representation Similarity calculation Clustering algorithmDoc clustering resultsFigure 4.The flowchart of Clustering Strategy II3.2 Document Representation and SimilarityComputationIn this study, Chinese-English parallel corpora are used as test dataset. Preprocessing has been done separately on the title and full text part of Chinese and English documents. For the Chinese corpus, we segment Chinese sentences by a Chinese seg- mentation tool, namely ICTCLAS 2 and remove the stop words via Chinese stop list. For the Eng- lish corpus, we first stem the words to their base forms using Porter Stemmer3, unify the letter case into lower case and then remove stop words via English stop list as well. Then, we use vector space model and topic model to do document representa- tion and computation of document similarity are done according to each model.Document Representation. Here, vector space model and topic model are used to represent the documents respectively.In the vector space model, TF*IDF value of each word is computed. For the word shown in title part of document, TF*IDF value of it is multiplied by 2 which denotes the weighting coefficient. Now, each document is treated as a vector in a high- dimensional space, where each component of vec- tor corresponds to the weighted TF*IDF of each word in document. The ith document doci vector can be described as [𝑊1𝑖,𝑊2𝑖,⋯,𝑊𝑗𝑖,⋯,𝑊𝑛𝑖] , where 𝑊𝑗𝑖 is weighted TF*IDF value of word j.2 http://ictclas.nlpir.org/3 http://tartarus.org/~martin/PorterStemmer/                   Translation Doc Set {𝑇 ,𝑇 ,⋯,𝑇 } Doc Set {𝑇′,𝑇′,⋯,𝑇′ }  12𝑚 12𝑚   Doc representationSimilarity calculation Clustering algorithmDoc clustering results Doc clustering results Center vectors set {𝑇′′, 𝑇′′, ⋯ , 𝑇′′}            12𝑚  Similarity calculation Clustering algorithmCenter vectors clustering resultsFigure 3.The flowchart of Clustering Strategy I-NC(2) Clustering Strategy without Translation (Strategy II)Strategy II does documents clustering without help of translation. Flowchart of it is shown in figure 4. {𝑇1,𝑇2,⋯,𝑇𝑚} and {𝑆1,𝑆2,⋯,𝑆𝑚} represent the parallel corpora in target language T and source language S, respectively. Document 𝑇𝑖 (i ∈ [1, m]) is concatenated with document 𝑆𝑖 (i ∈ [1, m]), new document 𝑇𝑖 𝑆𝑖 (i ∈ [1, m]) is generated. Whole corpora are organized as {𝑇1𝑆1, 𝑇2𝑆2, ⋯ , 𝑇𝑚𝑆𝑚} . Then we use these corpora to do the clustering. It is noted that represented features of each document 𝑇𝑖𝑆𝑖 (i ∈ [1,m]) will be different from the Strate- gy I-DC. Suppose the document 𝑇𝑖 (i ∈ [1, m]) and document 𝑆𝑖 (i ∈ [1, m]) can be represented as [𝑡1𝑖,𝑡2𝑖,⋯,𝑡𝑝𝑖] and [𝑠1𝑖,𝑠2𝑖,⋯,𝑠𝑞𝑖] respectively. After concatenation, new vector of 𝑇𝑖𝑆𝑖 (i ∈ [1, m]) is [𝑡1𝑖, 𝑡2𝑖, ⋯ , 𝑡𝑝𝑖, 𝑠1𝑖, 𝑠2𝑖, ⋯ , 𝑠𝑞𝑖], where p   
In the topic model, in order to find appropriate number of topics, Gibbs-sampled topic model is tested at the following topic count (T): 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150 and 200 respective- ly. In our experiments, we run for 3000 iterations and prior hyper parameter settings of β=0.01 and α=50/T. After running out GibbsLDA [6], topic probability distributions of each document will be achieved. The ith document doci can be described as (𝑃1𝑖, 𝑃2𝑖, ⋯ , 𝑃𝑗𝑖, ⋯ , 𝑃𝑚𝑖), where Pji is the proba- bility of topic j that doci gets.Similarity Computation. After documents representation, similarity between documents is computed according to the model.In VSM, we use the cosine coefficient [2] to calculate the similarity between two documents. It is computed via formula 2.When doing affinity propagation4, preference value needs to be set ahead according to the similarities. For VSM, median value among similarities is cho- sen to be the preference. To make the algorithm converge, preference value is tuned in two condi- tions. For the corpus of translated Chinese blogs, we choose the minimum value among similarities to be the preference. For topic model, we choose the mean value between median value and maxi- mum value of similarities to be the preference.⃑⃑⃑⃑⃑⃑⃑⃑⃑⃑ ⃑⃑⃑⃑⃑⃑⃑⃑⃑⃑ ⃑⃑⃑⃑⃑⃑⃑⃑⃑ ⃑⃑⃑⃑⃑⃑⃑⃑⃑ 𝑑𝑜𝑐1∙𝑑𝑜𝑐2In this study, parallel corpora are collected fromEngadget website, which is a multilingual technol-ogy blog website. We chose the Chinese5 and Eng-6lish versions of this website and downloaded 4,904 pairs of blogs to be the experimental dataset. A blog includes title, author, time, category, full text of the blog and tags. In this experiment, we make use of the title, full text of the blog and the catego- ry of each blog. Totally, there are 20 categories of all the blogs7.Table 1.Classification Distribution of Test Dataset𝑠𝑖𝑚(𝑑𝑜𝑐1,𝑑𝑜𝑐2)= ⃑⃑⃑⃑⃑⃑⃑⃑⃑⃑ ⃑⃑⃑⃑⃑⃑⃑⃑⃑⃑ (2) ‖𝑑𝑜𝑐1‖∙‖𝑑𝑜𝑐2‖In topic model, similarity between documents will be converted to similarity between two proba- bility distributions of topics. Jensen-Shannon di- vergence (Lin, 1991) measure is used to calculate similarity via formula 3. Based on the representa- tion definitions above, 𝑃𝑖 (𝑃1𝑖 , 𝑃2𝑖 , ⋯ , 𝑃𝑚𝑖 ) and 𝑃𝑗(𝑃1𝑗,𝑃2𝑗,⋯,𝑃𝑚𝑗)are topic probability distribu- tions of documents 𝑃𝑖 and 𝑃𝑗, where m is the topic numbers. Average probability distribution between 𝑃𝑖 and 𝑃𝑗 is 𝑃𝑘(𝑃1𝑘,𝑃2𝑘,⋯,𝑃𝑚𝑘), which is calcu- lated via formula 4.𝐽𝑆(𝑃𝑖 ∥ 𝑃𝑗) = 12 [𝐷𝐾𝐿(𝑃𝑖 ∥ 𝑃𝑘) + 𝐷𝐾𝐿(𝑃𝑗 ∥ 𝑃𝑘)] (3) 𝑃 𝑘 = 12 ( 𝑃 𝑖 + 𝑃 𝑖 ) ( 4 )Jensen–Shannon divergence is based on the Kullback-Leibler divergence (Kullback & Leibler, 1951). For discrete probability distributions 𝑃𝑖 and 𝑃𝑗 , Kullback–Leibler divergence of 𝑃𝑗 from 𝑃𝑖 is calculated via formula 5.𝐷𝐾𝐿(𝑃𝑖 ∥𝑃𝑗)=∑𝑚𝑃𝑖(𝑚)𝑙𝑛𝑃𝑖(𝑚) (5) 𝑃𝑗(𝑚)Where, 𝑃𝑖(𝑚) is the mth probability in the probability distributions 𝑃𝑖 , 𝑃𝑗 (𝑚) is the mth prob- ability in the probability distributions 𝑃𝑗.3.3 Affinity Propagation ClusteringAfter we get similarities in two different models, the affinity propagation clustering (Frey & Dueck, 2007) is carried out based on these similarities.4http://www.psi.toronto.edu/index.php?q=affinity%20propagat ion5 http://cn.engadget.com/6 http://www.engadget.com/7 Originally there are 34 categories. We checked the blogs in each category and found that blogs in some categories are very similar to each other. We made a new summary with 20 cate- gories.4 4.1Experiment and results analysis Experimental Dataset                 Category Sum Category Sum Category Sum          Mobile 918 Game prod- 319 Locating 21 products ucts products          News and 827 Playing 248 Wearing 105 report facilities products          Internet 462 Digital 244 Home 103 network camera appliance          Computer 442 High- 105 Intelligent 102 products definition machinetelevision          Peripheral 345 Transporta- 175 Display 94 equipment tion related products          Software 82 Wireless 52 Desktop 45 application application products          Tablet PC 188           
 4.2 Evaluation Measures of Experimental ResultsPurity and entropy value (Pang-Ning, Steinbach, & Kumar, 2006) are used to evaluate experimental results of parallel corpus.Entropy. The degree of each cluster that it is composed of objects from a single category. For each cluster, we need to calculate category distri- butions via formula 6, that is for cluster i, the prob- ability is computed that members in cluster i belong to category j.𝑝𝑖𝑗 = 𝑚𝑖𝑗 (6) 𝑚𝑖Where, mi is the object numbers in cluster i and mij is the object numbers of category j in the clus- ter i.We compute the entropy of each cluster and the entropy of cluster i is calculated via formula 7.𝑒 𝑖 = − ∑ 𝐿𝑗 = 1 𝑝 𝑖 𝑗 𝑙 𝑜 𝑔 2 𝑝 𝑖 𝑗 ( 7 ) Where, L is the categories count.The total entropy of the clusters set is calculat- ed via formula 8.𝐸𝑛𝑡𝑟𝑜𝑝𝑦 = ∑𝐾𝑖=1 𝑚𝑖 𝑒𝑖 (8) 𝑚Where, K is the clusters number and m is the number of all the objects.Purity. Another measurement about the degree of each cluster that it is composed of objects from a single category. The purity of cluster i is calcu- lated via equation 9. And total purity of the clusters is calculated via equation 10.tropy values while abbreviation of ‘P’ indicates that column represents purity values.Table 2.Entropy and Purity Value of Vector Space Model StrategiesTable 3.Entropy and Purity Values of Topic Model Strategies    Strategy Index      Strategy I-DC    Strategy I-NC       Strate- gy II       I-DC-c I-DC-e     I-NC-c   I-NC-e  Entropy      1.431    1.208      1.932    1.629    1.242  Purity   0.610   0.651   0.539   0.592   0.643          T        Strategy I-DC Strategy I-NC       Strategy II      I-DC-c I-DC-e     I-NC-c   I-NC-e    E     P     E   P      E      P     E   P   E    P     10 3.577 0.218 3.4940.218  3.539 0.215 3.4060.268 3.636  0.204    20   3.662   0.203   3.553 0.225     3.682   0.191   3.596 0.212  3.670   0.200    30     3.657     0.204     3.617   0.212      3.696      0.189     3.570   0.210   3.651    0.204   40   3.661   0.203   3.608  0.202   3.702    0.189   3.560  0.226  3.649   0.197   50 3.668 0.201 3.6480.197  3.694 0.190 3.5680.220 3.655  0.210    60     3.656     0.204     3.637   0.200      3.703      0.189     3.695   0.190   3.665    0.194   70 3.652 0.202 3.6540.198  3.708 0.188 3.6830.195 3.664  0.203    80   3.645   0.204   3.641 0.210     3.716   0.187   3.688 0.192  3.649   0.215    90     3.657     0.204     3.646   0.194      3.714      0.188     3.712   0.188   3.641    0.199   100 3.656 0.203 3.6400.204  3.714 0.188 3.6410.196 3.625  0.208    150     3.642     0.197     3.641   0.205      3.715      0.187     3.714   0.187   3.612    0.210   200   3.624   0.205   3.646  0.205   3.716    0.187   3.711  0.188  3.608    0.204     𝑝𝑖 = 𝑚𝑎𝑥𝑗 𝑝𝑖𝑗 𝑚 𝑃𝑢𝑟𝑖𝑡𝑦 = ∑𝐾𝑖=1 𝑚𝑖 𝑝𝑖4.3 Experimental Results Analysis(9) (10)(1) Analysis of Performance between Clustering StrategiesAccording to table 2 and table 3, we can find that, in VSM, Strategy I-DC-e performs the best among all the strategies, entropy value is 1.208 and purity value is 0.651 while in topic model, Strategy I-NC- e performs the best (T=10) among all the strategies, entropy value is 3.406 and purity value is 0.268. These two strategies all use the English monolin- gual corpora after translation. After clustering, we compare performances be- tween different strategies and models based on the entropy and purity values. Furthermore, we make statistical significant test to validate the effective- ness as well. The evaluation measures of experi- mental results are shown in table 2 and table 3.In the Strategy I, we translate parallel docu- ments into monolingual documents in one of the two languages. So, experimental inputs are all in Chinese or all in English. Character of ‘c’ behind strategy names shown in the table 2, 3 and figure 4 represents experimental input is all in Chinese lan- guage, character of ‘e’ represents experimental input is all in English language. Character of ‘E’ in the table 2, 3 indicates that column represents en-Figure 5.Entropy Value of Topic Model according to Topics Number I-DC-c I-DC-e I-NC-e III-NC-c     3.8 3.7 3.6 3.5 3.4 10 20 30 40 50 60 70 80 90100150200Topics numberEntropy value
  To better understand the performance of strate- gies under topic model, we draw figure 5 about entropy values between strategies of topic distribu- tion model. With the number of topics increasing, entropy value of the other strategies all gets in- creased. Strategy I-DC-e performs better than other strategies and it shows big difference with Strategy I-DC-c when topic number is smaller than 50. Be- sides, performance of Strategy II without transla- tion technique is moderate.We make a two independent samples t-test be- tween two groups of Strategy I-NC and a One-way ANOVA test with the least-significant difference (LSD) among three groups of strategy I-DC and Strategy II using SPSS 19.08 statistical software. We all use entropy values to be the test variable. Test results are in table 4 and table 5 respectively.Table 4.Independent Samples Test of Strategy I-NCTable 5.Multiple Comparisons between groups of strat- egy I-DC and Strategy IIFrom table 4, p-value is 0.054, there is no dif- ference between the mean entropy values of Chi- nese documents set and English documents set under Strategy I-NC at 5% significance level. From table 5, p-value between Strategy I-DC-c and Strategy I-DC-e is 0.05, there is difference be- tween the mean entropy values of Strategy I-DC-c and Strategy I-DC-e at 5% significance level. Strategy II doesn’t show significant difference from the other two methods.To sum up, no matter under strategy I-DC or strategy I-NC, corpora in English appear to have better performance than corpora in Chinese when the topic is smaller than 50. Taking the prepro- cessing into consideration, stemming step of Eng-8 http://www.spss.co.in/lish corpora changes inflected words to their word stem root form. Similarity between documents will increase due to the increasing number of same word bases generated from stemming. To the con- trary, different characteristics of a certain word in Chinese corpora may cause low similarities though they have the same semantic information.(2) Analysis of Performance between Representation ModelsAccording to the table 2 and table 3, we can clearly see that performances of VSM are better in all strategies than the performances of topic model. Comparisons between two groups of different doc- ument representation models are also performed using a two independent samples t-test to see if there is a significant main effect of different repre- sentation models. Test result is shown in table 6.Table 6.Independent Samples Test of Document Repre- sentation ModelsFrom table 6, since the p-value is 0.000, we conclude that there is difference between the mean entropy values of vector space model and topic model at 5% significance level. One possible rea- son for the difference between models is that we set a weighting coefficient of words in title part in VSM. Additionally, when using topic probability distributions to represent documents, the generated topic itself may be a fuzzy one. This will definitely reduce the accuracy of representing documents. To sum up, the vector space model is more reliable for representation in this study.5 Conclusion and future worksIn this paper, we use two different document repre- sentations with three strategies to do the bilingual document clustering. We also compare the strate- gies with or without translation technique. To sum up, different strategies show different performanc- es and the traditional VSM representation method performs better than the topic model. With the help of translation technique, input in English shows better performance than input in Chinese.In the future, comparable corpora will be cho- sen to be the test data for there are much more rel-           Levene's Test for Equality of Variances   T-test for Equality of Means      F  Sig.    t      df   Sig. (2-tailed)     entropy      6.182    .021     2.077        22      .050              2.077     16.747     .054                   Levene's Test for Equali- ty of Variances      T-test for Equality of Means   F   Sig.   t    df   Sig. (2-tailed)      entropy     58.217    .000    49.408     63    .000              16.074     4.025     .000            (I)Strategy         (J)Strategy   Mean Difference (I-J)       Std. Error        Sig.  I-DC-c          I-DC-e  .0276667*    .0135876    .050      II  .0026667    .0135876    .846  I-DC-e          I-DC-c     -.0276667*     .0135876      .050    II -.0250000  .0135876   .075  II         I-DC-c     -.0026667     .0135876      .846    I-DC-e    .0250000   .0135876     .075    
evant resources on the Internet. Other language pairs can be our options as well. Different translate engines show different translation qualities, we will use other automatic translation engines, like Google Translator for better comparison. Deep learning technique will also be added into the doc- ument representation methods to find out the best one. Referring to topic model representation meth- od, can we also set any weight on the probability of topic distribution to distinguish from ambiguous ones? More works are needed to be done in the future.AcknowledgementReferencesBlei, D. M., Ng, A. Y., & Jordan, M. I. 2003. Latent dirichlet allocation. the Journal of machine Learning research, 3, 993-1022.Boyack, K. W., Newman, D., Duhon, R. J., Klavans, R., Patek, M., Biberstine, J. R., et al. 2011. Clustering more than two million biomedical publications: Comparing the accuracies of nine text-based similarity approaches. PloS one, 6(3), e18029.Boyd-Graber, J., & Blei, D. M. 2009. Multilingual topic models for unaligned text. Paper presented at the Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence.Chen, H.-H., & Lin, C.-J. 2000. A multilingual news summarizer. Paper presented at the Proceedings of the 18th conference on Computational linguistics-Volume 1.Denicia-Carral, C., Montes-Gómez, M., Villaseñor- Pineda, L., & Aceves-Pérez, R. M. 2010. Bilingual document clustering using translation-independent features. Paper presented at the Proceedings of CICLing.Evans, D. K., Klavans, J. L., & McKeown, K. R. 2004.Columbia newsblaster: multilingual news summarization on the Web. Paper presented at the Demonstration Papers at HLT-NAACL 2004.Forsyth, R. S., & Sharoff, S. 2014. Document dissimilarity within and across languages: A benchmarking study. Literary and Linguistic Computing, 29(1), 6-22.Frey, B. J., & Dueck, D. 2007. Clustering by passing messages between data points. science, 315(5814), 972-976.Hofmann, T. 1999. Probabilistic latent semantic indexing. Paper presented at the Proceedings ofthe 22nd annual international ACM SIGIR conference on Research and development in information retrieval.Huang, H.-H., & Kuo, Y.-H. 2010. Cross-lingual document representation and semantic similarity measure: a fuzzy set and rough set based approach. Fuzzy Systems, IEEE Transactions on, 18(6), 1098-1111.Kullback, S., & Leibler, R. A. 1951. On information and sufficiency. The annals of mathematical statistics, 79-86.Kumar, K., Santosh, G., & Varma, V. 2011.Multilingual document clustering usingwikipedia as external knowledge: Springer. Leftin, L. J. 2003. Newsblaster Russian-English clustering performance analysis. ComputerScience Technical Report Series.Lin, J. 1991. Divergence measures based on theShannon entropy. Information Theory, IEEETransactions on, 37(1), 145-151.Mimno, D., Wallach, H. M., Naradowsky, J., Smith, D.A., & McCallum, A. 2009. Polylingual topic models. Paper presented at the Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2- Volume 2.Montalvo, S., Fresno, V., & Martínez, R. 2012. NESM: A named entity based proximity measure for multilingual news clustering. Procesamiento del lenguaje natural, 48, 81-88.Montalvo, S., Martinez, R., Casillas, A., & Fresno, V. 2006. Multilingual document clustering: an heuristic approach based on cognate named entities. Paper presented at the Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics.Pang-Ning, T., Steinbach, M., & Kumar, V. 2006. Introduction to data mining. Paper presented at the Library of Congress.Papadimitriou, C. H., Tamaki, H., Raghavan, P., & Vempala, S. 1998. Latent semantic indexing: A probabilistic analysis. Paper presented at the Proceedings of the seventeenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems.Pham, M. H., Bernhard, D., Diallo, G., Messai, R., & Simonet, M. 2007. SOM-based clustering of multilingual documents using an ontology. Data Mining with Ontologies: Implementations, Findings, and Frameworks, 65-82.Porteous, I., Newman, D., Ihler, A., Asuncion, A., Smyth, P., & Welling, M. 2008. Fast collapsed gibbs sampling for latent dirichlet allocation. Paper presented at the Proceedings of the 14th
ACM SIGKDD international conference onKnowledge discovery and data mining.Romeo, S., Tagarelli, A., & Ienco, D. 2014. Semantic- based multilingual document clustering via tensor modeling. Paper presented at the EMNLP, Conference on Empirical Methods inNatural Language Processing.Salton, G., Wong, A., & Yang, C.-S. 1975. A vectorspace model for automatic indexing.Communications of the ACM, 18(11), 613-620. Sharoff, S. 2013. Measuring the distance between comparable corpora between languages Building and Using Comparable Corpora (pp.113-130): Springer.Sun, X. 2014. Textual Document Clustering UsingTopic Models. Paper presented at the Semantics, Knowledge and Grids (SKG), 2014 10th International Conference on.Vulić, I., De Smet, W., Tang, J., & Moens, M.-F. 2015. Probabilistic topic modeling in multilingual settings: An overview of its methodology and applications. Information Processing & Management, 51(1), 111-147.Wagstaff, K., Cardie, C., Rogers, S., & Schrödl, S. 2001.Constrained k-means clustering with background knowledge. Paper presented at the ICML.Wang, X., Qian, B., & Davidson, I. 2012. Improving document clustering using automated machine translation. Paper presented at the Proceedings of the 21st ACM international conference on Information and knowledge management.Xie, P., & Xing, E. P. 2013. Integrating document clustering and topic modeling. arXiv preprint arXiv:1309.6874.Yang, Y., & Pedersen, J. O. 1997. A comparative study on feature selection in text categorization. Paper presented at the ICML.Zhao, Y., Karypis, G., & Fayyad, U. 2005. Hierarchical clustering algorithms for document datasets. Data mining and knowledge discovery, 10(2), 141-168.