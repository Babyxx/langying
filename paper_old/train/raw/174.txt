Korean Twitter Emotion Classi cation Using Automatically Built Emotion Lexicons and Fine-Grained FeaturesAbstractIn recent years many people have begun to express their thoughts and opinions on Twit- ter. Naturally, Twitter has become an ef- fective source to investigate people’s emo- tions for numerous applications. Classifying only positive and negative tweets has been ex- ploited in depth, whereas analyzing  ner emo- tions is still a dif cult task. More elaborate emotion lexicons should be developed to deal with this problem, but existing lexicon sets are mostly in English. Moreover, building such lexicons is known to be extremely labor- intensive or resource-intensive. Finer-grained features need to be taken into account when determining  ner-emotions, but many exist- ing works still utilize coarse features that have been widely used in analyzing only the po- larity of emotion. In this paper, we present a method to automatically build  ne-grained emotion lexicon sets and suggest features that improve the performance of machine learning based emotion classi cation in Korean Twitter texts.1 IntroductionNowadays, people freely express their thoughts on microblogs, and Twitter is known to be one of the popularly used services. In 2014, 500 million tweets were sent per day by 316 million monthly active users across the globe1. Not surprisingly, Twitter has been actively mined in the  eld of computer sci- ence to investigate public opinion (Diakopoulos and Shamma, 2010; Kim et al., 2014; O’Connor et al.,1 https://about.twitter.com/company2010), get real-time information (Doan et al., 2012), and even forecast future events (Bollen et al., 2011). All such research shows Twitter’s potentials in the analysis of human thought and behavior. In partic- ular, researchers are showing interest in the analysis of human emotions presented in Twitter messages. Many studies have been done to classify sentiments (positive and negative) in tweets. Going further, re- searchers are currently trying to analyze  ne-grained emotions beyond polarity. Fine-grained emotion analysis is known to be more challenging than sen- timent analysis because it must identify subtle dif- ferences between emotions. Dealing with emotions in an individual Twitter post is even more dif cult because of its short length with the frequent use of informal words and erroneous sentence structures. Elaborate emotion lexicons should be used to deal with the problem, but non-English speaking coun- tries have dif culties using existing lexicon sets be- cause they are mostly in English. Further, build- ing such lexicons is known to be extremely labor- intensive or resource-intensive that can be a burden to under-resourced countries. Moreover, a set of features that achieves the best performance in  ne- grained emotion classi cation should be exploited that is particularly attuned to tweets written in spe- ci c language.Our goal in this paper is to classify Korean Twit- ter messages into  ne-grained emotions. The emo- tion types are Ekman’s six basic emotions (Ekman, 1992) and it is known to be the most frequently used in the  eld of computer science for emotion min- ing and classi cation (Bann and Bryson, 2012). For this goal, we employed machine learning algorithms 
with  ne-grained features including an emotion lex- icon feature. Speci cally, we addressed the follow- ing problems:1. Emotion lexicon construction. Is there any sim- ple and automatic method to generate emotion lexicons particularly attuned to the Twitter do- main without using other lexical resources?2. Feature engineering. What is the best set of features that can effectively show the subtle distinctions between  ner-grained emotions ex- pressed in Korean Twitter texts?We propose an emotion lexicon construction method and features to address the problems above. Our main contributions are the following:1. Emotion lexicon construction. We propose the weighted tweet frequency (weighted TwF) method, a simple and automatic way to build emotion lexicon lists directly from an anno- tated corpus without using other resources. The method will be useful for many countries where relevant resources are not available.2. Feature engineering. We propose a set of  ne-grained and language-speci c features that improves the overall performance of machine learning based emotion classi cation in Korean Twitter texts.3. Resource and Dataset Our study is unique be- cause emotion analysis on Korean Twitter texts has rarely been addressed before. In addition, we built an annotated dataset, emotion lexicon sets, and other resources. Since  nding related datasets and resources in Korean is dif cult, we believe our work can contribute to future re- lated studies.The rest of this paper is organized as follows. Sec- tion 2 overviews related work, and in Section 3, we introduce our annotated dataset. In Section 4, we present our emotion lexicon construction method and in Section 5, we describe features designed for classi cation. We provide experimental results and analysis in Section 6 and conclude in Section 7.2 Related WorkThere have been extensive studies on sentiment analysis that classify expressions of sentiment into positive and negative emotions. In the last few years, researchers have started to explore  ner granularity of emotion because simple division of polarity may not suf ce in many real-world applications. There are two main approaches to emotion analysis, one is a lexicon based approach and the other is a machine learning based approach. The lexicon based ap- proach utilizes a dictionary of words annotated with their emotional orientation and simply counts the words or aggregates the according values presented in texts. In contrast, the machine learning based ap- proach performs classi cation using machine learn- ing algorithms based on carefully designed features. Roberts et al. (2012) tried to classify seven emo- tions in the Twitter domain with binary support vec- tor machine(SVM) classi ers, and Balabantaray et al. (2012) also used SVM classi ers with features including WordNet-Affect emotion lexicons.A large number of existing emotion lexicon sets were built manually such as WordNet-Affect (Strap- parava and Valitutti, 2004) and Linguistic Inquiry and Word Count (Pennebaker et al., 2001). Crowd- sourcing is often utilized to obtain a large volume of human annotated lexicon sets such as the NRC Word-Emotion Association Lexicon (Mohammad and Turney, 2013). Non-English speaking countries like Korea have dif culties building emotion lexi- cons without human labor because existing lexicons and crowd-sourcing platforms are mostly available in English. To deal with the dif culties, one pop- ular approach is to build lexicons upon other re- sources. For example, AffectNet (Cambria and Hus- sain, 2012) was constructed using ConceptNet(Liu and Singh, 2004) and WordNet-Affect (Strapparava and Valitutti, 2004). Another popular choice for building lexicon sets automatically is translating ex- isting lexicon lists written in English. Those built by Remus et al. (2010) and Momtazi (2012) are ex- amples. We also propose an automatic method that does not require lexical resources and translation.Very few attempts have been made so far to ana- lyze emotions in Korean text. Cho and Lee (2006) identi ed eight emotions in Korean song lyrics with manually annotated word emotion vectors. Lee et al.
  (2013) classi ed Korean tweets into seven emotions and achieved 52% accuracy when using the multi- nomial na ̈ıve Bayes algorithm with morpheme fea- tures. The only publicly available Korean emotion lexicons we found were a set of 265 terms of nine emotion types, manually built by Rhee et al. (2008). Our work differs from the aforementioned Korean studies because we automatically construct larger emotion lexicon sets and introduce  ne-grained fea- tures that are particularly attuned for Korean Twitter texts.3 Korean Twitter Emotion Analysis (KTEA) DatasetA Twitter dataset annotated by emotion types is essential in the machine learning based approach for the purpose of training. To build the corpus, we collected random Korean Twitter messages us- ing Twitter streaming API. We removed tweets with RT, URL links, and replies. After the collection process, a corpus can be annotated either manually by human annotators or automatically by distant la- bels (Go et al., 2009; Wicaksono et al., ; Lee et al., 2013). In our case, we manually annotated the cor- pus. Each tweet was labeled by three annotators, producing three emotion labels per tweet. Conse- quently, we constructed a Korean Twitter Emotion Analysis (KTEA) dataset2 , which contains 5,706 valid tweets labeled by seven types of emotions - Ekman’s six emotions and no emotion(neutral). Us- ing the dataset, we constructed emotion lexicon sets as described in Section 4 and trained our machine learning algorithm as presented in Section 5.Emotion Happiness Sadness Anger Disgust Surprise Fear TotalNumber of Tweets 77013779036944752284447          4 4.1Constructing Emotion LexiconsOur Approach - Weighted Tweet FrequencyTable 1: The number of tweets we used to generate emo- tion lexicons using weighted TwF approachTo generate emotion lexicons, we propose the weighted tweet Frequency (weighted TwF) method. First, we aggregated tweets of the same emotion la- bel in one document (d), producing six documents (D) of tweets as a result. Using the six documents, we calculated the weighted TwF for each term (t) that appeared in the documents. The weighted TwF is expressed in Equations 1, 2, and 3. Consequently, we generated six emotion lexicon lists, one list for each emotion type. Each lexicon has a weighted TwF value which shows the strength of the corre- sponding emotion, i.e., the higher the value is, the stronger the emotion is. The basic idea is simi- lar to the concept of term frequency - inverse doc- ument frequency (TF-IDF)3, for which the occur- rences of a term are counted and a penalty is given if the term appears in several documents. However, TF-IDF is not appropriate for our task because the structures of tweets are often highly ungrammati- cal, and there are many tweets with meaningless terms, which are sometimes excessively repeated in one tweet. In such cases, the meaningless terms produce high term frequency, which results in erro- neous emotion lexicons. As illustrated in Figure 1, when term frequency (TF-IDF) is used, we can see some words (that are names in this example), such as 시우민 “Xiumin”, 성규 “Sung Kyu”, and 김민 석 “Kim Min Seok”, ranked high in the happiness lexicon list. This is because there are few tweets that excessively repeat those names. Similar kinds of unstructured tweets are frequent in Twitter, and we can disregard such cases by using the tweet fre- quency de ned in Equation 1. It counts the num- ber of tweets instead as true emotion lexicons appear across many tweets, not in a few erroneous tweets.3 https://en.wikipedia.org/wiki/Tf-idfWe built emotion lexicons automatically from the annotated corpus without using other lexical re- sources. For the construction, we utilized part of our KTEA dataset, which is the set of tweets, each of which was labeled as representing one of Ekman’s six emotion types (disregarding the neutral case) by at least one annotator. Table 1 shows the number of tweets we used per emotion for the purpose of lexi- con construction.2 goo.gl/Gu0GNw  
 Figure 1: Example of top-ranked happiness lexicons generated from TF-IDF and weighted TwFAnother reason why TF-IDF is not suitable is the log term in IDF, which is trivial due to the small num- ber of documents. Thus, we used a simple weighting scheme instead as in Equation 2. We set the weight to zero when a lexicon appeared in all the emotion documents in order to remove lexical items that ap- pear very frequently but without any emotions, for example, 있다 “is”, and 나 “I”.thesaurus and adds them to the emotion lexicon lists. Due to the lack of a large and representative Ko- rean thesaurus, we combined various publicly avail- able resources, namely, Dong-a’s Prime dictionary4, Naver dictionary5 , a Korean thesaurus6 , and Wise- WordNet7. First, seed words – happiness, sadness, anger, disgust, surprise, and fear – were translated into Korean using Dong-a’s Prime English-Korean Dictionary. Then, we extended the emotion lexicon sets to include derivatives and synonyms using var- ious resources and thesauruses. Since the resources were not perfect, there were many erroneous syn- onyms. Thus, for the last step, we manually re- moved the unreasonable ones. The detailed proce- dure is summarized in Table 2.4.3 Translation-Based ApproachThere are many lexical resources in English for emotion analysis. This method translates such re- sources to a speci c language, in our case, Ko- rean. Among many lexical resources, we chose WordNet-Affect (Strapparava and Valitutti, 2004) as it is one of the popular and typical emotion lexicon sets used in emotion analysis, and it is freely avail- able. WordNet-Affect contains WordNet synonyms and is manually annotated by Ekman’s six emotions. We translated the WordNet-Affect list using Google Translate8. We employed the Google service as it is the most widely used translator and its performance is known to be fairly accurate. However, there were4 http://www.dongapublishing.com/entry/index.html 5 dic.naver.com6 http://www.wordnet.co.kr/7Software Research Laboratory, ETRI8 https://translate.google.co.kr/- d : A document with tweets of same emotion - D : Total set of ds- t : Target term- n : The number of ds where t appearsNormalized Tweet Frequency= Number of tweets in d where t appearsTotal number of terms in the d 1(1) Weight=n n<|D| (2) 0 n=|D| weighted Tweet Frequency (weighted TwF) = Normalized Tweet Frequency × Weight(3)Automatic methods of building emotion lexicons have been studied in many works. There are two widely used methods, namely, a thesaurus-based approach (Section 4.2) and a translation-based ap- proach (Section 4.3).4.2 Thesaurus-Based ApproachThe thesaurus-based method builds emotion lexicon lists using synonyms. Using a small set of emotion seed words, this method looks for synonyms using a 
  Thesaurus-Based ApproachSeed wordshappiness, sadness, anger, disgust, surprise, fear (each seed word constructs according emotion lexicon list)Step 1. Translate seed words to Korean usingDong-a’s Prime dictionaryStep 2. Add derivatives using NAVER dictionary Step 3. Using Korean thesaurus, add synonymsof each wordStep 4. Using WiseWordNet, add primarysynonyms of each wordStep 5. Leave only exclusive words for eachemotion and remove duplicates within list Step 6. Manually remove unreasonable ormisleading emotion wordsTable 2: Procedure of making emotion lexicons using thesaurus-based approachsome erroneous translations since the Korean trans- lator is not perfect. Thus, we manually modi ed and removed problematic words and duplicates.4.4 ComparisonIn this section, we explain the qualitative aspects of our lexicon construction method in comparison with other approaches. The advantages of our emotion lexicon sets built by weighted TwF approach are the following:1. As the wordlist is constructed based on real Twit- ter messages, the method generates Twitter-speci c lexicons that include slang, swear words, and un- grammatical words. Example: 존잘님 “slang for handsome person”, 조아 “ungrammatical word for like”2. Our method discovers topics that are closely re- lated to some particular emotions. Example: 야자 “night school study” (sadness - many students feel sad when they are forced to study at night in school)3. It is possible to discover keywords that particularly appear in a speci c time range. The method au- tomatically updates the lexicons to include newly- coined words, which are essential for emotion anal- ysis in Twitter domain. Example: 빅뱅 “Big Bang” (happiness - a famous Korean singer Big Bang re- leased a new album at the time we constructed the emotion lexicons)We show the effectiveness of our weighted TwF approach by comparing it with the popularApproach Automatic? Resource-free? No manual work? Twitter-speci c?Weighted TwF OOThesaurus Translation O O X(thesaurus) X(translator)  O X X O X X Table 3: Comparison of our weighted TwF approach with thesaurus-based and translation-based approachesthesaurus-based and translation-based approaches. Table 3 compares the three approaches. These ap- proaches can automatically generate emotion lexi- cons. To be speci c, using the thesaurus-based ap- proach, we are able to construct emotion wordlists easily and automatically by using only a small set of seed words. The translation-based approach also translates the existing emotion lexicons automati- cally using translators. However, the thesaurus- based approach is heavily dependent on lexical re- sources like dictionaries and thesauruses. A well- built thesaurus is not likely to be available in many non-English speaking countries. Additionally, translation-based approach requires a reliable trans- lator. In comparison, our weighted TwF approach is based on statistics, which are independent of lexical resources and translators; thus, it would be very use- ful for under-resourced countries. Moreover, we ob- served that the thesaurus- and translation-based ap- proaches generate a lot of erroneous words due to errors of resources and translators. Hence, manual removal of those words was necessary to achieve accurate results. In contrast, our approach gener- ates lexicons with strength values that show how ac- curately the word may belong to an emotion type. Even though erroneous words are included in the list, they are likely to be ignored due to the low weighted TwF value. Lastly, our lexicon sets are par- ticularly attuned to the Twitter domain; they include slang, jargon, ungrammatical words, and newly- coined words, whereas most other approaches do not.5 Machine Learning with Fine-Grained FeaturesOur goal is to classify Korean Twitter messages ac- cording to one of the following six emotions, happi- ness, sadness, anger, disgust, surprise, and fear. We used a machine learning algorithm to classify each Twitter message represented by a feature vector. We 
  rst explain features that we propose in this work and explain our machine learning classi cation.5.1 Fine-Grained FeaturesFeature engineering is very important in machine learning. Features that have been traditionally used in emotion analysis are lexicons and punctuations. Positive and negative emoticons such as :) and :( have also been used in some research. However, more  ne-grained and language-speci c features are necessary to distinguish  ner granularity of emo- tions. To come up with some effective features, we worked with the following ideas:• Emoticons and symbols may express speci c types of  ne-grained emotions• Some alphabet letters may convey emotions• Exclamation words may appear in surprisemessages• Swear words may appear in angry messagesWe explain how we designed the features accord- ing to the ideas we presented above with some ex- amples.Fine-Grained Emoticons and Symbols Emoticons and symbols are important in analyzing online lan- guage because many people express their feelings using them. We constructed a list of emoticons for each  ne-grained emotion type that are used in Ko- rea as well as general emoticons widely used in East- ern and Western countries. We constructed a dictio- nary of emoticons and symbols with the aid of vari- ous website articles. Moreover, we included Emojis which have become increasingly popular on Twitter since mobile devices adopted them. We sorted each emoticon and symbol into one of the six emotions using the explanations written in the websites. One interesting aspect of the dictionary is that it utilizes regular expressions to incorporate various mutations of emoticons. For example, Korean emoticons of- ten use various or extended particles to represent the mouth of a face. In the case of a smiling face (ˆˆ), people use various mutation of such emoticons such as (ˆ ˆ),(ˆ         ˆ),(ˆ.ˆ),(ˆᄉˆ),(ˆ3ˆ). In other words, similar to languages, emoticons also have informal versions of similar patterns. Thus, we incorporated such common cases with regular expressions. PartFigure 2: Example of  ne-grained emoticon-emotion dic- tionary  Korean Letters ᄏ , ᄒᅲ , ᅮ ᄃᄃ ᄇᄃᄇᄃMeaning Laughing with Happiness Crying with Sadness Shaking with Fear Trembling with Anger      Table 4: List of Korean letters closely related to emotionsof the dictionary of emoticons and symbols is shown in Figure 2.Korean Emotion Letters Language-speci c feature are important in performing emotion analysis for a speci c language. Koreans use certain Korean let- ters to show emotions, so we took certain letters into account that are listed in Table 4. ‘ᄏ’ and ‘ᄒ’ are often used to indicate laughter, while ‘ᅲ’ and ‘ᅮ’ indicate crying. Also, sequences of letters, such as ’ᄃᄃ’ and ’ᄇᄃᄇᄃ’, are often used to express fear and anger, respectively. We counted and normalized the number of such emotion letters and added them as a language-speci c feature.Exclamations of Surprise According to Merriam- Webster dictionary, the de nition of an exclamation is “a sharp or sudden cry, a word, phrase, or sound that expresses a strong emotion9”. We assumed that exclamations are often used in tweets expressing surprise, such as 맙소사 “oh no”, 앗 “oh dear”, and 우와 “wow”. We searched various websites and col- lected examples to make a list of exclamations of surprise. As a result, we constructed a list of 45 surprise exclamation words. We then counted the number of occurrences of such words in tweets and added them as a feature.Swear Words We observed that swear words are of- ten used in angry tweets; therefore, we assumed that there occurrence is a strong clue to identify tweets expressing anger. We constructed our own list of Korean swear words by combining numerous related9 http://www.merriam-webster.com/dictionary/exclamation  
resources and websites. As a result, a list of 227 Korean swear words was built. For each tweet, we counted the number of occurrences of swear words and added them as a feature.Consequently, we designed a feature vector based on the conventional features as well as the features we presented above. To sum up, we considered the following features for classi cation:1. Emotion lexicons (weighted TwF)2. Emotion lexicons (thesaurus+translation) 3. Punctuation (? ! !? . , ∼)4. Fine-grained emoticons and symbols5. Korean emotion letters6. Exclamations of surprise7. Swear words5.2 Machine Learning Based Classi cationBefore constructing a machine learning classi er, we applied the synthetic minority oversampling technique (SMOTE) (Chawla et al., 2002) to the training set, a well-known oversampling method, which is known to be more effective than the plain oversampling method with replication. We pre- ferred an oversampling method to an undersam- pling method since our dataset is highly imbalanced, and undersampling removes too many instances. SMOTE generates synthetic instances of the minor- ity class by choosing a random point for each line segment between randomly selected neighbors from k nearest minority neighbors. As a result of apply- ing SMOTE to our training set, we could make a balanced dataset, which is favored for most machine learning algorithms. We compared several machine learning algorithms for classi cation, including sup- port vector machine (SVM), multinomial logistic re- gression, random forest, J48, naive Bayes, and ze- roR.6 Experimental Results and AnalysisWe performed experiments using WEKA10 to eval- uate 1) our weighted tweet frequency method and 2) the performance of machine learning based classi - cation using the feature vector we engineered. Dataset For training and testing the machine learn- ing algorithms, we used 899 Twitter messages from our KTEA dataset, which contains tweets for which10 http://www.cs.waikato.ac.nz/ml/weka/three annotators all agreed on the emotion type, ex- cluding neutral. We performed 5-cross validation. Performance Measure We used precision, recall and F-measure to evaluate the classi cation perfor- mance for each emotion type. Also, the weighted average of each measure was computed to determine the overall performance of unbalanced test dataset. Weighted Tweet Frequency We investigated the performance of our lexicon building method, weighted tweet Frequency, and compared it with the performance of the thesaurus- and translation-based methods. We found that the lexicons based on the thesaurus- and translation-based approaches suffer from low coverage due to the lack of reliable words produced by the Korean resources and translator. Therefore, we combined the lexicon lists produced by the thesaurus- and translation-based approaches to make a larger emotion lexicon list. In other words, we compared our approach (weighted TwF) against the combined approach (thesaurus+translation). The precision, recall, and F-measure of using SVM is shown in Figure 3. The F-measure of our approach is higher than that of the thesaurus+translation ap- proach. The precision of the thesaurus+translation approach is relatively high due to the manual re- moval of erroneous words from the lists. How- ever, its recall is very low because it does not con- tain Twitter-speci c words. Furthermore, our ap- proach, used together with the thesaurus+translation approach, achieves the best performance.Machine Learning Based Classi cation First, we investigated the most appropriate machine learning algorithm for classi cation. We tested various ma- chine learning algorithms: SVM, multinomial logis- tic regression, random forest, J48, naive Bayes, and zeroR. Figure 4 shows the results. SVM produced the best precision, recall, and F-measure compared to the others.We conducted another experiment to evaluate how well the features we proposed improved the performance of SVM. As shown in Figure 5, the best performance was observed when all the fea- tures were combined and the overall F-measure was about 70%. Emotion lexicon and punctuation fea- tures achieved an F-measure of about 64%. Adding the exclamation of surprise feature improved the classi cation of the surprise emotion by a 12% F- measure. Further adding Korean emotion letters 
 Figure 3: Precision, recall, and F-measure of using our weighted TwF, thesaurus+translation, and the two approaches combined. The best accuracy was observed when all the approaches were used.  Figure 4: Precision, recall, and F-measure achieved by using different machine learning algorithms. SVM gen- erated the best performance.helped to classify sadness, increasing the classi - cation score from 67% to 72.1%, while the value for fear increased from 76.3% to 79.5%. Moreover, combining emoticon and symbol feature particularly improved the classi cation for happiness increased from 73% to 76.3%. Lastly, we added the swear word feature. As expected, it increased the classi-  cation of anger from 54.4% to 56.5%. Overall, we found that our  ne-grained features helped the anal- ysis of  ne-grained emotions, and we believe that improving the feature resources will further improve the overall performance.7 ConclusionWe proposed a machine learning based classi ca- tion method that sorts Korean Twitter messages intoFigure 5: Precision, recall, and F-measure using com- bined set of features. Using all features achieved the best performance which is about 70% F-measuresix emotion types using carefully designed features. Emotion analysis research in under-resourced coun- tries can bene t from our emotion lexicon building method as we automatically construct lexicons with- out any help from other resources and tools. In ad- dition, we suggested several  ne-grained features to improve classi cation performance. We believe that our research, the KTEA dataset, and resources rep- resent a signi cant step forward in Korean Twitter emotion analysis studies, which have been rarely ad- dressed before.AcknowledgmentThis work was supported by the National Research Foundation of Korea(NRF) grant funded by the Ko- rea government(MSIP) (No. 2010-0028631).
ReferencesR. C. Balabantaray, Mudasir Mohammad, and Nibha Sharma. 2012. Multi-class twitter emotion classi - cation: A new approach. International Journal of Ap- plied Information Systems, 4(1):48–53.E. Y. Bann and J. J. Bryson. 2012. The conceptualisation of emotion qualia: Semantic clustering of emotional tweets. In Proceedings of the 13th Neural Computa- tion and Psychology Workshop. World Scienti c.Johan Bollen, Huina Mao, and Xiaojun Zeng. 2011. Twitter mood predicts the stock market. Journal of Computational Science, 2(1):1–8.Erik Cambria and Amir Hussain. 2012. Sentic Comput- ing: Techniques, Tools, and Applications, volume 2. Springer Science & Business Media.Nitesh V. Chawla, Kevin W. Bowyer, Lawrence O. Hall, and W. Philip Kegelmeyer. 2002. Smote: synthetic minority over-sampling technique. Journal of Arti - cial Intelligence Research, 16:321–357.Young Hwan Cho and Kong Joo Lee. 2006. Auto- matic affect recognition using natural language pro- cessing techniques and manually built affect lexi- con. IEICE Transactions on Information and Systems, 89(12):2964–2971.Nicholas A. Diakopoulos and David A. Shamma. 2010. Characterizing debate performance via aggregated twitter sentiment. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pages 1195–1198. ACM.Son Doan, Bao-Khanh Ho Vo, and Nigel Collier. 2012. An analysis of twitter messages in the 2011 tohoku earthquake. In Electronic Healthcare, volume 91, pages 58–66. Springer.Paul Ekman. 1992. An argument for basic emotions. Cognition & Emotion, 6(3-4):169–200.Alec Go, Richa Bhayani, and Lei Huang. 2009. Twit- ter sentiment classi cation using distant supervision. CS224N Project Report, Stanford, 1:12.Jeongin Kim, Dongjin Choi, Myunggwon Hwang, and Pankoo Kim. 2014. Analysis on smartphone related twitter reviews by using opinion mining techniques. In Advanced Approaches to Intelligent Information and Database Systems, pages 205–212. Springer.Cheolseong Lee, Donghee Choi, Seongsoon Kim, and Jaewoo Kang. 2013. Classi cation and analysis of emotion in korean microblog texts. Journal of Ko- rean Institute of Information Scientists and Engineers: Databases, 40(3):159–167.Hugo Liu and Push Singh. 2004. Conceptnet — a prac- tical commonsense reasoning tool-kit. Journal of BT Technology, 22(4):211–226.Saif M. Mohammad and Peter D. Turney. 2013. Crowd- sourcing a word–emotion association lexicon. Com- putational Intelligence, 29(3):436–465.Saeedeh Momtazi. 2012. Fine-grained german senti- ment analysis on social media. In Proceedings of the 8th International Conference on Language Resources and Evaluation. European Language Resources Asso- ciation (ELRA).Brendan O’Connor, Ramnath Balasubramanyan, Bryan R Routledge, and Noah A Smith. 2010. From tweets to polls: Linking text sentiment to public opinion time series. Proceedings of the International Conference on Web and Social Media, 11(122-129):1–2.James W. Pennebaker, Martha E. Francis, and Roger J. Booth. 2001. Linguistic inquiry and word count: Liwc 2001. Mahway: Lawrence Erlbaum Associates, 71:2001.Robert Remus, Uwe Quasthoff, and Gerhard Heyer. 2010. Sentiws - a publicly available german-language resource for sentiment analysis. In Proceedings of the 7th International Conference on Language Resources and Evaluation. European Language Resources Asso- ciation (ELRA).June Woong Rhee, Hyun Joo Song, Eun Kyung Na, and Hyun Suk Kim. 2008. Classi cation of emotion terms in korean. Korean Journal of Journalism and Commu- nication Studies, 52(1):85–116.Kirk Roberts, Michael A. Roach, Joseph Johnson, Josh Guthrie, and Sanda M. Harabagiu. 2012. Empatweet: Annotating and detecting emotions on twitter. In Pro- ceedings of the 8th International Conference on Lan- guage Resources and Evaluation. European Language Resources Association (ELRA).Carlo Strapparava and Alessandro Valitutti. 2004. Word- net affect: an affective extension of wordnet. In Pro- ceedings of the 4th International Conference on Lan- guage Resources and Evaluation, volume 4, pages 1083–1086.Alfan F. Wicaksono, Clara Vania, Distiawan T. Bayu, and Mirna Adriani. Automatically building a corpus for sentiment analysis on indonesian tweets. 28th Paci c Asia Conference on Language, Information and Com- puting.