Finding the Origin of a Translated Historical DocumentAbstractGospels are one type of translated histori- cal document. There are many versions of the same Gospel that have been translated from the original, or from another Gospel that has already been translated into a dif- ferent language. Nowadays, it is difficult to determine the language of the original Gospel from where these Gospels were translated. In this paper we use a super- vised machine learning technique to deter- mine the origin of a version of the Geor- gian Gospel.1 IntroductionTranslation is a process of rewriting an original text in a different language (Lefevere, 2002). It is one of the oldest text manipulation related pro- cesses. Gospels are historical documents that were translated centuries ago. There are many ver- sions of the same Gospel, translated from the orig- inal, or from another Gospel that had already been translated into a different language. Nowadays, it is unclear what was the language of the original Gospel from where these were translated. Histori- ans and linguists are uncertain as to the origin of such historical documents. The Georgian Gospels are translated from Armenian or Greek Gospels (Lang, 1957). There are about 300 manuscripts of the four Gospels in Georgian that are translated from different languages (Kharanauli, 2000). Lin- guists are able to narrow down potential origins by looking at different linguistic properties, but skep- tical to choose a single origin. We have three such Gospels in Georgian, Armenian and Greek, where linguists believe that Armenian or Greek are the potential origin. In this paper we use a supervised machine learning technique to find out the correct origin of a version of the Georgian Gospel.One of the challenges of dealing with historical data is the requirement of specific knowledge ofNatia DundiaDepartment of Modern Languages Goethe University Frankfurt, Germany dunduanatia@gmail.comlanguages that are not spoken at present day. If the language is currently spoken, it is likely that many properties have changed due to language evolu- tion. Due to this issue, the available historical data set is very small in size, which proves a challenge for machine learning algorithms.From the early stage of translation studies research, translation scholars proposed different kinds of properties of source text and translated text. Recently, scholars in this area identified sev- eral properties of the translation process with the aid of corpora (Baker, 1993; Baker, 1996; Olohan, 2001; Laviosa, 2002; Hansen, 2003; Pym, 2005; Toury, 1995). These properties are subsumed un- der four keywords: explicitation, simplification, normalization, levelling out and interference.In this paper, we use texts from modern lan- guage to train a Support Vector Machine (SVM) that can be used to identify the original source of the Georgian Gospel.The paper is organized as follows: Section 2 in- troduced the historical documents that we are deal- ing with here, Section 3 discusses related work, followed by a discussion of the nature of a trans- lated text in Section 4. The methodology is de- scribed in Section 5. The corpus of modern lan- guages is described briefly in Section 6 followed by a discussion of different features we used in this paper in Section 7. The experiment and evaluation in Section 8 and finally, we present conclusions in Section 9.2 The historical documentsGospels are among the very first documents that were translated into Georgian language follow- ing the invention of the Georgian alphabet (Lang, 1957). The history begins with the palimpsest manuscripts from the fifth or sixth centuries and ends with the manuscripts from the eighteenth century. There are many open debates on the ta- ble about the origin of the Georgian translation of
 LanguageSentences Average Sentence LengthAverage Word Length4.71% 4.00% 4.24%menian version (Lang, 1957). The Gospels that were translated in the late ninth century show signs of revision by reference to the Greek Gospels.Corpus-based translation studies is a recent field of research with a growing interest within the field of computational linguistics. Baroni and Bernar- dini (2006) started corpus-based translation stud- ies empirically, where they work on a corpus of geo-political journal articles. A SVM was used to distinguish original and translated Italian text us- ing n-gram based features. According to their re- sults, word bigrams play an important role in the classification task.Van Halteren (2008) uses the Europarl corpus for the first time to identify the source language of text for which the source language marker was missing. In their experiments, the support vector regression was the best performing method.Pastor et al. (2008) and Ilisei et al. (2009; 2010) perform classification of Spanish original and translated text. The focus of their works is to investigate the simplification relation that was pro- posed by (Baker, 1996). In total, 21 quantitative features (e.g. a number of different POS, Average Sentence Length (ASL), the parse-tree depth etc.) were used where, nine (9) of them are able to grasp the simplification translation property.Koppel and Ordan (2011) have built a clas- sifier that can identify the correct source of the translated text (given different possible source lan- guages). They have built another classifier, which can identify source text and translated text. How- ever, the limitation of this study is that they only used a corpus of English original text and English text translated from various European languages. A list of 300 function words (Pennebaker et al., 2001) was used as feature vector for these classifi- cations.Popescu (2011) uses string kernels (Lodhi et al., 2002) to study translation properties. A clas- sifier was built to classify English original texts and English translated texts from French and Ger- man books that were written in the nineteenth cen- tury. The p-spectrum normalized kernel was used for the experiment. The system performs poorly when the source language of the training corpus is different from the one of the test corpus.Islam and Hoenen (2013) used a source and translated texts of six European languages in order to classify translated texts according to source lan- Georgian Armenian Greek3738 18.96% 3738 19.15% 3738 20.40% Table 1: Historical corpus statisticsthe holy script. According to Blake (1932), many translations were made from the Gospels of Syrian and Armenian.However, recent studies show two more sources from where the holy scripture were translated into Georgian. The first one is the Palestinian and other one is the Antiochian/Constantinopolian (Kharanauli, 2000).The precise date of these translations are un- known, but the earliest translations of the Geor- gian Bible are presented in the lower script of palimpsests, the so-called Xanmeti fragments. Xanmeti is a term already used by the famous Georgian monk, religious writer and translator George the Athonite1. He denotes the text where the x-prefix is employed to mark the second sub- ject and the third object persons in the Georgian verb. This prefix has not occurred in the inscrip- tions since the seventh Century. Based on philo- logical data, these fragments are dated from fifth to seventh centuries. Codicological study of the folio size reveals that they are fragments of quite large codices, and it can be assumed that these codices included several books of the Bible.Currently, there are about 300 manuscripts of the four Gospels in Georgian (Kharanauli, 2000). Among these, about 40 codices include text ver- sion of Georgian Gospels. The Gospel considered for this study is believed to be translated from Ar- menian or Greek. These Gospels are digitized and aligned manually. The aligned corpus of the Geor- gian Gospel manuscripts present the texts in their original form side by side, which means that a) nothing is corrected, not even the mistakes pre- sumably made by copyists; and b) abbreviations remain discernible as they are, with the abbrevi- ated letters being indicated in brackets. Table 1 shows the statistics of the Gospels.3 Related workThere is no work found that is exactly relevant to the problem we are dealing here. Lang (1957) studied Georgian Gospels and their origins. The first Georgian Gospels were translated from an Ar- 1Wikipage: http://en.wikipedia.org/wiki/George the Athonite guages. As features, they have used the hundred  
most frequent words. It is important to consider the properties of language family when dealing with source and translated texts (Islam and Hoe- nen, 2013).Features used by Koppel and Ordan (2011) and Islam and Hoenen (2013) are language dependent. As we use texts from twenty-one European lan- guages to build the training model, we only use features that are language and linguistic tools inde- pendent. It is also important to consider different properties of translated and source texts proposed by translation scholars.4 Translation propertiesRecently, translation scholars proposed different translation properties using monolingual or com- parable corpus. These properties are described in the following subsections.4.1 ExplicitationTranslators are biased to make translations more explicit in order to resolve ambiguities that might be inherited in the translated text. Vinay and Dar- belnet (1958) used the term explicitation as “ a process of introducing information into the tar- get language which is present only implicitly in the source language, but which can be derived from the context or situation”(Vinay and Darbel- net, 1995; Pym, 2005). However, Blum-Kulka (1986) first claimed explicitation as a translation universal where she studied translated French texts from English by professional and non-professional translators. Seguinot (1988) provides an empiri- cal study using two translated texts from French to English. There is a greater level of explicit- ness in the translated texts as linking words and conversion of subordinate clauses into coordinate clauses.4.2 SimplificationThe simplification translation property shows the tendency of a translator to simplify a text in or- der to improve the readability of a translated text. Blum-Kulka and Levenston (1978) mention the term simplification as part of the lexical simplifica- tion using a small data set of English and Hebrew translations. According to them, translators use techniques such as avoidance and approximation in the translation process to make a translated text simpler for the target readers. Later, Baker (1996) also observed this tendency in the translated texts.To make a translated text simpler, the transla- tor often breaks up complex sentences into two or more sentences. This tendency can be found in the ASL. That is, the ASL in a translated text will be shorter than a source text.4.3 NormalizationThe normalization property shows a translator’s effort to meet the normative criteria of the target language. It is a translator’s tendency to conform to patterns and practices that are typical of the tar- get language, even to exaggerate their use. This property can be observed in a translated text that contains very little trace of the source language. However, the opposite scenario can be seen as well, where the translation is influenced by the source language. In that case normalization will be weakened. The influence of English can be visible in many software manuals that are trans- lated from English. Hansen (2003) stated that this contrary tendency also can be seen in interpreting, where the interpreter tries to finish an unfinished sentence and to render an ungrammatical structure into something grammatical.4.4 Levelling outBaker (1996) refers to levelling out as “the ten- dency of translated text to gravitate towards the center of a continuum”. That is also known as convergence (Laviosa, 2002), where she stated that a “relatively higher level of homogeneity of translated texts with regard to their own scores on given measures of universal features” such as lexical density or sentence length, in contrast to source texts. If we have a sub-corpus of translated texts from different languages to the same lan- guage, and have source texts in the same language, then translated texts from different languages will be similar in terms of lexical density, TTR, and ASL; but will be different than the source texts. More specifically, translated texts from different languages will be alike but will be different than the source texts.4.5 InterferenceToury (1995) has a different theory that is different from the translation properties described above. He stated that “in translation, phenomena pertain- ing to the make-up of the source text tend to be transferred to the target text,” That is, some in- terference effects will be observable in translated
texts that are carried from source texts. These ef- fects will be in the form of negative transfer or in the form of positive transfer. As an example, spe- cific properties of the English language are visible in user manuals that have been translated to other languages from English (for instance, word order) (Lzwaini, 2003). We can summarize this transla- tion properties in a way that a translated text from different source languages will be sufficiently dif- ferent from each other.5 MethodologyThe above section describes the properties of translation. Based on these properties, a translated text is different than the corresponding source text. Properties proposed by translation scholars, focus on texts and the translation process. Our assump- tion is that even though historical texts were trans- lated many hundreds of years ago, there are some properties that are common to modern texts and the recent translation process.We model the task as a classification task where we use a SVM implementation to find the correct origin of the Georgian Gospel. Linguists believe that the Georgian Gospel is a translated document. They narrowed down potential origins by looking at different linguistic properties compared to the Greek and Armenian Gospel. Before finding the source of the Georgian Gospel, it is necessary to check that the Gospel itself is a translated docu- ment. If the gospel is classified as a translated doc- ument then we can move further to find the source. The gospel that has properties of an original doc- ument will be the closest candidate for the origin Georgian gospel.In order to build a training model, we use mod- ern texts from different European languages. We have compiled a suitable corpus for this task from the Europarl corpus (Koehn, 2005). This task re- quires features that are language independent and do not require any linguistic pre-processing. So, we have explored different features that are quan- titative indicators of translation properties men- tioned above. Finally, we have collected a list of useful features that are listed in Section 7. We use standard classification accuracy and F-Score in order to measure usefulness of a feature. At the beginning the feature list contains only ASL. We have added a new feature in the list if and only if the classification accuracy and F-Score improve by adding the feature with existing feature set. Thefeature collection process will be continued until the classifier achieves a reasonable accuracy F- Score. Figure 1 shows the approach we follow in this paper. Finally, the whole corpus of mod- ern texts will be considered for building the final training model.The final training model and the collected fea- ture set will be used in order to find the origin of the Georgian Gospel. We prepare the Gospels data into two sets similarly as the training data. The first set of data will contain texts from Armenian and Georgian Gospels and the other one will con- tain texts from Greek and Georgian Gospels.6 Corpus of modern textsThe area of translation studies lack corpora by which scholars can validate their theoretical claims, for example, regarding the scope of char- acteristics of the translation properties. This scope is obviously affected by the membership of the source and target languages to language families. Though the exploration of universally valid char- acteristics of translations is an important topic, there are not many resources for testing corre- sponding hypotheses.There are many parallel and multilingual cor- pora available nowadays. Most of them are not useful for translation studies immediately as they require customization. Islam and Mehler (2012) provide a customized resource in which the lan- guages of all source texts and their translations are annotated sufficiently. The resource they pro- vide is a customized version of the well-known Europarl corpus (Koehn, 2005). A central feature of this corpus is that it provides information on sentence-related alignments that can be explored for finding characteristics of the translation rela- tion.The language annotation in the Europarl corpus is not reliable because of erroneous annotations introduced by translators. There are many cases where one speaker has multiple speeches in differ- ent languages that cause problems for identifying the speaker’s native language.In order to resolve this issue we have collected the name of the member of the European parlia- ment and their native language manually. We col- lected names from the current members list page 2 of the European parliament. Names of for- mer members are collected from the correspond-2 http://www.europarl.europa.eu/meps/en/full-list.html 
        Europarl training dataEuroparl test datafeature vector representationFeature listGospelsSVMEvaluationif accuracy improvesTraning modelSource language name                  Figure 1: Machine learning approaching Wikipedia pages. The official language of the country of each member is assigned as the native language of a speaker. Members from Belgium and Luxembourg are not considered as we are not sure about the language spoken by members from these countries in the European parliament. Each member from Finland is assigned to the Finnish language. Finally, the list contains 2, 125 mem- ber names and their native language. This list is used to extract source and translated texts from the Europarl corpus. The corpus contains 2, 646, 765 parallel sentences from 412 language pairs of 21 European languages. We believe that such a cor- pus is an ideal resource for the problem we are addressing in this paper.7 FeaturesAs the training corpus contains texts from twenty- one European languages, we only experiment with lexical and information-theoretic features. Pastor et al. (2008) used various lexical, syntactic and discourse related features. Also, Ilisei et al. (2009; 2010) used similar type of features. The following sub sections describe features that are finally se- lected for the feature list.7.1 Lexical featuresDifferent lexical features are being used from the beginning of corpus based translation studies. These features are popular for other NLP applica- tions such as text readability classification. The reason behind the popularity is that these are lan- guage independent and do not require any linguis- tic pre-processing.to find the source of the Georgian GospelThe ASL is a quantitative measure of syntac- tic complexity. Generally, the syntax of a longer sentence is more complex than that of a shorter sentence. A translator tries to make a translation explicit and also simple. Translated texts might become longer due to the explicitation. How- ever, opposite can happen when a translator tries to make a translation simpler. Table 2 shows be- havior of some features in source and translated texts of four European languages. Translations of German, French and Dutch are more explicit than Spanish. The Average Word Length (AWL) is an- other useful lexical feature. Most of the cases, the AWL in translated texts is longer than source texts. It would be interesting to see the behavior of AWL in source and translated texts of an agglutinative language.The Average number of complex words feature is related to the AWL. A translated text will be difficult for readers if it contains more complex words. The average length of English written words is 5.5 (Na ́das, 1984) letters. We define a complex word as any word that contains 10 or more letters.The Type Token Ratio (TTR), which indicates the lexical density of text, has been considered as useful features by Pastor et al. (2008) and Also, Ilisei et al. (2009; 2010). Low lexical densities involve a great deal of repetition with the same words occurring again and again. Conversely, high lexical density shows the diverseness of a text. A diverse text is supposed to be difficult for read- ers, generally children (Temnikova, 2012). There are many different version of TTR formulas avail-
   ASL AWL  Source Translation Source Translation26.07 29.34 33.86 34.46 35.99 32.56 25.43 31.135.52 5.644.65 4.684.66 4.744.88 5.08EntropySource Translation German       9.95 9.58 French       9.43 9.12 Spanish       9.08 9.02Dutch       9.30 8.99Table 2: Observation of different features   able. Carrol (1964) proposed a variation of TTRin order to reduce the sample size effect. Anotherversion of TTR is called Bilogarithmic TTR (Her-dan, 1964). Kohler and Galle (1993) also defined aversion TTR (see: 1) that consider position of thetext. In the Equation 1 x refers to position in thetext, tx = number of types up to position x, T =number of types in the text and N refers to thenumber of tokes in the whole text. We also usedanother version of TTR that focuses on documentlevel TTR T as well as sentence level TTR t (Is- Nnlam and Mehler, 2013; Islam, 2014; Islam et al., 2014). Lower TTR in sentence level also shows the repetition of the text.7.2.1 Entropy based featuresThe most efficient way to send information through a noisy channel is at a constant rate (Gen- zel and Charniak, 2002; Genzel and Charniak, 2003; ?). This rule must be retained in any kind of communication to make it efficient. Any text as a medium of communication should satisfy this principle. Genzel and Charniak (2002; 2003) show that the entropy rate is constant in texts. That is, for example, each sentence of a text conveys roughly the same amount of information. In or- der to utilize this information-theoretic notion, we start from random variables and consider their en- tropy as indicators of readability.Shannon (1948) introduced entropy as a mea- sure of information. Entropy, the amount of infor- mation in a random variable, can be thought of as the average length of the message needed to have an outcome on that variable. The entropy of a ran- dom variable X is defined asnH(X) = −   p(xi) log p(xi) (6)i=1  • Ko ̈hler–Gale methodTTRx= Ntx+T−xT N(1)(2)(3)(4)(5)  • Root TTR• Corrected TTRT√ • Bilogarithmic TTR√  N T   • TTR deviation2N log Tlog N  n T ti The more the outcome of X converges towards a uniform distribution, the higher H (X ). Our hy- pothesis is that the higher the entropy, the less readable the text along the feature represented by X. Table 2 shows that translated texts have lower entropy than source texts. This is because trans- lators try to improve the readability of translated texts. In our experiment, we consider the follow- ing random variables: word probability, charac- ter probability, word length probability and word frequency probability (or frequency spectrum, re- spectively). Note that there is a correlation be- tween the probability distribution of words and the corresponding distribution of word frequen- cies. As we use SVM for classification, these cor- relations are taken into consideration.7.3 Information Transmission-based FeaturesThere is a relation among text difficulty, sentence length, and word length. The usefulness of similarN−n7.2 Information-theoretic features  i=0iInformation theory measures the statistical signifi- cance of how documents vary with different types of probability distributions. That is, it determines how much information can be encoded from a doc- ument using a certain type of probability distribu- tion. The use of information as a statistical mea- sure of significance is an extension of this pro- cess. Information theory allows us to use condi- tional probabilities. It should be noted that these features are being used for the first time on this kind of problem.
lexical features such as sentence length or number of difficult words in a sentence is shown in section 7.1. Generally, a longer sentence contains more entities that influence the difficulty level. Similar things happen with longer words. But, a sentence becomes more difficult if it is longer and contains more long words. These kinds of properties can be defined by joint and conditional probabilities.In the field of information theory, joint proba- bility measures the likelihood of two events oc- curring together. That is, two random variables X and Y will be defined in the probability space. The conditional probability gives the probability that the event will occur given the knowledge that another event has already occurred. By consider- ing the joint probability and two random variables X and Y , Shannon’s joint entropy can be defined as:8.1 Experiment with modern corpusThe training corpus contains 2,646,765 parallel sentences from 412 language pairs of 21 Euro- pean languages. We have divided the corpus into 26, 467 chunks. More specifically, 26, 467 chunks were source texts and the same number of chunks were translations. It should be noted that a hun- dred sets of data were randomly generated where 80% of the corpus is used for training and the re- maining 20% is used for evaluation. Later, when we get reasonable classification accuracy and F- Score, the whole corpus will be used to build the final training model. The weighted average of Ac- curacy and F-score is computed by considering all sets of data. Note that we have used the SMO (Platt, 1998; Keerthi et al., 2001) classifier model in WEKA (Hall et al., 2009) together with the Pearson VII function-based universal kernel PUK (U ̈stu ̈netal.,2006).As we showed in Figure 1, our goal was to build a model using texts from modern European lan- guages and later use that model to identify the source of the Georgian Gospel. The challenge was to find features that are language independent and improve the classification accuracy. A feature will be in the feature list if and only if the classification accuracy improves by adding the feature. Many different features were considered, but only use- ful features are listed in Table 3 and described in Section 7. Additionally, either measure Accuracy andF-scorehastobeaboveaverage. Individu- ally all features perform reasonably well. How- ever, information-theoretic features perform bet- ter than lexical features. Table 3 shows evalua- tion of selected features. Surprisingly word fre- quency entropy is the best performing individual feature. Altogether these features achieve 86.62% of F-Score.8.2 Experiment with target corpusIn order to experiment with the target corpus, we prepare them similarly to the training chunks. Each Gospel was divided into 37 chunks. Each chunk contains 100 verses. Then, these data are divided into two sets. The first set contains chunks from Armenian and Georgian. The other contains chunks from Greek and Georgian.As we stated earlier, the first task is to iden- tify chunks of the Georgian Gospel are transla- tions. Table 4 shows the confusion matrix of the first set. In this matrix 36 out of 37 chunks ofH(X,Y) = −   <x,y>∈XxYp(xi,yi)logp(xi,yi) (7)Two conditional entropies can be defined as:H (X |Y ) = −   P (yi )   p(xi |yi ) log p(xi |yi ) y∈Y x∈X(8)H(Y|X)=− P(xi) p(yi|xi)logp(yi|xi) x∈X y∈Y(9) From the equation 6, 7, 8 and 9, it can be shownthat:Ts(X,Y)=H(X)+H(Y)−H(X,Y) (10)The function is called Information transmis- sion, and it measures the strength of the relation- ship between elements of random variables X and Y . Details about this notion can be found in (Klir, 2005). The sentence length and word length prob- ability shows the relation between sentence length and word length and sentence length and difficult word probability shows the relation between sen- tence length and the number of difficult words.8 ExperimentThe experiments and evaluations are explained in the following subsections.
 Feature AccuracyF-Score ASLTTR per documentTTR per sentenceAverage complex word per documentAverage complex word per sentenceAWLKo ̈hler–Gale TTRRoot TTRCorrected TTRBi-logarithmic TTRTTR deviationWord entropyWord frequency entropyWord length entropyCharacter entropyCharacter frequency entropyInformation transmission of sentence length and word length probability Information transmission of sentence length and complex word probability All features54.01% 59.83% 58.93% 52.61% 52.52% 56.15% 59.58% 62.67% 62.61% 62.23% 60.54% 62.02% 63.36% 53.81% 57.78% 57.93% 52.93% 54.41% 86.63%53.29% 59.18% 57.42% 45.74% 45.83% 49.43% 58.89% 62.67% 62.61% 62.08% 60.00% 61.92% 63.39% 50.94% 56.58% 57.28% 50.26% 53.86% 86.62%  Table 3: Evaluation of lexical features in source and translation identification  Armenian GeorgianSource Translation0 37 1 369 ConclusionIt is important to identify a document as origi- nal or translated from another language. Such a tool is very useful for many NLP applications. Different linguistic features are being explored in recent days for many different NLP applica- tions. However, only simple lexical and classi- cal information-theoretic features are adequate to build a classifier which is able to identify an origi- nal or a translated document. It will be challenging to explore linguistic features for such applications that deal with multilingual data.There are many versions of the Georgian Gospels that are translated from different lan- guages. Linguists are able to narrow down poten- tial origins by looking at different linguistic prop- erties, but skeptical to decide the single origin. We have three such Gospels in Georgian, Armenian and Greek, where linguists believe that Armenian or Greek are the potential origin. For this paper, we have built a source and translation classifier using modern texts. The classifier is able to iden- tify translated documents that have been translated hundreds of years ago. Based on our experimental evaluation, the Greek Gospel is the source of the version of the Georgian Gospel.10 AcknowledgmentsWe would like to thank Prof. Dr. Alexander Mehler, Prof. Dr. David Scheffer and Armin Hoe- nen. We also like to thank the anonymous re- viewers for their helpful comments. This work was performed when both authors were part of the LOEWE Digital-Humanities project at Goethe- University Frankfurt. Travel was funded by MassineScheffer & Company GmbH. Table 4: Confusion matrix of Armenian–Georgian Gospels  Greek GeorgianSource Translation20 17 1 36 Table 5: Confusion matrix of Greek–Georgian Gospelsthe Georgian Gospel identified as translated text. So, experimental results show that the Georgian Gospel is a translated document. Table 5 shows the same result. All of the Armenian chunks are identified as translated documents. However, 20 out of 37 chunks of the Greek Gospel are identi- fied as source. Therefore, these two confusion ma- trices show that Greek is most likely the source of the Georgian Gospel. It becomes clearer when we have a look on Table 6. Here Armenian and Greek chunks are labeled as source and Georgian chunks are labeled as translation. The accuracy and F- Score of the Armenian–Georgian pair is below the baseline 50%. But the accuracy and F-Score of the Greek–Georgian pair is above 75%. So, our experimental results suggest that the Greek Gospel is the source of the version of Georgian Gospel. Source-translationArmenian–Georgian Greek–GeorgianAccuracy F-Score48.64% 32.73% 75.67% 74.48%  Table 6: Classification results of Gospels
ReferencesMona Baker. 1993. Corpus linguistics and translation studies - implications and applications. In Mona Baker, Gill Francis, and Elena Tognini-Bonelli, ed- itors, Text and Technology. In Honour of John Sin- clair, pages 233–354. John Benjamins.Mona Baker. 1996. Corpus-based translation studies: The challenges that lie ahead. In LSP and Trans- lation: Studies in Language Engineering in Hon- our of Juan C. Sager, pages 175–186. Amsterdam & Philadelphia: John Benjamins.Marco Baroni and Silvia Bernardini. 2006. A new ap- proach to the study of translationese: Machinelearn- ing the difference between original and translated text. Literary and Linguistic Computing, 21(3):259– 274.Robert Pierpont Blake. 1932. Khanmeti palimpsest fragments of the Old Georgian version of Jeremiah. Cambridge Univ Press.Shoshana Blum and Eddie A Levenston. 1978. Uni- versals of lexical simplification. Language learning, 28(2):399–415.Shoshana Blum-Kulka. 1986. Shifts of cohesion and coherence in translation. Interlingual and intercul- tural communication: Discourse and cognition in translation and second language acquisition studies, pages 17–35.John Bissell Carroll. 1964. Language and thought. Prentice-Hall Englewood Cliffs, NJ.Dimitry Genzel and Eugene Charniak. 2002. Entropy rate constancy in text. In Proceedings of the 40st Meeting of the Association for Computational Lin- guistics (ACL 2002).Dimitry Genzel and Eugene Charniak. 2003. Variation of entropy and parse trees of sentences as a function of the sentence number. In Proceedings of the Con- ference on Empirical Methods in Natural Language Processing (EMNLP).Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The WEKA data mining software: an update. ACM SIGKDD Explorations, 11(1):10–18.Silvia Hansen. 2003. The Nature of Translated Text: An Interdisciplinary Methodology for the Investiga- tion of the Specific Properties of Translations. Ph.D. thesis, University of Saarland.Gustav Herdan. 1964. Quantitative linguistics. But- terworths.Iustina Ilisei, Diana Inkpen, Gloria Corpas Pastor, and Ruslan Mitkov. 2009. Towards simplification: A supervised learning approach. In Proceedings of Machine Translation 25 Years On, London, United Kingdom, November 21-22.Iustina Ilisei, Diana Inkpen, Gloria Corpas Pastor, and Ruslan Mitkov, 2010. Identification of transla- tionese: A machine learning approach, pages 503– 511. Springer.Zahurul Islam and Armin Hoenen. 2013. Source and translation classification using most frequent words. In 6th International Joint Conference on Natural Language Processing (IJCNLP).Zahurul Islam and Alexander Mehler.tomization of the europarl corpus for translation studies. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC).Zahurul Islam and Alexander Mehler.tomatic readability classification of crowd-sourced data based on linguistic and information-theoretic features. In 14th International Conference on Intel- ligent Text Processing and Computational Linguis- tics.Md. Zahurul Islam, Md. Rashedur Rahman, and Alexander Mehler. 2014. Readability classification of bangla texts. In 15th International Conference on Intelligent Text Processing and Computational Lin- guistics (cicLing), Kathmandu, Nepal.Zahurul Islam. 2014. Multilingual text classification using information theoretic features. PhD Thesis, Goethe University Frankfurt.S.S. Keerthi, S. K. Shevade, C. Bhattacharyya, and K. R. K. Murthy. 2001. Improvements to Platt’s SMO algorithm for SVM classifier design. Neural Computation, 13(3):637–649.Anna Kharanauli, 2000. Einfhrung in die georgische Psalterbersetzung, pages 248–308. Vandenhoeck & Ruprecht.George Jiri Klir. 2005. Uncertainty and Information. Wiley-Interscience.Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In MT Summit.Reinhard Ko ̈hler and Matthias Galle. 1993. Dy- namic aspects of text characteristics. Quantitative text analysis, pages 46–53.Moshe Koppel and Noam Ordan. 2011. Translationese and its dialects. In 49th Annual Meeting of the As- sociation for Computational Linguistics (ACL).David Marshall Lang. 1957. Recent work on the geor- gian new testament. Bulletin of the School of Orien- tal and African Studies, 19(01):82–93.Sara Laviosa. 2002. Corpus-based translation stud- ies. Theory, findings, applications. Amsterdam/New York: Rodopi.Andre ́ Lefevere. 2002. Translation/history/culture: A sourcebook. Routledge.2012. Cus-2013. Au-
Huma Lodhi, Craig Saunders, John Shawe-Taylor, Nello Cristianini, and Chris Watkins. 2002. Text classification using string kernels. The Journal of Machine Learning Research, 2:419–444.Sattar Lzwaini. 2003. Building specialised corpora for translation studies. In Workshop on Multilin- gual Corpora: Linguistic Requirements and Tech- nical Perspectives, Corpus Linguistics.A. Na ́das. 1984. Estimation of probabilities in the lan- guage model of the ibm speech recognition system. IEEE Transactions on Acoustics, Speech and Signal Processing, 32(4):859–861.Maeve Olohan. 2001. Spelling out the optionals in translation:a corpus study. In Corpus Linguistics 2001 conference. UCREL Technical Paper number 13. Special issue.Gloria Corpas Pastor, Ruslan Mitkov, Naveed Afzal, and Viktor Pekar. 2008. Translation universals: do they exist? a corpus-based NLP study of con- vergence and simplification. In Proceedings of the Eighth Conference of the Association for Machine Translation in the Americas (AMTA-08).Jams W. Pennebaker, Martha E. Francis, and Roger J. Booth. 2001. Linguistic Inquiry and Word Count (LIWC): LIWC2001 Manual. Erlbaum Publishers.John C. Platt. 1998. Fast training of support vec- tor machines using sequential minimal optimization. MIT Press.Marius Popescu. 2011. Studying translationese at the character level. In Recent Advances in Natural Lan- guage Processing.Anthony Pym. 2005. Explaining explicitation. In New Trends in Translation Studies. In Honour of Kinga Klaudy, pages 29–34. Akadmia Kiad.Candace Se ́guinot. 1988. Pragmatics and the explic- itation hypothesis. TTR: traduction, terminologie, re ́daction, 1(2):106–113.Claude Elwood Shannon. 1948. A mathematical the- ory of communication. The Bell System Technical Journal, 27(1):379–423.Irina Temnikova. 2012. Text Complexity and Text Sim- plification in the Crisis Management Domain. Ph.D. thesis, University of Wolverhampton.Gideon Toury. 1995. Descriptive Translation Studies and Beyond. John Benjamins, Amster- dam/Philadelphia.B.U ̈stu ̈n,W.J.Melssen,andL.M.C.Buydens.2006. Facilitating the application of support vector regres- sion by using a universal Pearson VII function based kernel. Chemometrics and Intelligent Laboratory Systems, 81(1):29–40.Hans Van Halteren. 2008. Source language markers in europarl translations. In International Conference inComputational Linguistics(COLING), pages 937– 944.Jean-Paul Vinay and Jean Darbelnet. 1958. Stylistique compare ́e de langlais et du franc ̧ais.Jean-Paul Vinay and Jean Louis Darbelnet.1995.Comparative stylistics of French and English: a methodology for translation, volume 11. John Ben- jamins.