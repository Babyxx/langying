Dependency_NN Parsing_VBG for_IN Chinese_JJ Long_JJ Sentence_NN :_: A_DT Second-stage_JJ Main_NNP Structure_NNP Parsing_NNP Method_NNP Abstract_NNP This_DT paper_NN explores_VBZ the_DT problem_NN of_IN parsing_NN Chinese_JJ long_JJ sentences_NNS ._.
Inspired_VBN by_IN human_JJ sentence_NN processing_NN ,_, a_DT second-stage_JJ parsing_NN method_NN ,_, referred_VBD as_IN main_JJ structure_NN parsing_NN in_IN this_DT paper_NN ,_, are_VBP proposed_VBN to_TO improve_VB the_DT pars_NNS -_: ing_VBG performance_NN as_RB well_RB as_IN maintaining_VBG its_PRP$ high_JJ accuracy_NN and_CC efficiency_NN on_IN Chinese_JJ long_JJ sentences_NNS ._.
Three_CD different_JJ methods_NNS have_VBP at_IN -_: tempted_VBN in_IN this_DT paper_NN and_CC the_DT result_NN shows_VBZ that_IN the_DT best_JJS performance_NN comes_VBZ from_IN the_DT method_NN using_VBG Chinese_JJ comma_NN as_IN the_DT bounda_NN -_: ry_NN of_IN the_DT sub_NN -_: sentence_NN ._.
According_VBG to_TO our_PRP$ ex_FW -_: periment_NN about_IN testing_NN on_IN the_DT Chinese_NNP de_NNP -_: pendency_NN Treebank_NNP 1.0_CD data_NNS ,_, it_PRP improves_VBZ long_RB dependency_NN accuracy_NN by_IN around_IN 6.0_CD %_NN than_IN the_DT baseline_NN parser_NN and_CC 3.2_CD %_NN than_IN the_DT previ_NNS -_: ous_JJ best_JJS model_NN ._.
1_CD Introduction_NNP In_IN recent_JJ years_NNS ,_, the_DT transition-based_JJ dependency_NN parsing_NN has_VBZ been_VBN a_DT hot_JJ research_NN topic_NN in_IN Chinese_JJ parsing_NN because_IN of_IN suitable_JJ to_TO Chinese_JJ grammar_NN profile_NN and_CC its_PRP$ linear_JJ scale_NN time_NN complexity_NN ._.
-LRB-_-LRB- Zhou_NNP ,_, 2000_CD -RRB-_-RRB- -LRB-_-LRB- Nivre_NNP and_CC McDonald_NNP ,_, 2008_CD -RRB-_-RRB- ._.
However_RB ,_, although_IN transition-based_JJ dependency_NN parsing_NN research_NN has_VBZ made_VBN great_JJ progress_NN with_IN the_DT state-of-art_JJ performing_VBG at_IN around_IN 86_CD %_NN accu_NN -_: racy_JJ -LRB-_-LRB- Nivre_JJ et_FW al._FW ,_, 2011_CD -RRB-_-RRB- ,_, it_PRP still_RB faces_VBZ some_DT prob_SYM -_: lems_NNS when_WRB parsing_VBG Chinese_JJ long_JJ sentences_NNS ._.
First_RB ,_, the_DT parser_NN performance_NN decreases_VBZ when_WRB the_DT length_NN of_IN input_NN Chinese_JJ sentence_NN increases_NNS ._.
In_IN other_JJ words_NNS ,_, it_PRP can_MD not_RB parse_VB Chinese_JJ long_JJ sen_NN -_: tences_NNS as_IN accurate_JJ as_IN short_JJ ones_NNS ._.
As_IN a_DT result_NN ,_, if_IN there_EX are_VBP more_RBR long_JJ sentences_NNS in_IN the_DT input_NN sen_NN -_: tences_NNS ,_, the_DT overall_JJ accuracy_NN will_MD be_VB affected_VBN sig_NN -_: nificantly_RB ._.
The_DT experiments_NNS in_IN this_DT paper_NN on_IN sen_NN -_: tences_NNS of_IN different_JJ length_NN ranges_NNS show_VBP that_IN the_DT overall_JJ accuracy_NN will_MD decrease_VB more_JJR than_IN 1_CD %_NN when_WRB the_DT length_NN of_IN input_NN sentences_NNS is_VBZ more_JJR than_IN 50_CD ._.
This_DT phenomenon_NN is_VBZ not_RB only_RB present_JJ in_IN Chi_NNP -_: YunFei_NNP Long_NNP School_NNP of_IN Computer_NNP Science_NNP Nanjing_NNP Normal_NNP University_NNP No_NNP 1_CD ,_, Wen_NNP Yuan_NNP Road_NNP ,_, Nan_NNP -_: jing_NN ,_, China_NNP 893997052@qq.com_CD WeiGuang_NNP Qu_NNP School_NNP of_IN Computer_NNP Science_NNP Nanjing_NNP Normal_NNP University_NNP No_NNP 1_CD ,_, Wen_NNP Yuan_NNP Road_NNP ,_, Nanjing_NNP ,_, China_NNP wgqu_nj@163.com_CD nese_JJ long_JJ sentences_NNS ,_, but_CC also_RB found_VBN during_IN pars_NNS -_: ing_VBG research_NN of_IN other_JJ languages_NNS such_JJ as_IN English_NNP and_CC French_NNP -LRB-_-LRB- Candito_NNP et_NNP al_IN 2012_CD -RRB-_-RRB- ._.
The_DT second_JJ problem_NN is_VBZ that_DT long_JJ sentences_NNS al_SYM -_: ways_NNS contain_VBP global_JJ ambiguities_NNS ,_, and_CC the_DT inaccu_NN -_: racies_NNS on_IN long_JJ sentences_NNS can_MD lead_VB to_TO a_DT very_RB dif_SYM -_: ferent_JJ understanding_NN of_IN a_DT sentence_NN ._.
While_IN the_DT short_JJ sentences_NNS have_VBP more_JJR local_JJ ambiguity_NN and_CC inaccuracies_NNS on_IN short_JJ sentences_NNS normally_RB ,_, only_RB cause_VB misunderstanding_VBG on_IN details_NNS ._.
This_DT is_VBZ be_VB -_: cause_NN long_JJ sentences_NNS tend_VBP to_TO contain_VB more_JJR details_NNS about_IN semantic_JJ and_CC discourse_NN information_NN com_NN -_: pared_VBN with_IN short_JJ sentences_NNS ._.
Those_DT details_NNS confuse_VBP parsers_NNS and_CC prevent_VB them_PRP from_IN finding_VBG out_RP what_WP the_DT correct_JJ structure_NN of_IN the_DT long_JJ sentence_NN ._.
Although_IN the_DT reasons_NNS that_WDT should_MD be_VB responsi_SYM -_: ble_NN for_IN the_DT performance_NN decrease_NN in_IN parsing_VBG long_JJ sentences_NNS are_VBP still_RB controversial_JJ ,_, a_DT common_JJ ex_FW -_: planation_NN is_VBZ that_IN there_EX are_VBP some_DT rarely_RB seen_VBN fea_NN -_: tures_NNS in_IN long_JJ sentences_NNS causes_VBZ the_DT degraded_JJ per_IN -_: formance_NN -LRB-_-LRB- Candito_NNP et_FW al._FW ,_, 2012_CD -RRB-_-RRB- ._.
Unfortunately_RB ,_, these_DT features_NNS can_MD not_RB be_VB learnt_VBN by_IN transition-based_JJ parser_NN via_IN increasing_VBG the_DT scale_NN of_IN training_NN corpus_NN ,_, because_IN the_DT idea_NN of_IN the_DT transition-based_JJ dependency_NN parsing_NN methods_NNS is_VBZ to_TO process_VB a_DT sentence_NN incrementally_RB ,_, some_DT global_JJ information_NN from_IN those_DT input_NN sentences_NNS has_VBZ been_VBN neglected_VBN during_IN the_DT process_NN ._.
Attempts_NNS to_TO include_VB that_DT global_JJ information_NN in_IN transition-based_JJ de_IN -_: pendency_NN parsing_NN have_VBP been_VBN made_VBN in_IN past_JJ years_NNS -LRB-_-LRB- Nivre_NNP and_CC McDonald_NNP ,_, 2008_CD ;_: Nivre_NNP et_FW al._FW ,_, 2011_CD -RRB-_-RRB- ,_, but_CC those_DT methods_NNS always_RB have_VBP to_TO make_VB a_DT tradeoff_NN between_IN accuracy_NN and_CC efficiency_NN ._.
What_WP this_DT paper_NN tries_VBZ to_TO propose_VB is_VBZ a_DT parsing_NN method_NN that_WDT achieves_VBZ better_JJR performance_NN when_WRB parsing_VBG Chinese_JJ long_JJ sentences_NNS and_CC freezes_VBZ the_DT O_NNP -LRB-_-LRB- -RRB-_-RRB- time_NN complexity_NN simultaneously_RB ._.
The_DT fact_NN that_IN humans_NNS can_MD understand_VB a_DT long_JJ sentence_NN correctly_RB even_RB when_WRB some_DT words_NNS are_VBP unknown_JJ is_VBZ quite_RB inspiring_JJ ._.
It_PRP implies_VBZ that_IN not_RB all_DT words_NNS are_VBP equally_RB important_JJ in_IN terms_NNS of_IN under_IN -_: standing_VBG a_DT sentence_NN ._.
Some_DT words_NNS carry_VBP more_JJR syn_NN -_: tactic_NN and_CC semantic_JJ information_NN than_IN others_NNS dur_SYM -_: ing_NN people_NNS sentence_NN understanding_NN ._.
Errors_NNS in_IN rec_NN -_: ognizing_VBG those_DT words_NNS may_MD lead_VB to_TO understanding_VBG problems_NNS ._.
This_DT is_VBZ also_RB true_JJ for_IN dependency_NN parsers_NNS ._.
The_DT reason_NN why_WRB it_PRP can_MD not_RB parse_VB long_JJ sentence_NN accu_NN -_: rately_NN is_VBZ it_PRP does_VBZ not_RB distinguish_VB those_DT words_NNS from_IN all_DT words_NNS in_IN a_DT long_JJ sentence_NN ._.
In_IN short_JJ sentence_NN case_NN ,_, those_DT words_NNS are_VBP always_RB can_MD be_VB found_VBN be_VB -_: cause_VB the_DT pattern_NN between_IN those_DT words_NNS is_VBZ limited_VBN ,_, which_WDT means_VBZ a_DT large_JJ training_NN corpus_NN can_MD almost_RB cover_VB all_PDT the_DT patterns_NNS between_IN words_NNS ,_, but_CC that_DT does_VBZ not_RB work_VB well_RB in_IN long_JJ sentences_NNS ._.
On_IN one_CD hand_NN ,_, as_IN the_DT input_NN sentence_NN gets_VBZ longer_RB ,_, the_DT pos_NNS -_: sible_JJ combinations_NNS between_IN words_NNS will_MD outnum_VB -_: ber_NN the_DT patterns_NNS can_MD be_VB found_VBN in_IN the_DT training_NN cor_NN -_: pus_NN ._.
On_IN the_DT other_JJ hand_NN ,_, there_EX will_MD be_VB sentence_NN -_: level_NN instead_RB of_IN only_RB word-level_JJ combination_NN in_IN a_DT long_JJ sentence_NN ,_, which_WDT is_VBZ beyond_IN the_DT transition_NN -_: based_VBN parsing_NN mode_NN ._.
Therefore_RB ,_, this_DT paper_NN proposes_VBZ a_DT two-stage_JJ parsing_NN method_NN to_TO help_VB parsers_NNS find_VB out_RP those_DT important_JJ words_NNS in_IN sentences_NNS and_CC use_VB the_DT infor_NN -_: mation_NN to_TO improve_VB parsing_NN performance_NN with_IN out_RB at_IN the_DT expense_NN of_IN time_NN complexity_NN ._.
2_CD Related_JJ Work_NN Dominating_VBG dependency-parsing_JJ models_NNS can_MD be_VB categorized_VBN into_IN three_CD families_NNS :_: graph-based_JJ models_NNS -LRB-_-LRB- Eisner_NNP ,_, 1996_CD ;_: McDonald_NNP et_FW al._FW ,_, 2005_CD ;_: Mc-Donald_NNP and_CC Pereira_NNP ,_, 2006_CD ;_: Wang_NNP et_FW al._FW ,_, 2007_CD ;_: Zhang_NNP and_CC Clark_NNP ,_, 2008_CD -RRB-_-RRB- ,_, transition-based_JJ models_NNS -LRB-_-LRB- Yamada_NNP and_CC Matsumoto_NNP ,_, 2003_CD ;_: Nivre_NNP and_CC Scholz_NNP ,_, 2004_CD -RRB-_-RRB- and_CC hybrid_JJ models_NNS -LRB-_-LRB- Sagae_NNP and_CC Lavie_NNP ,_, 2006_CD ;_: Nivre_NNP and_CC McDonald_NNP ,_, 2008_CD ;_: Zhang_NNP and_CC Clark_NNP ,_, 2008_CD -RRB-_-RRB- ._.
The_DT advantage_NN of_IN the_DT graph-based_JJ parsing_NN is_VBZ that_IN it_PRP processes_VBZ the_DT input_NN sentence_NN as_IN a_DT whole_NN ._.
In_IN other_JJ words_NNS ,_, it_PRP takes_VBZ global_JJ information_NN of_IN the_DT input_NN sentence_NN into_IN consideration_NN ,_, which_WDT gives_VBZ it_PRP a_DT higher_JJR accuracy_NN on_IN average_NN than_IN other_JJ models_NNS -LRB-_-LRB- Nivre_NNP ,_, 2007_CD -RRB-_-RRB- However_RB ,_, because_IN of_IN adopting_VBG global_JJ information_NN ,_, the_DT efficiency_NN of_IN graph-based_JJ parsing_NN models_NNS are_VBP comparatively_RB lower_JJR -LRB-_-LRB- O_NNP -LRB-_-LRB- 2_LS -RRB-_-RRB- -RRB-_-RRB- as_IN the_DT searching_VBG space_NN is_VBZ much_RB larger_JJR ._.
By_IN contrast_NN ,_, transition-based_JJ model_NN ,_, which_WDT is_VBZ also_RB referred_VBN as_IN action-based_JJ parsing_NN model_NN ,_, sig_NN -_: nificantly_RB outperform_VBP in_IN efficiency_NN ._.
The_DT transi_NN -_: tion-based_JJ parsing_NN is_VBZ essentially_RB a_DT discriminative_JJ algorithm_NN which_WDT processes_VBZ words_NNS incrementally_RB ._.
According_VBG to_TO -LRB-_-LRB- Nivre_NNP and_CC McDonald_NNP ,_, 2008_CD -RRB-_-RRB- ,_, tran_SYM -_: sition-based_JJ parsing_NN gives_VBZ time_NN complexity_NN as_RB low_JJ as_IN O_NNP -LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- projective_JJ situation_NN -RRB-_-RRB- ._.
In_IN Chinese_JJ dependency_NN parsing_NN research_NN ,_, tran_NN -_: sition-based_JJ parsing_NN is_VBZ a_DT preferable_JJ choice_NN be_VB -_: cause_VB it_PRP suits_NNS better_RBR with_IN the_DT syntax_NN of_IN Chinese_NNP -LRB-_-LRB- Lai_NNP and_CC Huang_NNP ,_, 1994_CD ;_: Lai_NNP et_FW al._FW ,_, 2001_CD ;_: Wang_NNP ,_, William_NNP Yang_NNP ,_, et_FW al._FW ,_, 2014_CD -RRB-_-RRB- ._.
Compared_VBN with_IN English_NNP dependency_NN parsing_NN ,_, Chinese_JJ dependen_NN -_: cy_NN parsing_NN is_VBZ slightly_RB underperformed_VBN ._.
That_DT is_VBZ partially_RB because_IN there_EX are_VBP a_DT few_JJ widely_RB used_VBN Chinese_JJ dependency_NN corpus_NN ._.
The_DT Penn_NNP Chinese_NNP TreeBank_NNP -LRB-_-LRB- CTB_NNP -RRB-_-RRB- is_VBZ a_DT promising_JJ choice_NN ._.
However_RB ,_, it_PRP is_VBZ still_RB not_RB complete_VB enough_RB compared_VBN with_IN that_DT in_IN English_NNP ._.
For_IN performance_NN evaluation_NN ,_, Nivre_NNP -LRB-_-LRB- 2011_CD -RRB-_-RRB- provide_VBP a_DT widely_RB accepted_VBN comparison_NN result_NN ,_, according_VBG to_TO this_DT paper_NN ,_, the_DT state-of-art_JJ performance_NN of_IN Chinese_JJ dependency_NN parsing_NN is_VBZ around_IN 86.0_CD %_NN in_IN unlabeled_JJ attachment_NN scores_NNS -LRB-_-LRB- UAS_NNP -RRB-_-RRB- ._.
Some_DT recent_JJ research_NN on_IN improving_VBG the_DT Chi_NNP -_: nese_NN parsing_NN performance_NN by_IN introducing_VBG multi_NNS -_: ple_NN layer_NN parsing_VBG approach_NN -LRB-_-LRB- Ping_NNP Jian_NNP ,_, et_FW al._FW ,_, 2009_CD -RRB-_-RRB- has_VBZ been_VBN made_VBN ,_, but_CC it_PRP does_VBZ not_RB consider_VB Chinese_JJ features_NNS ._.
Zhenghua_NNP et_NNP al_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- proposed_VBD the_DT idea_NN of_IN using_VBG punctuation_NN to_TO help_VB improving_VBG parsing_NN ,_, which_WDT also_RB been_VBN discussed_VBN in_IN this_DT paper_NN ._.
Howev_NNP -_: er_NN ,_, the_DT major_JJ difference_NN is_VBZ that_IN punctuation_NN is_VBZ just_RB one_CD perspective_NN of_IN the_DT framework_NN proposed_VBN in_IN this_DT paper_NN ._.
In_IN addition_NN ,_, this_DT paper_NN achieves_VBZ a_DT bet_NN -_: ter_NN performance_NN compared_VBN with_IN previous_JJ works_NNS ._.
3_CD 3.1_CD A_DT New_NNP Framework_NNP Framework_NNP Design_NNP and_CC Parsing_NNP Process_NNP As_IN previous_JJ discussion_NN ,_, the_DT key_NN to_TO parse_VB long_JJ sentences_NNS accurately_RB is_VBZ to_TO find_VB out_RP the_DT words_NNS that_WDT carry_VBP structural_JJ information_NN about_IN the_DT sentence_NN ,_, which_WDT named_VBD as_IN the_DT main_JJ structure_NN words_NNS in_IN this_DT paper_NN ._.
However_RB ,_, the_DT challenge_NN is_VBZ that_IN normal_JJ transition-based_JJ parsing_NN methods_NNS can_MD not_RB find_VB out_RP those_DT main_JJ structure_NN words_NNS because_IN of_IN lack_NN of_IN global_JJ information_NN ._.
In_IN this_DT circumstance_NN ,_, we_PRP se_FW -_: lect_VB the_DT output_NN of_IN a_DT transition-based_JJ parsing_NN method_NN ,_, which_WDT contains_VBZ candidate_NN features_NNS for_IN main_JJ structure_NN word_NN recognition_NN ,_, after_IN main_JJ structure_NN word_NN recognition_NN ,_, a_DT second_JJ transition_NN -_: based_VBN parser_NN ,_, which_WDT trained_VBN in_IN a_DT special_JJ corpus_NN ,_, introduced_VBN to_TO adjust_VB the_DT dependencies_NNS between_IN those_DT main_JJ structure_NN words_NNS ._.
This_DT second-stage_JJ parsing_NN method_NN referred_VBD as_IN main_JJ structure_NN pars_NNS -_: ing_NN ._.
The_DT purpose_NN of_IN the_DT first_JJ parsing_NN stage_NN is_VBZ to_TO find_VB out_RP main_JJ structure_NN words_NNS ._.
In_IN the_DT first_JJ parsing_NN stage_NN ,_, the_DT baseline_NN parser_NN parses_VBZ the_DT input_NN sen_NN -_: tence_NN in_IN the_DT normal_JJ way_NN ._.
From_IN the_DT output_NN of_IN baseline_NN parser_NN ,_, the_DT information_NN for_IN finding_VBG out_RP main_JJ structure_NN words_NNS extracted_VBN by_IN following_VBG cer_NN -_: tain_NN steps_NNS in_IN the_DT framework_NN ,_, and_CC then_RB the_DT infor_NN -_: mation_NN is_VBZ pass_VB into_IN the_DT next_JJ parsing_NN stage_NN ._.
The_DT information_NN obtained_VBN from_IN baseline_NN parser_NN is_VBZ :_: Short_JJ Dependencies_NNS :_: The_DT short_JJ dependencies_NNS are_VBP normally_RB from_IN words_NNS that_WDT occur_VBP in_IN the_DT same_JJ sub-sentence_NN -LRB-_-LRB- sub-sentence_NN is_VBZ the_DT part_NN between_IN two_CD punctuations_NNS in_IN a_DT sentence_NN ;_: a_DT long_JJ sentence_NN normally_RB consists_VBZ of_IN multiple_JJ sub-sentences_NNS -RRB-_-RRB- ._.
The_DT structure_NN of_IN these_DT dependencies_NNS tends_VBZ to_TO be_VB less_RBR complicated_JJ ,_, and_CC traditional_JJ transition-based_JJ parser_NN can_MD achieve_VB over_IN 90_CD %_NN accuracy_NN on_IN these_DT dependencies_NNS ._.
As_IN the_DT accuracy_NN for_IN these_DT short_JJ dependencies_NNS is_VBZ high_JJ ,_, they_PRP are_VBP assumed_VBN as_IN correct_JJ dependencies_NNS within_IN the_DT sub-sentence_NN ._.
Therefore_RB ,_, in_IN the_DT next_JJ stage_NN ,_, the_DT main_JJ structure_NN parser_NN can_MD only_RB focus_VB on_IN these_DT long_JJ dependencies_NNS ,_, which_WDT is_VBZ the_DT key_JJ idea_NN of_IN the_DT framework_NN ._.
Long_NNP Dependencies_NNPS :_: The_DT long_JJ dependencies_NNS normally_RB occur_VBP between_IN words_NNS from_IN different_JJ sub-sentences_NNS ._.
The_DT words_NNS that_WDT carry_VBP long_JJ de_IN -_: pendencies_NNS are_VBP potential_JJ main_JJ structure_NN words_NNS ;_: normally_RB they_PRP determine_VBP the_DT global_JJ structure_NN of_IN the_DT whole_JJ sentence_NN ._.
However_RB ,_, as_IN the_DT dependen_NN -_: cies_NNS between_IN main_JJ structure_NN words_NNS are_VBP much_RB longer_JJR than_IN normal_JJ dependencies_NNS ,_, traditional_JJ transition-based_JJ parsers_NNS are_VBP inaccurate_JJ on_IN them_PRP ._.
Given_VBN this_DT ,_, this_DT paper_NN uses_VBZ a_DT specially_RB trained_VBN parser_NN to_TO re-parse_VB the_DT long_JJ dependencies_NNS regard_NN -_: less_JJR of_IN the_DT short_JJ dependencies_NNS ._.
The_DT result_NN can_MD be_VB merged_VBN with_IN short_JJ dependencies_NNS from_IN first_JJ stage_NN parsing_VBG through_IN a_DT voting_NN scheme_NN ._.
Other_JJ Information_NN :_: Including_VBG the_DT length_NN of_IN the_DT input_NN sentence_NN ,_, the_DT number_NN of_IN sub-sentences_NNS ,_, etc._FW ._.
The_DT challenge_NN after_IN obtaining_VBG the_DT three_CD kinds_NNS of_IN information_NN is_VBZ how_WRB to_TO distinguish_VB actual_JJ main_JJ structure_NN words_NNS from_IN these_DT potential_JJ ones_NNS ._.
Three_CD different_JJ methods_NNS are_VBP proposed_VBN and_CC discussed_VBN in_IN the_DT paper_NN in_IN Chapter_NN 3.2_CD ._.
The_DT goal_NN of_IN the_DT second_JJ parsing_NN stage_NN is_VBZ to_TO find_VB out_RP correct_JJ dependencies_NNS between_IN the_DT main_JJ struc_NN -_: ture_NN words_NNS ._.
From_IN previous_JJ discussion_NN ,_, the_DT reason_NN why_WRB a_DT transition-based_JJ parser_NN can_MD not_RB parse_VB main_JJ structure_NN words_NNS correctly_RB in_IN long_JJ sentence_NN is_VBZ that_IN syntactically_RB redundant_JJ detail_NN brings_VBZ significant_JJ ambiguity_NN ._.
Therefore_RB ,_, in_IN this_DT stage_NN ,_, those_DT details_NNS are_VBP ignored_VBN temporarily_RB and_CC only_RB main_JJ structure_NN words_NNS are_VBP processed_VBN ._.
Obviously_RB ,_, a_DT parser_NN trained_VBN in_IN normal_JJ corpus_NN is_VBZ not_RB able_JJ to_TO parse_VB main_JJ struc_NN -_: ture_NN words_NNS directly_RB ._.
The_DT parser_NN used_VBN in_IN the_DT sec_NN -_: ond_NN stage_NN will_MD be_VB trained_VBN in_IN a_DT special_JJ corpus_NN that_WDT only_RB contains_VBZ main_JJ structure_NN words_NNS ._.
As_IN there_EX is_VBZ no_DT available_JJ corpus_NN like_IN this_DT ,_, this_DT paper_NN adopts_VBZ a_DT special_JJ training_NN corpus_NN produced_VBN by_IN the_DT automat_NN -_: ic_FW main_JJ structure_NN words_NNS extraction_NN method_NN intro_NN -_: duced_VBN in_IN Chapter_NN 3.2_CD ._.
Figure_NN 1_CD :_: Framework_NN of_IN parser_NN 3.2_CD Automatic_NNP Main_NNP Structure_NNP Words_NNPS Ex_SYM -_: traction_NN Although_IN main_JJ structure_NN words_NNS are_VBP necessary_JJ for_IN sentences_NNS ,_, it_PRP is_VBZ not_RB easy_JJ to_TO extract_VB those_DT words_NNS automatically_RB ._.
The_DT differences_NNS between_IN main_JJ structure_NN words_NNS and_CC non-main-structure_JJ words_NNS provide_VBP features_NNS to_TO distinguish_VB them_PRP ._.
Since_IN it_PRP takes_VBZ at_IN least_JJS two_CD components_NNS ,_, namely_RB head_NN and_CC its_PRP$ dependency_NN ,_, to_TO form_VB a_DT dependency_NN unit_NN in_IN a_DT sentence_NN ,_, the_DT parsing_NN method_NN also_RB tries_VBZ to_TO find_VB features_NNS of_IN the_DT main_JJ structure_NN words_NNS from_IN the_DT two_CD perspectives_NNS ._.
From_IN the_DT head_NN perspective_NN ,_, the_DT main_JJ structure_NN words_NNS are_VBP normally_RB the_DT center_NN constituent_NN of_IN its_PRP$ sub-sentence_NN ._.
The_DT dependency_NN relation_NN between_IN words_NNS could_MD be_VB regarded_VBN as_IN a_DT voting_NN action_NN ._.
The_DT more_JJR votes_NNS a_DT word_NN receives_VBZ from_IN its_PRP$ neighbor_NN words_NNS ,_, the_DT more_RBR important_JJ the_DT word_NN is_VBZ ._.
Given_VBN the_DT main_JJ structure_NN words_NNS are_VBP usually_RB the_DT most_RBS im_SYM -_: portant_NN -LRB-_-LRB- important_JJ to_TO the_DT sentence_NN structure_NN -RRB-_-RRB- words_NNS ,_, they_PRP tend_VBP to_TO receive_VB more_JJR votes_NNS from_IN oth_NN -_: er_JJR words_NNS in_IN its_PRP$ sub-sentence_NN ._.
Figure_NN 2_CD -LRB-_-LRB- a_DT -RRB-_-RRB- shows_VBZ the_DT process_NN ,_, the_DT word_NN `_`` Chengwei_NNP '_'' -LRB-_-LRB- Becoming_NNP -RRB-_-RRB- and_CC `_`` Touzi_NNP '_'' -LRB-_-LRB- Investment_NNP -RRB-_-RRB- which_WDT have_VBP more_RBR in_IN -_: coming_VBG dependencies_NNS ,_, are_VBP selected_VBN as_IN main_JJ struc_NN -_: ture_NN words_NNS from_IN an_DT example_NN sentence_NN -LRB-_-LRB- Figure_NN 2_CD -LRB-_-LRB- a_DT -RRB-_-RRB- -RRB-_-RRB- ._.
Figure_NN 2_CD -LRB-_-LRB- a_DT -RRB-_-RRB- :_: An_DT example_NN sentence_NN Figure_NN 2_CD -LRB-_-LRB- b_NN -RRB-_-RRB- :_: word_NN `_`` ChengWei_NNP '_'' and_CC `_`` TouZi_NNP '_'' have_VBP more_JJR votes_NNS From_IN the_DT dependency_NN perspective_NN ,_, the_DT main_JJ structure_NN words_NNS are_VBP those_DT words_NNS with_IN long_JJ dis_SYM -_: tance_NN dependency_NN ._.
As_IN main_JJ structure_NN words_NNS are_VBP distributed_VBN among_IN sub-sentences_NNS ,_, the_DT dependen_NN -_: cies_NNS between_IN main_JJ structure_NN words_NNS are_VBP supposed_VBN to_TO cross_VB sub-sentences_NNS instead_RB of_IN being_VBG within_IN a_DT sub-sentence_NN ._.
As_IN previous_JJ discussion_NN ,_, three_CD selection_NN criteria_NNS that_WDT are_VBP significant_JJ in_IN selecting_VBG main_JJ structure_NN words_NNS are_VBP proposed_VBN :_: Crossing_VBG comma_NN ,_, the_DT num_NN -_: ber_NN of_IN incoming_JJ dependencies_NNS and_CC length_NN of_IN de_FW -_: pendency_NN ._.
Based_VBN on_IN the_DT selection_NN criteria_NNS ,_, the_DT following_VBG three_CD methods_NNS for_IN automatic_JJ main_JJ structure_NN selection_NN are_VBP attempted_VBN ._.
Method_NN 1_CD :_: Crossing_VBG comma_NN The_DT idea_NN of_IN this_DT method_NN is_VBZ to_TO check_VB whether_IN a_DT comma_NN lines_NNS between_IN the_DT dependency_NN head_NN and_CC its_PRP$ dependency_NN ._.
If_IN the_DT comma_NN exists_VBZ ,_, both_DT head_NN and_CC its_PRP$ dependency_NN have_VBP been_VBN identified_VBN as_IN main_JJ structure_NN words_NNS ._.
The_DT reason_NN is_VBZ that_IN Chinese_JJ comma_NN tends_VBZ to_TO represent_VB weak_JJ stop_NN between_IN sub-sentences_JJ com_NN -_: pared_VBN with_IN that_IN the_DT English_NNP comma_NN tends_VBZ to_TO rep_NN -_: resent_VBP weak_JJ stop_NN between_IN words_NNS or_CC terms_NNS ._.
In_IN oth_NN -_: er_JJR words_NNS ,_, the_DT sub-sentences_NNS separated_VBN by_IN com_NN -_: mas_FW are_VBP potential_JJ independent_JJ sentences_NNS ._.
They_PRP just_RB happen_VB to_TO be_VB connected_VBN by_IN commas_NNS because_IN of_IN the_DT expression_NN convention_NN in_IN Chinese_NNP ._.
Given_VBN this_DT ,_, dependency_NN that_WDT crosses_VBZ a_DT comma_NN is_VBZ of_IN high_JJ chance_NN to_TO be_VB between_IN words_NNS that_WDT control_VBP struc_SYM -_: ture_NN of_IN the_DT sentence_NN ._.
Otherwise_RB ,_, the_DT two_CD sub_SYM -_: sentences_NNS are_VBP disconnected_VBN syntactically_RB ._.
This_DT situation_NN is_VBZ very_RB common_JJ ,_, especially_RB in_IN Chinese_JJ long_JJ sentences_NNS ._.
The_DT process_NN of_IN the_DT extraction_NN is_VBZ as_IN follows_VBZ ._.
Step_NN 1_CD :_: For_IN each_DT word_NN In_IN a_DT sentence_NN S_NNP -LRB-_-LRB- 0_CD ,_, 1_CD ,_, 2_CD ..._: -RRB-_-RRB- ,_, find_VB out_RP all_PDT the_DT incoming_JJ de_IN -_: pendencies_NNS -LRB-_-LRB- dependency_NN starting_VBG at_IN word_NN and_CC ending_VBG at_IN word_NN ,_, i_FW =_SYM ̸_FW j_FW -RRB-_-RRB- ._.
Step_NN 2_CD :_: For_IN each_DT incoming_JJ dependency_NN ,_, check_NN if_IN there_EX is_VBZ a_DT word_NN -LRB-_-LRB- k_NN =_SYM ̸_FW i_FW ,_, j_VBN -RRB-_-RRB- equal_JJ to_TO the_DT character_NN comma_NN -LRB-_-LRB- ``_`` ,_, ''_'' -RRB-_-RRB- ._.
Step_NN 3_CD :_: If_IN there_EX such_PDT a_DT word_NN ,_, the_DT word_NN is_VBZ selected_VBN as_IN main_JJ structure_NN word_NN ._.
Figure_NN 3_CD shows_VBZ the_DT result_NN of_IN the_DT selecting_NN method_NN on_IN the_DT example_NN sentence_NN -LRB-_-LRB- Figure_NN 2_CD -LRB-_-LRB- a_DT -RRB-_-RRB- -RRB-_-RRB- ._.
Figure_NN 3_CD :_: An_DT example_NN of_IN Method_NN 1_CD Method_NN 2_CD :_: the_DT number_NN of_IN incoming_JJ dependen_NN -_: cies_NNS The_DT idea_NN behind_IN this_DT method_NN is_VBZ that_IN the_DT main_JJ structure_NN words_NNS are_VBP always_RB the_DT center_NN -LRB-_-LRB- root_NN -RRB-_-RRB- of_IN each_DT sub-sentences_NNS ,_, most_RBS other_JJ non-main_JJ struc_NN -_: ture_NN words_NNS act_VBP as_IN their_PRP$ modifier_NN ._.
Therefore_RB ,_, main_JJ structure_NN words_NNS tend_VBP to_TO have_VB the_DT most_RBS income_NN dependencies_NNS from_IN other_JJ words_NNS in_IN each_DT sub_NN -_: sentence_NN ._.
The_DT main_JJ structure_NN words_NNS can_MD be_VB found_VBN by_IN counting_VBG the_DT number_NN of_IN dependencies_NNS coming_VBG from_IN other_JJ words_NNS ._.
Given_VBN that_IN the_DT number_NN of_IN sentences_NNS varies_VBZ from_IN sentence_NN to_TO sentence_NN ,_, the_DT percentage_NN instead_RB of_IN numbers_NNS are_VBP used_VBN as_IN the_DT measurement_NN ._.
The_DT percentage_NN is_VBZ calculated_VBN within_IN each_DT sub_NN -_: sentence_NN rather_RB than_IN the_DT whole_JJ sentence_NN because_IN the_DT income_NN dependency_NN method_NN does_VBZ not_RB work_VB for_IN long_JJ distance_NN dependency_NN ._.
The_DT process_NN is_VBZ as_IN follows_VBZ ._.
Step_NN 1_CD :_: For_IN a_DT sentence_NN S_NNP -LRB-_-LRB- 0_CD ,_, 1_CD ,_, 2_CD ..._: -RRB-_-RRB- ,_, split_VBD it_PRP into_IN sub-sentences_NNS by_IN the_DT character_NN com_NN -_: ma_FW -LRB-_-LRB- ``_`` ,_, ''_'' -RRB-_-RRB- ._.
The_DT sub-sentences_NNS are_VBP :_: 1_CD -LRB-_-LRB- 0_CD ,_, 1_CD ,_, 2_CD ..._: −_SYM 1_LS -RRB-_-RRB- ,_, 2_CD -LRB-_-LRB- +1_CD ,_, +2_CD ,_, +3_CD ..._: −_SYM 1_LS -RRB-_-RRB- ..._: -LRB-_-LRB- −_SYM +1_CD ,_, −_CD +2_CD ,_, −_CD +3_CD ..._: -RRB-_-RRB- Step_NN 2_CD :_: For_IN each_DT sub-sentence_NN ,_, calculate_VBP the_DT number_NN of_IN words_NNS within_IN the_DT sub-sentence_NN ._.
Step_NN 3_CD :_: For_IN each_DT word_NN in_IN the_DT sub-sentence_NN ,_, calculate_VBP the_DT number_NN of_IN incoming_JJ depend_VBP -_: encies_NNS ._.
Figure_NN 4_CD :_: An_DT example_NN of_IN Method_NN 3_CD As_IN there_EX is_VBZ a_DT threshold_NN parameter_NN significantly_RB affecting_VBG the_DT performance_NN in_IN method_NN 2_CD and_CC meth_NN -_: od_NN 3_CD ,_, a_DT range_NN of_IN parameters_NNS examined_VBD over_IN the_DT whole_JJ testing_NN set_VBN to_TO find_VB out_RP the_DT one_CD with_IN the_DT best_JJS performance_NN ._.
Then_RB our_PRP$ experiment_NN was_VBD run_VBN over_RB different_JJ length_NN testing_NN set_VBN to_TO explore_VB the_DT best_JJS improvement_NN it_PRP brings_VBZ to_TO baseline_JJ performance_NN ,_, which_WDT will_MD ,_, demonstrated_VBD in_IN chapter_NN 4_CD ._.
3.3_CD Dependency_NNP Voting_NNP According_VBG to_TO previous_JJ discussion_NN ,_, the_DT first_JJ stage_NN parsing_NN achieves_VBZ high_JJ accuracy_NN -LRB-_-LRB- around_IN 90_CD %_NN -RRB-_-RRB- on_IN short_JJ dependencies_NNS and_CC low_JJ accuracy_NN -LRB-_-LRB- around_IN 30_CD %_NN -RRB-_-RRB- on_IN long_JJ dependencies_NNS ,_, while_IN the_DT second_JJ stage_NN parsing_NN has_VBZ significantly_RB better_JJR perfor_SYM -_: mance_NN -LRB-_-LRB- around_IN 40_CD %_NN ,_, will_MD discuss_VB it_PRP in_IN an_DT experi_NN -_: ment_NN -RRB-_-RRB- on_IN long_JJ distance_NN dependencies_NNS ._.
Some_DT words_NNS -LRB-_-LRB- mostly_RB main_JJ structure_NN words_NNS -RRB-_-RRB- may_MD have_VB two_CD parsing_JJ results_NNS ,_, one_CD from_IN first_JJ stage_NN parsing_NN ,_, and_CC the_DT other_JJ from_IN second_JJ stage_NN parsing_NN ._.
This_DT paper_NN uses_VBZ a_DT weighted_JJ voting_NN scheme_NN to_TO decide_VB what_WP the_DT final_JJ dependency_NN for_IN the_DT words_NNS is_VBZ ._.
The_DT weight_NN of_IN each_DT parser_NN comes_VBZ from_IN its_PRP$ accuracy_NN on_IN those_DT specific_JJ parts_NNS ._.
For_IN example_NN ,_, baseline_NN parser_NN achieves_VBZ around_IN 84_CD %_NN accuracy_NN in_IN short_JJ distance_NN dependency_NN ;_: when_WRB it_PRP predicates_VBZ a_DT short_JJ distance_NN dependency_NN ,_, there_EX are_VBP 84_CD %_NN possibility_NN that_IN the_DT dependency_NN is_VBZ right_RB ._.
Each_DT word_NN receives_VBZ two_CD predicates_NNS from_IN the_DT two_CD parsers_NNS ;_: if_IN the_DT two_CD predi_NNS -_: cates_NNS are_VBP the_DT same_JJ ,_, the_DT result_NN is_VBZ the_DT dependency_NN ._.
Otherwise_RB ,_, the_DT parser_NN with_IN higher_JJR accuracy_NN wins_NNS ._.
That_DT means_VBZ the_DT dependency_NN is_VBZ determined_VBN by_IN the_DT result_NN from_IN a_DT more_RBR reliable_JJ parser_NN ._.
In_IN this_DT case_NN ,_, the_DT two_CD parser_NN voting_NN can_MD be_VB simplified_VBN as_IN that_DT baseline_NN parser_NN controls_VBZ short_JJ distance_NN dependen_NN -_: cies_NNS parsing_VBG result_NN ,_, while_IN the_DT second_JJ stage_NN parser_NN controls_VBZ the_DT result_NN of_IN long_JJ distance_NN dependency_NN parsing_NN ._.
4_CD Result_NN Analysis_NNP 4.1_CD Corpus_NNP We_PRP train_VBP and_CC evaluate_VBP our_PRP$ parser_NN on_IN the_DT depend_VBP -_: ency_NN corpus_NN called_VBD Chinese_JJ dependency_NN Tree_NNP -_: bank_NN 1.0_CD from_IN Harbin_NNP Institute_NNP of_IN Technology_NNP Step_NN 4_CD :_: For_IN each_DT word_NN in_IN the_DT sub-sentence_NN ,_, calculate_VBP the_DT percentage_NN p_NN -LRB-_-LRB- -RRB-_-RRB- =_SYM ._.
Step_NN 5_CD :_: Compare_VB p_NN -LRB-_-LRB- -RRB-_-RRB- with_IN pre-fixed_JJ thresh_NN -_: old_JJ p_NN ,_, if_IN p_NN ≤_CD p_NN -LRB-_-LRB- -RRB-_-RRB- ,_, the_DT word_NN is_VBZ selected_VBN as_IN main_JJ structure_NN word_NN ._.
Method_NN 3_CD :_: Length_NNP of_IN dependency_NN This_DT method_NN uses_VBZ the_DT length_NN of_IN dependency_NN as_IN threshold_NN to_TO identify_VB main_JJ structure_NN words_NNS ;_: this_DT is_VBZ enlightened_VBN by_IN our_PRP$ observation_NN that_IN normally_RB non-main_JJ structure_NN words_NNS have_VBP short_JJ distance_NN dependency_NN because_IN their_PRP$ dependencies_NNS are_VBP with_IN -_: in_IN the_DT sub-sentence_NN ._.
Main_NNP structure_NN words_NNS have_VBP dependencies_NNS with_IN much_RB longer_JJR lengths_NNS ,_, so_RB those_DT words_NNS with_IN length_NN longer_RBR than_IN normal_JJ situation_NN are_VBP regarded_VBN as_IN main_JJ structure_NN words_NNS ._.
The_DT pro-_JJ cess_NN is_VBZ as_IN follows_VBZ ._.
Step_NN 1_CD :_: For_IN each_DT word_NN In_IN a_DT sentence_NN S_NNP -LRB-_-LRB- 0_CD ,_, 1_CD ,_, 2_CD ..._: −_SYM 1_LS -RRB-_-RRB- ,_, find_VB out_RP all_PDT the_DT incoming_JJ dependencies_NNS -LRB-_-LRB- dependency_NN starting_VBG at_IN word_NN and_CC ending_VBG at_IN word_NN ,_, i_FW =_SYM ̸_FW j_FW -RRB-_-RRB- ._.
Step_NN 2_CD :_: calculate_VB the_DT distance_NN between_IN i_FW and_CC j_SYM =|_SYM −_FW |_FW ._.
Step_NN 3_CD :_: Normalize_VB the_DT Distance_NNP by_IN div_SYM -_: ing_VBG the_DT whole_JJ length_NN of_IN sentence_NN S_NNP ,_, get_VB length_NN percentageP_NNP -LRB-_-LRB- -RRB-_-RRB- =_SYM -LRB-_-LRB- /_CD -RRB-_-RRB- ∗_SYM 100_CD %_NN ._.
Step_NN 4_CD :_: Compare_VB p_NN -LRB-_-LRB- -RRB-_-RRB- with_IN pre-fixed_JJ thresh_NN -_: old_JJ p_NN ,_, ifp_NN ≤_CD p_NN -LRB-_-LRB- -RRB-_-RRB- ,_, the_DT word_NN is_VBZ selected_VBN as_IN main_JJ structure_NN word_NN ._.
-LRB-_-LRB- HIT_VBN -RRB-_-RRB- ._.
This_DT corpus_NN is_VBZ available_JJ on_IN the_DT webpage_NN of_IN the_DT conference_NN of_IN natural_JJ language_NN processing_NN and_CC Chinese_JJ computing_NN -LRB-_-LRB- NLPCC_NNP -RRB-_-RRB- ._.
Corpus_NNP fol_SYM -_: lows_NNS the_DT CoNLL2007_NNP Standard_NNP ,_, contains_VBZ about_IN 8,301_CD sentences_NNS in_IN the_DT training_NN set_NN ,_, 534_CD sentences_NNS in_IN the_DT development_NN set_NN and_CC 1,233_CD sentences_NNS in_IN the_DT test_NN set_NN ._.
It_PRP has_VBZ a_DT much_RB longer_RBR average_JJ sentence_NN length_NN than_IN Penn_NNP Chinese_NNP Treebank_NNP -LRB-_-LRB- PCTB_NNP -RRB-_-RRB- -LRB-_-LRB- 33_CD compare_VBP to_TO 28_CD -LRB-_-LRB- Xue_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ._.
For_IN all_DT experi_FW -_: ments_NNS ,_, we_PRP use_VBP the_DT test_NN set_NN and_CC report_NN unlabeled_JJ attachment_NN scores_NNS -LRB-_-LRB- UAS_NNP -RRB-_-RRB- for_IN evaluation_NN ._.
4.2_CD Baseline_NNP Parser_NNP The_NNP baseline_NN parser_NN used_VBN in_IN this_DT paper_NN is_VBZ the_DT Malt_NNP parser_NN proposed_VBN by_IN -LRB-_-LRB- Nivre_NNP ,_, 2007_CD -RRB-_-RRB- ._.
Based_VBN on_IN the_DT previous_JJ analysis_NN ,_, the_DT state-of-art_JJ graph-based_JJ parser_NN is_VBZ slightly_RB outperformed_VBN than_IN transition_NN -_: based_VBN parser_NN while_IN at_IN the_DT expense_NN of_IN surging_VBG scale_NN of_IN efficiency_NN to_TO O_NNP -LRB-_-LRB- 2_LS -RRB-_-RRB- ._.
We_PRP aim_VBP to_TO improve_VB transition-based_JJ parser_NN in_IN order_NN to_TO maintain_VB O_NNP -LRB-_-LRB- -RRB-_-RRB- efficiency_NN while_IN improve_VB accuracy_NN as_RB much_RB as_IN possible_JJ ._.
In_IN other_JJ words_NNS ,_, there_EX are_VBP other_JJ ad_NN -_: vanced_VBN parsers_NNS giving_VBG better_JJR performance_NN than_IN Malt_NNP parser_NN in_IN terms_NNS of_IN accuracy_NN ,_, they_PRP are_VBP not_RB selected_VBN because_IN the_DT processing_NN speed_NN in_IN these_DT parsers_NNS is_VBZ sacrificed_VBN more_RBR or_CC less_RBR ._.
Compared_VBN with_IN short_JJ sentence_NN parsing_NN ,_, the_DT importance_NN of_IN parsing_VBG efficiency_NN -LRB-_-LRB- processing_NN speed_NN -RRB-_-RRB- in_IN long_JJ sentence_NN parsing_NN is_VBZ more_RBR significant_JJ ._.
From_IN this_DT perspective_NN ,_, the_DT Malt_NNP parser_NN ,_, providing_VBG O_NNP -LRB-_-LRB- -RRB-_-RRB- efficiency_NN with_IN a_DT little_JJ cost_NN of_IN accuracy_NN is_VBZ an_DT ideal_JJ choice_NN in_IN this_DT paper_NN ._.
4.3_CD Experiments_NNS Table_NNP 1_CD shows_VBZ the_DT test_NN results_NNS of_IN our_PRP$ parser_NN on_IN short_JJ dependencies_NNS ._.
We_PRP include_VBP in_IN the_DT table_NN re_SYM -_: sults_NNS from_IN the_DT pure_JJ transition-based_JJ parser_NN of_IN -LRB-_-LRB- Zhang_NNP and_CC Clark_NNP ,_, 2008_CD -RRB-_-RRB- ,_, the_DT dynamic_JJ -_: programming_NN arc-standard_JJ parser_NN of_IN -LRB-_-LRB- Huang_NNP and_CC Sagae_NNP ,_, 2010_CD -RRB-_-RRB- and_CC parsing_VBG with_IN rich_JJ non-local_JJ fea_NN -_: tures_NNS of_IN -LRB-_-LRB- Zhang_NNP and_CC Nirve_NNP ,_, 2011_CD -RRB-_-RRB- on_IN Chinese_NNP ._.
Our_PRP$ baseline_NN parser_NN and_CC its_PRP$ extended_JJ methods_NNS are_VBP very_RB close_RB to_TO its_PRP$ competing_VBG parsers_NNS in_IN terms_NNS of_IN the_DT performance_NN on_IN short_JJ dependencies_NNS ._.
Table_NNP 2_CD shows_VBZ the_DT results_NNS of_IN our_PRP$ parser_NN on_IN long_JJ dependencies_NNS -LRB-_-LRB- The_DT dependencies_NNS between_IN main_JJ structure_NN words_NNS -RRB-_-RRB- ._.
Normally_RB ,_, the_DT main_JJ structure_NN words_NNS located_VBN in_IN different_JJ sub-sentences_NNS of_IN a_DT long_JJ sentence_NN ._.
As_IN a_DT result_NN ,_, normal_JJ transition_NN -_: based_VBN parsers_NNS can_MD not_RB handle_VB them_PRP well_RB ,_, which_WDT is_VBZ the_DT reason_NN for_IN the_DT low_JJ scores_NNS overall_JJ ._.
Our_PRP$ scores_NNS for_IN this_DT test_NN set_VBN are_VBP the_DT best_JJS reported_VBN so_RB far_RB and_CC significantly_RB better_JJR than_IN the_DT previous_JJ systems_NNS ._.
In_IN all_DT our_PRP$ three_CD methods_NNS ,_, the_DT best_JJS result_NN is_VBZ from_IN the_DT method_NN 1_CD ,_, which_WDT improves_VBZ the_DT performance_NN on_IN long_JJ dependencies_NNS by_IN around_IN 6.2_CD %_NN from_IN baseline_JJ parser_NN ,_, while_IN outperformance_NN previous_JJ best_JJS sys_SYM -_: tem_NN by_IN 3.2_CD %_NN ._.
84.3_CD %_NN 84.2_CD %_NN 84.4_CD %_NN 84.3_CD %_NN 85.2_CD %_NN 86.0_CD %_NN Table_NNP 1_CD :_: Performance_NNP on_IN short_JJ dependencies_NNS 38.3_CD %_NN 36.6_CD %_NN 37.0_CD %_NN 33.3_CD %_NN 32.9_CD %_NN Table_NNP 2_CD :_: Performance_NNP on_IN long_JJ dependencies_NNS 4.4_CD Parameter_NNP Optimization_NNP In_IN the_DT three_CD methods_NNS ,_, the_DT performance_NN of_IN method_NN 2_CD and_CC method_NN 3_CD largely_RB affected_VBN by_IN threshold_NN pa_NN -_: rameters_NNS ,_, Table_NNP 3_CD shows_VBZ the_DT relationship_NN between_IN the_DT threshold_NN and_CC accuracy_NN ,_, the_DT best_JJS performance_NN of_IN method_NN 2_CD achieved_VBN when_WRB the_DT threshold_NN set_VBN to_TO be_VB 35_CD %_NN ._.
34.3_CD %_NN 36.1_CD %_NN 33.3_CD %_NN 30.7_CD %_NN 33.1_CD %_NN 26.4_CD %_NN Table_NNP 3_CD :_: Performance_NNP of_IN Method_NNP 2_CD with_IN Different_JJ Threshold_NNP The_DT method_NN 2_CD achieves_VBZ the_DT best_JJS performance_NN when_WRB there_EX are_VBP not_RB enough_JJ words_NNS chosen_VBN as_IN main_JJ structure_NN words_NNS ._.
For_IN example_NN ,_, the_DT 1.00_CD means_VBZ that_IN one_CD word_NN has_VBZ to_TO get_VB all_DT dependencies_NNS from_IN other_JJ words_NNS ,_, within_IN its_PRP$ sub-sentence_NN to_TO be_VB select_JJ -_: ed_VBN as_IN the_DT main_JJ structure_NN word_NN ,_, and_CC this_DT is_VBZ almost_RB impossible_JJ ._.
Lower_JJR the_DT threshold_NN also_RB deteriorates_VBZ Baseline_NNP Baseline_NNP +_NNP Method_NNP 1_CD Baseline_NNP +_NNP Method_NNP 2_CD Baseline_NNP +_NNP Method_NNP 3_CD UAS_NNP 84.6_CD %_NN Zhang_NNP and_CC Clark_NNP 2008_CD Huang_NNP and_CC Sagae_NNP 2010_CD Zhang_NNP ,_, Y._NNP ,_, &_CC Nivre_NNP 2011_CD UAS_NNP Baseline_NNP Baseline_NNP +_NNP Method_NNP 1_CD Baseline_NNP +_NNP Method_NNP 2_CD Baseline_NNP +_NNP Method_NNP 3_CD 32.1_CD %_NN Zhang_NNP and_CC Clark_NNP 2008_CD Huang_NNP and_CC Sagae_NNP 2010_CD Zhang_NNP ,_, Y_NNP ,_, &_CC Nivre_NNP 2011_CD 35.1_CD %_NN Threshold_NNP Accuracy_NNP Threshold_NNP Accuracy_NNP 1.00_CD 0.95_CD 0.90_CD 0.85_CD 0.80_CD 0.75_CD 0.70_CD 0.65_CD 0.60_CD 29.5_CD %_NN 0.50_CD 0.45_CD 0.40_CD 0.35_CD 0.30_CD 0.25_CD 0.20_CD 0.15_CD 0.10_CD 34.0_CD %_NN 29.6_CD %_NN 29.8_CD %_NN 29.8_CD %_NN 35.4_CD %_NN 30.0_CD %_NN 30.3_CD %_NN 35.3_CD %_NN 30.9_CD %_NN 31.8_CD %_NN 30.7_CD %_NN 32.0_CD %_NN 28.2_CD %_NN 0.55_CD 0.05_CD the_DT performance_NN because_IN that_DT means_VBZ more_RBR words_NNS are_VBP chosen_VBN as_IN main_JJ structure_NN words_NNS ._.
For_IN example_NN ,_, the_DT 0.00_CD means_VBZ all_DT words_NNS are_VBP main_JJ structure_NN words_NNS ,_, and_CC they_PRP are_VBP all_DT parsed_VBN by_IN stage_NN 2_CD parsers_NNS which_WDT training_NN in_IN a_DT main_JJ structure_NN corpus_NN ._.
32.6_CD %_NN 32.4_CD %_NN 32.3_CD %_NN 32.2_CD %_NN 32.1_CD %_NN 33.3_CD %_NN 32.0_CD %_NN Table_NNP 4_CD :_: Performance_NNP of_IN Method_NNP 3_CD with_IN Different_JJ Threshold_NNP Table_NNP 4_CD shows_VBZ the_DT performances_NNS of_IN the_DT main_JJ structure_NN parser_NN with_IN method_NN 3_CD with_IN different_JJ pa_NN -_: rameters_NNS ._.
The_DT method_NN achieves_VBZ the_DT best_JJS perfor_NN -_: mance_NN when_WRB the_DT parameter_NN is_VBZ set_VBN to_TO 16_CD ,_, the_DT per_FW -_: formance_NN curve_NN before_IN and_CC after_IN this_DT point_NN expe_NN -_: rience_NN a_DT comparable_JJ decrease_NN like_IN method_NN 2_CD ._.
32.0_CD %_NN 33.2_CD %_NN 31.8_CD %_NN 26.8_CD %_NN 28.1_CD %_NN 32.0_CD %_NN 31.1_CD %_NN 24.4_CD %_NN 27.8_CD %_NN Table_NNP 5_CD :_: Method_NN comparison_NN on_IN each_DT sub-set_NN As_IN can_MD be_VB seen_VBN from_IN section_NN 4.4_CD ,_, method_NN 1_CD outperformed_VBD the_DT other_JJ two_CD methods_NNS in_IN both_DT UAS_NNP and_CC ULAS_NNP ,_, Table_NNP 5_CD shows_NNS that_IN the_DT method_NN 3_CD achieves_VBZ better_JJR performance_NN than_IN method_NN 1_CD when_WRB the_DT length_NN of_IN sentence_NN is_VBZ longer_RBR than_IN 100_CD ,_, while_IN it_PRP is_VBZ worse_JJR than_IN method_NN 2_CD in_IN sentences_NNS with_IN length_NN less_JJR than_IN 80_CD ._.
5_CD Conclusion_NN This_DT research_NN proposes_VBZ a_DT two-stage_JJ parsing_NN method_NN called_VBN main_JJ structure_NN parsing_NN ,_, used_VBN to_TO improve_VB the_DT parsing_NN performance_NN for_IN Chinese_JJ long_JJ sentence_NN ._.
The_DT performance_NN of_IN normal_JJ de_IN -_: pendency_NN parser_NN decreases_VBZ on_IN long_JJ sentences_NNS be_VB -_: cause_NN of_IN the_DT long_JJ distance_NN dependencies_NNS between_IN main_JJ structure_NN words_NNS ._.
The_DT main_JJ structure_NN parsing_NN method_NN alleviates_VBZ long_RB dependency_NN problem_NN by_IN selecting_VBG out_RP the_DT main_JJ structure_NN words_NNS and_CC parse_VB them_PRP with_IN a_DT specially_RB trained_VBN parser_NN ._.
Three_CD dif_SYM -_: ferent_JJ methods_NNS regarding_VBG selecting_VBG those_DT main_JJ structure_NN words_NNS are_VBP compared_VBN and_CC tested_VBN in_IN the_DT thesis_NN ._.
The_DT best_JJS method_NN achieves_VBZ a_DT 6.0_CD %_NN im_SYM -_: provement_NN on_IN long_JJ dependency_NN than_IN baseline_NN parser_NN and_CC 3.2_CD %_NN improvement_NN than_IN the_DT previous_JJ best_JJS mode_NN ._.
Reference_NNP Jones_NNP ,_, B._NNP -LRB-_-LRB- 1996_CD -RRB-_-RRB- ._.
What_WP 's_VBZ the_DT point_NN ?_.
A_DT -LRB-_-LRB- computational_JJ -RRB-_-RRB- theory_NN of_IN punctuation_NN ._.
Bohnet_NNP ,_, B._NNP ,_, &_CC Kuhn_NNP ,_, J._NNP -LRB-_-LRB- 2012_CD ,_, April_NNP -RRB-_-RRB- ._.
The_DT best_JJS of_IN both_DT worlds_NNS :_: a_DT graph-based_JJ completion_NN model_NN for_IN transi_NN -_: tion-based_JJ parsers_NNS ._.
In_IN Proceedings_NNP of_IN the_DT 13th_JJ Con_NN -_: ference_NN of_IN the_DT European_JJ Chapter_NN of_IN the_DT Association_NNP for_IN Computational_NNP Linguistics_NNP -LRB-_-LRB- pp._FW 77-87_CD -RRB-_-RRB- ._.
Associ_SYM -_: ation_NN for_IN Computational_NNP Linguistics_NNP ._.
Candito_NNP ,_, M._NNP ,_, &_CC Seddah_NNP ,_, D._NNP -LRB-_-LRB- 2012_CD ,_, November_NNP -RRB-_-RRB- ._.
Effec_SYM -_: tively_RB long-distance_JJ dependencies_NNS in_IN French_JJ :_: anno_NN -_: tation_NN and_CC parsing_NN evaluation_NN ._.
In_IN TLT_NNP 11-The_NNP 11th_JJ International_NNP Workshop_NNP on_IN Treebanks_NNPS and_CC Linguis_NNP -_: tic_JJ Theories_NNS ._.
Chang_NNP ,_, C._NNP C._NNP ,_, &_CC Lin_NNP ,_, C._NNP J._NNP -LRB-_-LRB- 2011_CD -RRB-_-RRB- ._.
LIBSVM_NNP :_: A_NNP Li_NNP -_: brary_JJ for_IN Support_NN Vector_NNP Machines_NNP ._.
ACM_NNP Transac_NNP -_: tions_NNS on_IN Intelligent_NNP Systems_NNPS and_CC Technology_NNP ,_, 2_CD :_: 27_CD :_: 1_CD --_: 27_CD :_: 27_CD ,_, 2011_CD ._.
Software_NNP available_JJ at_IN http://www_NN ._.
csie_NN ._.
ntu_NN ._.
edu_NN ._.
tw/cjlin/libsvm_NN ._.
Zhao_NNP ,_, Y._NNP ,_, Che_NNP ,_, W._NNP ,_, Guo_NNP ,_, H._NNP ,_, Qin_NNP ,_, B._NNP ,_, Su_NNP ,_, Z._NNP ,_, &_CC Liu_NNP ,_, T._NNP -LRB-_-LRB- 2014_CD -RRB-_-RRB- ._.
Sentence_NN compression_NN for_IN target-polarity_JJ word_NN collocation_NN extraction_NN ._.
In_IN Proceedings_NNP of_IN COLING_NNP -LRB-_-LRB- pp._FW 1360-1369_CD -RRB-_-RRB- ._.
Che_NNP ,_, W._NNP ,_, Spitkovsky_NNP ,_, V._NNP I._NNP ,_, &_CC Liu_NNP ,_, T._NNP -LRB-_-LRB- 2012_CD ,_, July_NNP -RRB-_-RRB- ._.
A_DT comparison_NN of_IN chinese_JJ parsers_NNS for_IN stanford_NN depend_VBP -_: encies_NNS ._.
In_IN Proceedings_NNP of_IN the_DT 50th_JJ Annual_JJ Meeting_VBG of_IN the_DT Association_NNP for_IN Computational_NNP Linguistics_NNPS :_: Short_JJ Papers-Volume_JJ 2_CD -LRB-_-LRB- pp._FW 11-16_CD -RRB-_-RRB- ._.
Association_NNP for_IN Computational_NNP Linguistics_NNP ._.
Ferreira_NNP ,_, F._NNP ,_, Engelhardt_NNP ,_, P._NNP E._NNP ,_, &_CC Jones_NNP ,_, M._NNP W._NNP -LRB-_-LRB- 2009_CD -RRB-_-RRB- ._.
Good_JJ enough_JJ language_NN processing_NN :_: A_DT satisficing_VBG approach_NN ._.
In_IN Proceedings_NNP of_IN the_DT 31st_CD Annual_JJ con_NN -_: ference_NN of_IN the_DT Cognitive_NNP Science_NNP Society_NNP ._.
Austin_NNP :_: Cognitive_NNP Science_NNP Society_NNP ._.
Threshold_NN Accuracy_NNP Threshold_NNP Accuracy_NNP 0_CD 2_CD 4_CD 6_CD 8_CD 10_CD 12_CD 14_CD 11.7_CD %_NN 26_CD 28_CD 30_CD 32_CD 34_CD 36_CD 38_CD 40_CD 33.0_CD %_NN 21.1_CD %_NN 27.1_CD %_NN 32.6_CD %_NN 30.9_CD %_NN 32.9_CD %_NN 32.3_CD %_NN 32.6_CD %_NN 33.5_CD %_NN 32.2_CD %_NN 33.6_CD %_NN 16_CD 18_CD 20_CD 24_CD 33.8_CD %_NN 42_CD 44_CD 46_CD 48_CD 32.1_CD %_NN 33.4_CD %_NN 33.3_CD %_NN 32.0_CD %_NN Length_NNP Baseline_NNP M1_NNP M2_NNP M3_NNP 40-50_CD 50-60_CD 60-70_CD 70-80_CD 80-90_CD 90-100 100-110_CD 110-120 120-130_CD 130-140 140-150_CD 33.2_CD %_NN 40.0_CD %_NN 36.4_CD %_NN 36.9_CD %_NN 34.5_CD %_NN 30.2_CD %_NN 30.5_CD %_NN 29.1_CD %_NN 29.2_CD %_NN 22.5_CD %_NN 32.1_CD %_NN 21.9_CD %_NN 38.2_CD %_NN 33.4_CD %_NN 32.4_CD %_NN 35.5_CD %_NN 32.2_CD %_NN 37.2_CD %_NN 28.8_CD %_NN 35.2_CD %_NN 22.0_CD %_NN 23.5_CD %_NN 25.7_CD %_NN 29.1_CD %_NN 26.5_CD %_NN 26.1_CD %_NN 26.7_CD %_NN 28.4_CD %_NN 19.0_CD %_NN 21.7_CD %_NN 21.1_CD %_NN 22.2_CD %_NN 20.0_CD %_NN 27.1_CD %_NN 24.3_CD %_NN Yamada_NNP ,_, H._NNP ,_, &_CC Matsumoto_NNP ,_, Y._NNP -LRB-_-LRB- 2003_CD ,_, April_NNP -RRB-_-RRB- ._.
Statisti_NNP -_: cal_JJ dependency_NN analysis_NN with_IN support_NN vector_NN ma_SYM -_: chines_NNS ._.
In_IN Proceedings_NNP of_IN IWPT_NNP -LRB-_-LRB- Vol_NNP ._.
3_CD ,_, pp._SYM 195_CD -_: 206_CD -RRB-_-RRB- ._.
Lai_NNP ,_, B._NNP Y._NNP T._NNP ,_, &_CC Huang_NNP ,_, C._NNP -LRB-_-LRB- 1994_CD -RRB-_-RRB- ._.
Dependency_NN grammar_NN and_CC the_DT parsing_NN of_IN Chinese_JJ sentenc_NN -_: es_NNS ._.
arXiv_JJ preprint_NN cmp-lg/9412001_NN ._.
Lai_NNP ,_, T._NNP B._NNP ,_, Huang_NNP ,_, C._NNP ,_, Zhou_NNP ,_, M._NNP ,_, Miao_NNP ,_, J._NNP ,_, Siu_NNP ,_, T._NNP K._NNP ,_, 2001_CD ._.
Span-based_JJ statistical_JJ dependency_NN parsing_NN of_IN Chi_NNP -_: nese_NN ._.
In_IN :_: NLPRS_NNS ._.
pp._NNP 677_CD --_: 684_CD ._.
Li_NNP ,_, X._NNP ,_, Zong_NNP ,_, C._NNP ,_, &_CC Hu_NNP ,_, R._NNP -LRB-_-LRB- 2005_CD -RRB-_-RRB- ._.
A_DT Hierarchical_NNP Parsing_NNP Approach_NNP with_IN Punctuation_NNP Processing_NNP for_IN Long_NNP Sentence_NNP Sentences_NNS ._.
In_IN In_IN Proceedings_NNP of_IN the_DT Second_NNP International_NNP Joint_NNP Conference_NNP on_IN Natural_NNP Language_NNP Processing_NNP :_: Companion_NNP Volume_NN includ_NN -_: ing_NN Posters/Demos_NNS and_CC Tutorial_NNP Abstracts_NNPS ._.
Li_NNP ,_, Z._NNP ,_, Che_NNP ,_, W._NNP ,_, &_CC Liu_NNP ,_, T._NNP -LRB-_-LRB- 2010_CD ,_, December_NNP -RRB-_-RRB- ._.
Improv_SYM -_: ing_NN dependency_NN parsing_NN using_VBG punctuation_NN ._.
In_IN Asian_JJ Language_NN Processing_NNP -LRB-_-LRB- IALP_NNP -RRB-_-RRB- ,_, 2010_CD Inter_NNP -_: national_JJ Conference_NN on_IN -LRB-_-LRB- pp._FW 53-56_CD -RRB-_-RRB- ._.
IEEE_NNP ._.
Xun_NNP Jin_NNP ,_, M._NNP ,_, Kim_NNP ,_, M._NNP Y._NNP ,_, Kim_NNP ,_, D._NNP ,_, &_CC Lee_NNP ,_, J._NNP H._NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- ._.
Segmentation_NN of_IN Chinese_JJ long_JJ sentences_NNS using_VBG commas_NNS ._.
In_IN Proceedings_NNP of_IN SIGHAN_NNP -LRB-_-LRB- pp._FW 1_LS -_: 8_CD -RRB-_-RRB- ._.
Covington_NNP ,_, M._NNP A._NNP -LRB-_-LRB- 2001_CD -RRB-_-RRB- ._.
A_DT fundamental_JJ algorithm_NN for_IN dependency_NN parsing_NN ._.
InProceedings_NNS of_IN the_DT 39th_JJ annual_JJ ACM_NNP southeast_NN conference_NN -LRB-_-LRB- pp._FW 95-102_CD -RRB-_-RRB- ._.
Nivre_NNP ,_, J._NNP ,_, &_CC McDonald_NNP ,_, R._NNP T._NNP -LRB-_-LRB- 2008_CD ,_, June_NNP -RRB-_-RRB- ._.
Integrat_NNP -_: ing_NN Graph-Based_NNP and_CC Transition-Based_NNP Dependen_NNP -_: cy_NN Parsers_NNP ._.
In_IN ACL_NNP -LRB-_-LRB- pp._FW 950-958_CD -RRB-_-RRB- ._.
Nivre_NNP ,_, J._NNP ,_, Hall_NNP ,_, J._NNP ,_, &_CC Nilsson_NNP ,_, J._NNP -LRB-_-LRB- 2006_CD ,_, May_NNP -RRB-_-RRB- ._.
Malt_SYM -_: parser_NN :_: A_DT data-driven_JJ parser-generator_NN for_IN depend_VBP -_: ency_NN parsing_NN ._.
In_IN Proceedings_NNP of_IN LREC_NNP -LRB-_-LRB- Vol_NNP ._.
6_CD ,_, pp._SYM 2216-2219_CD -RRB-_-RRB- ._.
Nilsson_NNP ,_, J._NNP ,_, Riedel_NNP ,_, S._NNP ,_, &_CC Yuret_NNP ,_, D._NNP -LRB-_-LRB- 2007_CD ,_, June_NNP -RRB-_-RRB- ._.
The_DT CoNLL_NNP 2007_CD shared_VBD task_NN on_IN dependency_NN parsing_NN ._.
In_IN Proceedings_NNP of_IN the_DT CoNLL_NNP shared_VBD task_NN session_NN of_IN EMNLP-CoNLL_NNP -LRB-_-LRB- pp._FW 915-932_CD -RRB-_-RRB- ._.
Nivre_NNP ,_, J._NNP ,_, &_CC McDonald_NNP ,_, R._NNP T._NNP -LRB-_-LRB- 2008_CD ,_, June_NNP -RRB-_-RRB- ._.
Integrat_NNP -_: ing_NN Graph-Based_NNP and_CC Transition-Based_NNP Dependen_NNP -_: cy_NN Parsers_NNP ._.
In_IN ACL_NNP -LRB-_-LRB- pp._FW 950-958_CD -RRB-_-RRB- ._.
MAO_NNP ,_, Q._NNP ,_, LIAN_NNP ,_, L._NNP X._NNP ,_, ZHOU_NNP ,_, W._NNP C._NNP ,_, &_CC YUAN_NNP ,_, C._NNP F._NNP -LRB-_-LRB- 2007_CD -RRB-_-RRB- ._.
Chinese_JJ syntactic_NN parsing_NN algorithm_NN based_VBN on_IN segmentation_NN of_IN punctuation_NN ._.
Journal_NNP of_IN Chinese_NNP Information_NNP Processing_NNP ,_, 21_CD -LRB-_-LRB- 2_LS -RRB-_-RRB- ,_, 3_CD ._.
Sagae_NNP ,_, K_NNP and_CC Lavie_NNP ,_, A._NNP 2006a_NNP ._.
Parser_NNP combination_NN by_IN reparsing_VBG ._.
In_IN Proc_NNP ._.
HLT/NAACL_NNP ,_, pages_NNS 129_CD --_: 132_CD ,_, New_NNP York_NNP City_NNP ,_, USA_NNP ,_, June_NNP ._.
Sagae_NNP ,_, K._NNP ,_, &_CC Lavie_NNP ,_, A._NN -LRB-_-LRB- 2006_CD ,_, June_NNP -RRB-_-RRB- ._.
Parser_NNP combina_NN -_: tion_NN by_IN reparsing_VBG ._.
InProceedings_NNS of_IN the_DT Human_NNP Language_NNP Technology_NNP Conference_NNP of_IN the_DT NAACL_NNP ,_, Companion_NNP Volume_NN :_: Short_NNP Papers_NNP -LRB-_-LRB- pp._FW 129-132_CD -RRB-_-RRB- ._.
Association_NNP for_IN Computational_NNP Linguistics_NNP ._.
Wang_NNP ,_, W._NNP Y._NNP ,_, Kong_NNP ,_, L._NNP ,_, Mazaitis_NNP ,_, K._NNP ,_, &_CC Cohen_NNP ,_, W._NNP W._NNP -LRB-_-LRB- 2014_CD -RRB-_-RRB- ._.
Dependency_NN Parsing_NNP for_IN Weibo_NNP :_: An_DT Ef_SYM -_: ficient_JJ Probabilistic_NNP Logic_NNP Programming_NNP Approach_NNP ._.
Association_NNP for_IN Computational_NNP Linguistics_NNP ._.
Xue_NNP ,_, N._NNP ,_, Xia_NNP ,_, F._NNP ,_, Chiou_NNP ,_, F._NNP D._NNP ,_, &_CC Palmer_NNP ,_, M._NNP -LRB-_-LRB- 2005_CD -RRB-_-RRB- ._.
The_DT Penn_NNP Chinese_NNP TreeBank_NNP :_: Phrase_NN structure_NN an_DT -_: notation_NN of_IN a_DT large_JJ corpus_NN ._.
Natural_JJ language_NN engi_SYM -_: neering_NN ,_, 11_CD -LRB-_-LRB- 02_CD -RRB-_-RRB- ,_, 207-238_CD ._.
Zhou_NNP ,_, M._NNP -LRB-_-LRB- 2000_CD ,_, October_NNP -RRB-_-RRB- ._.
A_DT block-based_JJ robust_JJ de_IN -_: pendency_NN parser_NN for_IN unrestricted_JJ Chinese_JJ text_NN ._.
In_IN Proceedings_NNP of_IN the_DT second_JJ workshop_NN on_IN Chinese_JJ language_NN processing_NN :_: held_VBN in_IN conjunction_NN with_IN the_DT 38th_JJ Annual_JJ Meeting_VBG of_IN the_DT Association_NNP for_IN Com_NNP -_: putational_JJ Linguistics-Volume_NNP 12_CD -LRB-_-LRB- pp._FW 78-84_CD -RRB-_-RRB- ._.
As_IN -_: sociation_NN for_IN Computational_NNP Linguistics_NNP ._.
Zhang_NNP ,_, Y._NNP ,_, &_CC Nivre_NNP ,_, J._NNP -LRB-_-LRB- 2011_CD ,_, June_NNP -RRB-_-RRB- ._.
Transition-based_JJ dependency_NN parsing_VBG with_IN rich_JJ non-local_JJ features_NNS ._.
In_IN Proceedings_NNP of_IN the_DT 49th_JJ Annual_JJ Meeting_VBG of_IN the_DT Association_NNP for_IN Computational_NNP Linguistics_NNPS :_: Human_NNP Language_NNP Technologies_NNPS :_: short_JJ papers-Volume_JJ 2_CD -LRB-_-LRB- pp._FW 188-193_CD -RRB-_-RRB- ._.
Association_NNP for_IN Computational_NNP Linguistics_NNP ._.
