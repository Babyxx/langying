Discourse_NN Relation_NN Recognition_NN by_IN Comparing_VBG Various_JJ Units_NNS of_IN Sentence_NNP Expression_NNP with_IN Recursive_NNP Neural_NNP Network_NNP Abstract_NNP We_PRP propose_VBP a_DT method_NN for_IN implicit_JJ discourse_NN relation_NN recognition_NN using_VBG a_DT recursive_JJ neural_JJ network_NN -LRB-_-LRB- RNN_NNP -RRB-_-RRB- ._.
Many_JJ previous_JJ studies_NNS have_VBP used_VBN the_DT word-pair_NN feature_NN to_TO compare_VB the_DT meaning_NN of_IN two_CD sentences_NNS for_IN implicit_JJ dis_SYM -_: course_NN relation_NN recognition_NN ._.
Our_PRP$ proposed_VBN method_NN differs_VBZ in_IN that_DT we_PRP use_VBP various-sized_JJ sentence_NN expression_NN units_NNS and_CC compare_VB the_DT meaning_NN of_IN the_DT expressions_NNS between_IN two_CD sen_SYM -_: tences_NNS by_IN converting_VBG the_DT expressions_NNS into_IN vec_NN -_: tors_NNS using_VBG the_DT RNN_NNP ._.
Experiments_NNS showed_VBD that_IN our_PRP$ method_NN significantly_RB improves_VBZ the_DT accu_NN -_: racy_JJ of_IN identifying_VBG implicit_JJ discourse_NN relations_NNS compared_VBN with_IN the_DT word-pair_NN method_NN ._.
1_CD Introduction_NNP Discourse_NNP relation_NN recognition_NN is_VBZ a_DT technique_NN to_TO iden_VB -_: tify_VB the_DT type_NN of_IN discourse_NN relation_NN between_IN two_CD sen_SYM -_: tences_NNS ._.
Because_IN discourse_NN relation_NN contributes_VBZ to_TO the_DT coherence_NN of_IN sentences_NNS ,_, it_PRP has_VBZ potential_JJ applications_NNS in_IN many_JJ natural_JJ language_NN processing_NN -LRB-_-LRB- NLP_NNP -RRB-_-RRB- tasks_NNS ._.
For_IN example_NN ,_, in_IN text_NN summarization_NN ,_, it_PRP makes_VBZ sum_NN -_: mary_JJ documents_NNS more_RBR consistent_JJ by_IN using_VBG discourse_NN relations_NNS and_CC structures_NNS -LRB-_-LRB- Gerani_NNP et_FW al._FW ,_, 2014_CD -RRB-_-RRB- ._.
Simi_SYM -_: larly_RB ,_, in_IN conversational_JJ systems_NNS -LRB-_-LRB- Higashinaka_FW et_FW al._FW ,_, 2014_CD -RRB-_-RRB- ,_, discourse_NN relations_NNS can_MD help_VB the_DT system_NN select_JJ contextually_RB appropriate_JJ system_NN utterances_NNS ._.
Discourse_NN relations_NNS are_VBP categorized_VBN into_IN explicit_JJ and_CC implicit_JJ relations_NNS ._.
Explicit_JJ relations_NNS have_VBP a_DT dis_SYM -_: course_NN marker_NN such_JJ as_IN a_DT connective_NN ,_, making_VBG them_PRP easy_JJ to_TO identify_VB with_IN a_DT high_JJ degree_NN of_IN accuracy_NN -LRB-_-LRB- Pitler_NNP and_CC Nenkova_NNP ,_, 2009_CD -RRB-_-RRB- ._.
Implicit_JJ discourse_NN rela_NN -_: tions_NNS ,_, in_IN contrast_NN ,_, have_VBP no_DT discourse_NN marker_NN between_IN sentences_NNS ._.
Previous_JJ studies_NNS have_VBP proposed_VBN many_JJ methods_NNS for_IN implicit_JJ discourse_NN recognition_NN ,_, among_IN them_PRP reasoning-based_JJ -LRB-_-LRB- Sugiura_NNP et_FW al._FW ,_, 2013_CD -RRB-_-RRB- and_CC pattern-based_JJ -LRB-_-LRB- Saito_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- methods_NNS ._.
Many_JJ of_IN these_DT earlier_JJR studies_NNS -LRB-_-LRB- Marcu_NNP and_CC Echihabi_NNP ,_, 2002_CD ;_: Lin_NNP et_FW al._FW ,_, 2009_CD ;_: Pitler_NNP et_FW al._FW ,_, 2009_CD ;_: Wang_NNP et_FW al._FW ,_, 2012_CD ;_: Lan_NNP et_FW al._FW ,_, 2013_CD ;_: Biran_NNP and_CC McKeown_NNP ,_, 2013_CD ;_: Ruther_NNP -_: ford_NN and_CC Xue_NNP ,_, 2014_CD -RRB-_-RRB- focused_VBD on_IN using_VBG word_NN pairs_NNS or_CC their_PRP$ derivative_JJ features_NNS ._.
For_IN example_NN ,_, take_VB the_DT two_CD following_JJ sentences_NNS :_: A1_CD :_: I_PRP like_VBP summer_NN ._.
B1_CD :_: I_PRP prefer_VBP winter_NN ._.
In_IN this_DT case_NN ,_, we_PRP can_MD easily_RB identify_VB the_DT relation_NN as_IN ``_`` comparison_NN ''_'' by_IN focusing_VBG on_IN the_DT word_NN pair_NN ``_`` sum_NN -_: mer_SYM -_: winter_NN ''_'' ._.
However_RB ,_, there_EX is_VBZ emerging_VBG evidence_NN that_IN word_NN pairs_NNS may_MD no_RB longer_RB have_VB a_DT role_NN to_TO play_VB in_IN implicit_JJ discourse_NN relation_NN recognition_NN -LRB-_-LRB- Park_NNP and_CC Cardie_NNP ,_, 2012_CD -RRB-_-RRB- ._.
This_DT is_VBZ because_IN identification_NN is_VBZ not_RB always_RB possible_JJ by_IN using_VBG just_RB word_NN pairs_NNS ._.
When_WRB we_PRP consider_VBP the_DT following_JJ sentences_NNS ,_, A2_NNP :_: I_PRP got_VBD soaked_VBN by_IN the_DT sudden_JJ rain_NN yesterday_NN ._.
B21_CD :_: Did_VBD you_PRP forget_VB your_PRP$ umbrella_NN at_IN the_DT office_NN ?_.
B22_NNP :_: The_DT rain_NN was_VBD so_RB heavy_JJ that_IN my_PRP$ umbrella_NN was_VBD useless_JJ ._.
discourse_NN A2_CD −_CD B21_NNP and_CC A2_NNP −_CD B22_NNP have_VBP different_JJ relations_NNS ._.
discourse_NN A2_CD −_CD B21_NNP is_VBZ causal_JJ relation_NN :_: B21_CD explains_VBZ the_DT reason_NN for_IN A1_NNP ,_, and_CC A2_NNP −_CD B22_NNP is_VBZ expansion_NN relation_NN :_: B22_CD is_VBZ a_DT supplemental_JJ explana_NN -_: tion_NN about_IN the_DT ``_`` sudden_JJ rain_NN ''_'' in_IN A2_NNP ._.
Nevertheless_RB ,_, the_DT same_JJ word_NN pair_NN ``_`` soaked_JJ -_: umbrella_NN ''_'' can_MD be_VB ex_FW -_: 9_CD -LRB-_-LRB- %_NN A473_CD D_NNP -LRB-_-LRB- `_`` A89_NNP @_SYM 8_CD -RRB-_-RRB- D_NNP %_NN 948C_CD @_SYM -LRB-_-LRB- E99_NNP -LRB-_-LRB- @@_CD 487_CD C74A_NNP @_IN C@473_NNP A4_NNP -LRB-_-LRB- ii_FW ii_FW ''_'' -LRB-_-LRB- 7A_NN -LRB-_-LRB- 7_CD '_'' -LRB-_-LRB- -LRB-_-LRB- `_`` A89_NNP @_IN ii_FW ''_'' -LRB-_-LRB- 7A_NN -LRB-_-LRB- 7_CD '_'' -LRB-_-LRB- -LRB-_-LRB- `_`` A89_NNP @_SYM 8_CD -LRB-_-LRB- %_NN AC9_CD -LRB-_-LRB- '_'' 9_CD -LRB-_-LRB- %_NN A487_NNP -RRB-_-RRB- 987_CD D_NNP -LRB-_-LRB- `_`` A89_NNP @_IN -RRB-_-RRB- 89_CD 9_CD -LRB-_-LRB- 6_CD %_NN A487_CD 9_CD -LRB-_-LRB- '_'' 8374A487_NNP ''_'' -LRB-_-LRB- 7A_NN -LRB-_-LRB- 7_CD '_'' -LRB-_-LRB- ''_'' -LRB-_-LRB- 7A_NN -LRB-_-LRB- 7_CD '_'' -LRB-_-LRB- $_$ E7_CD %_NN 74_CD '_'' 886473_CD $_$ 4_CD -RRB-_-RRB- -RRB-_-RRB- -LRB-_-LRB- 9_CD -LRB-_-LRB- 7_CD '_'' -LRB-_-LRB- -LRB-_-LRB- `_`` A89_NN 8_CD -LRB-_-LRB- %_NN AC9_CD -LRB-_-LRB- -LRB-_-LRB- `_`` A89_NNP 8yh_CD vsvr_NN ..._: ''_'' h_VB $_$ 4@'8C9@_CD -LRB-_-LRB- -LRB-_-LRB- 6_CD %_NN A487_CD b_NN %_NN '_'' -LRB-_-LRB- 6_CD Figure_NN 1_CD :_: Overview_NNP of_IN proposed_VBN discourse_NN relation_NN recognition_NN ._.
SII_NNP T_NNP ..._: p_NN ..._: r_NN &_CC $_$ #_# 00_CD #_# 4_CD ###_CD G_NNP ##_CD 36_CD 9@@_CD @@_CD 8999_CD 8A_NN 8_CD @@_CD 999_CD @_IN @_SYM 89_CD @_SYM A9@@9@98A3_CD 00_CD #_# 4_CD ###_CD G_NNP ##_CD 36_CD 9@@_CD @@_CD 8999_CD 8A_NN 8_CD @@_CD 999_CD @_IN @_SYM 89@3_CD T_NNP '_POS hp_NN vp_NN T_NNP ..._: p_NN ..._: r_NN qr_NN r_NN qr_NN p_NN '_'' ..._: p_NN ..._: r_NN &_CC $_$ #_# 00_CD #_# 4_CD #_# ##_CD G_NNP #_# #_# 36_CD 9@@_CD @@_CD 8999_CD 8A_NN 8_CD @@_CD 999_CD @_IN @_SYM 89_CD @_SYM A9@@9@98A3_CD Tr_NNP r_NN pr_NN 9r_NN r_NN qr_NN p_NN '_'' Trt_NNP $_$ r_LS i_FW r_SYM 00_CD #_# 4_CD #_# 38A_CD 8_CD @@_CD 999_CD @_IN @_SYM 89@3_CD &_CC $_$ ###_CD G_NNP ##_NN 4_CD ###_CD G_NNP ##_CD 36_CD 9@@_CD @@_CD 8999_CD 8A_NN 8_CD @_SYM 89@3_CD &_CC $_$ #_# 00_CD #_# 3A9@@9@98A3_CD 3@@999@3_CD 4_CD #_# 38A_CD 8_CD @_SYM 89@3_CD 36_CD 9@@_CD @@_NN 8999_CD A9@@9@98A3_NNP ##_CD G_NNP ##_CD 36_CD 9@@_CD @@_NN 89993_CD tracted_NN for_IN both_DT cases_NNS ,_, making_VBG little_JJ contribution_NN to_TO relation_NN recognition_NN ._.
If_IN we_PRP can_MD use_VB pairs_NNS of_IN longer_JJR expressions_NNS such_JJ as_IN ``_`` I_PRP got_VBD soaked_JJ -_: forget_VB your_PRP$ um_SYM -_: brella_NN ''_'' and_CC ``_`` I_PRP got_VBD soaked_VBN by_IN the_DT sudden_JJ rain_NN -_: so_RB heavy_JJ that_IN my_PRP$ umbrella_NN was_VBD useless_JJ ''_'' ,_, it_PRP will_MD be_VB eas_SYM -_: ier_NN to_TO perform_VB relation_NN recognition_NN because_IN the_DT units_NNS employed_VBN are_VBP more_RBR specific_JJ and_CC distinguishing_NN of_IN discourse_NN relations_NNS ._.
This_DT paper_NN proposes_VBZ a_DT novel_NN method_NN for_IN implicit_JJ discourse_NN relation_NN recognition_NN that_WDT compares_VBZ various_JJ expression_NN units_NNS between_IN two_CD sentences_NNS ._.
The_DT small_JJ -_: est_NN units_NNS of_IN a_DT sentence_NN expression_NN are_VBP words_NNS ,_, and_CC the_DT largest_JJS are_VBP the_DT entire_JJ sentence_NN ._.
To_TO consider_VB various_JJ expression_NN units_NNS ,_, we_PRP turn_VBP to_TO a_DT recursive_JJ neural_NN net_NN -_: work_NN -LRB-_-LRB- RNN_NNP -RRB-_-RRB- based_VBN approach_NN ._.
The_DT RNN_NNP is_VBZ the_DT neural_JJ network_NN based_VBN method_NN to_TO create_VB vectors_NNS of_IN various_JJ expression_NN units_NNS on_IN the_DT basis_NN of_IN the_DT syntactic_NN struc_NN -_: ture_NN of_IN a_DT sentence_NN and_CC has_VBZ been_VBN applied_VBN to_TO various_JJ NLP_NNP tasks_NNS -LRB-_-LRB- Socher_NNP et_FW al._FW ,_, 2011_CD ;_: Li_NNP et_FW al._FW ,_, 2014_CD ;_: Liu_NNP et_FW al._FW ,_, 2014_CD -RRB-_-RRB- ._.
Here_RB ,_, we_PRP employ_VBP the_DT RNN_NNP based_VBN ap_SYM -_: proach_NN for_IN implicit_JJ discourse_NN recognition_NN and_CC show_VB that_IN our_PRP$ proposed_VBN method_NN significantly_RB outperforms_VBZ the_DT word_NN pair_NN based_VBN approach_NN ._.
In_IN this_DT paper_NN ,_, we_PRP demonstrate_VBP through_IN experi_NNS -_: ments_NNS using_VBG Japanese_JJ conversational_JJ data_NNS that_WDT our_PRP$ method_NN can_MD improve_VB the_DT estimation_NN performance_NN of_IN implicit_JJ discourse_NN relation_NN recognition_NN more_JJR than_IN the_DT conventional_JJ word_NN pair_NN method_NN ._.
In_IN the_DT following_JJ sections_NNS ,_, we_PRP first_RB describe_VBP our_PRP$ proposed_VBN method_NN us_PRP -_: ing_VBG the_DT RNN_NNP with_IN Japanese_JJ sentences_NNS in_IN Section_NN 2_CD ._.
Section_NN 3_CD explains_VBZ the_DT experiments_NNS we_PRP performed_VBD on_IN implicit_JJ discourse_NN recognition_NN in_IN Japanese_JJ dialogue_NN ,_, and_CC we_PRP discuss_VBP the_DT results_NNS in_IN Section_NN 4_CD ._.
Finally_RB ,_, we_PRP conclude_VBP in_IN Section_NN 5_CD ._.
2_CD Discourse_NN relation_NN recognition_NN by_IN comparing_VBG various_JJ units_NNS of_IN sentence_NN expressions_NNS Figure_NN 1_CD shows_VBZ an_DT overview_NN of_IN the_DT proposed_VBN method_NN using_VBG various_JJ units_NNS of_IN expressions_NNS in_IN a_DT sentence_NN to_TO identify_VB implicit_JJ discourse_NN relations_NNS ._.
First_RB ,_, we_PRP input_NN sentences_NNS to_TO the_DT RNN_NNP ._.
The_DT RNN_NNP then_RB creates_VBZ vectors_NNS of_IN various_JJ expression_NN units_NNS on_IN the_DT basis_NN of_IN the_DT input_NN syntactic_NN structures_NNS in_IN a_DT bottom-up_JJ fashion_NN ._.
Next_JJ ,_, we_PRP create_VBP a_DT feature_NN vector_NN by_IN comparing_VBG vectors_NNS of_IN X_NNP ..._: q_NN &_CC $_$ #_# 00_CD #_# 4_CD #_# ##_CD G_NNP #_# #_# Figure_NN 2_CD :_: RNN_NNP structure_NN in_IN Japanese_JJ dependency_NN structure_NN ._.
various_JJ units_NNS of_IN expression_NN ._.
The_DT discourse_NN relation_NN is_VBZ identified_VBN by_IN a_DT discriminative_JJ classifier_NN such_JJ as_IN a_DT support_NN vector_NN machine_NN -LRB-_-LRB- SVM_NNP -RRB-_-RRB- ._.
In_IN this_DT section_NN ,_, we_PRP explain_VBP how_WRB the_DT RNN_NNP works_VBZ ,_, describe_VBP how_WRB the_DT vec_NN -_: tors_NNS are_VBP created_VBN by_IN the_DT RNN_NNP ,_, and_CC show_VB how_WRB to_TO create_VB the_DT feature_NN for_IN the_DT classifier_NN from_IN vectors_NNS ._.
2.1_CD Recursive_JJ neural_JJ network_NN The_DT RNN_NNP is_VBZ a_DT kind_NN of_IN deep_JJ neural_JJ network_NN created_VBN by_IN applying_VBG the_DT same_JJ set_NN of_IN weights_NNS recursively_RB over_IN a_DT structure_NN ._.
The_DT RNN_NNP has_VBZ a_DT binary_JJ tree_NN structure_NN ,_, and_CC its_PRP$ framework_NN computes_VBZ the_DT representation_NN for_IN each_DT parent_NN iteratively_RB in_IN a_DT bottom-up_JJ fashion_NN on_IN the_DT basis_NN of_IN its_PRP$ children_NNS ._.
We_PRP assume_VBP that_IN word_NN vectors_NNS c1_VBP ,_, c2_VBP ,_, and_CC c3_CD have_VBP N_NNP dimensions_NNS ._.
Each_DT word_NN is_VBZ given_VBN vec_SYM -_: tors_NNS in_IN advance_NN by_IN word_NN embeddings_NNS -LRB-_-LRB- e.g._FW ,_, word2vec_JJ -LRB-_-LRB- Mikolov_NNP et_FW al._FW ,_, 2013a_JJ -RRB-_-RRB- -RRB-_-RRB- ._.
Segment_NN vectors_NNS are_VBP cre_SYM -_: ated_VBN by_IN combining_VBG word_NN vectors_NNS from_IN left_VBN to_TO right_RB in_IN each_DT segment_NN ._.
The_DT c1_CD and_CC c2_CD 's_POS parent_NN representation_NN vector_NN p1_CD is_VBZ computed_VBN as_IN p1_CD =_SYM f_LS -LRB-_-LRB- We_PRP -LSB-_VBP c1_CD ;_: c2_CD -RSB-_NNP +_NN be_VB -RRB-_-RRB- -LRB-_-LRB- 1_LS -RRB-_-RRB- where_WRB -LSB-_NNP c1_CD ;_: c2_CD -RSB-_NNP is_VBZ the_DT 2N-dimension_NN concatenation_NN vector_NN of_IN c1_CD and_CC c2_CD ,_, We_PRP is_VBZ the_DT N_NNP ×_CD 2N_NNP encoding_VBG matrix_NN ,_, be_VB is_VBZ the_DT N-dimension_NNP encode_VB bias_NN vector_NN ,_, and_CC f_LS denotes_VBZ an_DT element-wise_JJ activation_NN function_NN -LRB-_-LRB- we_PRP use_VBP tanh_NN -RRB-_-RRB- ._.
The_DT next_JJ parent_NN representation_NN vector_NN p2_NN ,_, which_WDT has_VBZ children_NNS p1_CD and_CC c3_CD ,_, is_VBZ computed_VBN in_IN the_DT same_JJ way_NN by_IN an_DT input_NN concatenation_NN vector_NN -LSB-_NNP p1_CD ;_: c3_CD -RSB-_NNP and_CC encoding_VBG parameters_NNS We_PRP and_CC be_VB ._.
2.2_CD Creating_VBG vectors_NNS of_IN various_JJ expression_NN units_NNS using_VBG the_DT RNN_NNP The_NNP RNN_NNP creates_VBZ vectors_NNS of_IN various_JJ expression_NN units_NNS during_IN the_DT process_NN of_IN creating_VBG a_DT sentence_NN vector_NN ._.
Our_PRP$ approach_NN compares_VBZ the_DT meaning_NN of_IN two_CD sentences_NNS by_IN using_VBG these_DT interim_JJ vectors_NNS ._.
In_IN this_DT subsection_NN ,_, we_PRP introduce_VBP a_DT method_NN for_IN extracting_VBG vectors_NNS of_IN various_JJ expression_NN units_NNS by_IN the_DT RNN_NNP for_IN Japanese_JJ sentences_NNS ._.
Figure_NN 2_CD shows_VBZ the_DT RNN_NNP structure_NN based_VBN on_IN Japanese_JJ dependency_NN structure_NN ._.
Japanese_JJ sentences_NNS have_VBP dependency_NN structures_NNS made_VBD up_IN of_IN bunsetsu_NN segments_NNS -LRB-_-LRB- bunsetsu_NN is_VBZ a_DT Japanese_JJ expression_NN unit_NN comprising_VBG one_CD or_CC more_JJR content_JJ words_NNS with_IN zero_CD or_CC more_JJR function_NN words_NNS -RRB-_-RRB- ._.
We_PRP obtain_VB the_DT syntac_NN -_: tic_JJ structures_NNS of_IN sentences_NNS by_IN Japanese_JJ dependency_NN parsing_NN ._.
Refer_VB to_TO -LRB-_-LRB- Kudo_NNP and_CC Matsumoto_NNP ,_, 2003_CD -RRB-_-RRB- for_IN how_WRB Japanese_JJ dependency_NN parsing_NN works_VBZ in_IN general_JJ ._.
We_PRP create_VBP segment_NN vectors_NNS by_IN combining_VBG word_NN vectors_NNS ._.
The_DT sentence_NN vector_NN is_VBZ the_DT root_NN vector_NN of_IN the_DT RNN_NNP created_VBN at_IN the_DT end_NN of_IN the_DT combining_VBG pro-_JJ cess_NN ._.
In_IN this_DT paper_NN ,_, we_PRP construct_VBP an_DT RNN_NNP tree_NN struc_NN -_: ture_NN on_IN top_NN of_IN the_DT Japanese_JJ dependency_NN structure_NN ._.
In_IN Japanese_JJ ,_, dependency_NN relationships_NNS are_VBP generally_RB di_FW -_: rected_VBN from_IN left_VBN to_TO right_RB ,_, so_IN we_PRP constantly_RB combine_VBP segment_NN vectors_NNS from_IN the_DT right-most_JJ segment_NN to_TO ob_SYM -_: tain_VB the_DT segment_NN vector_NN ,_, as_IN in_IN the_DT example_NN shown_VBN in_IN Fig._NNP 2_CD ._.
Because_IN Japanese_JJ dependency_NN structures_NNS are_VBP not_RB a_DT binary_JJ tree_NN ,_, there_EX are_VBP some_DT vectors_NNS that_WDT are_VBP not_RB used_VBN in_IN the_DT process_NN of_IN creating_VBG the_DT sentence_NN vector_NN ._.
For_IN example_NN ,_, the_DT vectors_NNS of_IN the_DT expressions_NNS ``_`` I_PRP got_VBD soaked_VBN yesterday_NN ''_'' and_CC ``_`` I_PRP got_VBD soaked_VBN by_IN rain_NN ''_'' are_VBP not_RB created_VBN in_IN the_DT process_NN of_IN creating_VBG the_DT sentence_NN vector_NN in_IN Fig._NNP 2_CD ._.
Since_IN these_DT vectors_NNS have_VBP an_DT independent_JJ meaning_NN and_CC can_MD be_VB useful_JJ ,_, in_IN our_PRP$ proposed_VBN method_NN ,_, we_PRP use_VBP all_PDT the_DT vectors_NNS -LRB-_-LRB- including_VBG ones_NNS that_WDT do_VBP not_RB lead_VB to_TO the_DT sentence_NN vector_NN -RRB-_-RRB- in_IN the_DT RNN_NNP structure_NN for_IN discourse_NN relation_NN recognition_NN as_IN we_PRP describe_VBP in_IN the_DT following_JJ section_NN ._.
2.3_CD Feature_NNP creation_NN from_IN vectors_NNS for_IN discourse_NN relation_NN recognition_NN If_IN sentences_NNS 1_CD and_CC 2_CD have_VBP n_VBN and_CC m_NN vectors_NNS ,_, respec_FW -_: tively_RB ,_, we_PRP have_VBP to_TO create_VB a_DT feature_NN vector_NN consider_VBP -_: ing_FW n_FW ×_FW m_FW patterns_NNS ._.
However_RB ,_, the_DT feature_NN vector_NN for_IN the_DT classifier_NN must_MD be_VB fixed-length_JJ although_IN the_DT num_NN -_: ber_NN of_IN vectors_NNS extracted_VBN from_IN a_DT sentence_NN changes_NNS dy_SYM -_: namically_RB depending_VBG on_IN the_DT number_NN of_IN words_NNS and_CC on_IN the_DT syntactic_NN structure_NN ._.
Therefore_RB ,_, we_PRP need_VBP to_TO create_VB a_DT fixed-length_JJ feature_NN vector_NN without_IN dependence_NN on_IN the_DT number_NN of_IN vectors_NNS ._.
The_DT simplest_JJS approach_NN to_TO do_VB this_DT is_VBZ to_TO use_VB a_DT concatenation_NN of_IN sentence_NN vectors_NNS as_IN the_DT feature_NN vector_NN ._.
However_RB ,_, this_DT way_NN does_VBZ not_RB al_SYM -_: low_JJ us_PRP to_TO directly_RB compare_VB the_DT meaning_NN of_IN interme_NN -_: diate_NN expression_NN units_NNS ._.
Here_RB ,_, we_PRP create_VBP fixed-length_JJ feature_NN vectors_NNS by_IN dynamic_JJ pooling_VBG and_CC difference_NN vectors_NNS as_IN follows_VBZ :_: Dynamic_NNP Pooling_NNP Dynamic_NNP Pooling_NNP -LRB-_-LRB- DP_NNP -RRB-_-RRB- -LRB-_-LRB- Socher_NNP et_FW al._FW ,_, 2011_CD -RRB-_-RRB- is_VBZ a_DT method_NN to_TO create_VB fixed-length_NN features_NNS using_VBG the_DT similarity_NN between_IN two_CD vectors_NNS -LRB-_-LRB- Fig._FW 3_LS -RRB-_-RRB- ._.
First_RB ,_, we_PRP create_VBP a_DT similarity_NN matrix_NN between_IN the_DT vec_FW -_: tors_NNS within_IN the_DT two_CD sentences_NNS ._.
The_DT similarity_NN between_IN two_CD vectors_NNS is_VBZ computed_VBN with_IN cosine_NN ''_'' -LRB-_-LRB- 7A_NN -LRB-_-LRB- 7_CD '_'' -LRB-_-LRB- &_CC RPSXWH_NNP WKH_NNP VLPLODULW_NNP \_NN IRU_NNP HDFK_NNP FRPELQDWLRQ_NNP RI_NNP YHFWRUV_NNP 6SOLW_NNP XS_NNP WKH_NNP VLPLODULW_NNP \_NN PDWUL_NNP -LSB-_NNP E_NNP \_VBD ZLQGRZ_NNP VL_NNP -RSB-_NNP H_NNP 6LPLODULW_NNP \_NN PDWUL_NNP -LSB-_NNP 6_CD ''_'' -LRB-_-LRB- 7A_NN -LRB-_-LRB- 7_CD '_'' -LRB-_-LRB- similarity_NN ,_, as_IN follows_VBZ :_: W_NNP -LRB-_-LRB- -LSB-_NNP WUDFW_NNP RQH_NNP VLPLODULW_NNP \_VBD IURP_NNP HDFK_NNP ZLQGRZV_NNP Figure_NNP 3_CD :_: Overview_NNP of_IN Dynamic_NNP Pooling_NNP ._.
Difference_NN vectors_NNS v1_FW ·_FW v2_FW sim_FW -LRB-_-LRB- v1_CD ,_, v2_CD -RRB-_-RRB- =_SYM |_SYM v1_FW |_FW |_FW v2_FW |_FW -LRB-_-LRB- 2_LS -RRB-_-RRB- Recent_JJ studies_NNS of_IN word_NN embeddings_NNS such_JJ as_IN word2vec_CD -LRB-_-LRB- Mikolov_NNP et_FW al._FW ,_, 2013b_JJ -RRB-_-RRB- have_VBP re_SYM -_: vealed_VBD that_IN difference_NN vectors_NNS are_VBP meaningful_JJ ._.
In_IN the_DT well-known_JJ word2vec_JJ example_NN ,_, the_DT vec_NN -_: tor_NN operation_NN ``_`` king_NN -_: man_NN +_NN woman_NN =_SYM queen_NN ''_'' holds_VBZ ._.
That_DT is_VBZ ,_, the_DT difference_NN vector_NN ``_`` king_NN -_: man_NN ''_'' represents_VBZ the_DT information_NN of_IN kingship_NN ._.
Fol_SYM -_: lowing_VBG this_DT insight_NN ,_, we_PRP use_VBP the_DT difference_NN vec_NN -_: tor_NN in_IN the_DT hope_NN that_IN it_PRP can_MD capture_VB some_DT rela_NN -_: tions_NNS between_IN sentences_NNS ._.
The_DT difference_NN vector_NN is_VBZ computed_VBN by_IN subtracting_VBG two_CD vectors_NNS ,_, v1_CD and_CC v2_CD ,_, v1_CD −_CD v2_NN diff_NN -LRB-_-LRB- v1_FW ,_, v2_FW -RRB-_-RRB- =_SYM |_SYM v1_FW −_FW v2_FW |_FW -LRB-_-LRB- 3_LS -RRB-_-RRB- where_WRB vectors_NNS v1_CD and_CC v2_CD denote_VBP vectors_NNS cre_SYM -_: ated_VBN by_IN the_DT RNN_NNP ._.
In_IN this_DT paper_NN ,_, we_PRP utilize_VBP the_DT mean_JJ vector_NN of_IN all_DT difference_NN vectors_NNS created_VBN by_IN a_DT combination_NN of_IN all_PDT the_DT vectors_NNS -LRB-_-LRB- i.e._FW ,_, vectors_NNS that_WDT correspond_VBP to_TO all_PDT the_DT cells_NNS in_IN the_DT matrix_NN S_NNP in_IN Fig._NNP 3_CD -RRB-_-RRB- of_IN two_CD sentences_NNS as_IN a_DT feature_NN vector_NN ._.
3_CD Experiment_NN We_PRP performed_VBD experiments_NNS using_VBG a_DT Japanese_JJ conver_NN -_: sational_JJ corpus_NN ._.
First_RB ,_, we_PRP explain_VBP the_DT dataset_NN used_VBN where_WRB v1_CD and_CC v2_CD denote_JJ vectors_NNS extracted_VBN from_IN sentences_NNS 1_CD and_CC 2_CD ,_, respectively_RB ._.
The_DT row_NN and_CC column_NN order_NN of_IN the_DT matrix_NN is_VBZ placed_VBN depth-first_NN in_IN the_DT RNN_NNP tree_NN ,_, right-to-left_NN ._.
Specifically_RB ,_, ma_SYM -_: trix_NN element_NN s00_NN ,_, which_WDT is_VBZ the_DT first_JJ element_NN of_IN similarity_NN matrix_NN S_NNP ,_, is_VBZ the_DT degree_NN of_IN similarity_NN between_IN the_DT left-most_JJ word_NN vectors_NNS in_IN each_DT sen_NN -_: tence_NN ._.
In_IN DP_NNP ,_, the_DT similarity_NN matrix_NN is_VBZ split_VBN up_RP into_IN a_DT sub-matrix_JJ by_IN a_DT grid_NN window_NN ._.
The_DT size_NN of_IN the_DT grid_NN window_NN is_VBZ computed_VBN depending_VBG on_IN pool_NN -_: ing_NN size_NN np_NN ._.
If_IN sentences_NNS 1_CD and_CC 2_CD have_VBP N_NNP and_CC M_NNP vectors_NNS ,_, respectively_RB ,_, the_DT grid_NN window_NN size_NN is_VBZ -LSB-_JJ N_NNP -RSB-_NNP ×_CD -LSB-_NNP M_NNP -RSB-_NNP ._.
We_PRP extract_VBP a_DT maximum_NN similar_JJ -_: np_NN np_NN ity_NN value_NN element_NN in_IN each_DT sub-matrix_NN to_TO create_VB a_DT pooled_VBN matrix_NN ._.
This_DT pooled_VBD matrix_NN is_VBZ con_JJ -_: sistently_RB fixed-length_JJ because_IN the_DT grid_NN window_NN size_NN dynamically_RB varies_VBZ depending_VBG on_IN sentence_NN length_NN ._.
Similarity_NN information_NN between_IN two_CD sentences_NNS is_VBZ consolidated_VBN into_IN a_DT fixed-length_JJ feature_NN by_IN the_DT DP_NNP ._.
@_SYM 647_CD -LRB-_-LRB- @_IN 9_CD -LRB-_-LRB- %_NN 6_CD -LRB-_-LRB- 9_CD @_IN $_$ 8_CD E8C_NN -LRB-_-LRB- 9476_CD %_NN 6_CD '_'' 84864_CD '_'' '_'' -LRB-_-LRB- D_NNP -LRB-_-LRB- 9_CD %_NN 3_CD -LRB-_-LRB- @_SYM 47_CD E8C9_NNP -LRB-_-LRB- %_NN 46E_CD 64_CD -RRB-_-RRB- -LRB-_-LRB- @_IN @_SYM 647_CD -LRB-_-LRB- @_IN 9_CD -LRB-_-LRB- %_NN 6_CD -LRB-_-LRB- 9_CD '_'' 877_CD -LRB-_-LRB- `_`` A4D_NNS -LRB-_-LRB- '_'' %_NN A_DT -LRB-_-LRB- 389E_CD `_`` G7964_NNP '_'' 4A_NNP '_POS 6%@@_CD `_`` -LRB-_-LRB- @i_FW ''_'' Gui_NNP AE9_NNP -LRB-_-LRB- `_`` G7@A%7A4%A487_NN 9_CD -LRB-_-LRB- 6_CD `_`` 7_CD %_NN 96_CD -LRB-_-LRB- 9_CD `_`` 889_CD -LRB-_-LRB- E_NNP %_NN 796_CD -LRB-_-LRB- G_NNP 8_CD -RRB-_-RRB- A_DT -LRB-_-LRB- 7_CD -LRB-_-LRB- 9476_CD ''_'' 74978_CD -RRB-_-RRB- -RRB-_-RRB- 4_CD '_'' -LRB-_-LRB- ..._: @_IN @_SYM 647_CD -LRB-_-LRB- @_IN 9_CD -LRB-_-LRB- %_NN 6_CD -LRB-_-LRB- 9_CD @_IN '_'' 877_CD -LRB-_-LRB- `_`` A4D_NNS -LRB-_-LRB- '_'' %_NN A_DT -LRB-_-LRB- 389E_CD G7964_NNP '_POS 4A_NN '_'' 6%@@_CD ui_FW Gi9_FW -LRB-_-LRB- i_FW AE9_FW -LRB-_-LRB- %_NN C_NNP @_IN -LRB-_-LRB- 9_CD -LRB-_-LRB- 6_CD 7_CD %_NN 96_CD -LRB-_-LRB- 9_CD -LRB-_-LRB- '_'' %_NN C_NNP @_IN -LRB-_-LRB- GA_NNP 4_CD %_NN @_IN %_NN 9_CD -LRB-_-LRB- -RRB-_-RRB- 9_CD -LRB-_-LRB- @_SYM 4473_CD A%@A_NNP -LRB-_-LRB- ..._: @_IN @_SYM 647_CD -LRB-_-LRB- @_IN 9_CD -LRB-_-LRB- %_NN 6_CD -LRB-_-LRB- 9_CD @_IN $_$ 8_CD E8C_NN -LRB-_-LRB- 9476_CD X_NNP %_NN 9_CD %_NN 7_CD -LRB-_-LRB- @_IN -LRB-_-LRB- ''_'' %_NN 6_CD -LRB-_-LRB- @_IN @_SYM 647_CD -LRB-_-LRB- @_IN 9_CD -LRB-_-LRB- %_NN 6_CD -LRB-_-LRB- 9_CD '_'' 877_CD -LRB-_-LRB- `_`` A4D_NNS -LRB-_-LRB- '_'' %_NN A_DT -LRB-_-LRB- 389E_CD G7964_NNP '_POS 4A_NN '_'' 6%@@_CD uh@Gui_NNP AE9_NNP -LRB-_-LRB- 87A9%@A_NNP 9_CD -LRB-_-LRB- 6_CD 7_CD %_NN 96_CD -LRB-_-LRB- 9_CD CA_NNP G_NNP 9_CD %_NN 9_CD -LRB-_-LRB- 6E_NN -LRB-_-LRB- 9476_CD X_NNP %_NN 9_CD %_NN 7_CD -LRB-_-LRB- @_IN -LRB-_-LRB- ''_'' %_NN 6_CD -LRB-_-LRB- ..._: @_IN @_SYM 647_CD -LRB-_-LRB- @_IN 9_CD -LRB-_-LRB- %_NN 6_CD -LRB-_-LRB- 9_CD 4A_CD @_SYM A%@A_NNP -LRB-_-LRB- 4_CD @_IN @_SYM 8_CD C749C_NNP -LRB-_-LRB- ..._: '_'' 877_CD -LRB-_-LRB- `_`` A4D_NNS -LRB-_-LRB- '_'' %_NN A_DT -LRB-_-LRB- 389E_NNP -LRB-_-LRB- E964_NNP '_POS 4A_NN '_'' 6%@@_CD ui_FW Gi9_FW -LRB-_-LRB- i_FW AE9_FW -LRB-_-LRB- %_NN C_NNP @_IN -LRB-_-LRB- 9_CD -LRB-_-LRB- 6_CD -LRB-_-LRB- '_'' %_NN C_NNP @_IN -LRB-_-LRB- '_'' 877_CD -LRB-_-LRB- `_`` A4D_NNS -LRB-_-LRB- @_IN Figure_NN 4_CD :_: Discourse_NN relation_NN corpus_NN from_IN Japanese_JJ dialogue_NN ._.
Utterance_NN 2_CD Relation_NN -LRB-_-LRB- I_PRP often_RB drink_VBP Smirnoff_NNP Ice_NNP ._. -RRB-_-RRB-
Implicit_JJ EXPANSION_NNP Instantiation_NNP -LRB-_-LRB- It_PRP has_VBZ a_DT refreshing_JJ taste_NN ._. -RRB-_-RRB-
Implicit_JJ CONTINGENCY_NNP Cause_NN -LRB-_-LRB- I_PRP rarely_RB drink_VBP Japanese_JJ sake_NN ._. -RRB-_-RRB-
Implicit_JJ COMPARISON_NNP Contrast_NNP -LRB-_-LRB- Because_IN I_PRP think_VBP its_PRP$ taste_NN is_VBZ so_RB unique_JJ ._. -RRB-_-RRB-
Explicit_JJ CONTINGENCY_NNP Cause_NNP Utterance_NNP 1_CD Connective_JJ -LRB-_-LRB- For_IN example_NN -RRB-_-RRB- -LRB-_-LRB- Because_IN -RRB-_-RRB- -LRB-_-LRB- But_CC -RRB-_-RRB- -LRB-_-LRB- Because_IN -RRB-_-RRB- Table_NNP 1_CD :_: Examples_NNS of_IN utterance_NN pairs_NNS and_CC discourse_NN relations_NNS extracted_VBN from_IN Fig._NNP 4_CD ._.
-LRB-_-LRB- Do_VBP you_PRP drink_VBP alcoholic_JJ bever_NN -_: ages_NNS in_IN your_PRP$ daily_JJ life_NN ?_. -RRB-_-RRB- -RRB-_-RRB-
-LRB-_-LRB- I_PRP often_RB drink_VBP Smirnoff_NNP Ice_NNP ._. -RRB-_-RRB-
-LRB-_-LRB- I_PRP often_RB drink_VBP Smirnoff_NNP Ice_NNP ._. -RRB-_-RRB-
for_IN the_DT experiment_NN ._.
Next_JJ ,_, we_PRP describe_VBP our_PRP$ experi_NNS -_: mental_JJ methodology_NN and_CC comparative_JJ methods_NNS ._.
Fi_SYM -_: nally_RB ,_, we_PRP present_VBP the_DT experimental_JJ results_NNS ._.
3.1_CD Dataset_NNP In_IN this_DT paper_NN ,_, we_PRP focus_VBP on_IN conversational_JJ dialogue_NN because_IN we_PRP want_VBP sophistication_NN of_IN dialogue_NN analysis_NN by_IN using_VBG discourse_NN relations_NNS ._.
The_DT annotation_NN framework_NN follows_VBZ the_DT Penn_NNP Dis_NNP -_: course_NN Treebank_NNP -LRB-_-LRB- PDTB_NNP -RRB-_-RRB- ,_, a_DT corpus_NN of_IN English_NNP texts_NNS from_IN the_DT Wall_NNP Street_NNP Journal_NNP in_IN which_WDT the_DT relations_NNS -LRB-_-LRB- I_PRP rarely_RB drink_VBP Japanese_JJ sake_NN ._. -RRB-_-RRB-
between_IN abstract_JJ objects_NNS in_IN discourse_NN are_VBP annotated_VBN -LRB-_-LRB- Prasad_NNP et_FW al._FW ,_, 2008_CD -RRB-_-RRB- ._.
The_DT PDTB_NNP has_VBZ four_CD classes_NNS -LRB-_-LRB- CONTINGENCY_NNP ,_, COMPARISON_NNP ,_, EXPANSION_NNP ,_, and_CC TEMPORAL_NNP -RRB-_-RRB- and_CC 16_CD types_NNS of_IN discourse_NN rela_NN -_: tion_NN within_IN its_PRP$ hierarchical_JJ structure_NN ._.
In_IN the_DT PDTB_NNP ,_, the_DT discourse_NN relations_NNS are_VBP decided_VBN with_IN connectives_NNS :_: ``_`` because_IN ''_'' ,_, ``_`` and_CC ''_'' ,_, ``_`` but_CC ''_'' ,_, and_CC so_RB on_IN ._.
If_IN a_DT discourse_NN marker_NN -LRB-_-LRB- e.g._FW ,_, a_DT connective_NN -RRB-_-RRB- is_VBZ written_VBN clearly_RB in_IN ei_SYM -_: ther_NN target_NN sentence_NN ,_, the_DT discourse_NN relation_NN is_VBZ cate_NN -_: gorized_VBN as_IN Explicit_NNP ._.
Discourse_NN relations_NNS without_IN any_DT discourse_NN marker_NN are_VBP called_VBN Implicit_NNP ._.
We_PRP annotated_VBD PDTB-style_JJ discourse_NN relations_NNS to_TO the_DT Japanese_JJ conversational_JJ dialogue_NN corpus_NN created_VBN by_IN Higashinaka_NNP et_FW al._FW -LRB-_-LRB- 2014_CD -RRB-_-RRB- ._.
Figure_NN 4_CD shows_VBZ the_DT annotated_JJ Japanese_JJ conversational_JJ dialogue_NN corpus_NN ._.
We_PRP provide_VBP connective_NN tags_NNS to_TO each_DT utterance_NN if_IN they_PRP have_VBP a_DT connective_NN ._.
Connective_JJ elements_NNS have_VBP five_CD at_IN -_: tributes_NNS :_: category_NN ,_, which_WDT denotes_VBZ discourse_NN relation_NN category_NN and_CC can_MD be_VB either_RB explicit_JJ or_CC implicit_JJ ;_: class_NN ,_, which_WDT includes_VBZ the_DT four_CD discourse_NN relations_NNS ;_: type_NN ,_, which_WDT denotes_VBZ detailed_JJ relation_NN types_NNS ;_: rel_NN ,_, which_WDT de_FW -_: notes_VBZ an_DT utterance_NN line_NN number_NN that_WDT has_VBZ a_DT discourse_NN relation_NN ;_: and_CC marker_NN ,_, which_WDT denotes_VBZ the_DT connective_JJ appropriate_JJ for_IN discourse_NN relation_NN if_IN the_DT relation_NN is_VBZ Implicit_NNP ._.
Table_NNP 1_CD gives_VBZ a_DT tabular_JJ view_NN of_IN the_DT utter_JJ -_: ance_NN pairs_NNS from_IN Fig._NNP 4_CD ._.
Note_VB that_IN there_EX is_VBZ another_DT dialogue_NN corpus_NN anno_NN -_: tated_VBN with_IN PDTB-style_JJ discourse_NN relations_NNS -LRB-_-LRB- Tonelli_NNP et_FW al._FW ,_, 2010_CD -RRB-_-RRB- ;_: however_RB ,_, they_PRP focus_VBP on_IN the_DT design_NN of_IN the_DT corpus_NN and_CC do_VB not_RB tackle_VB the_DT problem_NN of_IN discourse_NN relation_NN recognition_NN ._.
3.2_CD Experimental_JJ method_NN and_CC results_NNS We_PRP evaluate_VBP our_PRP$ proposed_VBN approach_NN using_VBG the_DT anno_NN -_: tated_VBN conversational_JJ dialogue_NN corpus_NN ._.
We_PRP created_VBD an_DT implicit_JJ discourse_NN relation_NN classifier_NN using_VBG an_DT SVM_NNP with_IN training_NN data_NNS consisting_VBG of_IN utterance_NN pairs_NNS that_WDT have_VBP an_DT explicit_JJ discourse_NN relation_NN ._.
Explicit_JJ relations_NNS are_VBP more_RBR certain_JJ than_IN implicit_JJ relations_NNS ,_, so_RB explicit_JJ relational_JJ data_NNS have_VBP been_VBN used_VBN as_IN training_NN data_NNS -LRB-_-LRB- Pitler_NNP and_CC Nenkova_NNP ,_, 2009_CD -RRB-_-RRB- ._.
We_PRP performed_VBD the_DT evaluation_NN by_IN classifying_VBG three_CD discourse_NN relations_NNS -LRB-_-LRB- CONTINGENCY_NNP ,_, COMPARI_NNP -_: SON_NNP ,_, and_CC EXPANSION_NNP -RRB-_-RRB- using_VBG classifiers_NNS ._.
Here_RB ,_, we_PRP do_VBP not_RB use_VB the_DT TEMPORAL_NNP relation_NN class_NN be_VB -_: cause_NN far_RB fewer_JJR utterance_NN pairs_NNS have_VBP a_DT relation_NN to_TO TEMPORAL_NNP than_IN the_DT other_JJ relations_NNS ._.
Training_VBG data_NNS consisted_VBN of_IN 5,000_CD utterance_NN pairs_NNS for_IN each_DT relation_NN ._.
Test_NN data_NNS were_VBD utterance_NN pairs_NNS that_WDT have_VBP an_DT implicit_JJ discourse_NN relation_NN ,_, with_IN each_DT relation_NN containing_VBG 500_CD utterance_NN pairs_NNS by_IN random_JJ sampling_NN ._.
We_PRP evaluated_VBD our_PRP$ proposed_VBN method_NN along_IN with_IN several_JJ comparative_JJ methods_NNS ._.
All_PDT the_DT methods_NNS de_IN -_: rive_NN features_NNS for_IN two_CD sentences_NNS to_TO be_VB classified_VBN by_IN the_DT SVM_NNP ._.
The_DT features_NNS used_VBN by_IN the_DT methods_NNS are_VBP de_IN -_: scribed_VBN as_RB below_IN ._.
•_NNP Comparative_NNP methods_NNS Word_VBD pair_NN The_DT word_NN pair_NN feature_NN is_VBZ a_DT basic_JJ feature_NN for_IN discourse_NN recognition_NN ._.
Input_NN sentences_NNS are_VBP split_VBN into_IN words_NNS by_IN a_DT morphological_JJ analyzer_NN MeCab1_NNP -LRB-_-LRB- we_PRP used_VBD this_DT analyzer_NN throughout_IN the_DT paper_NN -RRB-_-RRB- ._.
We_PRP create_VBP word_NN pair_NN tokens_NNS from_IN the_DT combination_NN of_IN words_NNS between_IN two_CD sentences_NNS ._.
Finally_RB ,_, the_DT word_NN pair_NN feature_NN is_VBZ created_VBN by_IN creating_VBG word_NN -_: pair_NN appearance_NN frequency_NN vectors_NNS ._.
Vector_NNP centroid_JJ We_PRP create_VBP a_DT sentence_NN vector_NN by_IN computing_VBG the_DT centroid_NN of_IN all_DT word_NN vectors_NNS in_IN the_DT sen_NN -_: tence_NN and_CC use_VB the_DT vector_NN as_IN a_DT feature_NN ._.
Here_RB ,_, word_NN vectors_NNS are_VBP given_VBN by_IN the_DT word2vec_CD model_NN created_VBN using_VBG Japanese_JJ Wikipedia_NNP data_NNS ._.
Note_VB that_IN the_DT word_NN centroid_JJ vector_NN reflects_VBZ the_DT whole_JJ meaning_NN of_IN the_DT sentence_NN without_IN syntactic_NN structure_NN or_CC word_NN order_NN ._.
RNN_NNP sentence_NN The_DT RNN_NNP sentence_NN feature_NN is_VBZ the_DT root_NN node_NN vector_NN of_IN the_DT RNN_NNP structure_NN ._.
Parameters_NNS of_IN the_DT RNN_NNP are_VBP trained_VBN with_IN data_NNS consist_VBP -_: ing_NN of_IN 100,000_CD utterances_NNS from_IN the_DT afore_NN -_: mentioned_VBN dialogue_NN corpus_NN ._.
The_DT sentence_NN vector_NN differs_VBZ from_IN the_DT word_NN centroid_JJ vec_NN -_: tor_NN in_IN that_DT it_PRP includes_VBZ the_DT information_NN of_IN syntactic_NN structure_NN ._.
•_NNP Proposed_NNP methods_NNS RNN_NNP +_CD DP_NNP The_NNP RNN+DP_NNP feature_NN is_VBZ a_DT concatenation_NN vector_NN with_IN the_DT RNN_NNP sentence_NN vector_NN and_CC Dynamic_NNP Pooling_VBG vector_NN -LRB-_-LRB- window_NN size_NN :_: 5_LS -RRB-_-RRB- ._.
RNN_NNP +_CD DP_NNP +_CD diff_NN The_DT RNN+DP_NNP +_NN diff_NN feature_NN is_VBZ a_DT concatena_NN -_: tion_NN vector_NN with_IN the_DT RNN_NNP sentence_NN vector_NN ,_, Dynamic_NNP Pooling_NNP ,_, and_CC a_DT difference_NN vector_NN ._.
Figure_NN 5_CD shows_VBZ the_DT results_NNS of_IN the_DT overall_JJ classi_NN -_: fication_NN accuracy_NN and_CC McNemar_NNP 's_POS testing_NN ,_, and_CC Ta_SYM -_: ble_NN 2_CD shows_VBZ the_DT implicit_JJ discourse_NN classification_NN per_IN -_: formance_NN for_IN each_DT discourse_NN relation_NN by_IN using_VBG pre_SYM -_: cision_NN ,_, recall_NN ,_, and_CC F-score_NN ._.
As_IN can_MD be_VB seen_VBN in_IN Fig._NNP 5_CD ,_, our_PRP$ proposed_VBN method_NN -LRB-_-LRB- RNN_NNP +_CD DP_NNP +_CD diff_NN -RRB-_-RRB- had_VBD the_DT 1_CD http://taku910.github.io/mecab/_CD CONTINGENCY_NNP Precision_NNP COMPARISON_NNP Precision_NNP Recall_VBP F-score_JJ Recall_VB F-score_NNP Precision_NNP Recall_VB 0.38_CD 0.39_CD 0.42_CD 0.60_CD 0.38_CD 0.26_CD 0.32_CD 0.40_CD 0.26_CD 0.22_CD 0.43_CD 0.66_CD 0.41_CD 0.45_CD 0.41_CD 0.41_CD 0.46_CD 0.38_CD 0.32_CD 0.41_CD 0.43_CD 0.41_CD 0.40_CD 0.47_CD 0.46_CD 0.48_CD 0.29_CD 0.30_CD 0.36_CD 0.40_CD 0.34_CD 0.36_CD 0.37_CD 0.37_CD 0.41_CD 0.36_CD 0.39_CD 0.41_CD 0.53_CD 0.60_CD Word_NN pair_NN Vector_NNP centroid_VBD RNN_NNP sentence_NN RNN_NNP +_CD DP_NNP RNN_NNP +_CD DP_NNP +_CD diff_NN Utterance_NN 1_CD Table_NNP 2_CD :_: Implicit_NN discourse_NN classification_NN scores_NNS ._.
Example_NN of_IN correct_JJ classification_NN by_IN all_DT methods_NNS EXPANSION_NNP F-score_NN 0.28_CD 0.42_CD 0.47_CD 0.45_CD 0.49_CD Predicted_VBN relation_NN COMPARISON_NNP EXPANSION_NNP CONTINGENCY_NNP EXPANSION_NNP -LRB-_-LRB- Snowboarding_NNP is_VBZ hard_JJ for_IN me_PRP ._. -RRB-_-RRB-
-LRB-_-LRB- I_PRP like_VBP variety_NN shows_NNS ._. -RRB-_-RRB-
-LRB-_-LRB- I_PRP 'm_VBP good_JJ at_IN skiing_NN too_RB !_. -RRB-_-RRB-
-LRB-_-LRB- What_WP type_NN of_IN TV_NN programs_NNS do_VBP you_PRP like_IN ?_. -RRB-_-RRB-
Example_NN of_IN correct_JJ classification_NN by_IN RNN_NNP +_CD DP_NNP +_CD diff_NN -LRB-_-LRB- I_PRP went_VBD to_TO an_DT amuse_VB -_: ment_NN park_NN yesterday_NN ._. -RRB-_-RRB-
-LRB-_-LRB- Where_WRB do_VBP you_PRP learn_VB your_PRP$ makeup_NN tech_SYM -_: niques_NNS ?_. -RRB-_-RRB-
-LRB-_-LRB- My_PRP$ favorite_JJ band_NN performed_VBN played_VBD a_DT live_JJ show_NN there_RB ._. -RRB-_-RRB-
-LRB-_-LRB- I_PRP learn_VBP them_PRP by_IN reading_VBG magazines_NNS ._. -RRB-_-RRB-
``_`` ``_`` -LRB-_-LRB- 0.38_CD -RRB-_-RRB- is_VBZ very_RB close_JJ to_TO that_DT of_IN pure_JJ chance_NN -LRB-_-LRB- 0.33_CD -RRB-_-RRB- ._.
We_PRP separately_RB checked_VBD the_DT inter-annotator_JJ agree_VBP -_: ment_NN of_IN discourse_NN relation_NN relation_NN annotation_NN and_CC found_VBD that_IN the_DT accuracy_NN of_IN human_JJ -LRB-_-LRB- taking_VBG another_DT annotator_NN 's_POS annotation_NN as_IN gold_JJ standard_NN -RRB-_-RRB- is_VBZ 0.67_CD ._.
If_IN the_DT upper_JJ bound_VBN is_VBZ 0.67_CD ,_, then_RB our_PRP$ proposed_VBN method_NN -LRB-_-LRB- 0.43_CD -RRB-_-RRB- achieves_VBZ 64_CD %_NN accuracy_NN relative_JJ to_TO human_JJ per_IN -_: formance_NN ,_, which_WDT is_VBZ a_DT lot_NN higher_JJR than_IN 57_CD %_NN accuracy_NN -LRB-_-LRB- 0.38_CD -RRB-_-RRB- of_IN Word_NN pair_NN ,_, showing_VBG our_PRP$ contribution_NN to_TO implicit_JJ discourse_NN relation_NN recognition_NN ._.
We_PRP show_VBP examples_NNS of_IN the_DT discourse_NN relation_NN recognition_NN results_NNS between_IN two_CD Japanese_JJ utterances_NNS in_IN Table_NNP 3_CD ._.
The_DT upper_JJ two_CD examples_NNS show_VBP utterance_NN pairs_NNS that_WDT were_VBD classified_VBN correctly_RB by_IN all_DT methods_NNS ,_, while_IN the_DT two_CD examples_NNS at_IN the_DT bottom_NN were_VBD correctly_RB classified_VBN by_IN only_RB the_DT -LRB-_-LRB- RNN_NNP +_CD DP_NNP +_CD diff_NN -RRB-_-RRB- method_NN ._.
4_CD Discussion_NNP The_NNP accuracy_NN and_CC McNemar_NNP 's_POS testing_NN results_NNS indi_SYM -_: cate_NN that_IN our_PRP$ proposed_VBN approach_NN -LRB-_-LRB- RNN_NNP +_CD DP_NNP +_CD diff_NN -RRB-_-RRB- outperformed_VBD the_DT word-pair_NN and_CC sentence_NN vector_NN ap_SYM -_: proach_NN ,_, demonstrating_VBG that_IN our_PRP$ approach_NN ,_, with_IN its_PRP$ use_NN of_IN various_JJ units_NNS of_IN expression_NN ,_, is_VBZ more_RBR effective_JJ than_IN the_DT approach_NN based_VBN on_IN word_NN pair_NN and_CC sentences_NNS ._. ''_'' '_''
:_: RUG_NNP 3DLU_NNP #_# !_.
9HFWRU_NNP &_CC HQWURLG_NNP ''_'' -LRB-_-LRB- 511_CD 6HQWHQFH_NNP #_# 511_CD '_'' 3_CD #_# ''_'' 511_CD '_'' 3_CD GLII_NNP Table_NNP 3_CD :_: Examples_NNS of_IN discourse_NN relation_NN recognition_NN between_IN two_CD utterances_NNS ._.
Figure_NN 5_CD :_: Comparison_NN of_IN classification_NN accuracy_NN ._.
highest_JJS accuracy_NN -LRB-_-LRB- accuracy_NN =_SYM 0.43_CD -RRB-_-RRB- ,_, and_CC the_DT results_NNS of_IN McNemar_NNP 's_POS testing_NN reveal_VBP a_DT significant_JJ difference_NN between_IN the_DT -LRB-_-LRB- Word_NN pair_NN -RRB-_-RRB- and_CC -LRB-_-LRB- RNN_NNP +_CD DP_NNP +_CD diff_NN -RRB-_-RRB- methods_NNS -LRB-_-LRB- p_FW =_SYM 0.0046_CD ,_, p_SYM <_SYM 0.001_CD -RRB-_-RRB- and_CC between_IN the_DT -LRB-_-LRB- RNN_NNP sentence_NN -RRB-_-RRB- and_CC -LRB-_-LRB- RNN_NNP +_CD DP_NNP +_CD diff_NN -RRB-_-RRB- methods_NNS -LRB-_-LRB- p_FW =_SYM 0.0077_CD ,_, p_SYM <_SYM 0.001_CD -RRB-_-RRB- ._.
In_IN contrast_NN ,_, the_DT differ_VBP -_: ence_NN between_IN the_DT -LRB-_-LRB- Vector_NNP centroid_JJ -RRB-_-RRB- and_CC -LRB-_-LRB- RNN_NNP +_CD DP_NNP +_CD diff_NN -RRB-_-RRB- methods_NNS was_VBD only_RB marginally_RB significant_JJ -LRB-_-LRB- p_JJ =_SYM 0.12_CD -RRB-_-RRB- ._.
The_DT accuracy_NN of_IN the_DT baseline_NN method_NN Word_NN pair_NN Utterance_NN 2_CD 6pp_CD ..._: hp_NN '_'' G_NNP 646_CD -LRB-_-LRB- @_SYM 8_CD ''_'' -LRB-_-LRB- 9_CD A4_CD %_NN 7_CD '_'' %_NN @_IN -LRB-_-LRB- '_'' %_NN 66_CD G_NNP 646_CD -LRB-_-LRB- @_SYM 8_CD ''_'' -LRB-_-LRB- 9_CD A4_CD %_NN 7_CD '_'' %_NN @_IN -LRB-_-LRB- '_'' %_NN 66_CD G_NNP 646_CD -LRB-_-LRB- @_SYM 8_CD ''_'' -LRB-_-LRB- 9_CD G_NNP 646_CD -LRB-_-LRB- @_SYM 8_CD ''_'' -LRB-_-LRB- 9_CD G_NNP 646_CD -LRB-_-LRB- '_'' %_NN @_IN -LRB-_-LRB- '_'' %_NN 66_CD G_NNP 646_CD -LRB-_-LRB- '_'' %_NN @_IN -LRB-_-LRB- '_'' %_NN 66_CD G_NNP 646_CD -LRB-_-LRB- '_'' %_NN @_IN -LRB-_-LRB- '_'' %_NN 66_CD A4_CD %_NN 7_CD @_SYM 8_CD ''_'' -LRB-_-LRB- 9_CD G_NNP 646_CD -LRB-_-LRB- '_'' %_NN @_IN -LRB-_-LRB- '_'' %_NN 66_CD A4_CD %_NN 7_CD @_SYM 8_CD ''_'' -LRB-_-LRB- 9_CD Figure_NN 6_CD :_: Visualization_NNP of_IN RNN_NNP sentence_NN vectors_NNS ._.
G_NNP 646_CD -LRB-_-LRB- '_'' %_NN @_IN -LRB-_-LRB- '_'' %_NN 66_CD A4_CD %_NN 7_CD @_SYM 8_CD ''_'' -LRB-_-LRB- 9_CD Figure_NN 7_CD :_: Visualization_NNP of_IN word_NN centroid_JJ vectors_NNS ._.
Note_VB that_IN the_DT vector_NN ``_`` I_PRP like_VBP soccer_NN more_JJR than_IN baseball_NN ''_'' overlaps_VBZ with_IN the_DT vector_NN ``_`` I_PRP like_VBP baseball_NN more_JJR than_IN soccer_NN ._. ''_'' ._.
In_IN the_DT example_NN in_IN Table_NNP 3_CD ,_, the_DT inputs_NNS classified_VBN correctly_RB by_IN all_DT methods_NNS were_VBD identified_VBN by_IN extract_VB -_: ing_VBG the_DT characteristic_JJ content_NN words_NNS from_IN each_DT ut_SYM -_: terance_NN ._.
For_IN example_NN ,_, in_IN the_DT first_JJ example_NN ,_, the_DT re_SYM -_: lation_NN is_VBZ identified_VBN as_IN COMPARISON_NNP by_IN extracting_VBG the_DT pair_NN ``_`` skiing_NN -_: snowboarding_NN ''_'' ._.
In_IN contrast_NN ,_, in_IN the_DT last_JJ example_NN ,_, while_IN the_DT relation_NN is_VBZ difficult_JJ to_TO identify_VB as_IN EXPANSION_NN by_IN extracting_VBG the_DT pairs_NNS ``_`` makeup_NN -_: magazine_NN ''_'' or_CC ``_`` makeup_NN -_: learn_VB ''_'' ,_, we_PRP can_MD identify_VB the_DT relation_NN by_IN extracting_VBG the_DT expression_NN pairs_NNS ``_`` your_PRP$ makeup_NN techniques_NNS -_: by_IN reading_VBG a_DT magazine_NN ''_'' ._.
By_IN taking_VBG advantage_NN of_IN the_DT various_JJ units_NNS of_IN expression_NN in_IN a_DT sentence_NN ,_, our_PRP$ approach_NN appropriately_RB identifies_VBZ the_DT discourse_NN relation_NN between_IN two_CD sentences_NNS ._.
Our_PRP$ experimental_JJ results_NNS show_VBP that_IN the_DT RNN_NNP vec_NN -_: tors_NNS are_VBP not_RB always_RB superior_JJ to_TO word_NN centroid_JJ vectors_NNS because_IN there_EX are_VBP cases_NNS where_WRB it_PRP is_VBZ not_RB necessary_JJ to_TO consider_VB syntax_NN ._.
Sometimes_RB ,_, word_NN pairs_NNS are_VBP better_RBR suited_VBN for_IN obtaining_VBG the_DT generic_JJ topic_NN of_IN a_DT sentence_NN ._.
However_RB ,_, we_PRP also_RB found_VBD that_IN implicit_JJ discourse_NN rela_NN -_: tion_NN recognition_NN requires_VBZ to_TO detect_VB slight_JJ differences_NNS in_IN expressions_NNS in_IN sentences_NNS ._.
For_IN example_NN ,_, Figs._NNP 6_CD and_CC 7_CD compare_VBP RNN_NNP vectors_NNS and_CC word-centroid_JJ vec_NN -_: tors_NNS in_IN the_DT visualization_NN of_IN vector_NN space_NN ._.
The_DT sen_NN -_: tences_NNS ``_`` I_PRP like_VBP baseball_NN more_JJR than_IN soccer_NN ._. ''_''
and_CC ``_`` I_PRP like_VBP soccer_NN more_JJR than_IN baseball_NN ._. ''_''
are_VBP in_IN different_JJ places_NNS in_IN Fig._NNP 6_CD ._.
If_IN the_DT first_JJ sentence_NN is_VBZ ``_`` I_PRP like_VBP soccer_NN ._. ''_''
and_CC the_DT second_JJ sentence_NN is_VBZ ``_`` I_PRP like_VBP soccer_NN more_JJR than_IN base_NN -_: ball_NN ._. ''_''
,_, the_DT discourse_NN relation_NN between_IN two_CD sentences_NNS is_VBZ EXPANSION_NNP -LRB-_-LRB- I_PRP like_VBP soccer_NN ._.
Moreover_RB ,_, I_PRP like_VBP soc_SYM -_: cer_NN more_JJR than_IN baseball_NN ._. -RRB-_-RRB- ._.
However_RB ,_, if_IN the_DT second_JJ sentence_NN is_VBZ ``_`` I_PRP like_VBP baseball_NN more_JJR than_IN soccer_NN ._. ''_''
,_, the_DT most_RBS appropriate_JJ discourse_NN relation_NN is_VBZ COMPARI_NNP -_: SON_NNP -LRB-_-LRB- I_PRP like_VBP soccer_NN ._.
But_CC I_PRP like_VBP baseball_NN more_JJR than_IN soccer_NN ._. -RRB-_-RRB- ._.
The_DT RNN_NNP vectors_NNS are_VBP able_JJ to_TO capture_VB these_DT different_JJ structures_NNS ,_, enabling_VBG our_PRP$ proposed_VBN method_NN to_TO recognize_VB discourse_NN relations_NNS more_RBR precisely_RB ._.
5_CD Conclusion_NN We_PRP proposed_VBD an_DT implicit_JJ discourse_NN relation_NN detection_NN method_NN using_VBG various_JJ units_NNS of_IN expressions_NNS between_IN two_CD sentences_NNS ._.
All_DT expressions_NNS are_VBP converted_VBN into_IN vectors_NNS by_IN the_DT RNN_NNP and_CC then_RB applied_VBD to_TO Japanese_NNP de_IN -_: pendency_NN structures_NNS ._.
Experimental_JJ results_NNS showed_VBD that_IN our_PRP$ approach_NN performs_VBZ better_JJR than_IN the_DT conven_NN -_: tional_JJ word-pair_NN features_NNS method_NN ._.
This_DT paper_NN is_VBZ the_DT first_JJ to_TO show_VB that_DT various_JJ expression_NN units_NNS in_IN sen_NN -_: tences_NNS are_VBP effective_JJ for_IN implicit_JJ discourse_NN relation_NN recognition_NN ._.
Our_PRP$ future_JJ work_NN is_VBZ to_TO enable_VB more_JJR feature_NN selec_NN -_: tion_NN using_VBG intermediate_JJ expression_NN vectors_NNS and_CC to_TO consider_VB applications_NNS for_IN dialogue_NN systems_NNS ._.
Current_JJ dialogue_NN systems_NNS have_VBP problems_NNS that_IN they_PRP choose_VBP a_DT contextually_RB inappropriate_JJ utterance_NN for_IN the_DT user_NN in_IN -_: put_VB ._.
Since_IN two_CD utterances_NNS with_IN a_DT discourse_NN relation_NN can_MD be_VB coherent_JJ ,_, we_PRP expect_VBP the_DT quality_NN of_IN utterance_NN selection_NN to_TO be_VB increased_VBN by_IN selecting_VBG an_DT utterance_NN that_WDT has_VBZ a_DT discourse_NN relation_NN with_IN the_DT user_NN utterance_NN ._.
G_NNP 646_CD -LRB-_-LRB- @_SYM 8_CD ''_'' -LRB-_-LRB- 9_CD A4_CD %_NN 7_CD '_'' %_NN @_IN -LRB-_-LRB- '_'' %_NN 66_CD G_NNP 646_CD -LRB-_-LRB- @_SYM 8_CD ''_'' -LRB-_-LRB- 9_CD G_NNP 646_CD -LRB-_-LRB- @_SYM 8_CD ''_'' -LRB-_-LRB- 9_CD G_NNP 646_CD -LRB-_-LRB- @_SYM 8_CD ''_'' -LRB-_-LRB- 9_CD A4_CD %_NN 7_CD '_'' %_NN @_IN -LRB-_-LRB- '_'' %_NN 66_CD G_NNP 646_CD -LRB-_-LRB- '_'' %_NN @_IN -LRB-_-LRB- '_'' %_NN 66_CD G_NNP 646_CD -LRB-_-LRB- '_'' %_NN @_IN -LRB-_-LRB- '_'' %_NN 66_CD A4_CD %_NN 7_CD @_SYM 8_CD ''_'' -LRB-_-LRB- 9_CD G_NNP 646_CD -LRB-_-LRB- '_'' %_NN @_IN -LRB-_-LRB- '_'' %_NN 66_CD References_NNS ternational_JJ Conference_NN on_IN Learning_NNP Representations_NNPS -LRB-_-LRB- ICLR_NNP 2013_CD -RRB-_-RRB- ._.
Tomas_NNP Mikolov_NNP ,_, Wen-tau_NNP Yih_NNP ,_, and_CC Geoffrey_NNP Zweig_NNP ._.
2013b_JJ ._.
Linguistic_JJ regularities_NNS in_IN continuous_JJ space_NN word_NN representations_NNS ._.
Proc_NNP of_IN the_DT 2013_CD Conference_NN of_IN the_DT North_JJ American_JJ Chapter_NN of_IN the_DT Association_NNP for_IN Computational_NNP Linguistics_NNPS :_: Human_NNP Language_NNP Tech_NNP -_: nologies_NNS -LRB-_-LRB- NAACL-HLT_JJ 2013_CD -RRB-_-RRB- ,_, pages_NNS 746_CD --_: 751_CD ._.
Joonsuk_NNP Park_NNP and_CC Claire_NNP Cardie_NNP ._.
2012_CD ._.
Improving_NN im_SYM -_: plicit_NN discourse_NN relation_NN recognition_NN through_IN feature_NN set_VBN optimization_NN ._.
Proc_NNP of_IN the_DT 13th_JJ Annual_JJ Meeting_VBG of_IN the_DT Special_JJ Interest_NNP Group_NNP on_IN Discourse_NNP and_CC Dialogue_NNP -LRB-_-LRB- SIGDIAL_NNP 2012_CD -RRB-_-RRB- ,_, pages_NNS 108_CD --_: 112_CD ._.
Emily_NNP Pitler_NNP and_CC Ani_NNP Nenkova_NNP ._.
2009_CD ._.
Using_VBG Syntax_NNP to_TO Disambiguate_NNP Explicit_NNP Discourse_NNP Connectives_NNP in_IN Text_NNP ._.
Proc_NNP of_IN the_DT Joint_NNP Conference_NN of_IN the_DT 47th_JJ Annual_JJ Meet_NNP -_: ing_NN of_IN the_DT ACL_NNP and_CC the_DT 4th_JJ International_NNP Joint_NNP Confer_NNP -_: ence_NN on_IN Natural_JJ Language_NN Processing_NNP of_IN the_DT AFNLP_NNP Short_NNP Papers_NNP -LRB-_-LRB- ACL-IJCNLP_NNP 2009_CD -RRB-_-RRB- ,_, pages_NNS 13_CD --_: 16_CD ._.
Emily_NNP Pitler_NNP ,_, Annie_NNP Louis_NNP ,_, and_CC Ani_NNP Nenkova_NNP ._.
2009_CD ._.
Au_SYM -_: tomatic_JJ Sense_NN Prediction_NN for_IN Implicit_NNP Discourse_NNP Rela_NNP -_: tions_NNS in_IN Text_NN ._.
Proc_NNP of_IN the_DT Joint_NNP Conference_NN of_IN the_DT 47th_JJ Annual_JJ Meeting_VBG of_IN the_DT ACL_NNP and_CC the_DT 4th_JJ International_NNP Joint_NNP Conference_NNP on_IN Natural_NNP Language_NNP Asian_NNP Federa_NNP -_: tion_NN of_IN Natural_JJ Language_NN Processing_NNP -LRB-_-LRB- AFNLP_NNP 2009_CD -RRB-_-RRB- ,_, pages_NNS 683_CD --_: 691_CD ._.
Rashmi_NNP Prasad_NNP ,_, Nikhil_NNP Dinesh_NNP ,_, Alan_NNP Lee_NNP ,_, Eleni_NNP Milt_NNP -_: sakaki_NN ,_, Livio_NNP Robaldo_NNP ,_, Aravind_NNP Joshi_NNP ,_, and_CC Bonnie_NNP Webber_NNP ._.
2008_CD ._.
The_DT Penn_NNP Discourse_NNP TreeBank_NNP 2.0_CD ._.
Proc_NNP of_IN the_DT sixth_JJ international_JJ conference_NN on_IN Lan_NNP -_: guage_NN Resources_NNPS and_CC Evaluation_NNP -LRB-_-LRB- LREC_NNP 2008_CD -RRB-_-RRB- ._.
Attapol_NNP Rutherford_NNP and_CC Nianwen_NNP Xue_NNP ._.
2014_CD ._.
Discov_NNP -_: ering_VBG implicit_JJ discourse_NN relations_NNS through_IN brown_JJ clus_NN -_: ter_NN pair_NN representation_NN and_CC coreference_NN patterns_NNS ._.
Proc_NNP of_IN the_DT 14th_JJ Conference_NN of_IN the_DT European_JJ Chapter_NN of_IN the_DT Association_NNP for_IN Computational_NNP Linguistics_NNP -LRB-_-LRB- EACL_NNP 2014_CD -RRB-_-RRB- ,_, pages_NNS 645_CD --_: 654_CD ,_, April_NNP ._.
Manami_NNP Saito_NNP ,_, Kazuhide_NNP Yamamoto_NNP ,_, and_CC Satoshi_NNP Sekine_NNP ._.
2006_CD ._.
Using_VBG phrasal_JJ patterns_NNS to_TO identify_VB discourse_NN re_SYM -_: lations_NNS ._.
Proc_NNP of_IN the_DT 2006_CD Conference_NN of_IN the_DT North_JJ American_JJ Chapter_NN of_IN the_DT Association_NNP for_IN Computa_NNP -_: tional_JJ Linguistics_NNPS :_: Human_NNP Language_NNP Technologies_NNP -LRB-_-LRB- NAACL-HLT_NNP 2006_CD -RRB-_-RRB- ,_, pages_NNS 133_CD --_: 136_CD ._.
Richard_NNP Socher_NNP ,_, Eric_NNP H._NNP Huang_NNP ,_, Jeffrey_NNP Pennin_NNP ,_, Christo_NNP -_: pher_NN D_NNP Manning_NNP ,_, and_CC Andrew_NNP Y._NNP Ng_NNP ._.
2011_CD ._.
Dy_SYM -_: namic_NN Pooling_NN and_CC Unfolding_NNP Recursive_NNP Autoencoders_NNP for_IN Paraphrase_NNP Detection_NNP ._.
Proc_NNP of_IN Advances_NNPS in_IN Neural_NNP Information_NNP Processing_NNP Systems_NNP -LRB-_-LRB- NIPS_NNP 2011_CD -RRB-_-RRB- ,_, pages_NNS 801_CD --_: 809_CD ._.
Jun_NNP Sugiura_NNP ,_, Naoya_NNP Inoue_NNP ,_, and_CC Kentaro_NNP Inui_NNP ._.
2013_CD ._.
Rec_NN -_: ognizing_VBG Implicit_NNP Discourse_NNP Relations_NNPS through_IN Abduc_NNP -_: tive_JJ Reasoning_NN with_IN Large-scale_JJ Lexical_NNP Knowledge_NNP ._.
Proc_NNP of_IN the_DT 1st_CD Workshop_NNP on_IN Natural_NNP Language_NNP and_CC Automated_NNP Reasoning_NN -LRB-_-LRB- NLPAR_NNP 2013_CD -RRB-_-RRB- ,_, pages_NNS 76_CD --_: 87_CD ._.
Or_CC Biran_NNP and_CC Kathleen_NNP McKeown_NNP ._.
2013_CD ._.
Aggregated_JJ word_NN pair_NN features_NNS for_IN implicit_JJ discourse_NN relation_NN dis_SYM -_: ambiguation_NN ._.
Proc_NNP of_IN the_DT 51st_CD Annual_JJ Meeting_VBG of_IN the_DT Association_NNP for_IN Computational_NNP Linguistics_NNP -LRB-_-LRB- ACL_NNP 2013_CD -RRB-_-RRB- ,_, pages_NNS 69_CD --_: 73_CD ._.
Shima_NNP Gerani_NNP ,_, Yashar_NNP Mehdad_NNP ,_, Giuseppe_NNP Carenini_NNP ,_, Ray_NNP -_: mond_NN T._NNP Ng_NNP ,_, and_CC Bita_NNP Nejat_NNP ._.
2014_CD ._.
Abstractive_JJ sum_NN -_: marization_NN of_IN product_NN reviews_NNS using_VBG discourse_NN struc_NN -_: ture_NN ._.
Proc_NNP of_IN the_DT 2014_CD Conference_NN on_IN Empirical_NNP Meth_NNP -_: ods_NNS in_IN Natural_JJ Language_NN Processing_NNP -LRB-_-LRB- EMNLP_NNP 2014_CD -RRB-_-RRB- ,_, pages_NNS 1602_CD --_: 1613_CD ._.
Ryuichiro_NNP Higashinaka_NNP ,_, Kenji_NNP Imamura_NNP ,_, Toyomi_NNP Me_PRP -_: guro_NN ,_, Chiaki_NNP Miyazaki_NNP ,_, Nozomi_NNP Kobayashi_NNP ,_, Hiroaki_NNP Sugiyama_NNP ,_, Toru_NNP Hirano_NNP ,_, Toshiro_NNP Makino_NNP ,_, and_CC Yoshi_NNP -_: hiro_NN Matsuo_NNP ._.
2014_CD ._.
Towards_IN an_DT Open_NNP Domain_NNP Con_NN -_: versational_JJ System_NNP Fully_RB Based_VBD on_IN Natural_JJ Language_NN Processing_NNP ._.
Proc_NNP of_IN the_DT 25th_JJ International_NNP Conference_NNP on_IN Computational_NNP Linguistics_NNP -LRB-_-LRB- COLING_NNP 2014_CD -RRB-_-RRB- ,_, pages_NNS 928_CD --_: 939_CD ._.
Taku_NNP Kudo_NNP and_CC Yuji_NNP Matsumoto_NNP ._.
2003_CD ._.
Fast_RB methods_NNS for_IN kernel-based_JJ text_NN analysis_NN ._.
Proc_NNP of_IN the_DT 41st_CD Annual_JJ Meeting_VBG of_IN the_DT Association_NNP for_IN Computational_NNP Linguis_NNP -_: tics_NNS -LRB-_-LRB- ACL_NNP 2003_CD -RRB-_-RRB- ,_, pages_NNS 24_CD --_: 31_CD ._.
Man_NN Lan_NNP ,_, Yu_NNP Xu_NNP ,_, and_CC Zhengyu_NNP Niu_NNP ._.
2013_CD ._.
Leveraging_VBG Synthetic_NNP Discourse_NNP Data_NNP via_IN Multi-task_NNP Learning_NNP for_IN Implicit_NNP Discourse_NNP Relation_NNP Recognition_NNP ._.
Proc_NNP of_IN the_DT 51st_CD Annual_JJ Meeting_VBG of_IN the_DT Association_NNP for_IN Computa_NNP -_: tional_JJ Linguistics_NNP -LRB-_-LRB- ACL_NNP 2013_CD -RRB-_-RRB- ,_, pages_NNS 476_CD --_: 485_CD ._.
Jiwei_NNP Li_NNP ,_, Rumeng_NNP Li_NNP ,_, and_CC Eduard_NNP Hovy_NNP ._.
2014_CD ._.
Re_NNP -_: cursive_JJ deep_JJ models_NNS for_IN discourse_NN parsing_NN ._.
Proc_NNP of_IN the_DT 2014_CD Conference_NN on_IN Empirical_JJ Methods_NNS in_IN Natu_NNP -_: ral_NN Language_NN Processing_NNP -LRB-_-LRB- EMNLP_NNP 2014_CD -RRB-_-RRB- ,_, pages_NNS 2061_CD --_: 2069_CD ._.
Ziheng_NNP Lin_NNP ,_, Min-Yen_NNP Kan_NNP ,_, and_CC Hwee_NNP Tou_NNP Ng_NNP ._.
2009_CD ._.
Recognizing_VBG Implicit_NNP Discourse_NNP Relations_NNPS in_IN the_DT Penn_NNP Discourse_NNP Treebank_NNP ._.
Proc_NNP of_IN the_DT 2009_CD Conference_NN on_IN Empirical_JJ Methods_NNS in_IN Natural_JJ Language_NN Processing_NNP -LRB-_-LRB- EMNLP_NNP 2009_CD -RRB-_-RRB- ,_, pages_NNS 343_CD --_: 351_CD ._.
Shujie_NNP Liu_NNP ,_, Nan_NNP Yang_NNP ,_, Mu_NNP Li_NNP ,_, and_CC Ming_NNP Zhou_NNP ._.
2014_CD ._.
A_DT recursive_JJ recurrent_JJ neural_JJ network_NN for_IN statistical_JJ ma_NN -_: chine_NN translation_NN ._.
Proc_NNP of_IN the_DT 52nd_JJ Annual_JJ Meeting_VBG of_IN the_DT Association_NNP for_IN Computational_NNP Linguistics_NNP -LRB-_-LRB- ACL_NNP 2014_CD -RRB-_-RRB- ,_, pages_NNS 1491_CD --_: 1500_CD ._.
Daniel_NNP Marcu_NNP and_CC Abdessamad_NNP Echihabi_NNP ._.
2002_CD ._.
An_DT Un_SYM -_: supervised_JJ Approach_NNP to_TO Recognizing_VBG Discourse_NNP Rela_NNP -_: tions_NNS ._.
Proc_NNP of_IN the_DT 40th_JJ Annual_JJ Meeting_VBG on_IN Associa_NNP -_: tion_NN for_IN Computational_NNP Linguistics_NNP -LRB-_-LRB- ACL_NNP 2002_CD -RRB-_-RRB- ,_, pages_NNS 368_CD --_: 375_CD ._.
Tomas_NNP Mikolov_NNP ,_, Kai_NNP Chen_NNP ,_, Greg_NNP Corrado_NNP ,_, and_CC Jeffrey_NNP Dean_NNP ._.
2013a_NNS ._.
Efficient_JJ Estimation_NN of_IN Word_NNP Represen_NNP -_: tations_NNS in_IN Vector_NNP Space_NNP ._.
Proc_NNP of_IN the_DT Workshop_NNP at_IN In_NNP -_: Sara_NNP Tonelli_NNP ,_, Giuseppe_NNP Riccardi_NNP ,_, Rashmi_NNP Prasad_NNP ,_, and_CC Ar_SYM -_: avind_NN Joshi_NNP ._.
2010_CD ._.
Annotation_NN of_IN Discourse_NNP Relations_NNPS for_IN Conversational_NNP Spoken_NNP Dialogs_NNPS ._.
Proc_NNP of_IN the_DT Sev_NNP -_: enth_NN International_NNP Conference_NNP on_IN Language_NNP Resources_NNPS and_CC Evaluation_NNP -LRB-_-LRB- LREC_NNP 2010_CD -RRB-_-RRB- ,_, pages_NNS 19_CD --_: 21_CD ._.
Xun_NNP Wang_NNP ,_, Sujian_NNP Li_NNP ,_, Jiwei_NNP Li_NNP ,_, and_CC Wenjie_NNP Li_NNP ._.
2012_CD ._.
Im_SYM -_: plicit_NN discourse_NN relation_NN recognition_NN by_IN selecting_VBG typi_SYM -_: cal_JJ training_NN examples_NNS ._.
Proc_NNP of_IN the_DT 24th_JJ International_NNP Conference_NNP on_IN Computational_NNP Linguistics_NNP -LRB-_-LRB- COLING_NNP 2012_CD -RRB-_-RRB- ,_, pages_NNS 2757_CD --_: 2772_CD ._.
