Recognizing_VBG Complex_JJ Negation_NN on_IN Twitter_NNP Abstract_NNP After_IN the_DT Great_NNP East_NNP Japan_NNP Earthquake_NN in_IN 2011_CD ,_, an_DT abundance_NN of_IN false_JJ rumors_NNS were_VBD dis_SYM -_: seminated_VBN on_IN Twitter_NNP that_WDT actually_RB hindered_VBD rescue_NN activities_NNS ._.
This_DT work_NN presents_VBZ a_DT method_NN for_IN recognizing_VBG the_DT negation_NN of_IN predicates_NNS on_IN Twitter_NNP to_TO find_VB Japanese_JJ tweets_NNS that_WDT refute_VBP false_JJ rumors_NNS ._.
We_PRP assume_VBP that_IN the_DT predicate_NN ``_`` oc_SYM -_: cur_NN ''_'' is_VBZ negated_VBN in_IN the_DT sentence_NN ``_`` The_DT guy_NN who_WP tweeted_VBD that_IN a_DT nuclear_JJ explosion_NN occurred_VBD has_VBZ watched_VBN too_RB many_JJ SF_NNP movies_NNS ._. ''_''
The_DT challenge_NN is_VBZ in_IN the_DT treatment_NN of_IN such_JJ complex_JJ negation_NN ._.
We_PRP have_VBP to_TO recognize_VB a_DT wide_JJ range_NN of_IN complex_JJ negation_NN expressions_NNS such_JJ as_IN ``_`` it_PRP is_VBZ theoreti_SYM -_: cally_RB impossible_JJ that_IN ..._: ''_'' and_CC ``_`` The_DT guy_NN who_WP ..._: watched_VBN too_RB many_JJ SF_NNP movies_NNS ._. ''_''
We_PRP tackle_VBP this_DT problem_NN using_VBG a_DT combination_NN of_IN a_DT supervised_JJ classifier_NN and_CC clusters_NNS of_IN n-grams_JJ derived_VBN from_IN large_JJ un-annotated_JJ corpora_NN ._.
The_DT n-gram_JJ clus_NN -_: ters_NNS give_VBP us_PRP a_DT gain_NN of_IN about_IN 22_CD %_NN in_IN F-score_NN for_IN complex_JJ negations_NNS ._.
1_CD Introduction_NNP After_IN the_DT Great_NNP East_NNP Japan_NNP Earthquake_NN in_IN 2011_CD ,_, hun_SYM -_: dreds_NNS of_IN false_JJ rumors_NNS were_VBD disseminated_VBN on_IN Twitter_NNP ._.
At_IN the_DT same_JJ time_NN ,_, many_JJ experts_NNS and_CC other_JJ knowl_NN -_: edgeable_JJ people_NNS posted_VBD tweets_NNS to_TO refute_VB such_JJ false_JJ rumors_NNS as_IN ``_`` There_EX is_VBZ no_DT truth_NN to_TO the_DT rumor_NN that_IN a_DT nu_NN -_: clear_JJ explosion_NN has_VBZ occurred_VBN in_IN Fukushima_NNP ._. ''_''
How_WRB -_: ever_RB ,_, since_IN many_JJ people_NNS did_VBD not_RB notice_VB such_JJ refuta_NN -_: tions_NNS ,_, they_PRP retweeted_VBD the_DT false_JJ rumors_NNS ,_, inadvertently_RB fueling_VBG the_DT confusion_NN and_CC creating_VBG serious_JJ obstacles_NNS to_TO rescue_VB activities_NNS ._.
This_DT paper_NN presents_VBZ a_DT method_NN that_WDT recognizes_VBZ the_DT negation_NN of_IN predicates_NNS on_IN Twitter_NNP to_TO identify_VB the_DT tweets_NNS that_WDT refute_VBP false_JJ rumors1_CD ._.
Our_PRP$ proposed_VBN method_NN uses_VBZ a_DT supervised_JJ learning_NN method_NN to_TO judge_VB whether_IN a_DT given_VBN predicate_NN in_IN a_DT tweet_NN is_VBZ negated_VBN ._. ._.
An_DT important_JJ point_NN here_RB is_VBZ that_IN we_PRP have_VBP to_TO deal_VB with_IN complex_JJ forms_NNS of_IN negations_NNS to_TO achieve_VB our_PRP$ final_JJ goal_NN ;_: the_DT detection_NN of_IN false_JJ rumors_NNS ._.
Note_VB that_IN although_IN our_PRP$ target_NN data_NNS are_VBP Japanese_JJ tweets_NNS ,_, we_PRP provide_VBP exam_NN -_: ples_NNS in_IN English_NNP for_IN readability_NN ._.
S1_CD It_PRP is_VBZ theoretically_RB impossible_JJ that_IN a_DT nuclear_JJ ex_FW -_: plosion_NN occurred_VBD in_IN Fukushima_NNP ._.
S2_CD The_DT guy_NN who_WP tweeted_VBD that_IN a_DT nuclear_JJ explosion_NN occurred_VBD has_VBZ watched_VBN too_RB many_JJ SF_NNP movies_NNS ._.
Both_DT S1_CD and_CC S2_CD refute_VBP that_IN a_DT nuclear_JJ explosion_NN occurred_VBD ._.
In_IN other_JJ words_NNS ,_, the_DT predicate_NN ``_`` occur_VBP ''_'' is_VBZ negated_VBN ,_, even_RB though_IN no_DT negation_NN words_NNS -LRB-_-LRB- e.g._FW ,_, ``_`` not_RB ''_'' -RRB-_-RRB- are_VBP explicitly_RB written_VBN in_IN the_DT sentences_NNS ._.
Many_JJ sen_SYM -_: tences_NNS similar_JJ to_TO the_DT above_JJ examples_NNS were_VBD actually_RB posted_VBN on_IN Twitter_NNP to_TO refute_VB false_JJ rumors_NNS after_IN the_DT earthquake_NN ._.
In_IN this_DT paper_NN ,_, we_PRP categorize_VBP negation_NN into_IN two_CD types_NNS :_: simple_JJ and_CC complex_JJ ._.
Given_VBN a_DT predicate_NN that_WDT is_VBZ annotated_VBN as_IN negation_NN by_IN a_DT human_JJ annotator_NN ,_, its_PRP$ cat_NN -_: egorization_NN is_VBZ done_VBN based_VBN on_IN the_DT following_VBG criteria_NNS ._.
Simple_NN negation_NN If_IN at_IN least_JJS one_CD of_IN the_DT words_NNS in_IN the_DT same_JJ phrase_NN of_IN the_DT negated_VBN predicate_NN ends_NNS with_IN ``_`` ない_FW nai_FW ,_, わけない_CD wakenai_NN ,_, ぬ_CD nu_NN -LRB-_-LRB- all_DT of_IN which_WDT mean_VBP not_RB -RRB-_-RRB- ''_'' we_PRP define_VBP this_DT form_NN as_IN sim_NN -_: ple_NN negation_NN ._.
These_DT three_CD words_NNS are_VBP called_VBN sim_SYM -_: ple_NN negation_NN suffixes_NNS -LRB-_-LRB- SNW_NNP -RRB-_-RRB- hereafter_NN -LRB-_-LRB- Table_NNP 1_CD -RRB-_-RRB- and_CC roughly_RB correspond_VB to_TO such_JJ simple_JJ forms_NNS of_IN negations_NNS in_IN English_NNP as_IN ``_`` do_VBP not_RB ''_'' and_CC ``_`` has_VBZ not_RB ._. ''_''
1Even_JJ though_IN other_JJ linguistic_JJ expressions_NNS might_MD also_RB be_VB use_NN -_: ful_NN to_TO detect_VB false_JJ rumors_NNS ,_, we_PRP focus_VBP on_IN negation_NN ._.
Complex_JJ negation_NN If_IN a_DT human_JJ annotator_NN annotates_VBZ a_DT predicate_NN as_IN negated_VBN even_RB without_IN words_NNS that_WDT end_VBP with_IN SNW_NNP in_IN the_DT same_JJ phrase_NN of_IN the_DT negated_VBN predicate_NN ,_, we_PRP define_VBP this_DT form_NN as_IN com_NN -_: plex_NN negation_NN ._.
For_IN instance_NN ,_, the_DT literal_JJ Japanese_JJ translations_NNS of_IN S1_NNP and_CC S2_NNP do_VBP not_RB have_VB any_DT words_NNS that_WDT end_VBP with_IN SNW_NNP ._.
We_PRP only_RB focus_VB on_IN complex_JJ negation_NN in_IN this_DT paper_NN ,_, since_IN simple_JJ negation_NN can_MD be_VB recognized_VBN by_IN match_NN -_: ing_NN SNW_NNP against_IN the_DT words_NNS in_IN the_DT same_JJ phrase_NN of_IN the_DT predicate_NN with_IN a_DT high_JJ accuracy_NN ._.
Thus_RB ,_, we_PRP have_VBP to_TO recognize_VB a_DT wide_JJ range_NN of_IN ex_FW -_: pressions_NNS that_WDT indicate_VBP negation_NN ,_, including_VBG ``_`` it_PRP is_VBZ the_DT -_: oretically_RB impossible_JJ that_IN ..._: ''_'' and_CC ``_`` The_DT guy_NN who_WP ..._: has_VBZ watched_VBN too_RB many_JJ SF_NNP movies_NNS ._. ''_''
To_TO tackle_VB this_DT problem_NN ,_, we_PRP use_VBP ,_, as_IN features_NNS for_IN our_PRP$ supervised_JJ classifier_NN ,_, n-gram_JJ clusters_NNS derived_VBN from_IN large_JJ un_NN -_: annotated_JJ corpora_NN and_CC generalize_VB specific_JJ words_NNS or_CC n-grams_NNS for_IN them_PRP ._.
Consider_VB this_DT sentence_NN :_: ``_`` It_PRP is_VBZ un_SYM -_: true_JJ that_IN Kyoto_NNP has_VBZ been_VBN heavily_RB contaminated_VBN by_IN radiation_NN ._. ''_''
If_IN such_PDT a_DT sentence_NN exists_VBZ in_IN the_DT training_NN data_NNS for_IN our_PRP$ classifier_NN and_CC the_DT predicate_NN ``_`` contami_NN -_: nated_VBN ''_'' is_VBZ annotated_VBN as_IN ``_`` negated_VBN ,_, ''_'' by_IN the_DT generaliza_NN -_: tion_NN of_IN the_DT word_NN ``_`` untrue_JJ ''_'' to_TO a_DT cluster_NN that_WDT includes_VBZ ``_`` theoretically_RB impossible_JJ ,_, ''_'' our_PRP$ method_NN might_MD suc_VB -_: cessfully_RB recognize_VBP that_IN ``_`` occur_VBP ''_'' in_IN S1_NNP is_VBZ negated_VBN ._.
It_PRP also_RB might_MD even_RB be_VB possible_JJ to_TO recognize_VB the_DT nega_NN -_: tion_NN in_IN S2_CD if_IN several_JJ n-grams_NNS such_JJ as_IN ``_`` guy_NN ,_, ''_'' ``_`` too_RB many_JJ ,_, ''_'' and_CC ``_`` SF_NNP movies_NNS ''_'' are_VBP generalized_VBN to_TO certain_JJ clusters_NNS and_CC training_NN samples_NNS can_MD be_VB found_VBN like_IN ``_`` The_DT people_NNS who_WP claim_VBP that_IN Tokyo_NNP was_VBD completely_RB de_IN -_: stroyed_VBN have_VBP watched_VBN too_RB many_JJ Godzilla_NNP movies_NNS ._. ''_''
Through_IN a_DT series_NN of_IN experiments_NNS ,_, we_PRP show_VBP that_IN n_SYM -_: gram_NN clusters_NNS give_VBP a_DT 22_CD %_NN improvement_NN in_IN F-score_NN for_IN complex_JJ negations_NNS over_IN the_DT rule-based_JJ baseline_NN ._.
Our_PRP$ method_NN successfully_RB recognizes_VBZ the_DT complex_JJ forms_NNS of_IN such_JJ negations_NNS as_IN ``_`` An_DT urban_JJ legend_NN that_WDT ..._: ''_'' and_CC ``_`` Did_VBD dome_NN idiot_NN really_RB say_VBP that_IN ..._: ?_. ''_'' ._.
To_TO the_DT best_JJS of_IN our_PRP$ knowledge_NN ,_, this_DT work_NN is_VBZ the_DT first_JJ attempt_NN to_TO introduce_VB n-gram_JJ clusters_NNS for_IN recognizing_VBG complex_JJ forms_NNS of_IN negation_NN ._.
Saur_NNP ́ı_NNP -LRB-_-LRB- 2008_CD -RRB-_-RRB- developed_VBD a_DT rule-based_JJ method_NN to_TO recognize_VB the_DT factuality_NN of_IN events_NNS ,_, whose_WP$ negation_NN recognition_NN can_MD be_VB regarded_VBN as_IN a_DT subtask_NN ._.
However_RB ,_, it_PRP seems_VBZ quite_RB difficult_JJ to_TO write_VB rules_NNS that_WDT cover_VBP the_DT complex_JJ negation_NN forms_NNS exemplified_VBN above_IN ._.
We_PRP expect_VBP that_DT n-gram_JJ clusters_NNS play_VBP the_DT role_NN of_IN the_DT condition_NN parts_NNS of_IN the_DT rules_NNS for_IN complex_JJ negation_NN forms_NNS ._.
Also_RB note_NN that_IN we_PRP evaluate_VBP the_DT performance_NN of_IN our_PRP$ method_NN using_VBG the_DT cross-validation_NN on_IN tweet_NN data_NNS posted_VBD during_IN one_CD month_NN immediately_RB after_IN the_DT Great_NNP East_NNP Japan_NNP Earthquake_NN ._.
There_EX is_VBZ a_DT possibil_NN -_: ity_NN that_IN this_DT evaluation_NN scheme_NN may_MD provide_VB a_DT high_JJ accuracy_NN that_WDT can_MD not_RB be_VB achieved_VBN on_IN real_JJ situation_NN since_IN the_DT test_NN data_NNS and_CC training_NN data_NNS were_VBD taken_VBN from_IN the_DT tweets_NNS concerning_VBG the_DT same_JJ disaster_NN ._.
Nonethe_NNP -_: less_JJR ,_, it_PRP is_VBZ difficult_JJ to_TO provide_VB test_NN and_CC training_NN data_NNS concerning_VBG distinct_JJ large_JJ scale_NN disasters_NNS ._.
Therefore_RB ,_, we_PRP tried_VBD another_DT setting_NN in_IN which_WDT the_DT tweets_NNS posted_VBD during_IN the_DT two_CD days_NNS immediately_RB after_IN the_DT Great_NNP East_NNP Japan_NNP Earthquake_NN were_VBD used_VBN as_IN training_NN data_NNS and_CC the_DT tweets_NNS posted_VBD after_IN the_DT first_JJ two_CD days_NNS were_VBD used_VBN as_IN test_NN data_NNS ._.
This_DT evaluation_NN scheme_NN simulates_VBZ the_DT situ_NN -_: ation_NN where_WRB new_JJ large_JJ scale_NN disaster_NN occurs_VBZ and_CC we_PRP have_VBP to_TO prepare_VB our_PRP$ system_NN using_VBG the_DT data_NNS available_JJ during_IN first_JJ few_JJ days_NNS ._.
We_PRP expect_VBP that_IN the_DT results_NNS give_VBP a_DT lower_JJR bound_VBN of_IN the_DT performance_NN of_IN our_PRP$ method_NN ._.
2_CD Related_JJ Work_NN Previous_JJ studies_NNS addressed_VBD negation_NN recognition_NN as_IN part_NN of_IN modality/factuality_JJ analysis_NN ._.
Saur_NNP ́ı_NNP and_CC Puste_NNP -_: jovsky_NN -LRB-_-LRB- 2009_CD -RRB-_-RRB- annotated_JJ factuality_NN for_IN each_DT event_NN in_IN TimeBank_NNP -LRB-_-LRB- Pustejovsky_NNP et_FW al._FW ,_, 2003_CD -RRB-_-RRB- ._.
Saur_NNP ́ı_NNP and_CC Pustejovsky_NNP -LRB-_-LRB- 2007_CD -RRB-_-RRB- defined_VBN three_CD markers_NNS :_: polarity_NN particles_NNS such_JJ as_IN ``_`` not_RB ''_'' or_CC ``_`` no_RB ,_, ''_'' modal_JJ particles_NNS such_JJ as_IN ``_`` may_MD ''_'' or_CC ``_`` likely_JJ ,_, ''_'' and_CC situation_NN selecting_NN pred_VBD -_: icates_NNS such_JJ as_IN ``_`` prevent_VB ''_'' or_CC ``_`` suggest_VBP ._. ''_''
They_PRP used_VBD these_DT cue_NN words_NNS to_TO detect_VB polarity_NN -LRB-_-LRB- positive_JJ ,_, negative_JJ ,_, or_CC unknown_NN -RRB-_-RRB- and_CC epistemic_JJ modality_NN -LRB-_-LRB- certain_JJ ,_, prob_SYM -_: able_JJ ,_, possible_JJ ,_, or_CC unknown_NN -RRB-_-RRB- and_CC combined_VBN these_DT two_CD values_NNS to_TO indicate_VB an_DT event_NN 's_POS factuality_NN ._.
de_IN Marneffe_NNP et_FW al._FW -LRB-_-LRB- 2012_CD -RRB-_-RRB- annotated_VBD the_DT veridi_NNS -_: cality_NN which_WDT roughly_RB corresponds_VBZ to_TO the_DT factual_JJ -_: ity_NN for_IN each_DT event_NN by_IN ten_CD annotators_NNS to_TO the_DT Fact_NNP -_: Bank_NNP corpus_VBZ -LRB-_-LRB- Saur_NNP ́ı_NN and_CC Pustejovsky_NNP ,_, 2009_CD -RRB-_-RRB- and_CC trained_VBD a_DT classifier_NN to_TO predict_VB the_DT probabilistic_JJ dis_NN -_: tribution_NN of_IN event_NN veridicality_NN using_VBG a_DT maximum_NN en_IN -_: tropy_JJ method_NN -LRB-_-LRB- Berger_NNP et_FW al._FW ,_, 1996_CD -RRB-_-RRB- ._.
They_PRP compared_VBD the_DT distributions_NNS predicted_VBN by_IN the_DT classifier_NN and_CC the_DT distributions_NNS annotated_VBN by_IN human_JJ annotators_NNS ._.
Soni_NNP et_FW al._FW -LRB-_-LRB- 2014_CD -RRB-_-RRB- examined_VBD the_DT factuality_NN of_IN quoted_VBN statements_NNS in_IN tweets_NNS ._.
They_PRP used_VBD the_DT cue_NN words_NNS defined_VBN in_IN Saur_NNP ́ı_NNP -LRB-_-LRB- 2008_CD -RRB-_-RRB- that_WDT introduced_VBD the_DT quoted_VBN event_NN negation_NN or_CC speculation_NN and_CC the_DT tweet_NN 's_POS author_NN ._.
They_PRP reported_VBD that_IN conducting_VBG factuality_NN analysis_NN for_IN quoted_VBN statements_NNS is_VBZ quite_RB difficult_JJ due_JJ to_TO the_DT error_NN rate_NN ._.
核爆発_CD か_CD nuclear_JJ explosion_NN 起きる_CD なんて_CD occur_VBP verb_NN adverbial_JJ particle_NN テ_CD マ_CD た_NN false_JJ rumor_NN be_VB noun_NN verb_NN that_WDT warns_VBZ the_DT occurrence_NN of_IN the_DT explosion_NN ._. ''_''
The_DT au_SYM -_: thor_NN of_IN this_DT tweet_NN expresses_VBZ his_PRP$ opinion_NN that_IN the_DT ex_FW -_: plosion_NN does_VBZ not_RB occur_VB ._.
For_IN each_DT word_NN in_IN the_DT list_NN ,_, the_DT features_NNS indicate_VBP the_DT existence/non-existence_NN of_IN the_DT word_NN in_IN the_DT target_NN sentence_NN and_CC its_PRP$ position_NN -LRB-_-LRB- ``_`` before_RB ''_'' or_CC ``_`` after_IN ''_'' the_DT target_NN predicate_NN -RRB-_-RRB- ._.
They_PRP also_RB include_VBP the_DT distance_NN of_IN the_DT negation_NN words_NNS in_IN the_DT CNW_NNP from_IN the_DT target_NN predicate_NN ._.
We_PRP encode_VBP the_DT distance_NN using_VBG 11_CD -_: bit_NN binary_JJ features_NNS -LRB-_-LRB- i.e._FW ,_, 1_CD ,_, 2_CD ,_, ..._: ,_, 10_CD ,_, or_CC more_JJR -RRB-_-RRB- ._.
In_IN the_DT above_JJ example_NN ,_, the_DT feature_NN set_VBN encodes_VBZ the_DT infor_NN -_: mation_NN that_IN the_DT word_NN ``_`` テ_FW マ_FW dema_FW -LRB-_-LRB- false_JJ rumor_NN -RRB-_-RRB- ''_'' in_IN the_DT list_NN is_VBZ located_VBN after_IN the_DT target_NN predicate_VB ``_`` 起きる_FW okiru_FW -LRB-_-LRB- occur_VBP -RRB-_-RRB- ''_'' along_IN with_IN the_DT distance_NN between_IN ``_`` テ_FW マ_FW dema_FW -LRB-_-LRB- false_JJ rumor_NN -RRB-_-RRB- ''_'' and_CC ``_`` 起きる_FW okiru_FW -LRB-_-LRB- occur_VBP -RRB-_-RRB- ._. ''_''
Sentiment_NN We_PRP also_RB consider_VBP the_DT sentiment_NN polar_JJ -_: ity_NN of_IN the_DT words_NNS -LRB-_-LRB- positive_JJ or_CC negative_JJ -RRB-_-RRB- in_IN the_DT bunset_NN -_: sus_NN from_IN which_WDT the_DT n-grams_NNS in_IN the_DT Basic_JJ feature_NN set_VBN are_VBP taken_VBN ._.
This_DT feature_NN set_NN is_VBZ useful_JJ because_IN some_DT words_NNS with_IN negative_JJ polarities_NNS can_MD express_VB negation_NN ,_, like_IN the_DT word_NN ``_`` ignorant_JJ ''_'' in_IN ``_`` An_DT ignorant_JJ person_NN claimed_VBD a_DT nuclear_JJ explosion_NN actually_RB occurred_VBD ._. ''_''
We_PRP ignore_VBP words_NNS having_VBG neutral_JJ sentiment_NN polarity_NN ._.
The_DT words_NNS themselves_PRP with_IN sentiment_NN polarities_NNS are_VBP also_RB encoded_VBN in_IN this_DT feature_NN set_NN ._.
We_PRP use_VBP a_DT list_NN of_IN words_NNS with_IN manually_RB annotated_JJ sentiment_NN polarities_NNS -LRB-_-LRB- Oh_UH et_FW al._FW ,_, 2012_CD -RRB-_-RRB- ._.
Following_VBG Words_NNS In_IN this_DT feature_NN set_NN ,_, we_PRP capture_VBP at_IN most_JJS seven_CD words_NNS -LRB-_-LRB- surface_NN -RRB-_-RRB- that_WDT follow_VBP the_DT target_NN predicate_NN ,_, not_RB including_VBG the_DT target_NN predicate_NN ._.
This_DT feature_NN is_VBZ simple_JJ bag-of-words_NNS of_IN uni-grams_NNS ._.
One_CD crucial_JJ point_NN is_VBZ that_IN we_PRP excluded_VBD from_IN the_DT feature_NN set_VBD such_JJ propositional_JJ contents_NNS as_IN ``_`` A_DT nuclear_JJ explosion_NN occurred_VBD ,_, ''_'' which_WDT is_VBZ judged_VBN as_IN ``_`` negated_VBN ''_'' in_IN the_DT S1_NNP and_CC S2_NNP based_VBN on_IN our_PRP$ criteria_NNS ._.
This_DT deci_SYM -_: sion_NN avoids_VBZ the_DT possibility_NN that_IN the_DT classifier_NN biases_NNS the_DT negation_NN of_IN popular_JJ false_JJ rumors_NNS like_IN the_DT above_JJ nuclear_JJ explosion_NN example_NN ._.
We_PRP assumed_VBD that_IN propo_NN -_: sitional_JJ content_JJ which_WDT might_MD be_VB negated_VBN ,_, is_VBZ repre_JJ -_: sented_VBN by_IN a_DT predicate_NN and_CC its_PRP$ argument_NN and_CC modi_SYM -_: fiers_NNS -LRB-_-LRB- and_CC their_PRP$ descendants_NNS -RRB-_-RRB- ._.
Since_IN Japanese_NNP is_VBZ a_DT head-final_JJ language_NN ,_, where_WRB a_DT predicate_NN appears_VBZ at_IN the_DT right-hand_JJ side_NN of_IN its_PRP$ arguments_NNS and_CC modifiers_NNS ,_, we_PRP did_VBD not_RB include_VB the_DT information_NN concerning_VBG the_DT left_NN -_: hand_NN side_NN of_IN a_DT target_NN predicate_NN in_IN the_DT features_NNS and_CC the_DT target_NN predicate_VB itself2_CD ._.
In_IN Figure_NN 1_CD ,_, the_DT predicate_NN ``_`` 起きる_FW okiru_FW -LRB-_-LRB- occur_VBP -RRB-_-RRB- ''_'' and_CC its_PRP$ argument_NN ``_`` 核爆発_FW kakubakuhatsu_FW -LRB-_-LRB- nuclear_JJ explosion_NN -RRB-_-RRB- ''_'' are_VBP excluded_VBN ._.
2Except_JJ for_IN the_DT Sentiment_NN Polarity_NN features_NNS ._.
noun_NN case_NN -_: marker_NN Figure_NN 1_CD :_: Japanese_JJ bunsetsu_NN example_NN 3_CD Approach_NNP Our_PRP$ negation_NN recognition_NN algorithm_NN takes_VBZ an_DT in_IN -_: put_JJ sentence_NN and_CC classifies_VBZ each_DT predicate_NN in_IN it_PRP as_IN ``_`` negated_VBN ''_'' or_CC ``_`` non-negated_JJ ._. ''_''
We_PRP train_VBP our_PRP$ classi_NNS -_: fier_NN using_VBG support_NN vector_NN machines_NNS -LRB-_-LRB- SVMs_NNS -RRB-_-RRB- -LRB-_-LRB- Vapnik_NNP ,_, 2000_CD -RRB-_-RRB- ._.
We_PRP use_VBP the_DT notion_NN of_IN a_DT bunsetsu_NN which_WDT roughly_RB corresponds_VBZ to_TO a_DT minimum_NN phrase_NN in_IN English_NNP and_CC consists_VBZ of_IN a_DT content_JJ words_NNS -LRB-_-LRB- basically_RB nouns_NNS or_CC verbs_NNS -RRB-_-RRB- and_CC the_DT functional_JJ words_NNS surrounding_VBG them_PRP ._.
Figure_NN 1_CD shows_VBZ an_DT example_NN of_IN a_DT Japanese_JJ sentence_NN ,_, which_WDT means_VBZ ``_`` That_IN a_DT nuclear_JJ explosion_NN occurred_VBD is_VBZ a_DT false_JJ rumor_NN ._. ''_''
The_DT vertical_JJ bars_NNS indicate_VBP the_DT bunsetsu_NN boundaries_NNS ._.
A_DT Japanese_JJ dependency_NN tree_NN is_VBZ defined_VBN as_IN a_DT tree_NN of_IN the_DT dependencies_NNS among_IN the_DT bunsetsus_NN ._.
In_IN the_DT above_JJ example_NN ,_, the_DT first_JJ bunsetsu_NN ``_`` 核爆発_FW か_FW kakubakuhatsu_FW ga_FW -LRB-_-LRB- nuclear_JJ explosion_NN -RRB-_-RRB- ''_'' depends_VBZ on_IN another_DT bunsetsu_NN ``_`` 起きる_FW なんて_FW okiru_FW nante_FW -LRB-_-LRB- oc_SYM -_: cur_NN -RRB-_-RRB- ,_, ''_'' which_WDT in_IN turn_NN depends_VBZ on_IN ``_`` テ_FW マ_FW た_FW dema_FW da_NN -LRB-_-LRB- be_VB false_JJ rumor_NN -RRB-_-RRB- ''_'' ._.
The_DT final_JJ bunsetsu_NN is_VBZ an_DT excep_NN -_: tional_JJ case_NN in_IN which_WDT both_DT a_DT verb_NN and_CC a_DT noun_NN are_VBP included_VBN unlike_IN the_DT other_JJ bunsetsus_NN that_WDT contain_VBP ei_SYM -_: ther_VB a_DT noun_NN or_CC a_DT verb_NN ._.
Note_VB that_IN in_IN this_DT paper_NN ,_, bun_NN -_: setsu_NN boundaries_NNS and_CC a_DT dependency_NN tree_NN are_VBP given_VBN by_IN J.DepP_NNP -LRB-_-LRB- Yoshinaga_NNP and_CC Kitsuregawa_NNP ,_, 2009_CD -RRB-_-RRB- ._.
3.1_CD Baseline_NNP Features_NNP Basic_NNP Uni_NNP -_: ,_, bi_SYM -_: ,_, and_CC tri-grams_NNS of_IN words_NNS -LRB-_-LRB- surface_NN ,_, base_NN form_NN ,_, and_CC part_NN of_IN speech_NN -RRB-_-RRB- in_IN the_DT bunsetsu_NN in_IN -_: clude_VBP the_DT target_NN predicate_NN and_CC its_PRP$ head_NN bunsetsu_NN are_VBP used_VBN as_IN basic_JJ features_NNS ._.
The_DT words_NNS in_IN the_DT two_CD bunset_NN -_: sus_NN are_VBP distinguished_VBN in_IN the_DT feature_NN set_NN ._.
If_IN a_DT bunsetsu_NN includes_VBZ a_DT target_NN predicate_NN ,_, n-grams_NNS are_VBP taken_VBN only_RB from_IN the_DT strings_NNS following_VBG it_PRP ._.
In_IN the_DT above_JJ example_NN sentence_NN ,_, bi-gram_JJ ``_`` テ_FW マ_FW た_FW dema_FW da_NN -LRB-_-LRB- be_VB false_JJ ru_SYM -_: mor_NN -RRB-_-RRB- ''_'' and_CC uni-gram_JJ ``_`` テ_FW マ_FW dema_FW -LRB-_-LRB- false_JJ rumor_NN -RRB-_-RRB- ''_'' are_VBP included_VBN in_IN this_DT feature_NN set_VBN when_WRB the_DT target_NN predicate_NN is_VBZ ``_`` 起きる_FW okiru_FW -LRB-_-LRB- occur_VBP -RRB-_-RRB- ._. ''_''
Negation_NNP Words_NNPS We_PRP manually_RB created_VBD a_DT short_JJ list_NN of_IN 33_CD words_NNS -LRB-_-LRB- CNW_NNP -RRB-_-RRB- ,_, such_JJ as_IN ``_`` テ_FW マ_FW dema_FW -LRB-_-LRB- false_JJ ru_SYM -_: mor_NN -RRB-_-RRB- ''_'' and_CC ``_`` チェーンメール_CD chainmail_NN -LRB-_-LRB- chain_NN let_VBD -_: ter_NN -RRB-_-RRB- ''_'' shown_VBN in_IN Table_NNP 2_CD that_WDT indicate_VBP complex_JJ forms_NNS of_IN negations_NNS ._.
These_DT are_VBP often_RB used_VBN to_TO refute_VB the_DT in_IN -_: formation_NN ._.
Consider_VB this_DT tweet_NN :_: ``_`` I_PRP have_VBP a_DT chain_NN letter_NN Synonyms_NNS of_IN ``_`` not_RB ''_'' Synonyms_NNPS of_IN ``_`` false_JJ rumor_NN ,_, ''_'' ``_`` lie_NN ,_, ''_'' ``_`` forgery_NN ''_'' and_CC ``_`` mistake_NN ''_'' Synonyms_NNPS of_IN ``_`` chain_NN letter_NN ''_'' ない_FW nai_FW ,_, ぬ_CD nu_NN ,_, わけない_CD wakenai_NN Table_NNP 1_CD :_: List_NN of_IN simple_JJ negation_NN suffixes_NNS -LRB-_-LRB- SNW_NNP -RRB-_-RRB- テ_SYM マ_CD dema_NN ,_, て_CD ま_CD dema_NN ,_, カ_CD セ_CD gase_NN ,_, カ_CD セネタ_CD gaseneta_NN ,_, か_CD せ_CD gase_NN ,_, ネタ_CD neta_NN ,_, 風説_CD fusetsu_NN ,_, 流言_CD ryugen_NN ,_, 流言飛語_CD ryugenhigo_NN ,_, 流言蜚語_CD ryugenhigo_NN ,_, 誤報_CD goho_NN ,_, 誤情_CD 報_NN gojoho_NN ,_, 誤解_CD gokai_NNS ,_, 嘘_NN uso_NN ,_, うそ_CD uso_NN ,_, ウソ_CD uso_NN ,_, 偽る_CD itsuwaru_NN ,_, 偽り_CD itsuwari_NNS ,_, 捏_SYM 造_SYM netsuzo_NN ,_, ねつ造_CD netsuzo_NN ,_, 虚偽_CD kyogi_NNS ,_, 間違う_CD machigau_NN ,_, 間違い_CD machigai_NN ,_, 出任_CD せ_NN demakase_NN ,_, て_CD まかせ_CD demakase_NN ,_, 誤る_CD ayamaru_NN ,_, 誤り_CD ayamari_NNS ,_, 虚構_NN kyoko_NN ,_, 違う_CD chigau_NN ,_, 違い_CD chigai_NN チェーンメール_CD chainmail_NN ,_, チェンメ_CD chenme_NN ,_, ちぇんめ_CD chenme_NN Table_NNP 2_CD :_: List_NN of_IN complex_JJ negation_NN words_NNS -LRB-_-LRB- CNW_NNP -RRB-_-RRB- 3.2_CD N-Gram_NNP Cluster_NNP Features_VBZ numbers_NNS of_IN vector_NN dimensions_NNS and_CC clusters_NNS ,_, whose_WP$ values_NNS were_VBD based_VBN on_IN 5-fold_JJ cross-validation_NN on_IN our_PRP$ annotated_JJ training_NN data_NNS ,_, as_IN described_VBN in_IN Section_NN 4.1_CD ._.
We_PRP tried_VBD eight_CD dimensions_NNS -LRB-_-LRB- 50_CD ,_, 100_CD ,_, 150_CD ,_, 200_CD ,_, 250_CD ,_, 300_CD ,_, 350_CD ,_, and_CC 500_CD -RRB-_-RRB- of_IN vectors_NNS and_CC six_CD numbers_NNS of_IN clusters_NNS -LRB-_-LRB- 100_CD ,_, 500_CD ,_, 1,000_CD ,_, 2,000_CD 5,000_CD ,_, and_CC 10,000_CD -RRB-_-RRB- for_IN each_DT corpus_NN ._.
For_IN the_DT optimal_JJ parameters_NNS ,_, which_WDT worked_VBD best_JJS in_IN our_PRP$ preliminary_JJ experiments_NNS ,_, we_PRP fi_SYM -_: nally_RB chose_VBD 250_CD as_IN the_DT dimension_NN and_CC 10,000_CD as_IN the_DT number_NN of_IN clusters_NNS for_IN Wikipedia_NNP ,_, 350_CD dimensions_NNS and_CC 10,000_CD clusters_NNS for_IN the_DT Web_NNP ,_, and_CC 300_CD dimensions_NNS and_CC 10,000_CD number_NN of_IN clusters_NNS for_IN Twitter_NNP ._.
The_DT tun_NN -_: ing_NN for_IN the_DT word2vec_JJ parameters_NNS was_VBD done_VBN by_IN using_VBG a_DT classifier_NN with_IN the_DT word2vec_JJ features_NNS and_CC the_DT Ba_NNP -_: sic_NN ,_, Negation_NNP Words_NNPS ,_, and_CC Sentiment_NN features_NNS for_IN our_PRP$ classifiers_NNS ._.
In_IN our_PRP$ experiments_NNS ,_, many_JJ synonymous_JJ expres_NNS -_: sions_NNS such_JJ as_IN ``_`` 偽_FW 情_FW 報_FW nise_FW joho_FW -LRB-_-LRB- false_JJ infor_NN -_: mation_NN -RRB-_-RRB- ''_'' and_CC ``_`` 不確かな_FW 情報_FW futashikana_FW joho_FW ,_, 不正確な情報_CD fuseikakunajoho_NN ,_, 不確定_CD な_CD 情報_NN fukakuteina_NN joho_NN ,_, 真偽_CD 不明な_CD 情報_NN shingi_NN fumeina_NN joho_NN -LRB-_-LRB- all_DT of_IN which_WDT mean_VBP uncertain_JJ information_NN -RRB-_-RRB- ''_'' were_VBD assigned_VBN vectors_NNS close_RB to_TO that_DT of_IN ``_`` テ_FW マ_FW dema_FW -LRB-_-LRB- false_JJ rumor_NN -RRB-_-RRB- ''_'' in_IN terms_NNS of_IN cosine_NN sim_NN -_: ilarity_NN ._.
We_PRP assume_VBP that_IN the_DT clusters_NNS obtained_VBN by_IN k_NN -_: means_VBZ might_MD capture_VB such_JJ synonyms_NNS ,_, i.e._FW ,_, the_DT clus_NN -_: ter_NN including_VBG ``_`` テ_FW マ_FW dema_FW -LRB-_-LRB- false_JJ rumor_NN -RRB-_-RRB- ''_'' also_RB in_IN -_: cludes_VBZ its_PRP$ synonyms_NNS ._.
CNW_NNP also_RB includes_VBZ only_RB sin_NN -_: gle_NN words_NNS ,_, while_IN performing_VBG k-means_NNS clusters_NNS on_IN word/phrase_NN vectors_NNS can_MD assign_VB cluster_NN IDs_NNS to_TO n_SYM -_: grams_NNS ._.
Actually_RB ,_, in_IN the_DT above_JJ examples_NNS the_DT ex_FW -_: pression_NN ``_`` 不確かな_FW 情報_FW futashikana_FW joho_FW -LRB-_-LRB- uncer_SYM -_: tain_NN information_NN -RRB-_-RRB- ''_'' consists_VBZ of_IN two_CD words_NNS ._.
Further_JJ -_: more_JJR ,_, we_PRP assume_VBP that_IN the_DT combination_NN of_IN a_DT super_JJ -_: vised_VBN classifier_NN and_CC n-gram_JJ clusters_NNS can_MD capture_VB ,_, to_TO a_DT certain_JJ degree_NN ,_, extremely_RB complex_JJ negation_NN forms_NNS ,_, such_JJ as_IN the_DT negations_NNS of_IN ``_`` occur_VBP ''_'' in_IN the_DT sentence_NN ,_, ``_`` The_DT guy_NN who_WP tweeted_VBD that_IN a_DT nuclear_JJ explosion_NN oc_SYM -_: curred_VBN has_VBZ watched_VBN too_RB many_JJ SF_NNP movies_NNS ''_'' by_IN such_JJ clusters_NNS including_VBG n-grams_NNS as_IN ``_`` guy_NN ,_, ''_'' ``_`` too_RB many_JJ ,_, ''_'' and_CC ``_`` SF_NNP movies_NNS ._. ''_''
A_DT primary_JJ motivation_NN behind_IN the_DT introduction_NN of_IN the_DT n-gram_JJ cluster_NN features_NNS is_VBZ to_TO generalize_VB our_PRP$ CNW_NNP ,_, which_WDT includes_VBZ only_RB 33_CD words_NNS ._.
For_IN in_IN -_: stance_NN ,_, ``_`` テ_FW マ_FW dema_FW -LRB-_-LRB- false_JJ rumor_NN -RRB-_-RRB- ''_'' has_VBZ many_JJ syn_NN -_: onymous_JJ expressions_NNS such_JJ as_IN ``_`` 偽_FW 情報_FW nise_FW joho_FW -LRB-_-LRB- false_JJ information_NN -RRB-_-RRB- ''_'' ,_, and_CC ``_`` 不確かな情報_CD fu_SYM -_: tashikana_NN joho_NN ,_, 不正確な_CD 情報_NN fuseikakuna_NN joho_NN ,_, 不確定な_CD 情報_NN fukakuteina_NN joho_NN ,_, 真偽_FW 不明な_FW 情_FW 報_FW shingi_FW humeina_FW joho_FW -LRB-_-LRB- all_DT of_IN which_WDT mean_VBP uncer_JJ -_: tain_NN information_NN -RRB-_-RRB- ''_'' ,_, which_WDT are_VBP not_RB covered_VBN by_IN CNW_NNP ._.
We_PRP used_VBD an_DT implementation_NN of_IN a_DT neural_JJ network_NN -_: based_VBN algorithm_NN -LRB-_-LRB- i.e._FW ,_, word2vec3_NNS -LRB-_-LRB- Mikolov_NNP et_FW al._FW ,_, 2013_CD -RRB-_-RRB- -RRB-_-RRB- to_TO construct_VB the_DT synonym_NN clusters_NNS ._.
To_TO get_VB larger_JJR units_NNS of_IN words_NNS -LRB-_-LRB- i.e._FW n-grams_FW -RRB-_-RRB- ,_, we_PRP ran_VBD the_DT word2phrase_JJ tool_NN on_IN these_DT corpora_NN twice_RB and_CC gen_SYM -_: erated_VBD n-gram_JJ clusters_NNS by_IN performing_VBG the_DT k-means_NNS clustering_VBG algorithm_NN on_IN the_DT top_NN of_IN the_DT word_NN -LRB-_-LRB- and_CC phrase_NN -RRB-_-RRB- vectors_NNS ._.
This_DT feature_NN set_VBN encodes_VBZ the_DT seman_NN -_: tic_JJ cluster_NN IDs_NNS of_IN the_DT words_NNS and_CC the_DT n-grams_NNS -LRB-_-LRB- n_SYM ≤_SYM 4_LS -RRB-_-RRB- found_VBN in_IN the_DT seven_CD words_NNS that_WDT follow_VBP a_DT target_NN predi_NN -_: cate_NN ._.
Note_VB that_IN we_PRP modified_VBD the_DT k-means_JJ clustering_NN of_IN the_DT word2vec_CD tool_NN so_IN that_IN the_DT word_NN vectors_NNS are_VBP normalized_VBN to_TO the_DT length_NN of_IN the_DT vector_NN ._.
Three_CD distinct_JJ corpora_NN were_VBD given_VBN to_TO the_DT word2vec_CD tool_NN :_: 1_CD ._.
All_DT of_IN the_DT articles_NNS from_IN Japanese_JJ Wikipedia_NNP -LRB-_-LRB- re_SYM -_: vision_NN of_IN 18_CD Jan._NNP 2015_CD -RRB-_-RRB- ,_, 2_CD ._.
Web_NN pages_NNS crawled_VBD in_IN 2007_CD ,_, i.e._FW ,_, about_IN four_CD years_NNS before_IN the_DT earthquake_NN ,_, 3_CD ._.
Twitter_NNP data_NNS posted_VBD from_IN Feb._NNP 14_CD to_TO 28_CD ,_, 2015_CD ,_, i.e._FW ,_, about_IN four_CD years_NNS after_IN the_DT earthquake_NN ._.
We_PRP randomly_RB sampled_VBD sentences_NNS for_IN corpora_NN 2_CD -LRB-_-LRB- 4.5_CD GB_NNP -RRB-_-RRB- and_CC 3_CD -LRB-_-LRB- 4.3_CD GB_NNP -RRB-_-RRB- to_TO match_VB Wikipedia_NNP 's_POS size_NN -LRB-_-LRB- 4.2_CD GB_NNP -RRB-_-RRB- ._.
We_PRP tokenized_VBD each_DT document_NN with_IN a_DT morpho_NN -_: logical_JJ analyzer_NN MeCab_NNP -LRB-_-LRB- Kudo_NNP et_FW al._FW ,_, 2004_CD -RRB-_-RRB- and_CC the_DT Juman_NNP PoS_NNP tag_NN set_NN -LRB-_-LRB- Kurohashi_NNP et_FW al._FW ,_, 1994_CD -RRB-_-RRB- and_CC ap_SYM -_: plied_VBD the_DT word2vec_JJ tool_NN and_CC k-means_NNS clustering_VBG ._.
We_PRP needed_VBD to_TO choose_VB several_JJ parameters_NNS ,_, including_VBG the_DT 3_CD https://code.google.com/p/word2vec/_NN Usage_NN Source_NN #predicates_VBZ #nps_NNS #cns_VBZ training_NN tweets_NNS 96,824_CD 11,842_CD 1,541_CD artificial_JJ 4,048_CD 1,638_CD 849_CD total_JJ 100,872_CD 13,480_CD 2,390_CD test_NN tweets_NNS 14,253_CD 2,250_CD 393_CD Table_NNP 3_CD :_: The_DT training_NN and_CC test_NN sets_NNS ._.
#nps_NNS indicates_VBZ num_SYM -_: ber_NN of_IN negation_NN instances_NNS and_CC #cns_NNS indicates_VBZ number_NN of_IN complex_JJ negated_VBN instances_NNS ._.
4_CD Experiments_NNS 4.1_CD Experimental_JJ Settings_NNS We_PRP first_RB asked_VBD human_JJ annotators_NNS to_TO judge_VB whether_IN 115,125_CD predicate_NN instances_NNS sampled_VBN from_IN tweets_NNS were_VBD negated_VBN ._.
Table_NNP 3_CD shows_VBZ the_DT number_NN of_IN in_IN -_: stances_NNS in_IN the_DT training_NN and_CC test_NN sets_NNS ._.
Instances_NNS whose_WP$ source_NN is_VBZ tweets_NNS in_IN the_DT table_NN were_VBD extracted_VBN from_IN tweets_NNS posted_VBN during_IN within_IN one_CD month_NN after_IN the_DT Great_NNP East_NNP Japan_NNP Earthquake_NN -LRB-_-LRB- from_IN March_NNP 11_CD 2011_CD to_TO April_NNP 11_CD 2011_CD -RRB-_-RRB- and_CC instances_NNS whose_WP$ source_NN is_VBZ arti_SYM -_: ficial_NN in_IN the_DT table_NN were_VBD manually_RB composed_VBN of_IN tweet_NN -_: like_IN texts_NNS that_WDT included_VBD typical_JJ examples_NNS of_IN complex_JJ forms_NNS of_IN negations_NNS to_TO expand_VB the_DT number_NN of_IN com_NN -_: plex_NN negations_NNS ._.
Note_VB that_IN we_PRP also_RB used_VBD the_DT training_NN set_VBN as_IN the_DT development_NN set_VBN for_IN parameter_NN tuning_VBG by_IN 5-fold_JJ cross-validation_NN ._.
All_DT of_IN the_DT test_NN set_VBN instances_NNS were_VBD extracted_VBN from_IN tweets_NNS and_CC there_EX was_VBD no_DT overlap_VBP between_IN the_DT training_NN and_CC test_NN sets_NNS ._.
In_IN both_DT sets_NNS ,_, each_DT predicate_NN was_VBD annotated_VBN by_IN a_DT single_JJ annotator_NN by_IN the_DT following_JJ steps_NNS :_: 1_LS ._.
We_PRP annotated_VBD predicates_VBZ based_VBN on_IN Iida_NNP et_FW al._FW -LRB-_-LRB- 2007_CD -RRB-_-RRB- ._.
All_DT of_IN the_DT verbs_NNS and_CC adjectives_NNS were_VBD annotated_VBN as_IN predicates_NNS ,_, and_CC some_DT nouns_NNS were_VBD annotated_VBN as_IN nominal_JJ predicates_NNS ._.
2_LS ._.
We_PRP annotated_VBD negation_NN by_IN the_DT negation_NN cues_NNS surrounding_VBG the_DT predicate_NN ._.
Both_DT such_JJ func_NN -_: tional_JJ expressions_NNS as_IN ``_`` ない_FW nai_FW -LRB-_-LRB- not_RB -RRB-_-RRB- ''_'' and_CC such_JJ content_JJ words_NNS as_IN ``_`` 嘘_FW た_FW uso_FW da_NN -LRB-_-LRB- it_PRP is_VBZ doubtful_JJ that_IN -RRB-_-RRB- ''_'' are_VBP used_VBN as_IN negation_NN cues_NNS ._.
3_LS ._.
The_DT predicates_NNS -LRB-_-LRB- interpreted_VBN by_IN the_DT annotator_NN as_IN negated_VBN by_IN the_DT cues_NNS -RRB-_-RRB- are_VBP annotated_VBN as_IN negated_VBN predicates_NNS and_CC used_VBN as_IN positive_JJ instances_NNS for_IN SVM_NNP ,_, and_CC the_DT others_NNS are_VBP used_VBN as_IN negative_JJ in_IN -_: stances_NNS ._.
Note_VB that_DT recognizing_VBG negated_VBN instances_NNS as_IN either_DT simple_JJ or_CC complex_JJ is_VBZ done_VBN automatically_RB based_VBN on_IN the_DT definitions_NNS described_VBN in_IN Section_NN 1_CD ._.
In_IN all_DT the_DT experiments_NNS ,_, we_PRP used_VBD LIBSVM_NNP -LRB-_-LRB- Chang_NNP and_CC Lin_NNP ,_, 2011_CD -RRB-_-RRB- with_IN a_DT degree_NN 2_CD polynomial_JJ kernel_NN ,_, where_WRB gamma_NN =_SYM 1_CD and_CC cost_NN =_SYM 0.001_CD ,_, which_WDT worked_VBD best_JJS in_IN our_PRP$ preliminary_JJ experiments_NNS ._.
We_PRP set_VBD the_DT re_NN -_: maining_VBG parameters_NNS to_TO the_DT tool_NN 's_POS default_NN values_NNS ._.
4.2_CD Baseline_NNP Methods_NNPS We_PRP conducted_VBD experiments_NNS using_VBG three_CD baselines_NNS and_CC created_VBN two_CD baseline_NN systems_NNS built_VBN on_IN rule_NN -_: and_CC ma_SYM -_: chine_NN learning-based_JJ methods_NNS ._.
We_PRP also_RB adapted_VBD a_DT method_NN -LRB-_-LRB- de_FW Marneffe_FW et_FW al._FW ,_, 2012_CD -RRB-_-RRB- that_WDT recognizes_VBZ veridicality_NN and_CC negation_NN ._.
Rule_NNP is_VBZ a_DT simple_JJ rule-based_JJ method_NN that_WDT regards_VBZ a_DT predicate_NN as_IN ``_`` negated_VBN ''_'' only_RB when_WRB any_DT of_IN the_DT nega_NN -_: tion_NN words_NNS in_IN Tables_NNP 1_CD and_CC 2_CD are_VBP found_VBN in_IN a_DT window_NN of_IN seven_CD words_NNS on_IN each_DT side_NN of_IN the_DT target_NN predicate_NN as_RB well_RB as_IN the_DT target_NN predicate_VB itself_PRP ._.
ML_NNP uses_VBZ the_DT SVM_NNP classifier_NN with_IN the_DT four_CD features_NNS described_VBN in_IN Section_NN 3_CD :_: basic_JJ ,_, negation_JJ words_NNS ,_, senti_NNS -_: ment_NN ,_, and_CC following_VBG words_NNS ._.
Marneffe12_NNP predicts_VBZ the_DT veridicality_NN of_IN the_DT propo_NN -_: sitions_NNS written_VBN in_IN a_DT sentence_NN as_RB well_RB as_IN the_DT negation_NN recognition_NN ._.
We_PRP replicated_VBD their_PRP$ features_NNS ,_, except_IN the_DT ``_`` world_NN knowledge_NN ''_'' feature_NN that_WDT captures_VBZ the_DT subject_NN of_IN the_DT target_NN predicate_NN ._.
In_IN the_DT following_NN ,_, we_PRP describe_VBP how_WRB to_TO apply_VB these_DT features_NNS to_TO Japanese_JJ ._.
Predicate_NNP classes_NNS Some_DT words_NNS are_VBP often_RB used_VBN to_TO introduce_VB the_DT factuality_NN of_IN events_NNS ._.
For_IN instance_NN ,_, given_VBN ``_`` He_PRP confirmed_VBD that_IN she_PRP will_MD come_VB ,_, ''_'' ``_`` con_NN -_: firmed_VBD ''_'' indicates_VBZ that_IN the_DT factuality_NN of_IN ``_`` come_VBN ''_'' is_VBZ certainty_NN ._.
We_PRP translated_VBD 779_CD words_NNS with_IN 38_CD classes_NNS -LRB-_-LRB- Saur_NNP ́ı_NN ,_, 2008_CD -RRB-_-RRB- into_IN 4,110_CD words_NNS in_IN Japanese_JJ ._.
We_PRP used_VBD the_DT class_NN name_NN and_CC the_DT original_JJ form_NN of_IN the_DT word_NN as_IN binary_JJ features_NNS to_TO detect_VB whether_IN the_DT target_NN predicate_NN is_VBZ led_VBN by_IN one_CD of_IN these_DT words_NNS ._.
General_NNP features_VBZ We_PRP used_VBD the_DT original_JJ forms_NNS of_IN the_DT predicate_NN and_CC the_DT sentence_NN 's_POS root_NN ._.
Modality_NN features_NNS We_PRP identified_VBD such_JJ modal_JJ ex_FW -_: pressions_NNS as_IN ``_`` かも_FW kamo_FW -LRB-_-LRB- might_MD -RRB-_-RRB- ''_'' in_IN two_CD bunsetsus_NN in_IN a_DT dependency_NN ,_, where_WRB the_DT head_NN bunsetsu_NN contains_VBZ the_DT target_NN predicate_NN ._.
The_DT other_JJ modal_JJ expressions_NNS found_VBD elsewhere_RB in_IN the_DT sentence_NN are_VBP marked_VBN as_IN dif_NN -_: ferent_NN features_NNS ._.
Negation_NNP We_PRP used_VBD both_DT SNW_NNP and_CC CNW_NNP to_TO find_VB negation_JJ words_NNS ._.
Conditional_JJ We_PRP examined_VBD whether_IN the_DT predicates_NNS are_VBP in_IN an_DT if-clause_NN and_CC checked_VBD whether_IN they_PRP end_VBP with_IN ``_`` たら_FW tara_FW -LRB-_-LRB- if_IN -RRB-_-RRB- ''_'' or_CC ``_`` れは_FW reba_FW -LRB-_-LRB- if_IN -RRB-_-RRB- ''_'' and_CC words_NNS indicating_VBG if_IN -_: clauses_NNS such_JJ as_IN ``_`` もし_FW moshi_FW -LRB-_-LRB- if_IN -RRB-_-RRB- ''_'' and_CC ``_`` 仮に_FW karini_FW -LRB-_-LRB- if_IN -RRB-_-RRB- ._. ''_''
Quotation_NN We_PRP also_RB checked_VBD whether_IN the_DT sentence_NN opened_VBD and_CC ended_VBD with_IN quotation_NN marks_NNS ._.
Originally_RB ,_, de_IN Marneffe_NNP et_FW al._FW -LRB-_-LRB- 2012_CD -RRB-_-RRB- used_VBD the_DT maximum_NN entropy_NN classifier_NN -LRB-_-LRB- Berger_NNP et_FW al._FW ,_, 1996_CD -RRB-_-RRB- ._.
Method_NNP Precision_NNP -LRB-_-LRB- %_NN -RRB-_-RRB- Recall_VB -LRB-_-LRB- %_NN -RRB-_-RRB- F-score_NN -LRB-_-LRB- %_NN -RRB-_-RRB- Rule_NNP 8.01_CD -LRB-_-LRB- 1071_CD /_CD 13377_CD -RRB-_-RRB- 44.81_CD -LRB-_-LRB- 1071_CD /_CD 2390_CD -RRB-_-RRB- 13.59_CD Marneffe12_NNP 14.62_CD -LRB-_-LRB- 371_CD /_CD 2538_CD -RRB-_-RRB- 15.52_CD -LRB-_-LRB- 371_CD /_CD 2390_CD -RRB-_-RRB- 15.06_CD ML_NNP 77.43_CD -LRB-_-LRB- 621_CD /_CD 802_CD -RRB-_-RRB- 25.98_CD -LRB-_-LRB- 621_CD /_CD 2390_CD -RRB-_-RRB- 38.91_CD ML_NNP +_CD web-d350_JJ 76.84_CD -LRB-_-LRB- 617_CD /_CD 803_CD -RRB-_-RRB- 25.82_CD -LRB-_-LRB- 617_CD /_CD 2390_CD -RRB-_-RRB- 38.65_CD ML_NNP +_CD wikipedia-d250_JJ 76.89_CD -LRB-_-LRB- 632_CD /_CD 822_CD -RRB-_-RRB- 26.44_CD -LRB-_-LRB- 632_CD /_CD 2390_CD -RRB-_-RRB- 39.35_CD ML_NNP +_CD twitter-d300_JJ 77.28_CD -LRB-_-LRB- 643_CD /_CD 832_CD -RRB-_-RRB- 26.90_CD -LRB-_-LRB- 643_CD /_CD 2390_CD -RRB-_-RRB- 39.91_CD ML_NNP +_CD all_DT 71.40_CD -LRB-_-LRB- 839_CD /_CD 1175_CD -RRB-_-RRB- 35.10_CD -LRB-_-LRB- 839_CD /_CD 2390_CD -RRB-_-RRB- 47.07_CD Proposed_VBN 69.81_CD -LRB-_-LRB- 867_CD /_CD 1242_CD -RRB-_-RRB- 36.28_CD -LRB-_-LRB- 867_CD /_CD 2390_CD -RRB-_-RRB- 47.74_CD Table_NNP 4_CD :_: Results_NNS on_IN the_DT training_NN set_VBN by_IN 5-fold_JJ cross-validation_NN Table_NNP 5_CD :_: Comparison_NN to_TO other_JJ clustering_NN methods_NNS on_IN the_DT training_NN set_VBN by_IN 5-fold_JJ cross-validation_NN Method_NNP Precision_NNP -LRB-_-LRB- %_NN -RRB-_-RRB- Recall_VB -LRB-_-LRB- %_NN -RRB-_-RRB- F-score_NN -LRB-_-LRB- %_NN -RRB-_-RRB- web_NN d300_CD n2000_CD 78.09_CD -LRB-_-LRB- 613_CD /_CD 785_CD -RRB-_-RRB- 25.65_CD -LRB-_-LRB- 613_CD /_CD 2390_CD -RRB-_-RRB- 38.61_CD wikipedia_NN d500_CD n2000_CD 77.42_CD -LRB-_-LRB- 617_CD /_CD 797_CD -RRB-_-RRB- 25.82_CD -LRB-_-LRB- 617_CD /_CD 2390_CD -RRB-_-RRB- 38.72_CD twitter_NN d200_CD n2000_CD 77.56_CD -LRB-_-LRB- 622_CD /_CD 802_CD -RRB-_-RRB- 26.03_CD -LRB-_-LRB- 622_CD /_CD 2390_CD -RRB-_-RRB- 38.97_CD noun-cls_NNS n2000_JJ 77.12_CD -LRB-_-LRB- 691_CD /_CD 896_CD -RRB-_-RRB- 28.91_CD -LRB-_-LRB- 691_CD /_CD 2390_CD -RRB-_-RRB- 42.06_CD We_PRP used_VBD SVM_NNP as_IN a_DT classifier_NN with_IN the_DT same_JJ parame_NN -_: ters_NNS as_IN our_PRP$ proposed_VBN method_NN described_VBN in_IN Section_NN 3_CD ._.
4.3_CD Proposed_NNP Methods_NNPS In_IN our_PRP$ proposed_VBN method_NN ,_, we_PRP used_VBD all_DT of_IN the_DT features_NNS described_VBN in_IN Section_NN 3_CD along_IN with_IN all_DT of_IN the_DT clus_NN -_: ter_NN IDs_NNS obtained_VBD using_VBG the_DT Wikipedia_NNP ,_, Tweets_NNP ,_, and_CC Web_NNP sets_NNS ._.
Table_NNP 4_CD shows_VBZ the_DT results_NNS of_IN our_PRP$ proposed_VBN methods_NNS ,_, some_DT baselines_NNS ,_, and_CC our_PRP$ method_NN without_IN certain_JJ types_NNS of_IN features_NNS on_IN the_DT training_NN set_VBN by_IN 5-fold_JJ cross-validation_NN ._.
Although_IN both_DT simple_JJ and_CC complex_JJ negations_NNS are_VBP used_VBN as_IN positive_JJ instances_NNS for_IN SVM_NNP ,_, we_PRP evaluated_VBD only_RB complex_JJ negations_NNS ._.
The_DT comparison_NN between_IN ``_`` Rule_NNP ''_'' and_CC ``_`` ML_NNP ''_'' sug_SYM -_: gests_NNS that_IN a_DT predicate_NN is_VBZ not_RB always_RB negated_VBN even_RB if_IN it_PRP is_VBZ surrounded_VBN by_IN negation_NN words_NNS ._.
There_EX are_VBP two_CD reasons_NNS for_IN poor_JJ performance_NN of_IN ``_`` Rule_NNP ._. ''_''
The_DT first_JJ is_VBZ false_JJ matching_NN of_IN simple_JJ negation_NN words_NNS for_IN id_SYM -_: iomatic_JJ expressions_NNS ._.
For_IN instance_NN ,_, ``_`` 思_FW い_FW か_FW け_FW な_FW い_FW omoigake_FW nai_FW -LRB-_-LRB- unexpected_JJ -RRB-_-RRB- ''_'' contains_VBZ the_DT nega_NN -_: tion_NN word_NN ``_`` ない_FW nai_FW -LRB-_-LRB- not_RB -RRB-_-RRB- ''_'' at_IN the_DT end_NN of_IN the_DT word_NN but_CC it_PRP does_VBZ not_RB express_VB negation_NN in_IN Japanese_JJ ._.
The_DT second_JJ is_VBZ a_DT double_JJ negative_JJ ._.
For_IN instance_NN ,_, ``_`` 間違_FW い_FW ない_FW machigai_FW nai_FW -LRB-_-LRB- it_PRP is_VBZ not_RB incorrect_JJ -RRB-_-RRB- ''_'' contains_VBZ two_CD negation_NN words_NNS ``_`` 間違う_FW machigau_FW -LRB-_-LRB- incorrect_JJ -RRB-_-RRB- ''_'' and_CC ``_`` ない_FW nai_FW -LRB-_-LRB- not_RB -RRB-_-RRB- ''_'' but_CC it_PRP does_VBZ not_RB express_VB nega_JJ -_: tion_NN and_CC roughly_RB corresponds_VBZ to_TO ``_`` it_PRP is_VBZ correct_JJ ._. ''_''
The_DT comparison_NN between_IN ``_`` Marneffe12_NNP ''_'' and_CC ``_`` ML_NNP ''_'' sug_SYM -_: gests_NNS that_IN it_PRP is_VBZ infeasible_JJ to_TO cover_VB various_JJ negation_NN words_NNS and_CC their_PRP$ n-grams_NNS using_VBG word_NN lists_NNS organized_VBN manually_RB ._.
The_DT ``_`` ML_NNP +_NNP web-d350_NN ,_, ''_'' ``_`` ML_NNP +_NNP wikipedia-d250_NN ,_, ''_'' and_CC ``_`` ML_NNP +_NNP twitter-d300_NN ''_'' columns_NNS indicate_VBP the_DT per_FW -_: formance_NN of_IN using_VBG the_DT n-gram_JJ cluster_NN features_NNS with_IN three_CD types_NNS of_IN corpora_NN ._.
The_DT n-gram_JJ cluster_NN fea_NN -_: ture_NN generated_VBD from_IN Twitter_NNP outperforms_VBZ the_DT other_JJ two_CD corpora_NN ._.
The_DT ``_`` ML_NNP +_NNP all_DT ''_'' column_NN indicates_VBZ us_PRP -_: ing_VBG three_CD corpora_NN at_IN once_RB ._.
These_DT features_NNS are_VBP distin_SYM -_: guished_VBN by_IN their_PRP$ sources_NNS ._.
It_PRP outperforms_VBZ the_DT other_JJ settings_NNS of_IN using_VBG each_DT corpora_NN ._.
The_DT comparisons_NNS be_VB -_: tween_IN the_DT ``_`` ML_NNP ''_'' and_CC ``_`` ML_NNP +_NNP all_DT ''_'' and_CC ``_`` Marneffe12_NNP ''_'' and_CC ``_`` ML_NNP +_NNP all_DT ''_'' suggest_VBP that_IN n-gram_JJ clusters_NNS success_NN -_: fully_RB generalize_VB complex_JJ negations_NNS forms_NNS by_IN their_PRP$ cluster_NN IDs_NNS ._.
We_PRP compare_VBP our_PRP$ n-gram_JJ clustering_NN method_NN with_IN ``_`` noun-cls_NNS ,_, ''_'' another_DT clustering_VBG method_NN that_WDT was_VBD pro-_JJ posed_VBN by_IN Kazama_NNP and_CC Torisawa_NNP -LRB-_-LRB- 2008_CD -RRB-_-RRB- ._.
We_PRP applied_VBD their_PRP$ clustering_NN algorithm_NN to_TO nouns_NNS extracted_VBN from_IN roughly_RB six_CD hundred_CD million_CD Web_NNP documents_NNS ._.
The_DT Web_NNP documents_NNS that_IN we_PRP used_VBD for_IN our_PRP$ clustering_NN are_VBP a_DT subset_NN of_IN these_DT documents_NNS ._.
The_DT variation_NN of_IN words_NNS in_IN the_DT noun-cluster_NN is_VBZ wider_JJR than_IN in_IN other_JJ clusters_NNS ._.
We_PRP set_VBP the_DT clustering_VBG number_NN to_TO 2,000_CD in_IN our_PRP$ n-gram_JJ clustering_NN method_NN and_CC ``_`` noun-cls_NNS ._. ''_''
Table_NNP 5_CD compares_VBZ the_DT clustering_VBG method_NN and_CC the_DT corpora_NN that_IN we_PRP used_VBD ._.
We_PRP tried_VBD eight_CD dimensions_NNS -LRB-_-LRB- 50_CD ,_, 100_CD ,_, 150_CD ,_, 200_CD ,_, 250_CD ,_, 300_CD ,_, 350_CD ,_, and_CC 500_CD -RRB-_-RRB- ,_, and_CC the_DT number_NN of_IN dimensions_NNS in_IN Table_NNP 5_CD achieved_VBD the_DT best_JJS performance_NN for_IN each_DT corpus_NN ._.
The_DT ``_`` noun-cls_JJ ''_'' column_NN outperformed_VBD the_DT other_JJ clusters_NNS ._.
This_DT suggests_VBZ that_IN generalization_NN by_IN noun-cluster_NN is_VBZ more_RBR effective_JJ than_IN n-gram_JJ clusters_NNS for_IN complex_JJ negation_NN recognition_NN because_IN the_DT noun_NN -_: cluster_NN has_VBZ more_JJR various_JJ words_NNS than_IN the_DT others_NNS ._.
In_IN future_JJ work_NN ,_, we_PRP will_MD generate_VB n-gram_JJ clusters_NNS from_IN large-scale_JJ documents_NNS ._.
4.4_CD Results_NNS on_IN the_DT Test_NN Set_NNP We_PRP trained_VBD a_DT classifier_NN using_VBG the_DT whole_JJ training_NN set_VBN as_IN training_NN data_NNS and_CC applied_VBD it_PRP to_TO our_PRP$ test_NN set_NN ._.
Table_NNP 6_CD shows_VBZ the_DT performance_NN of_IN the_DT following_VBG seven_CD meth_NN -_: ods_NNS ._.
Here_RB ,_, ``_`` Proposed_VBN ''_'' indicates_VBZ the_DT performance_NN of_IN our_PRP$ proposed_VBN method_NN ,_, and_CC ``_`` Rule_NNP ''_'' is_VBZ the_DT perfor_NN -_: Method_NNP Precision_NNP -LRB-_-LRB- %_NN -RRB-_-RRB- Recall_VB -LRB-_-LRB- %_NN -RRB-_-RRB- F-score_NN -LRB-_-LRB- %_NN -RRB-_-RRB- Proposed_VBN 64.04_CD -LRB-_-LRB- 114_CD /_CD 178_CD -RRB-_-RRB- 29.01_CD -LRB-_-LRB- 114_CD /_CD 393_CD -RRB-_-RRB- 39.93_CD Rule_NNP 10.43_CD -LRB-_-LRB- 220_CD /_CD 2109_CD -RRB-_-RRB- 55.98_CD -LRB-_-LRB- 220_CD /_CD 393_CD -RRB-_-RRB- 17.59_CD ablation_NN test_NN −_CD n-gram-cls_NNS 71.57_CD -LRB-_-LRB- 73_CD /_CD 102_CD -RRB-_-RRB- 18.58_CD -LRB-_-LRB- 73_CD /_CD 393_CD -RRB-_-RRB- 29.49_CD −_CD noun-cls_NNS 62.96_CD -LRB-_-LRB- 102_CD /_CD 162_CD -RRB-_-RRB- 25.95_CD -LRB-_-LRB- 102_CD /_CD 393_CD -RRB-_-RRB- 36.76_CD −_CD basic_JJ 73.04_CD -LRB-_-LRB- 84_CD /_CD 115_CD -RRB-_-RRB- 21.37_CD -LRB-_-LRB- 84_CD /_CD 393_CD -RRB-_-RRB- 33.07_CD −_NN following_VBG 66.23_CD -LRB-_-LRB- 100_CD /_CD 151_CD -RRB-_-RRB- 25.45_CD -LRB-_-LRB- 100_CD /_CD 393_CD -RRB-_-RRB- 36.76_CD −_NN negation_NN 63.25_CD -LRB-_-LRB- 105_CD /_CD 166_CD -RRB-_-RRB- 26.72_CD -LRB-_-LRB- 105_CD /_CD 393_CD -RRB-_-RRB- 37.57_CD −_NN sentiment_NN 61.59_CD -LRB-_-LRB- 101_CD /_CD 164_CD -RRB-_-RRB- 25.70_CD -LRB-_-LRB- 101_CD /_CD 393_CD -RRB-_-RRB- 36.27_CD −_CD n-gram-cls_NNS +_VBP uni-gram-cls_JJ 63.75_NNS -LRB-_-LRB- 102_CD /_CD 160_CD -RRB-_-RRB- 25.95_CD -LRB-_-LRB- 102_CD /_CD 393_CD -RRB-_-RRB- 36.89_CD Table_NNP 6_CD :_: Results_NNS on_IN the_DT test_NN set_VBN We_PRP also_RB show_VBP in_IN Table_NNP 7_CD three_CD negated_VBD predi_SYM -_: cates_VBZ extracted_VBN from_IN real_JJ tweets_NNS that_WDT were_VBD not_RB prop_VB -_: erly_JJ recognized_VBN by_IN either_CC the_DT rule-based_JJ method_NN or_CC the_DT machine_NN learning_VBG method_NN without_IN the_DT n-gram_JJ clusters_NNS ,_, but_CC they_PRP were_VBD correctly_RB classified_VBN by_IN our_PRP$ method_NN ._.
5_CD Simulation_NN of_IN Disaster_NN Situation_NN We_PRP constructed_VBD our_PRP$ data_NN set_NN from_IN tweets_NNS in_IN the_DT month_NN following_VBG the_DT Great_NNP East_NNP Japan_NNP Earthquake_NN ._.
Since_IN that_IN the_DT purpose_NN of_IN negation_NN recognition_NN is_VBZ to_TO detect_VB false_JJ rumors_NNS during_IN a_DT disaster_NN ,_, taking_VBG one_CD month_NN to_TO annotate_VB the_DT data_NNS and_CC to_TO train_VB classifiers_NNS is_VBZ too_RB long_RB ._.
Therefore_RB ,_, we_PRP simulated_JJ the_DT situation_NN as_IN in_IN Figure_NN 2_CD ._.
納豆か_IN 放射能に効くという都市伝説か_CD あったりも_CD There_EX 's_VBZ also_RB this_DT urban_JJ legend_NN saying_VBG that_IN natto_NN -LRB-_-LRB- Japanese_JJ food_NN made_VBN from_IN fermented_JJ soybeans_NNS -RRB-_-RRB- is_VBZ effective_JJ against_IN ra_SYM -_: diation_NN ._.
避難所て_FW 物資横流しか_FW 起きてるってツイートしてる_FW 奴_FW 、_FW 北斗の拳の見すき_FW ~_FW The_DT guy_NN who_WP tweeted_VBD that_IN there_EX is_VBZ some_DT supplies_NNS black_JJ mar_NN -_: ket_NN at_IN the_DT shelters_NNS ,_, -LRB-_-LRB- I_PRP 'm_VBP sure_JJ -RRB-_-RRB- he_PRP watched_VBD too_RB much_JJ of_IN ``_`` Fist_NN of_IN the_DT North_NNP Star_NNP ''_'' -LRB-_-LRB- Japanese_NNP dystopic_JJ SF_NNP animation_NN -RRB-_-RRB- 国会議事堂か_CD 破壊されたなんてほさ_CD いてるハ_CD カいるの_NN Is_VBZ there_EX really_RB an_DT idiot_NN who_WP said_VBD that_IN the_DT National_NNP Diet_NNP -LRB-_-LRB- build_VB -_: ing_NN -RRB-_-RRB- was_VBD destroyed_VBN ?_.
Table_NNP 7_CD :_: Examples_NNS of_IN output_NN mance_NN of_IN a_DT rule-based_JJ baseline_NN method_NN ,_, which_WDT re_SYM -_: gards_NNS a_DT predicate_NN as_IN ``_`` negated_VBN ''_'' only_RB when_WRB any_DT words_NNS of_IN SNW_NNP and_CC CNW_NNP in_IN Tables_NNP 1_CD and_CC 2_CD are_VBP found_VBN in_IN a_DT 14-word_JJ window_NN centered_VBN on_IN the_DT predicate_NN ._.
The_DT proposed_VBN method_NN achieved_VBD more_JJR than_IN 20_CD %_NN improve_VB -_: ment_NN in_IN F-score_NN over_IN the_DT rule-based_JJ method_NN for_IN com_NN -_: plex_NN negations_NNS ._.
Our_PRP$ ablation_NN test_NN on_IN the_DT test_NN set_NN is_VBZ shown_VBN in_IN ``_`` ab_SYM -_: lation_NN test_NN ._. ''_''
For_IN each_DT result_NN ,_, one_CD of_IN the_DT features_NNS is_VBZ ablated_JJ ._.
The_DT ``_`` −_FW ngram-cls_FW +_FW uni-gram-cls_FW ''_'' column_NN indicates_VBZ that_IN we_PRP only_RB generalized_VBD a_DT uni-gram_NN -LRB-_-LRB- i.e._FW ,_, single_JJ word_NN -RRB-_-RRB- ._.
This_DT setting_VBG confirms_VBZ the_DT effect_NN of_IN n-gram_JJ generalization_NN ._.
In_IN the_DT ablation_NN test_NN ,_, the_DT re_NN -_: sults_NNS indicate_VBP that_IN every_DT feature_NN was_VBD effective_JJ ._.
In_IN other_JJ words_NNS ,_, lower_JJR performance_NN was_VBD observed_VBN af_SYM -_: ter_NN removing_VBG each_DT feature_NN ._.
The_DT comparison_NN be_VB -_: tween_IN the_DT proposed_VBN method_NN and_CC the_DT method_NN with_IN -_: out_RP cluster_NN IDs_NNS ``_`` -_: n-gram-cls_NNS ''_'' suggests_VBZ that_DT cluster_NN IDs_NNS are_VBP useful_JJ for_IN recognizing_VBG complex_JJ types_NNS of_IN negations_NNS ._.
The_DT comparison_NN between_IN the_DT proposed_VBN method_NN and_CC the_DT method_NN without_IN 2,3,4-gram_JJ gener_NN -_: alization_NN ``_`` −_FW n-gram-cls_FW +_FW uni-gram-cls_FW ''_'' suggests_VBZ that_DT n-gram_JJ generalization_NN is_VBZ effective_JJ for_IN complex_JJ nega_NN -_: tion_NN recognition_NN ._.
For_IN instance_NN ,_, an_DT n-gram_JJ cluster_NN of_IN Wikipedia_NNP has_VBZ such_JJ uni-grams_NNS as_IN ``_`` 不_FW 正_FW 確_FW て_FW あ_FW る_FW fuseikakudearu_FW -LRB-_-LRB- incorrect_JJ -RRB-_-RRB- ''_'' and_CC ``_`` 不_FW 完_FW 全_FW て_FW あ_FW る_FW fukanzendearu_FW -LRB-_-LRB- incomplete_JJ -RRB-_-RRB- ''_'' as_IN synonyms_NNS of_IN bi_SYM -_: gram_NN ``_`` 正しく_FW ない_FW tadashiku_FW nai_FW -LRB-_-LRB- not_RB correct_VB -RRB-_-RRB- ._. ''_''
Before_IN 3/10_CD 14:46_CD at_IN 3/11_CD 14:00_CD at_IN 3/13_CD After_IN 14:00_CD at_IN 3/13_CD We_PRP do_VBP not_RB have_VB any_DT annotated_JJ corpus_NN ._.
The_DT earthquake_NN occurred_VBD ._.
Start_VB anno_NN -_: tation_NN ._.
Stop_NNP annotation_NN ._.
Now_RB we_PRP have_VBP anno_NN -_: tated_VBD the_DT data_NNS extracted_VBN from_IN tweets_NNS posted_VBD two_CD days_NNS just_RB after_IN the_DT earth_NN -_: quake_NN ._.
Start_VB negation_NN recognition_NN using_VBG the_DT trained_JJ classifier_NN with_IN the_DT annotated_JJ data_NNS ._.
Figure_NN 2_CD :_: Simulation_NN settings_NNS We_PRP re-organized_VBD the_DT composition_NN of_IN the_DT training_NN and_CC the_DT test_NN sets_VBZ as_IN follows_VBZ :_: •_CD Training_NN set_VBN 2_CD contains_VBZ 626_CD complex_JJ negation_NN instances_NNS extracted_VBN from_IN tweets_NNS posted_VBD from_IN 14:00_CD 3/11_CD to_TO 14:00_CD 3/13_CD ,_, •_CD Test_NN set_VBN 2_CD contains_VBZ 1,269_CD complex_JJ negation_NN instances_NNS extracted_VBN from_IN tweets_NNS posted_VBN after_IN 14:00_CD 3/13_CD ._.
Note_VB that_IN some_DT tweets_NNS have_VBP been_VBN posted_VBN before_IN 14:00_CD 3/11_CD and_CC they_PRP are_VBP not_RB used_VBN in_IN this_DT experiments_NNS ._.
In_IN this_DT case_NN ,_, we_PRP should_MD make_VB the_DT classifier_NN more_RBR specific_JJ to_TO the_DT disaster_NN that_WDT actually_RB occurred_VBD ;_: the_DT previous_JJ experiments_NNS considered_VBN a_DT general_JJ situation_NN ._.
We_PRP experimented_VBD with_IN two_CD approaches_NNS ._.
Method_NNP Precision_NNP -LRB-_-LRB- %_NN -RRB-_-RRB- Recall_VB -LRB-_-LRB- %_NN -RRB-_-RRB- F-score_NN -LRB-_-LRB- %_NN -RRB-_-RRB- Proposed_VBN 48.96_CD -LRB-_-LRB- 212_CD /_CD 433_CD -RRB-_-RRB- 16.71_CD -LRB-_-LRB- 212_CD /_CD 1269_CD -RRB-_-RRB- 24.91_CD +_SYM twitter2days_NNS 46.41_CD -LRB-_-LRB- 220_CD /_CD 474_CD -RRB-_-RRB- 17.34_CD -LRB-_-LRB- 220_CD /_CD 1269_CD -RRB-_-RRB- 25.24_CD +_NN content_NN 52.49_CD -LRB-_-LRB- 253_CD /_CD 482_CD -RRB-_-RRB- 19.94_CD -LRB-_-LRB- 253_CD /_CD 1269_CD -RRB-_-RRB- 28.90_CD +_SYM twitter2days_NNS +_VBP content_JJ 51.64_CD -LRB-_-LRB- 268_CD /_CD 519_CD -RRB-_-RRB- 21.12_CD -LRB-_-LRB- 268_CD /_CD 1269_CD -RRB-_-RRB- 29.98_CD The_DT first_JJ approach_NN obtained_VBD another_DT set_NN of_IN n-gram_JJ clusters_NNS using_VBG all_PDT the_DT tweets_NNS posted_VBD in_IN the_DT two_CD days_NNS -LRB-_-LRB- 4.8_CD GB_NNP -RRB-_-RRB- denoted_VBN by_IN twitter2days_NNS ._.
We_PRP set_VBP the_DT num_NN -_: ber_NN of_IN vector_NN dimensions_NNS to_TO 300_CD and_CC the_DT number_NN of_IN clusters_NNS to_TO 10,000_CD ._.
This_DT set_NN of_IN clusters_NNS has_VBZ more_JJR spe_NN -_: cific_JJ synonymous_JJ words_NNS than_IN the_DT other_JJ clusters_NNS ob_SYM -_: tained_VBN for_IN tweets_NNS not_RB in_IN the_DT disaster_NN ._.
For_IN instance_NN ,_, ``_`` 雨_FW ame_FW -LRB-_-LRB- rain_NN -RRB-_-RRB- ''_'' has_VBZ many_JJ expressions_NNS that_WDT are_VBP syn_SYM -_: onyms_NNS only_RB in_IN this_DT disaster_NN ,_, such_JJ as_IN ``_`` 汚染_FW さ_FW れ_FW た雨osensaretaame_FW ,_, 黒い雨kuroiame_NN ,_, 有害_CD な_CD 雨_NN yugaina_NN ame_NN ,_, 有_FW 毒_FW な_FW 雨_FW yudokuna_FW ame_FW -LRB-_-LRB- all_DT of_IN which_WDT mean_VBP toxic_JJ rain_NN -RRB-_-RRB- ,_, ''_'' while_IN in_IN other_JJ clusters_NNS ``_`` 雨_FW ame_FW -LRB-_-LRB- rain_NN -RRB-_-RRB- ''_'' has_VBZ general_JJ synonyms_NNS ,_, such_JJ as_IN ``_`` 小_FW 雨_FW kosame_FW -LRB-_-LRB- light_JJ rain_NN -RRB-_-RRB- ,_, ''_'' ``_`` 冷_FW た_FW い_FW 雨_FW tsumetai_FW ame_FW -LRB-_-LRB- cold_JJ rain_NN -RRB-_-RRB- ,_, ''_'' and_CC ``_`` 大雨_FW ohame_FW -LRB-_-LRB- heavy_JJ rain_NN -RRB-_-RRB- ._. ''_''
These_DT specific_JJ synonyms_NNS were_VBD obtained_VBN because_IN the_DT fol_NN -_: lowing_VBG false_JJ rumor_NN was_VBD disseminated_VBN and_CC repeated_VBN for_IN a_DT long_JJ period_NN :_: ``_`` There_EX may_MD be_VB toxic_JJ rain_NN due_JJ to_TO an_DT explosion_NN at_IN Cosmo_NNP Oil_NNP ._. ''_''
The_DT second_JJ approach_NN uses_VBZ target_NN predicates_NNS and_CC their_PRP$ arguments_NNS for_IN feature_NN generation_NN ._.
Some_DT false_JJ rumors_NNS were_VBD disseminated_VBN and_CC repeated_VBN for_IN a_DT long_JJ periods_NNS ,_, such_JJ as_IN ``_`` Drinking_JJ iodine_NN protects_VBZ against_IN radiation_NN ._. ''_''
There_EX were_VBD also_RB many_JJ tweets_NNS to_TO negate_VB such_JJ false_JJ rumors_NNS ._.
Therefore_RB ,_, we_PRP used_VBD the_DT content_NN of_IN the_DT false_JJ rumors_NNS for_IN training_NN to_TO recognize_VB other_JJ negated_VBN predicates_NNS whose_WP$ content_NN is_VBZ the_DT same_JJ as_IN the_DT trained_JJ ones_NNS ._.
We_PRP modified_VBD the_DT ``_`` following_JJ words_NNS ''_'' and_CC ``_`` n-gram_JJ clusters_NNS ''_'' features_NNS to_TO use_VB not_RB only_RB the_DT seven_CD words_NNS that_WDT follow_VBP the_DT target_NN predicate_NN but_CC also_RB the_DT target_NN predicate_VB itself_PRP ._.
We_PRP had_VBD to_TO choose_VB two_CD parameters_NNS :_: the_DT number_NN of_IN vector_NN dimensions_NNS and_CC the_DT number_NN of_IN clusters_NNS for_IN four_CD corpora_NN :_: web_NN ,_, wikipedia_NN ,_, twitter_NN ,_, and_CC twit_NN -_: ter2days_NNS ._.
We_PRP chose_VBD the_DT same_JJ numbers_NNS of_IN the_DT pre_NN -_: vious_JJ experiment_NN for_IN the_DT three_CD former_JJ corpora_NN and_CC chose_VBD 300_CD as_IN the_DT dimension_NN and_CC 10,000_CD as_IN the_DT num_NN -_: ber_NN of_IN clusters_NNS for_IN the_DT last_JJ one_NN that_WDT is_VBZ identical_JJ to_TO twit_VB -_: ter_NN in_IN the_DT general_JJ situation_NN ._.
Table_NNP 8_CD shows_VBZ the_DT results_NNS ._.
The_DT ``_`` +_JJ twitter2days_NNS d300_VBP n10000_CD ''_'' column_NN indicates_VBZ that_IN we_PRP used_VBD the_DT extra_JJ n-gram_JJ cluster_NN and_CC outperformed_VBD ``_`` Proposed_VBN ,_, ''_'' which_WDT had_VBD the_DT best_JJS setting_NN in_IN the_DT previous_JJ experi_NNS -_: ments_NNS ._.
Even_RB if_IN we_PRP have_VBP a_DT limited_JJ amount_NN of_IN anno_NN -_: tated_VBN data_NNS in_IN the_DT disaster_NN ,_, large_JJ un-annotated_JJ corpora_NN can_MD improve_VB the_DT performance_NN of_IN complex_JJ negation_NN recognition_NN ._.
Note_VB that_IN the_DT performance_NN of_IN complex_JJ negation_NN recognition_NN is_VBZ lower_JJR than_IN the_DT previous_JJ ex_FW -_: periments_NNS since_IN we_PRP used_VBD a_DT smaller_JJR annotated_JJ corpus_NN in_IN this_DT simulation_NN ._.
The_DT ``_`` +_JJ content_NN ''_'' column_NN indicates_VBZ that_IN we_PRP modi_SYM -_: fied_VBD the_DT features_NNS to_TO capture_VB the_DT content_NN of_IN the_DT pred_VBN -_: icate_NN ,_, and_CC the_DT ``_`` +_JJ twitter2days_NNS +_VBP content_NN ''_'' column_NN in_IN -_: dicates_NNS that_IN we_PRP used_VBD the_DT extra_JJ n-gram_JJ cluster_NN with_IN the_DT content_NN features_NNS ._.
The_DT comparisons_NNS between_IN ``_`` Proposed_VBN ''_'' and_CC ``_`` +_JJ content_NN ''_'' and_CC ``_`` +_SYM twitter2days_NNS ''_'' and_CC ``_`` +_SYM twitter2days_NNS +_VBP content_NN ''_'' suggest_VBP that_IN when_WRB many_JJ tweets_NNS are_VBP disseminated_VBN and_CC repeated_VBN for_IN a_DT long_JJ pe_NN -_: riods_NNS about_IN particular_JJ topics_NNS ,_, we_PRP must_MD use_VB content_JJ words_NNS ._.
6_CD Conclusion_NN We_PRP presented_VBD a_DT method_NN for_IN recognizing_VBG negations_NNS on_IN Twitter_NNP and_CC showed_VBD that_IN n-gram_JJ clusters_NNS de_IN -_: rived_VBN from_IN large_JJ un-annotated_JJ corpora_NN obtained_VBN by_IN word2vec_CD are_VBP effective_JJ for_IN capturing_VBG complex_JJ types_NNS of_IN negations_NNS ,_, like_IN the_DT negations_NNS of_IN ``_`` occur_VBP ''_'' in_IN the_DT sen_NN -_: tence_NN ``_`` The_DT guy_NN who_WP tweeted_VBD that_IN a_DT nuclear_JJ explosion_NN occurred_VBD has_VBZ watched_VBN too_RB many_JJ SF_NNP movies_NNS ._. ''_''
We_PRP also_RB simulated_JJ the_DT situation_NN of_IN the_DT Great_NNP East_NNP Japan_NNP Earthquake_NN in_IN 2011_CD ._.
We_PRP used_VBD annotated_JJ data_NNS posted_VBD within_IN two_CD days_NNS after_IN the_DT earthquake_NN for_IN training_NN ,_, and_CC we_PRP also_RB recognized_VBD negation_NN for_IN tweets_NNS posted_VBD on_IN other_JJ days_NNS ._.
We_PRP found_VBD that_IN using_VBG un-annotated_JJ data_NNS for_IN the_DT ``_`` n-gram_JJ clusters_NNS ''_'' feature_NN and_CC the_DT captur_NN -_: ing_NN contents_NNS are_VBP effective_JJ for_IN negation_NN recognition_NN ._.
We_PRP are_VBP going_VBG to_TO implement_VB a_DT false_JJ rumor_NN detection_NN system_NN by_IN integrating_VBG our_PRP$ proposed_VBN method_NN with_IN the_DT rule-based_JJ method_NN ._.
We_PRP expect_VBP our_PRP$ system_NN to_TO be_VB use_NN -_: ful_NN in_IN future_JJ disaster_NN situations_NNS ._.
Acknowledgments_NNS This_DT work_NN was_VBD partially_RB supported_VBN by_IN the_DT Coun_NNP -_: cil_NN for_IN Science_NN ,_, Technology_NNP and_CC Innovation_NNP -LRB-_-LRB- CSTI_NNP -RRB-_-RRB- through_IN the_DT Cross-ministerial_JJ Strategic_NNP Innovation_NNP Promotion_NNP Program_NNP -LRB-_-LRB- SIP_NNP -RRB-_-RRB- ,_, titled_VBN ``_`` Enhancement_NN of_IN societal_JJ resiliency_NN against_IN natural_JJ disasters_NNS ''_'' -LRB-_-LRB- Fund_NNP -_: ing_NN agency_NN :_: JST_NNP -RRB-_-RRB- ._.
Table_NNP 8_CD :_: Results_NNS of_IN disaster_NN situation_NN simulation_NN References_NNP Adam_NNP L_NNP Berger_NNP ,_, Vincent_NNP J_NNP Della_NNP Pietra_NNP ,_, and_CC Stephen_NNP A_NNP Della_NNP Pietra_NNP ._.
1996_CD ._.
A_DT maximum_NN entropy_NN approach_NN to_TO natural_JJ language_NN processing_NN ._.
Computational_JJ lin_NN -_: guistics_NNS ,_, 22_CD -LRB-_-LRB- 1_CD -RRB-_-RRB- :39_CD --_: 71_CD ._.
Chih-Chung_NNP Chang_NNP and_CC Chih-Jen_NNP Lin_NNP ._.
2011_CD ._.
LIBSVM_NNP :_: A_NNP library_NN for_IN support_NN vector_NN machines_NNS ._.
ACM_NNP Transac_NNP -_: tions_NNS on_IN Intelligent_NNP Systems_NNPS and_CC Technology_NNP ,_, 2:27:1_CD --_: 27:27_CD ._.
Software_NNP available_JJ at_IN http://www.csie_NN ._.
ntu.edu.tw_NNP /_CD ̃cjlin_JJ /_NN libsvm_NN ._.
Marie-Catherine_NNP de_NNP Marneffe_NNP ,_, Christopher_NNP D._NNP Manning_NNP ,_, and_CC Christopher_NNP Potts_NNP ._.
2012_CD ._.
Did_VBD it_PRP happen_VB ?_.
The_DT pragmatic_JJ complexity_NN of_IN veridicality_NN assessment_NN ._.
Computational_NNP Linguistics_NNP ,_, 38_CD -LRB-_-LRB- 2_LS -RRB-_-RRB- :301_CD --_: 333_CD ._.
Ryu_NNP Iida_NNP ,_, Mamoru_NNP Komachi_NNP ,_, Kentaro_NNP Inui_NNP ,_, and_CC Yuji_NNP Mat_NNP -_: sumoto_NN ._.
2007_CD ._.
Annotating_VBG a_DT Japanese_JJ text_NN corpus_NN with_IN predicate-argument_NN and_CC coreference_NN relations_NNS ._.
In_IN Pro-_JJ ceedings_NNS of_IN the_DT Linguistic_NNP Annotation_NNP Workshop_NNP ,_, pages_NNS 132_CD --_: 139_CD ._.
Jun_NN '_'' ichi_FW Kazama_FW and_CC Kentaro_NNP Torisawa_NNP ._.
2008_CD ._.
Inducing_VBG gazetteers_NNS for_IN named_VBN entity_NN recognition_NN by_IN large-scale_JJ clustering_NN of_IN dependency_NN relations_NNS ._.
In_IN Proceedings_NNP of_IN ACL-08_NNP :_: HLT_NNP ,_, pages_NNS 407_CD --_: 415_CD ,_, Columbus_NNP ,_, Ohio_NNP ,_, June_NNP ._.
Association_NNP for_IN Computational_NNP Linguistics_NNP ._.
Taku_NNP Kudo_NNP ,_, Kaoru_NNP Yamamoto_NNP ,_, and_CC Yuji_NNP Matsumoto_NNP ._.
2004_CD ._.
Applying_VBG conditional_JJ random_JJ fields_NNS to_TO Japanese_JJ morphological_JJ analysis_NN ._.
In_IN EMNLP_NNP ,_, volume_NN 4_CD ,_, pages_NNS 230_CD --_: 237_CD ._.
Sadao_NNP Kurohashi_NNP ,_, Toshihisa_NNP Nakamura_NNP ,_, Yuji_NNP Matsumoto_NNP ,_, and_CC Makoto_NNP Nagao_NNP ._.
1994_CD ._.
Improvements_NNP of_IN Japanese_NNP morphological_JJ analyzer_NN JUMAN_NNP ._.
In_IN Proceedings_NNP of_IN The_DT International_NNP Workshop_NNP on_IN Sharable_NNP Natural_NNP Lan_NNP -_: guage_NN ,_, pages_NNS 22_CD --_: 28_CD ._.
Tomas_NNP Mikolov_NNP ,_, Ilya_NNP Sutskever_NNP ,_, Kai_NNP Chen_NNP ,_, Greg_NNP S_NNP Cor_NNP -_: rado_NN ,_, and_CC Jeff_NNP Dean_NNP ._.
2013_CD ._.
Distributed_VBN representations_NNS of_IN words_NNS and_CC phrases_NNS and_CC their_PRP$ compositionality_NN ._.
In_IN C.J.C._NNP Burges_NNP ,_, L._NNP Bottou_NNP ,_, M._NNP Welling_NNP ,_, Z._NNP Ghahramani_NNP ,_, and_CC K.Q._NNP Weinberger_NNP ,_, editors_NNS ,_, Advances_NNS in_IN Neural_NNP In_IN -_: formation_NN Processing_NNP Systems_NNP 26_CD ,_, pages_NNS 3111_CD --_: 3119_CD ._.
Curran_NNP Associates_NNPS ,_, Inc._NNP ._.
Jong-Hoon_NNP Oh_UH ,_, Kentaro_NNP Torisawa_NNP ,_, Chikara_NNP Hashimoto_NNP ,_, Takuya_NNP Kawada_NNP ,_, Stijn_NNP De_NNP Saeger_NNP ,_, Jun_NNP '_POS ichi_JJ Kazama_NNP ,_, and_CC Yiou_NNP Wang_NNP ._.
2012_CD ._.
Why_WRB question_NN answering_VBG using_VBG sentiment_NN analysis_NN and_CC word_NN classes_NNS ._.
In_IN Proceedings_NNP of_IN the_DT 2012_CD Joint_NNP Conference_NNP on_IN Empirical_NNP Methods_NNPS in_IN Natural_NNP Language_NNP Processing_NNP and_CC Computational_NNP Natural_NNP Language_NNP Learning_NNP ,_, pages_NNS 368_CD --_: 378_CD ._.
Associa_SYM -_: tion_NN for_IN Computational_NNP Linguistics_NNP ._.
James_NNP Pustejovsky_NNP ,_, Patrick_NNP Hanks_NNP ,_, Roser_NNP Sauri_NNP ,_, Andrew_NNP See_NNP ,_, Robert_NNP Gaizauskas_NNP ,_, Andrea_NNP Setzer_NNP ,_, Dragomir_NNP Radev_NNP ,_, Beth_NNP Sundheim_NNP ,_, David_NNP Day_NNP ,_, Lisa_NNP Ferro_NNP ,_, et_FW al._FW 2003_CD ._.
The_DT timebank_JJ corpus_NN ._.
In_IN Corpus_NNP linguistics_NNS ,_, volume_NN 2003_CD ,_, page_NN 40_CD ._.
Roser_NNP Saur_NNP ́ı_NN and_CC James_NNP Pustejovsky_NNP ._.
2007_CD ._.
Determining_VBG modality_NN and_CC factuality_NN for_IN text_NN entailment_NN ._.
In_IN First_NNP IEEE_NNP International_NNP Conference_NNP on_IN Semantic_NNP Comput_NNP -_: ing_NN ,_, pages_NNS 509_CD --_: 516_CD ._.
IEEE_NNP ._.
Roser_NNP Saur_NNP ́ı_NN and_CC James_NNP Pustejovsky_NNP ._.
2009_CD ._.
FactBank_NNP :_: A_DT corpus_NN annotated_VBN with_IN event_NN factuality_NN ._.
Language_NN resources_NNS and_CC evaluation_NN ,_, 43_CD -LRB-_-LRB- 3_LS -RRB-_-RRB- :227_CD --_: 268_CD ._.
Roser_NNP Saur_NNP ́ı_NN ._.
2008_CD ._.
A_DT factuality_NN profiler_NN for_IN eventualities_NNS in_IN text_NN ._.
Ph.D._NNP thesis_NN ,_, Brandeis_NNP University_NNP ._.
Sandeep_NNP Soni_NNP ,_, Tanushree_NNP Mitra_NNP ,_, Eric_NNP Gilbert_NNP ,_, and_CC Jacob_NNP Eisenstein_NNP ._.
2014_CD ._.
Modeling_VBG factuality_NN judgments_NNS in_IN social_JJ media_NNS text_NN ._.
In_IN Proceedings_NNP of_IN the_DT 52nd_JJ Annual_JJ Meeting_VBG of_IN the_DT Association_NNP for_IN Computational_NNP Linguis_NNP -_: tics_NNS -LRB-_-LRB- Volume_NN 2_CD :_: Short_JJ Papers_NNP -RRB-_-RRB- ,_, pages_NNS 415_CD --_: 420_CD ,_, Balti_NNP -_: more_JJR ,_, Maryland_NNP ,_, June_NNP ._.
Association_NNP for_IN Computational_NNP Linguistics_NNP ._.
Vladimir_NNP Vapnik_NNP ._.
2000_CD ._.
The_DT nature_NN of_IN statistical_JJ learning_NN theory_NN ._.
Springer_NNP Science_NNP &_CC Business_NNP Media_NNP ._.
Naoki_NNP Yoshinaga_NNP and_CC Masaru_NNP Kitsuregawa_NNP ._.
2009_CD ._.
Poly_SYM -_: nomial_JJ to_TO linear_JJ :_: Efficient_JJ classification_NN with_IN conjunc_NN -_: tive_JJ features_NNS ._.
In_IN Proceedings_NNP of_IN the_DT 2009_CD Conference_NN on_IN Empirical_JJ Methods_NNS in_IN Natural_JJ Language_NN Process_NNP -_: ing_NN ,_, pages_NNS 1542_CD --_: 1551_CD ._.
