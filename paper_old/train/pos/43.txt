1_CD Abstract_NNP High_NNP dimension_NN of_IN bag-of-words_JJ vectors_NNS poses_VBZ a_DT serious_JJ challenge_NN from_IN sparse_JJ data_NNS ,_, overfitting_NN ,_, irrelevant_JJ features_NNS to_TO document_VB classification_NN ._.
Filter_NNP feature_NN selection_NN is_VBZ one_CD of_IN effective_JJ methods_NNS for_IN dimensionality_NN reduction_NN by_IN removing_VBG irrelevant_JJ features_NNS from_IN feature_NN set_NN ._.
This_DT paper_NN focuses_VBZ on_IN two_CD main_JJ problems_NNS of_IN filter_NN feature_NN selection_NN which_WDT are_VBP the_DT feature_NN score_NN computation_NN and_CC the_DT imbalance_NN in_IN the_DT feature_NN selection_NN performance_NN between_IN categories_NNS ._.
We_PRP propose_VBP a_DT novel_NN filter_NN feature_NN selection_NN method_NN ,_, named_VBN ExFCFS_NNP ,_, to_TO comprehensively_RB resolve_VB these_DT problems_NNS ._.
We_PRP experiment_NN on_IN related_JJ filter_NN feature_NN selection_NN methods_NNS with_IN two_CD benchmark_JJ datasets_NNS -_: Reuters-21578_NN dataset_NN and_CC Ohsumed_NNP dataset_NN ._.
The_DT experimental_JJ results_NNS show_VBP the_DT effectiveness_NN of_IN our_PRP$ solutions_NNS in_IN terms_NNS of_IN both_DT Micro-F1_NN measure_NN and_CC Macro-F1_NN measure_NN ._.
Keywords_NNS --_: bag-of-words_NNS vector_NN ,_, filter_NN feature_NN selection_NN ,_, document_NN classification_NN Introduction_NNP Ho_NNP Bao_NNP Quoc_NNP School_NNP of_IN Information_NNP Technology_NNP VNUHCM_NNP -_: University_NNP of_IN Science_NNP Ho_NNP Chi_NNP Minh_NNP City_NNP ,_, Vietnam_NNP hbquoc@fit.hcmus.edu.vn_NNP is_VBZ shown_VBN in_IN the_DT form_NN of_IN a_DT vector_NN in_IN which_WDT each_DT term_NN appearing_VBG in_IN the_DT document_NN is_VBZ considered_VBN as_IN a_DT feature_NN ._.
However_RB ,_, with_IN a_DT large_JJ set_NN of_IN documents_NNS ,_, the_DT dimension_NN of_IN a_DT bag-of-words_JJ vector_NN can_MD reach_VB thousands_NNS -LRB-_-LRB- Fragoudis_NNPS et_FW al._FW 2005_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Yang_NNP et_FW al._FW 2012_CD -RRB-_-RRB- ._.
Therefore_RB ,_, it_PRP poses_VBZ a_DT serious_JJ challenge_NN from_IN sparse_JJ data_NNS ,_, overfitting_NN ,_, irrelevant_JJ features_NNS to_TO document_VB classification_NN -LRB-_-LRB- Fragoudis_NNPS et_FW al._FW 2005_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Sebastiani_NNP 2002_CD -RRB-_-RRB- ._.
In_IN -LRB-_-LRB- Bellman_NNP 1961_CD -RRB-_-RRB- ,_, the_DT author_NN referred_VBD it_PRP to_TO as_IN ``_`` the_DT curse_NN of_IN dimensionality_NN ''_'' ._.
Thus_RB ,_, dimensionality_NN reduction_NN is_VBZ a_DT major_JJ research_NN area_NN ._.
The_DT aim_NN of_IN dimensionality_NN reduction_NN is_VBZ to_TO decrease_VB the_DT number_NN of_IN features_NNS without_IN degrading_VBG the_DT performance_NN of_IN the_DT system_NN -LRB-_-LRB- Sebastiani_NNP 2002_CD -RRB-_-RRB- ._.
An_DT efficient_JJ approach_NN for_IN dimension_NN reduction_NN is_VBZ Feature_NNP Selection_NNP -LRB-_-LRB- FS_NNP -RRB-_-RRB- -LRB-_-LRB- Yang_NNP and_CC Pedersen_NNP 1997_CD -RRB-_-RRB- ._.
Feature_NN selection_NN eliminates_VBZ irrelevant_JJ features_NNS to_TO select_VB a_DT good_JJ subset_NN of_IN the_DT original_JJ feature_NN set_NN ._.
A_DT strong_JJ point_NN of_IN FS_NNP is_VBZ that_IN the_DT interpretation_NN of_IN the_DT important_JJ features_NNS in_IN the_DT original_JJ set_NN is_VBZ not_RB altered_VBN in_IN dimensionality_NN reduction_NN process_NN ._.
T_NNP wo_MD main_JJ types_NNS of_IN FS_NNP are_VBP wrapper_JJ methods_NNS -LRB-_-LRB- Bermejo_NNP et_FW al._FW 2014_CD -RRB-_-RRB- and_CC filter_NN methods_NNS -LRB-_-LRB- Yang_NNP and_CC Pedersen_NNP 1997_CD -RRB-_-RRB- ._.
Wrapper_NN methods_NNS select_VBP a_DT subset_NN of_IN features_NNS which_WDT is_VBZ the_DT most_RBS suitable_JJ with_IN a_DT specific_JJ classification_NN algorithm_NN ._.
Conversely_RB ,_, filter_NN methods_NNS do_VBP not_RB depend_VB on_IN any_DT classification_NN algorithms_NNS ._.
It_PRP relies_VBZ on_IN a_DT function_NN for_IN evaluating_VBG the_DT importance_NN of_IN a_DT feature_NN in_IN the_DT classification_NN process_NN ._.
A_DT subset_NN of_IN features_NNS is_VBZ selected_VBN by_IN simply_RB ranking_VBG the_DT value_NN of_IN every_DT feature_NN on_IN the_DT evaluation_NN function_NN ._.
Therefore_RB ,_, it_PRP is_VBZ commonly_RB used_VBN in_IN document_NN classification_NN -LRB-_-LRB- Fragoudis_NNPS et_FW al._FW 2005_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Yang_NNP et_FW al._FW 2012_CD -RRB-_-RRB- ._.
A_DT Comprehensive_NNP Filter_NNP Feature_NNP Selection_NNP for_IN Improving_NN Document_NNP Classification_NNP Document_NNP classification_NN is_VBZ to_TO assign_VB documents_NNS to_TO predefined_JJ categories_NNS based_VBN on_IN their_PRP$ text_NN contents_NNS -LRB-_-LRB- Sebastiani_NNP 2002_CD -RRB-_-RRB- ._.
It_PRP is_VBZ a_DT useful_JJ tool_NN for_IN managing_VBG the_DT organization_NN of_IN a_DT large_JJ set_NN of_IN documents_NNS ._.
In_IN the_DT document_NN classification_NN ,_, a_DT bag-of-words_JJ vector_NN is_VBZ usually_RB used_VBN for_IN presenting_VBG a_DT document_NN -LRB-_-LRB- Yang_NNP et_FW al._FW 2012_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Joachims_NNPS 1996_CD -RRB-_-RRB- ._.
Concretely_RB ,_, a_DT document_NN In_IN this_DT paper_NN ,_, we_PRP focus_VBP on_IN filter_NN feature_NN selection_NN methods_NNS ._.
Table_NNP 1_CD shows_NNS their_PRP$ general_JJ structure_NN ._.
With_IN this_DT greedy_JJ characteristic_NN ,_, Information_NNP Gain_NNP is_VBZ a_DT non-optimal_JJ method_NN -LRB-_-LRB- Yan_JJ et_FW al._FW 2005_CD -RRB-_-RRB- ._.
1.2_CD Chi-square_JJ Similar_JJ to_TO IG_NNP ,_, Chi-square_JJ -LRB-_-LRB- Yang_NNP and_CC Pedersen_NNP 1997_CD -RRB-_-RRB- -LRB-_-LRB- CHI_NNP -RRB-_-RRB- is_VBZ a_DT greedy_JJ algorithm_NN ._.
It_PRP measures_VBZ the_DT independence_NN of_IN category_NN value_NN and_CC feature_NN value_NN ._.
The_DT formula_NN of_IN CHI_NNP is_VBZ as_RB following_JJ :_: -LRB-_-LRB- ,_, -RRB-_-RRB- =_SYM ._.
-LRB-_-LRB- -RRB-_-RRB- ._.
-LRB-_-LRB- -LRB-_-LRB- |_NN -RRB-_-RRB- −_NN -LRB-_-LRB- -RRB-_-RRB- -RRB-_-RRB- -LRB-_-LRB- -RRB-_-RRB- ._.
-LRB-_-LRB- 1_CD −_CD -LRB-_-LRB- -RRB-_-RRB- -RRB-_-RRB- ._.
-LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- 1_CD −_CD -LRB-_-LRB- -RRB-_-RRB- -RRB-_-RRB- Where_WRB is_VBZ the_DT number_NN of_IN documents_NNS ,_, |_JJ |_NN is_VBZ the_DT number_NN of_IN categories_NNS ,_, -LRB-_-LRB- -RRB-_-RRB- is_VBZ the_DT probability_NN of_IN a_DT document_NN containing_VBG term_NN ,_, -LRB-_-LRB- -RRB-_-RRB- is_VBZ the_DT probability_NN of_IN a_DT document_NN belonging_VBG to_TO category_NN ,_, -LRB-_-LRB- |_JJ -RRB-_-RRB- is_VBZ the_DT conditional_JJ probabilities_NNS of_IN a_DT document_NN belonging_VBG to_TO category_NN given_VBN that_IN it_PRP contains_VBZ term_NN ._.
1.3_CD Frequency-based_JJ approach_NN This_DT approach_NN only_RB focuses_VBZ on_IN the_DT term-category_JJ frequency_NN matrix_NN for_IN computing_NN -LRB-_-LRB- ,_, -RRB-_-RRB- as_IN Document_NNP Frequency_NNP -LRB-_-LRB- DF_NNP -RRB-_-RRB- -LRB-_-LRB- Yang_NNP and_CC Pedersen_NNP 1997_CD -RRB-_-RRB- ,_, DIA_NNP association_NN factor_NN -LRB-_-LRB- DIF_NNP -RRB-_-RRB- -LRB-_-LRB- Sebastiani_NNP 2002_CD -RRB-_-RRB- ,_, Comprehensively_RB Measure_NN Feature_NNP Selection_NNP -LRB-_-LRB- CMFS_NNP -RRB-_-RRB- -LRB-_-LRB- Yang_NNP et_FW al._FW 2012_CD -RRB-_-RRB- ._.
In_IN CMFS_NNP ,_, term_NN is_VBZ important_JJ in_IN the_DT prediction_NN of_IN category_NN if_IN term_NN largely_RB appears_VBZ in_IN category_NN and_CC the_DT frequency_NN of_IN term_NN in_IN the_DT training_NN set_VBN focuses_VBZ much_RB on_IN category_NN ._.
Therefore_RB ,_, -LRB-_-LRB- ,_, -RRB-_-RRB- is_VBZ computed_VBN as_IN following_VBG :_: -LRB-_-LRB- ,_, -RRB-_-RRB- =_SYM -LRB-_-LRB- |_JJ -RRB-_-RRB- ._.
-LRB-_-LRB- |_JJ -RRB-_-RRB- -LRB-_-LRB- 1_LS -RRB-_-RRB- Where_WRB -LRB-_-LRB- |_JJ -RRB-_-RRB- is_VBZ the_DT conditional_JJ probabilities_NNS of_IN term_NN given_VBN that_IN it_PRP occurred_VBD in_IN category_NN ;_: -LRB-_-LRB- |_JJ -RRB-_-RRB- is_VBZ the_DT conditional_JJ probabilities_NNS of_IN category_NN given_VBN the_DT occurrence_NN of_IN term_NN ._.
In_IN -LRB-_-LRB- ,_, -RRB-_-RRB- ,_, -LRB-_-LRB- |_JJ -RRB-_-RRB- presents_VBZ a_DT intra_NN -_: category_NN condition_NN for_IN the_DT frequency_NN of_IN terms_NNS in_IN category_NN ,_, while_IN -LRB-_-LRB- |_NN -RRB-_-RRB- indicates_VBZ a_DT inter_NN -_: category_NN condition_NN related_VBN to_TO the_DT frequency_NN of_IN term_NN not_RB only_RB in_IN category_NN but_CC also_RB in_IN various_JJ categories_NNS ._.
1.4_CD Cluster-based_JJ approach_NN This_DT approach_NN aims_VBZ at_IN selecting_VBG a_DT subset_NN of_IN features_NNS in_IN order_NN to_TO optimize_VB objective_JJ functions_NNS for_IN clustering_VBG where_WRB each_DT cluster_NN is_VBZ corresponding_JJ to_TO a_DT predefined_VBN document_NN category_NN ._.
Orthogonal_NNP Centroid_NNP Feature_NNP Selection_NNP -LRB-_-LRB- OCFS_NNP -RRB-_-RRB- is_VBZ a_DT well_RB -_: Input_NN :_: Bag-of-words_NNS vectors_NNS ;_: :_: the_DT number_NN of_IN selected_VBN features_NNS ._.
Output_NN :_: :_: a_DT subset_NN of_IN features_NNS with_IN predefined_VBN size_NN For_IN each_DT term_NN -LRB-_-LRB- =_SYM 1_CD ..._: |_CD |_NN -RRB-_-RRB- For_IN each_DT category_NN -LRB-_-LRB- =_SYM 1_CD ..._: |_CD |_NN -RRB-_-RRB- Step_NN 1_CD :_: Step_NN 2_CD :_: Step_NN 3_CD :_: for_IN the_DT Step_NN 4_CD :_: Step_NN 5_CD :_: prediction_NN of_IN all_DT categories_NNS from_IN of_IN term_NN :_: -LRB-_-LRB- -RRB-_-RRB- ._.
Step6_NNP :_: Endfor_NNP Step_NN 7_CD :_: Select_NNP L_NNP terms_NNS from_IN top_JJ L_NNP highest_JJS :_: ._.
Compute_VB the_DT importance_NN of_IN term_NN prediction_NN of_IN category_NN :_: -LRB-_-LRB- ,_, -RRB-_-RRB- ._.
End_NN for_IN Compute_NNP global_JJ score_NN of_IN term_NN for_IN the_DT Table_NNP 1_CD :_: The_DT general_JJ structure_NN of_IN filter_NN FS_NNP methods_NNS Specifically_RB ,_, filter_NN feature_NN selection_NN methods_NNS compute_VBP the_DT importance_NN of_IN term_NN for_IN the_DT prediction_NN of_IN category_NN ,_, noted_VBN by_IN -LRB-_-LRB- ,_, -RRB-_-RRB- ._.
Then_RB ,_, the_DT importance_NN of_IN term_NN for_IN the_DT prediction_NN of_IN all_DT categories_NNS ,_, noted_VBN by_IN -LRB-_-LRB- -RRB-_-RRB- ,_, is_VBZ calculated_VBN by_IN using_VBG the_DT average_JJ or_CC maximum_JJ value_NN of_IN category-specific_JJ scores_NNS of_IN term_NN over_IN the_DT different_JJ categories_NNS -LRB-_-LRB- Yang_NNP and_CC Pedersen_NNP 1997_CD -RRB-_-RRB- ._.
The_DT terms_NNS from_IN top_JJ highest_JJS are_VBP selected_VBN to_TO the_DT final_JJ set_NN ._.
Next_JJ ,_, we_PRP present_VBP main_JJ methods_NNS for_IN computing_NN -LRB-_-LRB- ,_, -RRB-_-RRB- as_IN following_NN :_: 1.1_CD Information_NN Gain_NNP The_NNP basic_JJ idea_NN of_IN Information_NNP Gain_NNP -LRB-_-LRB- Quinlan_NNP 1986_CD -RRB-_-RRB- is_VBZ to_TO measure_VB predictable_JJ bits_NNS of_IN category_NN value_NN if_IN we_PRP know_VBP in_IN advance_NN the_DT occurrence_NN of_IN a_DT term_NN ._.
With_IN IG_NNP ,_, the_DT score_NN of_IN term_NN with_IN respect_NN to_TO a_DT specific_JJ category_NN is_VBZ as_IN following_VBG :_: -LRB-_-LRB- ,_, -RRB-_-RRB- =_SYM -LRB-_-LRB- ,_, -RRB-_-RRB- -LRB-_-LRB- ,_, -RRB-_-RRB- є_FW -LCB-_-LRB- ,_, -RCB-_-RRB- є_FW -LCB-_-LRB- ,_, -RCB-_-RRB- where_WRB -LRB-_-LRB- ,_, -RRB-_-RRB- is_VBZ the_DT probability_NN of_IN a_DT document_NN belonging_VBG to_TO category_NN C_NNP and_CC containing_VBG term_NN t_NN ;_: -LRB-_-LRB- C_NNP -RRB-_-RRB- is_VBZ the_DT probability_NN of_IN a_DT document_NN belonging_VBG to_TO category_NN C_NNP ;_: -LRB-_-LRB- -RRB-_-RRB- is_VBZ the_DT probability_NN of_IN a_DT document_NN containing_VBG term_NN t._NN However_RB ,_, it_PRP is_VBZ impossible_JJ to_TO determine_VB a_DT set_NN of_IN features_NNS whose_WP$ IG_NNP is_VBZ maximal_JJ ._.
It_PRP is_VBZ NP_NNP problem_NN -LRB-_-LRB- Yan_JJ et_FW al._FW 2005_CD -RRB-_-RRB- ._.
Therefore_RB ,_, IG_NNP formula_NN is_VBZ applied_VBN for_IN each_DT feature_NN and_CC the_DT final_JJ set_NN consists_VBZ of_IN the_DT features_NNS from_IN the_DT top_JJ global_JJ scores_NNS ._.
-LRB-_-LRB- -RRB-_-RRB- ._.
-LRB-_-LRB- -RRB-_-RRB- known_VBN method_NN of_IN this_DT approach_NN -LRB-_-LRB- Yan_JJ et_FW al._FW 2005_CD -RRB-_-RRB- ._.
It_PRP optimizes_VBZ the_DT separation_NN of_IN categories_NNS -LRB-_-LRB- clusters_NNS -RRB-_-RRB- in_IN the_DT filter_NN FS_NNP process_NN ._.
It_PRP is_VBZ implemented_VBN into_IN of_IN a_DT term_NN as_IN following_VBG :_: -LRB-_-LRB- -RRB-_-RRB- |_JJ |_NN -LRB-_-LRB- -RRB-_-RRB- =_SYM −_FW -LRB-_-LRB- 2_LS -RRB-_-RRB- Where_WRB is_VBZ the_DT number_NN of_IN documents_NNS in_IN training_NN set_VBN ;_: is_VBZ the_DT mean_JJ vector_NN of_IN all_DT documents_NNS in_IN training_NN set_VBN ;_: is_VBZ the_DT number_NN of_IN documents_NNS in_IN category_NN ;_: is_VBZ the_DT mean_JJ vector_NN of_IN all_DT documents_NNS in_IN ;_: -LRB-_-LRB- -RRB-_-RRB- denotes_VBZ the_DT feature_NN value_NN of_IN term_NN in_IN global_JJ centroid_JJ vector_NN ;_: -LRB-_-LRB- -RRB-_-RRB- denotes_VBZ the_DT feature_NN value_NN of_IN term_NN in_IN category_NN centroid_JJ vector_NN According_VBG to_TO -LRB-_-LRB- Yang_NNP and_CC Pedersen_NNP 1997_CD -RRB-_-RRB- ,_, a_DT way_NN for_IN computing_VBG the_DT global_JJ score_NN of_IN term_NN for_IN the_DT category_NN prediction_NN ,_, -LRB-_-LRB- -RRB-_-RRB- ,_, is_VBZ the_DT average_NN of_IN the_DT category-specific_JJ scores_NNS of_IN term_NN over_IN the_DT different_JJ categories_NNS as_IN following_VBG :_: -LRB-_-LRB- -RRB-_-RRB- |_FW |_FW =_SYM -LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- ,_, -RRB-_-RRB- -LRB-_-LRB- 3_LS -RRB-_-RRB- =_SYM -LRB-_-LRB- -RRB-_-RRB- −_CD -LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- 4_LS -RRB-_-RRB- Approach_NNP In_IN this_DT section_NN ,_, we_PRP analyze_VBP two_CD filter_NN feature_NN selection_NN approaches_NNS which_WDT are_VBP the_DT frequency_NN -_: based_VBN approach_NN and_CC the_DT cluster-based_JJ approach_NN ._.
Our_PRP$ aim_NN is_VBZ to_TO point_VB out_RP their_PRP$ weak_JJ points_NNS and_CC strong_JJ points_NNS to_TO propose_VB a_DT filter_NN feature_NN selection_NN method_NN for_IN improving_VBG the_DT performance_NN of_IN document_NN classification_NN ._.
For_IN the_DT frequency-based_JJ approach_NN ,_, -LRB-_-LRB- ,_, -RRB-_-RRB- is_VBZ a_DT comprehensive_JJ combination_NN of_IN the_DT frequency-based_JJ intra-category_JJ condition_NN ,_, which_WDT is_VBZ -LRB-_-LRB- |_JJ -RRB-_-RRB- ,_, and_CC the_DT frequency_NN -_: based_VBN inter-category_JJ condition_NN ,_, which_WDT is_VBZ -LRB-_-LRB- |_JJ -RRB-_-RRB- ._.
Regarding_VBG the_DT frequency-based_JJ inter_NN -_: category_NN condition_NN ,_, -LRB-_-LRB- |_JJ -RRB-_-RRB- is_VBZ rewritten_VBN according_VBG to_TO conditional_JJ probability_NN theory_NN as_IN following_VBG :_: -LRB-_-LRB- |_JJ -RRB-_-RRB- =_SYM -LRB-_-LRB- ,_, -RRB-_-RRB- +_SYM 1_CD -LRB-_-LRB- -RRB-_-RRB- +_FW |_FW |_FW Where_WRB -LRB-_-LRB- ,_, -RRB-_-RRB- is_VBZ the_DT frequency_NN of_IN term_NN in_IN category_NN ;_: -LRB-_-LRB- -RRB-_-RRB- is_VBZ the_DT frequency_NN of_IN term_NN in_IN the_DT training_NN set_NN ;_: |_CD |_NN is_VBZ the_DT number_NN of_IN categories_NNS ._.
For_IN -LRB-_-LRB- |_NN -RRB-_-RRB- ,_, the_DT greatness_NN of_IN the_DT proportion_NN of_IN the_DT frequency_NN of_IN term_NN in_IN category_NN to_TO the_DT frequency_NN of_IN term_NN in_IN the_DT other_JJ categories_NNS is_VBZ utilized_VBN to_TO present_VB the_DT contribution_NN of_IN term_NN for_IN discriminating_VBG category_NN from_IN the_DT other_JJ categories_NNS ._.
However_RB ,_, this_DT is_VBZ not_RB really_RB perfect_JJ because_IN a_DT term_NN almost_RB never_RB showed_VBD in_IN category_NN but_CC often_RB appearing_VBG in_IN the_DT other_JJ categories_NNS is_VBZ still_RB useful_JJ for_IN classifying_VBG a_DT document_NN into_IN category_NN ._.
Therefore_RB ,_, an_DT inter-category_JJ condition_NN in_IN -LRB-_-LRB- ,_, -RRB-_-RRB- is_VBZ presented_VBN more_JJR clearly_RB under_IN the_DT view_NN point_NN of_IN clustering_NN ._.
Concretely_RB ,_, this_DT is_VBZ the_DT deviation_NN of_IN the_DT representative_NN of_IN term_NN in_IN category/cluster_NN ,_, which_WDT is_VBZ the_DT centroid_JJ value_NN of_IN term_NN in_IN -LRB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RRB-_-RRB- ,_, to_TO the_DT representative_NN of_IN term_NN in_IN the_DT training_NN set_NN ,_, which_WDT is_VBZ the_DT centroid_JJ value_NN of_IN term_NN in_IN the_DT training_NN set_NN -LRB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RRB-_-RRB- as_IN shown_VBN in_IN -LRB-_-LRB- ,_, -RRB-_-RRB- ._.
In_IN the_DT other_JJ hand_NN ,_, -LRB-_-LRB- ,_, -RRB-_-RRB- presents_VBZ such_JJ a_DT good_JJ inter_NN -_: category_NN condition_NN but_CC does_VBZ not_RB mention_VB any_DT conditions_NNS of_IN term_NN for_IN intra-category_JJ ._.
Therefore_RB ,_, according_VBG to_TO the_DT conclusion_NN of_IN CMFS_NNP -LRB-_-LRB- Yang_NNP et_FW al._FW 2012_CD -RRB-_-RRB- ,_, this_DT is_VBZ not_RB good_JJ for_IN a_DT filter_NN FS_NNP process_NN ._.
Based_VBN on_IN this_DT observation_NN ,_, we_PRP propose_VBP a_DT novel_NN filter_NN feature_NN selection_NN approach_NN for_IN the_DT combination_NN of_IN the_DT cluster-based_JJ inter-category_JJ condition_NN ,_, which_WDT is_VBZ -LRB-_-LRB- ,_, -RRB-_-RRB- as_IN Eq_NNP ._.
-LRB-_-LRB- 4_LS -RRB-_-RRB- ,_, and_CC the_DT frequency-based_JJ intra-category_JJ condition_NN ,_, which_WDT is_VBZ the_DT first_JJ part_NN of_IN Eq_NNP ._.
-LRB-_-LRB- 1_LS -RRB-_-RRB- ._.
The_DT formula_NN of_IN FCFS_NNP is_VBZ as_RB following_JJ :_: -LRB-_-LRB- ,_, -RRB-_-RRB- =_SYM -LRB-_-LRB- |_JJ -RRB-_-RRB- ._.
-LRB-_-LRB- -RRB-_-RRB- −_CD -LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- ,_, -RRB-_-RRB- +1_CD -LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- -RRB-_-RRB- =_SYM -LRB-_-LRB- ,_, -RRB-_-RRB- +_FW |_FW |_FW ._.
−_NNP Where_WRB -LRB-_-LRB- ,_, -RRB-_-RRB- is_VBZ the_DT sum_NN of_IN the_DT frequency_NN of_IN all_DT terms_NNS in_IN category_NN ;_: |_CD |_NN is_VBZ the_DT number_NN of_IN terms_NNS in_IN the_DT bag-of-words_NNS vector_NN ._.
Furthermore_RB ,_, FCFS_NNP does_VBZ not_RB consider_VB the_DT imbalance_NN in_IN the_DT classification_NN performance_NN between_IN categories_NNS after_IN the_DT filter_NN feature_NN selection_NN process_NN ._.
This_DT problem_NN is_VBZ caused_VBN by_IN two_CD factors_NNS ._.
From_IN Eq_NNP ._.
can_MD be_VB presented_VBN as_IN following_NN :_: 2_CD -LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- 2_LS -RRB-_-RRB- and_CC Eq_NNP ._.
-LRB-_-LRB- 3_LS -RRB-_-RRB- ,_, -LRB-_-LRB- ,_, -RRB-_-RRB- -LRB-_-LRB- ,_, -RRB-_-RRB- Firstly_RB ,_, classification_NN algorithms_NNS tend_VBP to_TO focus_VB on_IN categories_NNS containing_VBG more_JJR training_NN documents_NNS than_IN the_DT others_NNS ._.
This_DT is_VBZ a_DT big_JJ challenge_NN of_IN data_NNS mining_NN field_NN ._.
Secondly_RB ,_, the_DT computation_NN of_IN -LRB-_-LRB- ,_, -RRB-_-RRB- does_VBZ not_RB mention_VB the_DT separation_NN degree_NN of_IN the_DT category_NN from_IN the_DT others_NNS ._.
Concretely_RB ,_, if_IN the_DT separation_NN degree_NN of_IN category_NN is_VBZ greater_JJR than_IN that_DT of_IN category_NN from_IN the_DT other_JJ categories_NNS ,_, presented_VBN terms_NNS of_IN category_NN obviously_RB have_VBP higher_JJR score_NN compared_VBN with_IN those_DT of_IN category_NN ._.
Therefore_RB ,_, after_IN the_DT term_NN score_NN ranking_NN ,_, there_EX are_VBP a_DT large_JJ number_NN of_IN terms_NNS supporting_VBG category_NN to_TO be_VB selected_VBN into_IN the_DT final_JJ set_NN ,_, while_IN it_PRP does_VBZ not_RB contain_VB enough_JJ terms_NNS for_IN classifying_VBG category_NN ._.
To_TO solve_VB this_DT problem_NN ,_, we_PRP propose_VBP an_DT Extended_VBN version_NN of_IN FCFS_NNP ,_, named_VBN ExFCFS_NNP ,_, with_IN aim_NN of_IN strengthening_VBG the_DT score_NN of_IN a_DT term_NN with_IN respect_NN to_TO rare_JJ categories_NNS and_CC poor_JJ separation_NN categories_NNS ,_, and_CC weakening_VBG the_DT score_NN of_IN a_DT term_NN with_IN respect_NN to_TO abundant_JJ categories_NNS and_CC great_JJ separation_NN categories_NNS ._.
Therefore_RB ,_, in_IN ExFCFS_NNP ,_, we_PRP modify_VBP -LRB-_-LRB- ,_, -RRB-_-RRB- in_IN inverse_JJ proportion_NN to_TO the_DT number_NN of_IN training_NN document_NN of_IN category_NN -LRB-_-LRB- -RRB-_-RRB- and_CC the_DT separation_NN degree_NN of_IN category_NN from_IN the_DT other_JJ categories_NNS as_IN following_VBG :_: -LRB-_-LRB- ,_, -RRB-_-RRB- -LRB-_-LRB- ,_, -RRB-_-RRB- +1_CD ._.
-LRB-_-LRB- -RRB-_-RRB- −_CD -LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- ,_, -RRB-_-RRB- +_FW |_FW |_FW ._.
-LRB-_-LRB- -RRB-_-RRB- Where_WRB -LRB-_-LRB- -RRB-_-RRB- is_VBZ the_DT separation_NN degree_NN of_IN category_NN from_IN the_DT other_JJ categories_NNS ._.
According_VBG to_TO -LRB-_-LRB- Friedman_NNP et_FW al._FW 2001_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Chakraborti_NNP et_FW al._FW 2007_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Howland_NNP and_CC Park_NNP 2004_CD -RRB-_-RRB- ,_, under_IN the_DT view_NN point_NN of_IN clustering_VBG where_WRB each_DT cluster_NN is_VBZ considered_VBN as_IN a_DT predefined_VBN document_NN category_NN ,_, -LRB-_-LRB- -RRB-_-RRB- is_VBZ computed_JJ using_VBG the_DT ``_`` within-cluster_NN ''_'' -LRB-_-LRB- W_NNP -RRB-_-RRB- and_CC ``_`` between-cluster_NN ''_'' -LRB-_-LRB- B_NNP -RRB-_-RRB- factor_NN of_IN cluster_NN -LRB-_-LRB- category_NN -RRB-_-RRB- as_RB following_VBG :_: -LRB-_-LRB- -RRB-_-RRB- =_SYM -LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- -RRB-_-RRB- =_SYM −_FW m_FW ∑_FW ∈_FW −_FW To_TO compute_VB the_DT importance_NN of_IN a_DT term_NN globally_RB ,_, the_DT maximum_NN value_NN of_IN the_DT category-specific_JJ term_NN scores_NNS of_IN a_DT term_NN over_IN the_DT different_JJ categories_NNS is_VBZ particularly_RB useful_JJ according_VBG to_TO -LRB-_-LRB- Aggawal_JJ and_CC Zhai_NNP 2012_CD -RRB-_-RRB- :_: -LRB-_-LRB- -RRB-_-RRB- =_SYM -LRB-_-LRB- ,_, -RRB-_-RRB- -LRB-_-LRB- 5_CD -RRB-_-RRB- ..._: |_CD |_NN Therefore_RB ,_, in_IN this_DT paper_NN ,_, we_PRP apply_VBP Eq_NNP ._.
-LRB-_-LRB- 5_CD -RRB-_-RRB- for_IN computing_VBG the_DT global_JJ score_NN of_IN ExFCFS_NNP as_IN following_VBG :_: -LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- ,_, -RRB-_-RRB- +1_CD ._.
-LRB-_-LRB- -RRB-_-RRB- −_CD -LRB-_-LRB- -RRB-_-RRB- =_SYM max_FW ..._: |_CD |_NN -LRB-_-LRB- ,_, -RRB-_-RRB- +_FW |_FW |_FW ._.
-LRB-_-LRB- -RRB-_-RRB- For_IN the_DT feature_NN selection_NN ,_, the_DT final_JJ set_NN consists_VBZ of_IN the_DT terms_NNS from_IN the_DT top_JJ L_NNP highest_JJS global_JJ term_NN scores_NNS where_WRB L_NNP is_VBZ a_DT predefined_VBN size_NN of_IN the_DT selected_VBN feature_NN set_NN ._.
The_DT detail_NN of_IN ExFCFS_NNP is_VBZ presented_VBN in_IN Table_NNP 2_CD ._.
Input_NN :_: Bag-of-words_NNS vectors_NNS ;_: :_: the_DT number_NN of_IN selected_VBN features_NNS Output_NN :_: :_: the_DT subset_NN of_IN features_NNS with_IN the_DT predefined_VBN size_NN Step_NN 1_CD :_: For_IN each_DT category_NN -LRB-_-LRB- =_SYM 1_CD ..._: |_CD |_NN -RRB-_-RRB- Step_NN 2_CD :_: Compute_VB the_DT sum_NN of_IN term_NN frequency_NN of_IN all_DT terms_NNS in_IN category_NN :_: -LRB-_-LRB- ,_, -RRB-_-RRB- ._.
Step_NN 3_CD :_: Compute_VB the_DT centroid_JJ vector_NN of_IN all_DT documents_NNS in_IN category_NN :_: ._.
Step_NN 4_CD :_: End_NN for_IN Step_NN 5_CD :_: Compute_VB the_DT centroid_JJ vector_NN of_IN all_DT documents_NNS :_: ._.
Step_NN 6_CD :_: For_IN each_DT term_NN -LRB-_-LRB- =_SYM 1_CD ..._: |_CD |_NN -RRB-_-RRB- Step_NN 7_CD :_: Get_VB the_DT value_NN of_IN term_NN in_IN global_JJ centroid_JJ vector_NN :_: -LRB-_-LRB- -RRB-_-RRB- ._.
Step_NN 8_CD :_: For_IN each_DT category_NN -LRB-_-LRB- =_SYM 1_CD ..._: |_CD |_NN -RRB-_-RRB- Step_NN 9_CD :_: Get_VB the_DT value_NN of_IN term_NN in_IN category_NN centroid_JJ vector_NN :_: -LRB-_-LRB- -RRB-_-RRB- ._.
Step_NN 10_CD :_: Compute_VB the_DT frequency_NN of_IN term_NN in_IN category_NN :_: -LRB-_-LRB- ,_, -RRB-_-RRB- ._.
Step_NN 11_CD :_: Get_VB the_DT number_NN of_IN training_NN documents_NNS in_IN category_NN :_: ._.
Step_NN 12_CD :_: Compute_VB the_DT score_NN of_IN term_NN with_IN category_NN from_IN -LRB-_-LRB- ,_, -RRB-_-RRB- ,_, -LRB-_-LRB- ,_, -RRB-_-RRB- ,_, -LRB-_-LRB- -RRB-_-RRB- ,_, -LRB-_-LRB- -RRB-_-RRB- ,_, ,_, ,_, :_: -LRB-_-LRB- ,_, -RRB-_-RRB- ._.
Step_NN 13_CD :_: Compute_VB the_DT maximum_NN of_IN -LRB-_-LRB- ,_, -RRB-_-RRB- :_: -LRB-_-LRB- -RRB-_-RRB- Step_NN 14_CD :_: End_NN for_IN Step_NN 15_CD :_: End_NN for_IN Step_NN 16_CD :_: Select_NNP terms_NNS from_IN the_DT top_JJ highest_JJS :_: =_SYM Table_NNP 2_CD :_: The_DT description_NN of_IN ExFCFS_NNP 3_CD Experiment_NNP 3.1_CD Experimental_JJ steps_NNS In_IN the_DT experiment_NN ,_, we_PRP compare_VBP the_DT performance_NN of_IN the_DT proposed_VBN filter_NN FS_NNP method_NN with_IN that_DT of_IN related_JJ filter_NN feature_NN selection_NN methods_NNS as_IN CMFS_NNP -LRB-_-LRB- Yang_NNP et_FW al._FW 2012_CD -RRB-_-RRB- ,_, OCFS_NNP -LRB-_-LRB- Yan_NNP et_FW al._FW 2005_CD -RRB-_-RRB- ,_, IG_NNP -LRB-_-LRB- Quinlan_NNP 1986_CD -RRB-_-RRB- ,_, CHI_NNP -LRB-_-LRB- Yang_NNP and_CC Pedersen_NNP 1997_CD -RRB-_-RRB- ._.
The_DT experimental_JJ steps_NNS are_VBP as_RB following_VBG :_: For_IN preprocessing_NN ,_, stop_VB words_NNS are_VBP removed_VBN by_IN using_VBG a_DT set_NN of_IN 659_CD stop_NN words_NNS ._.
The_DT stemming_VBG process_NN is_VBZ executed_VBN with_IN Porter_NNP Stemming_VBG algorithm_NN -LRB-_-LRB- Porter_NNP 1997_CD -RRB-_-RRB- ._.
For_IN text_NN representation_NN ,_, we_PRP use_VBP TF-IDF_NNP of_IN every_DT term_NN as_RB well_RB as_IN bag-of-words_NNS technique_NN ._.
The_DT training_NN bag-of-words_JJ vectors_NNS are_VBP reduced_VBN by_IN a_DT filter_NN FS_NNP method_NN ._.
Then_RB ,_, they_PRP are_VBP used_VBN for_IN building_VBG a_DT leaning_VBG model_NN using_VBG SVM_NNP classifier_NN by_IN SMO_NNP -LRB-_-LRB- Platt_NNP 1999_CD -RRB-_-RRB- with_IN default_NN setting_NN of_IN WEKA_NNP tool_NN -LRB-_-LRB- Hall_NNP et_FW al._FW 2009_CD -RRB-_-RRB- ._.
The_DT testing_NN bag-of-words_NNS vectors_NNS are_VBP created_VBN only_RB based_VBN on_IN the_DT selected_VBN terms_NNS from_IN the_DT filter_NN feature_NN selection_NN process_NN ._.
The_DT classification_NN system_NN is_VBZ evaluated_VBN on_IN these_DT bag-of-words_NNS vectors_NNS ._.
3.2_CD Dataset_NNP In_IN this_DT paper_NN ,_, we_PRP use_VBP two_CD benchmark_JJ datasets_NNS for_IN evaluating_VBG the_DT performance_NN of_IN filter_NN feature_NN selection_NN methods_NNS ._.
The_DT first_JJ dataset_NN is_VBZ the_DT top-10_JJ categories_NNS of_IN Reuters-21578_NN ModApte_NNP 's_POS split_NN -LRB-_-LRB- Asuncion_NNP and_CC Newman_NNP 2007_CD -RRB-_-RRB- ._.
They_PRP consist_VBP of_IN stories_NNS collected_VBN from_IN the_DT Reuters_NNP news_NN ._.
The_DT second_JJ dataset_NN is_VBZ top-10_JJ categories_NNS of_IN medical_JJ abstracts_NNS of_IN year_NN 1991_CD from_IN U.S_NNP National_NNP Library_NNP of_IN Medicine_NNP ,_, named_VBN Ohsumed_NNP collection_NN ._.
A_DT standard_JJ training_NN and_CC testing_NN split_NN of_IN Ohsumed_NNP collection_NN is_VBZ Joachim_NNP 's_POS split_NN -LRB-_-LRB- Joachims_NNPS 1998_CD -RRB-_-RRB- ._.
The_DT detailed_JJ description_NN of_IN these_DT datasets_NNS is_VBZ presented_VBN in_IN Table_NNP 3-4_CD ._.
3.3_CD Measure_NN T_NNP wo_MD standard_JJ measures_NNS for_IN evaluating_VBG the_DT performance_NN for_IN multi_NNS categories_NNS classification_NN are_VBP Macro-F1_NNP and_CC Micro-F1_NNP -LRB-_-LRB- Sebastiani_NNP 2002_CD -RRB-_-RRB- ._.
Macro_NNP -_: F1_CD measure_NN considers_VBZ all_DT categories_NNS equally_RB including_VBG rare_JJ categories_NNS -LRB-_-LRB- Tascı_NNP and_CC Güngör_NNP 2013_CD -RRB-_-RRB- ._.
Concretely_RB ,_, Macro-F1_NNP is_VBZ computed_VBN as_IN following_VBG :_: ∑_FW |_FW |_FW ∑_FW |_FW |_FW =_SYM |_FW |_FW =_SYM |_FW |_FW 1_CD =_SYM 2_CD +_CD Where_WRB and_CC are_VBP precision_NN and_CC recall_NN measure_NN on_IN category_NN ,_, |_CD |_NN is_VBZ the_DT number_NN of_IN categories_NNS ._.
Contrary_JJ to_TO Macro-F1_NNP ,_, Micro-F1_NN measure_NN ignores_VBZ the_DT category_NN discrimination_NN ._.
The_DT Micro-F1_NN measure_NN is_VBZ computed_VBN globally_RB as_IN following_VBG :_: ∑_FW |_FW |_FW ∑_FW |_FW |_FW =_SYM =_SYM ∑_FW |_FW |_FW -LRB-_-LRB- +_JJ -RRB-_-RRB- ∑_FW |_FW |_FW -LRB-_-LRB- +_JJ -RRB-_-RRB- 1_CD =_SYM 2_CD +_CD To_TO explicitly_RB compare_VB the_DT performance_NN of_IN filter_NN feature_NN selection_NN methods_NNS ,_, -LRB-_-LRB- Gunal_NNP &_CC Edizkan_NNP 2008_CD -RRB-_-RRB- relies_VBZ on_IN the_DT above_JJ measures_NNS to_TO propose_VB dimension_NN reduction_NN rate_NN as_IN following_NN :_: 1_CD =_SYM -LRB-_-LRB- 10_CD -RRB-_-RRB- where_WRB is_VBZ the_DT number_NN of_IN tests_NNS in_IN the_DT experiment_NN ,_, is_VBZ the_DT number_NN of_IN selected_VBN features_NNS in_IN th_JJ test_NN ,_, is_VBZ the_DT accuracy_NN measure_NN in_IN th_JJ test_NN ,_, and_CC is_VBZ the_DT maximum_NN feature_NN size_NN which_WDT is_VBZ tested_VBN ._.
Category_NNP Train_NNP Docs_NNPS Test_NNP Docs_NNP C01_NNP 423_CD 506_CD C04_NNP 1163_CD 1467_CD C06_NNP 588_CD 632_CD C08_NNP 473_CD 600_CD C10_NNP 621_CD 941_CD C12_NNP 491_CD 548_CD C14_NNP 1249_CD 1301_CD C20_NNP 525_CD 695_CD C21_NNP 546_CD 717_CD C23_NNP 1799_CD 777_CD The_DT number_NN of_IN features_NNS in_IN bag-of-words_JJ vector_NN :_: 17756_CD Table_NNP 3_CD :_: The_DT description_NN of_IN Ohsumed_NNP dataset_NN Category_NNP Training_NNP Docs_NNP Testing_NNP Docs_NNP Corn_NNP 181_CD 56_CD Wheat_NN 212_CD 71_CD Ship_NN 197_CD 89_CD Trade_NNP 369_CD 117_CD Interest_NN 347_CD 131_CD Grain_NN 433_CD 149_CD money-fx_JJ 538_CD 179_CD Crude_JJ 389_CD 189_CD Acq_NNP 1650_CD 719_CD Earn_NNP 2877_CD 1087_CD The_DT number_NN of_IN features_NNS in_IN bag-of-words_JJ vector_NN :_: 16684_CD Table_NNP 4_CD :_: The_DT description_NN of_IN Reuters-21578dataset_NNP 3.4_CD Experimental_JJ Result_NN and_CC Discussion_NNP Table_NNP 5-8_CD show_VBP the_DT experimental_JJ results_NNS of_IN the_DT filter_NN feature_NN selection_NN methods_NNS in_IN our_PRP$ study_NN ._.
It_PRP can_MD be_VB noted_VBN from_IN these_DT tables_NNS as_IN following_VBG :_: In_IN terms_NNS of_IN Macro-F1_NNP ,_, the_DT best_JJS filter_NN selection_NN methods_NNS are_VBP FCFS_NNP and_CC ExFCFS_NNP ._.
In_IN comparison_NN between_IN them_PRP ,_, ExFCFS_JJ products_NNS better_RBR result_VB than_IN FCFS_NNP ._.
Regarding_VBG Micro-F1_NN ,_, ExFCFS_NNP attains_VBZ the_DT most_RBS favourable_JJ result_NN ._.
FCFS_NNP is_VBZ often_RB superior_JJ to_TO IG_NNP ,_, CHI_NNP ,_, OCFS_NNP ,_, CMFS_NNP ,_, but_CC at_IN the_DT large_JJ number_NN of_IN selected_VBN features_NNS ,_, their_PRP$ differences_NNS are_VBP rather_RB small_JJ ._.
An_DT exact_JJ explanation_NN for_IN the_DT goodness_NN of_IN FCFS_NNP and_CC ExFCFS_NNP is_VBZ the_DT effective_JJ combination_NN of_IN the_DT clustered-based_JJ inter-category_JJ condition_NN and_CC frequency-based_JJ intra-category_JJ condition_NN in_IN the_DT computation_NN of_IN their_PRP$ term_NN score_NN ._.
This_DT lends_VBZ support_NN to_TO the_DT theory_NN of_IN CMFS_NNP -LRB-_-LRB- Yang_NNP et_FW al._FW 2012_CD -RRB-_-RRB- ._.
To_TO observe_VB detailed_JJ performance_NN of_IN filter_NN feature_NN selection_NN methods_NNS ,_, we_PRP present_VBP F1-measure_NN of_IN each_DT category_NN with_IN CMFS_NNP ,_, IG_NNP ,_, FCFS_NNP ,_, and_CC ExFCFS_NNP at_IN 60_CD features_NNS in_IN Fig._NNP 1-2_CD ._.
Specifically_RB ,_, FCFS_NNP and_CC ExFCFS_NNP show_VBP the_DT effectiveness_NN with_IN rare_JJ categories_NNS as_IN ``_`` Ship_NNP ,_, Trade_NNP ,_, Grain_NNP ,_, Interest_NNP ,_, Money_NNP -_: Fx_NNP ,_, Crude_NNP ''_'' of_IN Reuters-21578_NN dataset_NN and_CC ``_`` C01_NNP ,_, C06_NNP ,_, C08_NNP ,_, C10_NNP ,_, C12_NNP ,_, C20_NNP ,_, C21_NNP ''_'' of_IN Ohsumed_NNP dataset_NN in_IN comparison_NN with_IN IG_NNP and_CC CMFS_NNP ._.
This_DT occurs_VBZ due_JJ to_TO the_DT reason_NN that_IN in_IN case_NN of_IN IG_NNP ,_, CMFS_NNP ,_, the_DT score_NN of_IN a_DT term_NN with_IN respect_NN to_TO a_DT category_NN is_VBZ based_VBN on_IN the_DT greatness_NN of_IN the_DT frequency_NN of_IN a_DT term_NN in_IN the_DT entire_JJ category_NN ,_, while_IN the_DT frequency_NN of_IN a_DT term_NN in_IN rare_JJ categories_NNS is_VBZ very_RB low_JJ ._.
Conversely_RB ,_, FCFS_NNP and_CC ExFCFS_NNP only_RB use_VBP the_DT centroid_JJ value_NN of_IN a_DT term_NN in_IN every_DT category_NN and_CC in_IN the_DT training_NN set_VBN for_IN term_NN score_NN computation_NN ._.
Therefore_RB ,_, they_PRP preliminarily_RB improve_VBP the_DT feature_NN selection_NN performance_NN of_IN rare_JJ categories_NNS ._.
Next_JJ ,_, we_PRP consider_VBP the_DT correlation_NN between_IN performance_NN of_IN FCFS_NNP and_CC ExFCFS_NNP ._.
ExFCFS_NNP is_VBZ actually_RB an_DT extended_JJ version_NN of_IN FCFS_NNP for_IN radically_RB overcoming_VBG the_DT imbalance_NN of_IN classification_NN performance_NN between_IN categories_NNS after_IN filter_NN feature_NN selection_NN process_NN ._.
As_IN analyzed_VBN in_IN this_DT paper_NN ,_, this_DT problem_NN is_VBZ directly_RB caused_VBN by_IN the_DT imbalance_NN of_IN the_DT number_NN of_IN training_NN documents_NNS between_IN categories_NNS and_CC the_DT imbalance_NN of_IN the_DT separation_NN degree_NN between_IN categories_NNS ._.
Therefore_RB ,_, in_IN ExFCFS_NNP ,_, we_PRP adjust_VBP FCFS_NNP score_NN of_IN a_DT term_NN with_IN respect_NN to_TO a_DT category_NN in_IN inverse_JJ proportion_NN to_TO these_DT factors_NNS in_IN order_NN to_TO improve_VB the_DT classification_NN performance_NN of_IN rare_JJ categories_NNS and_CC poor_JJ separation_NN categories_NNS after_IN filter_NN feature_NN selection_NN process_NN ._.
Especially_RB ,_, both_DT of_IN these_DT two_CD factors_NNS are_VBP occurred_VBN in_IN Reuters-21578_NN datset_NN and_CC Ohsumed_NNP dataset_NN ._.
Under_IN these_DT properties_NNS of_IN two_CD experimental_JJ datasets_NNS ,_, the_DT performance_NN of_IN ExFCFS_NNP is_VBZ superior_JJ to_TO that_DT of_IN FCFS_NNP ._.
This_DT accounts_VBZ for_IN the_DT effectiveness_NN of_IN our_PRP$ adjustments_NNS in_IN ExFCFS_NNP formula_NN ._.
100_CD 90_CD 80_CD 70_CD 60_CD 50_CD 40_CD 30_CD 20_CD 10_CD 0_CD CMFS_NNP IG_NNP FCFS_NNP ExFCFS_NNP Fig._NNP 1_CD :_: F1-measure_NN of_IN CMFS_NNP ,_, IG_NNP ,_, FCFS_NNP ,_, and_CC ExFCFS_NNP on_IN Reuter_NNP dataset_NN at_IN 60_CD features_NNS 80_CD 70_CD 60_CD 50_CD 40_CD 30_CD 20_CD 10_CD CMFS_NNP IG_NNP FCFS_NNP ExFCFS_NNPS 0_CD C01_CD C04_NNP C06_NNP C08_NNP C10_NNP C12_NNP C14_NNP C20_NNP C21_NNP C23_NNP Fig._NNP 2_CD :_: F1-measure_NN of_IN CMFS_NNP ,_, IG_NNP ,_, FCFS_NNP ,_, and_CC ExFCFS_NNP on_IN Ohsumed_NNP dataset_NN at_IN 60_CD features_NNS Table_NNP 9_CD shows_VBZ the_DT performance_NN of_IN dissimilar_JJ terms_NNS and_CC similar_JJ terms_NNS selected_VBN by_IN filter_NN FS_NNP methods_NNS ._.
For_IN the_DT comparison_NN between_IN two_CD FS_NNP methods_NNS ,_, similar_JJ terms_NNS are_VBP terms_NNS selected_VBN by_IN both_DT of_IN them_PRP ,_, while_IN dissimilar_JJ terms_NNS are_VBP terms_NNS selected_VBN by_IN only_RB one_CD of_IN them_PRP ._.
Clearly_RB ,_, dissimilar_JJ terms_NNS are_VBP the_DT most_RBS important_JJ for_IN considering_VBG two_CD FS_NNP methods_NNS ._.
The_DT result_NN listed_VBN in_IN Table_NNP 9_CD shows_NNS that_WDT at_IN top-60_JJ selected_VBN terms_NNS ,_, dissimilar_JJ terms_NNS of_IN FCFS_NNP are_VBP superior_JJ to_TO those_DT of_IN CHI_NNP ,_, IG_NNP ,_, CMFS_NNP ,_, and_CC OCFS_NNP but_CC is_VBZ inferior_JJ to_TO those_DT of_IN ExFCFS_NNS ._.
This_DT is_VBZ one_CD of_IN strong_JJ evidences_NNS for_IN the_DT superiority_NN of_IN ExFCFS_NNP and_CC FCFS_NNP over_IN the_DT other_JJ methods_NNS ._.
Regarding_VBG dimension_NN reduction_NN rate_NN ,_, due_JJ to_TO the_DT best_JJS Micro-F1_NN and_CC Macro-F1_JJ results_NNS of_IN ExFCFS_NNP ,_, it_PRP produces_VBZ better_JJR dimension_NN reduction_NN rate_NN than_IN the_DT other_JJ methods_NNS in_IN all_DT two_CD datasets_NNS as_IN shown_VBN in_IN Fig._NNP 3-4_CD ._.
FCFS_NNP is_VBZ superior_JJ to_TO CHI_NNP ,_, IG_NNP ,_, CMFS_NNP and_CC OCFS_NNP at_IN the_DT small_JJ number_NN of_IN selected_VBN features_NNS and_CC they_PRP show_VBP the_DT competition_NN at_IN the_DT larger_JJR number_NN of_IN features_NNS ._.
However_RB ,_, based_VBN on_IN dimension_NN reduction_NN rate_NN formula_NN presented_VBN in_IN Eq_NNP ._.
-LRB-_-LRB- 10_CD -RRB-_-RRB- ,_, FS_NNP methods_NNS having_VBG better_JJR performance_NN at_IN smaller_JJR number_NN of_IN selected_VBN features_NNS are_VBP preferred_VBN ._.
Therefore_RB ,_, dimension_NN reduction_NN rate_NN of_IN FCFS_NNP is_VBZ better_JJR than_IN that_DT of_IN CHI_NNP ,_, IG_NNP ,_, CMFS_NNP ,_, and_CC OCFS_NNP as_IN presented_VBN in_IN Fig._NNP 3-4_CD ._.
1000_CD 900_CD 800_CD 700_CD 600_CD 500_CD 400_CD Fig._NN 3_CD ._.
700_CD 650_CD 600_CD 559.26_CD 558.39_CD 550_CD 901.04_CD 1200_CD 1150_CD 1100_CD 1050_CD 1000_CD 950_CD 900_CD 1142.53_CD 1033.14_CD 500 450 400_CD Fig._NN 4_CD ._.
Dimension_NN Reduction_NNP Rate_NNP on_IN Ohsumed_NNP dataset_NN :_: -LRB-_-LRB- a_DT -RRB-_-RRB- for_IN Macro-F1_NN ;_: -LRB-_-LRB- b_NN -RRB-_-RRB- for_IN Micro-F1_NN 768.33_CD 659.84_CD 837.27_CD FCFS_NNP 781.94_CD OCFS_NNP 1100.40_CD CHI_NNP 1109.80_CD FCFS_NNP 1094.67_CD IG_NNP OCFS_NNP CHI_NNP CMFS_NNP ExFCFS_NNP -LRB-_-LRB- a_DT -RRB-_-RRB- CMFS_NNP ExFCFS_NNS -LRB-_-LRB- b_NN -RRB-_-RRB- CHI_NNP CMFS_NNP FxFCFS_NNP -LRB-_-LRB- a_DT -RRB-_-RRB- IG_NNP OCFS_NNP CMFS_NNP ExFCFS_NNP -LRB-_-LRB- b_NN -RRB-_-RRB- 677.27_CD 700_CD 650_CD 600_CD 550_CD 500_CD 450_CD 400_CD 685.25_CD 589.69_CD 610.63_CD FCFS_NNP 626.57_CD CHI_NNP 637.59_CD FCFS_NNP 628.96_CD IG_NNP OCFS_NNP 740.61_CD IG_NNP 1084.12_CD Dimension_NNP Reduction_NNP Rate_NNP on_IN Reuters-21578_NNP dataset_NN :_: -LRB-_-LRB- a_DT -RRB-_-RRB- for_IN Macro-F1_NN ;_: -LRB-_-LRB- b_NN -RRB-_-RRB- for_IN Micro-F1_NN 563.74_CD 581.50_CD 612.02_CD FS_NNP 20 60 100 200_CD 400 600 800 1000_CD 1200 1400 1600 1800_CD 2000_CD CHI_NNP 48.88_CD 58.12_CD 62.21_CD 64.91_CD 64.22_CD 65.03_CD 66.24_CD 67.97_CD 65.95_CD 66.53_CD 67.32_CD 66.91_CD 66.67_CD CMFS_NNP 35.82_CD 55.83_CD 61.3_CD 63.44_CD 64.56_CD 65.92_CD 67.53_CD 66.01_CD 65.85_CD 67.78_CD 67.53_CD 66.43_CD 66.46_CD ExFCFS_NNP 58.89_CD 67.08_CD 73.83_CD 72.57_CD 73.35_CD 70.72_CD 71.53_CD 71.15_CD 71.75_CD 71.64_CD 71.86_CD 71.67_CD 71.18_CD FCFS_NNP 53.55_CD 62.00_CD 70.12_CD 71.75_CD 71.85_CD 67.74_CD 68.9_CD 68.58_CD 68.24_CD 70.62_CD 69.8_CD 69.52_CD 69.37_CD IG_NNP 45.45_CD 58.56_CD 61.23_CD 63.99_CD 64.18_CD 64.6_CD 65.48_CD 66.7_CD 67.39_CD 66.8_CD 67.3_CD 67.39_CD 66.36_CD OCFS_NNP 49.66_CD 60.00_CD 63.02_CD 64.43_CD 67.36_CD 66.65_CD 66.97_CD 67.13_CD 67.86_CD 67.18_CD 66.95_CD 66.88_CD 66.87_CD Table_NNP 5_CD :_: Macro-F1_JJ result_NN on_IN Reuters-21578_NN dataset_NN ._.
Bold_JJ numbers_NNS are_VBP the_DT top_JJ 2_CD performances_NNS FS_NNP 20 60 100 200_CD 400 600 800 1000_CD 1200 1400 1600 1800_CD 2000_CD CHI_NNP 72.95_CD 81.93_CD 86.13_CD 86.73_CD 87.14_CD 87.51_CD 88.05_CD 88.23_CD 87.73_CD 87.69_CD 87.76_CD 87.55_CD 87.48_CD CMFS_NNP 65.14_CD 80.45_CD 84.79_CD 85.8_CD 85.91_CD 86.16_CD 88.2_CD 88.05_CD 87.94_CD 88.27_CD 88.05_CD 87.59_CD 87.69_CD ExFCFS_NNP 76.48_CD 85.74_CD 87.15_CD 88.23_CD 89.23_CD 89.94_CD 89.05_CD 88.94_CD 89.20_CD 89.05_CD 89.23_CD 89.09_CD 88.76_CD FCFS_NNP 73.12_CD 84.1_CD 87.06_CD 87.82_CD 87.82_CD 87.97_CD 88.07_CD 88.11_CD 87.11_CD 87.23_CD 87_CD 87.89_CD 87.61_CD IG_NNP 70.88_CD 81.98_CD 85.89_CD 86.41_CD 87.09_CD 87.87_CD 88.02_CD 87.94_CD 87.98_CD 87.66_CD 87.69_CD 87.8_CD 87.33_CD OCFS_NNP 71.36_CD 83.89_CD 86.11_CD 87.73_CD 88.30_CD 88.05_CD 88.23_CD 88.16_CD 88.2_CD 87.94_CD 87.73_CD 87.48_CD 87.51_CD Table_NNP 6_CD :_: Micro-F1_JJ result_NN on_IN Reuters-21578_NN dataset_NN ._.
Bold_JJ numbers_NNS are_VBP the_DT top_JJ 2_CD performances_NNS FS_NNP 20 60 100 200_CD 400 600 800 1000_CD 1200 1400 1600 1800_CD 2000_CD CHI_NNP 32.59_CD 44.59_CD 49.83_CD 50.71_CD 53.52_CD 54.32_CD 53.82_CD 52.96_CD 52.34_CD 51.59_CD 51.08_CD 50.98_CD 50.37_CD CMFS_NNP 33.72_CD 43.08_CD 47.4_CD 49.69_CD 51.76_CD 51.96_CD 52.65_CD 52.44_CD 52.74_CD 52.5_CD 52.27_CD 51.91_CD 51.66_CD ExFCFS_NNP 43.93_CD 51.66_CD 53.33_CD 54.33_CD 56.40_CD 56.75_CD 56.15_CD 56.51_CD 55.97_CD 55.02_CD 54.79_CD 54.36_CD 54.29_CD FCFS_NNP 37.26_CD 49.21_CD 50.82_CD 51.8_CD 54.07_CD 54.49_CD 54.2_CD 54.13_CD 53.47_CD 53.28_CD 52.78_CD 52.37_CD 52.23_CD IG_NNP 33.07_CD 45.34_CD 48.8_CD 51.28_CD 53.43_CD 54.44_CD 53.82_CD 52.98_CD 52.34_CD 51.6_CD 51.1_CD 50.98_CD 50.36_CD OCFS_NNP 34.53_CD 46.68_CD 49.8_CD 51.88_CD 53.77_CD 54.2_CD 54.54_CD 54.03_CD 53.59_CD 53.46_CD 52.65_CD 52.02_CD 52.3_CD Table_NNP 7_CD :_: Macro-F1_JJ result_NN on_IN Ohsumed_NNP dataset_NN ._.
Bold_JJ numbers_NNS are_VBP the_DT top_JJ 2_CD performances_NNS FS_NNP 20 60 100 200_CD 400 600 800 1000_CD 1200 1400 1600 1800_CD 2000_CD CHI_NNP 39.69_CD 48.8_CD 50.71_CD 51.8_CD 52.88_CD 54.04_CD 53.43_CD 52.79_CD 52.44_CD 51.94_CD 51.37_CD 51.45_CD 50.88_CD CMFS_NNP 38.23_CD 43.91_CD 44.9_CD 48.01_CD 50.68_CD 51.56_CD 51.63_CD 52.69_CD 53.15_CD 53.04_CD 52.94_CD 52.57_CD 52.39_CD ExFCFS_NNP 45.22_CD 51.60_CD 52.97_CD 53.06_CD 55.54_CD 56.22_CD 55.96_CD 56.67_CD 56.09_CD 55.43_CD 55.37_CD 55.21_CD 54.99_CD FCFS_NNP 41.35_CD 47.97_CD 50.51_CD 50.97_CD 53.2_CD 53.85_CD 53.87_CD 54.24_CD 53.75_CD 54.76_CD 53.35_CD 53.19_CD 52.9_CD IG_NNP 39.79_CD 44.31_CD 48.78_CD 50.65_CD 52.99_CD 54.15_CD 53.42_CD 52.81_CD 52.43_CD 51.93_CD 51.39_CD 51.45_CD 50.87_CD OCFS_NNP 40.66_CD 47.24_CD 49.83_CD 50.61_CD 53.02_CD 53.63_CD 54.39_CD 54.12_CD 53.97_CD 54.08_CD 53.4_CD 52.96_CD 52.34_CD Table_NNP 8_CD :_: Micro-F1_JJ result_NN on_IN Ohsumed_NNP dataset_NN ._.
Bold_JJ numbers_NNS are_VBP the_DT top_JJ 2_CD performances_NNS DataSet_NNP Measure_NN Type_NN CHI_NNP CMFS_NNP IG_NNP OCFS_NNP ExFCFS_NNP Measure_NN Type_NN CHI_NNP CMFS_NNP IG_NNP OCFS_NNP ExFCFS_NNPS A_DT Reuters_NNP Micro-F1_NNP B_NNP C_NNP A_NNP Ohsumed_NNP Micro-F1_NNP B_NNP C_NNP 54.64_CD 58.08_CD 56.30_CD 63.94_CD 80.98_CD 78.70_CD 19.62_CD 16.69_CD 12.26_CD 20.15_CD 48.70_CD 47.61_CD 52.90_CD 51.31_CD 60.28_CD 51.67_CD 80.93_CD 82.96_CD 14.42_CD 10.92_CD 19.90_CD 12.98_CD 45.00_CD 47.05_CD 65.21_CD 62.42_CD 83.07_CD 23.93_CD 17.58_CD 47.31_CD Table_NNP 9_CD :_: Micro-F1_NN and_CC Macro-F1result_NN of_IN similar_JJ terms_NNS other_JJ FS_NNP methods_NNS at_IN top-60_JJ selected_VBN terms_NNS ._.
A_DT ,_, B_NNP ,_, and_CC C_NNP dissimilar_JJ terms_NNS of_IN FCFS_NNP ,_, and_CC their_PRP$ similar_JJ terms_NNS respectively_RB ._.
4_CD Conclusion_NN This_DT paper_NN propose_VB a_DT comprehensive_JJ filter_NN FS_NNP method_NN ,_, named_VBN ExFCFS_NNP ,_, for_IN computing_VBG feature_NN score_NN and_CC overcoming_VBG the_DT imbalance_NN of_IN FS_NNP performance_NN between_IN categories_NNS ._.
In_IN ExFCFS_NNP ,_, the_DT feature_NN score_NN with_IN respect_NN to_TO a_DT specific_JJ category_NN is_VBZ the_DT combination_NN of_IN the_DT cluster-based_JJ inter-category_JJ condition_NN and_CC the_DT frequency_NN --_: based_VBN intra-category_JJ 31.42_CD 18.92_CD 32.51_CD 49.62_CD 57.31_CD 55.27_CD 16.89_CD 11.68_CD 20.78_CD 23.54_CD 44.38_CD 44.59_CD and_CC dissimilar_JJ terms_NNS selected_VBN by_IN FCFS_NNP and_CC the_DT condition_NN to_TO exploit_VB the_DT strong_JJ point_NN of_IN two_CD related_JJ approaches_NNS ._.
Then_RB ,_, we_PRP adjust_VBP this_DT combination_NN in_IN inverse_JJ proportion_NN to_TO the_DT number_NN of_IN training_NN document_NN of_IN the_DT category_NN and_CC the_DT separation_NN degree_NN of_IN the_DT category_NN ._.
The_DT experimental_JJ results_NNS show_VBP the_DT effectiveness_NN of_IN our_PRP$ solutions_NNS in_IN terms_NNS of_IN both_DT Micro-F1_NN measure_NN and_CC Macro-F1_NN measure_NN ._.
A_DT Macro-F1_NNP B_NNP C_NNP A_NNP Macro-F1_NNP B_NNP C_NNP 30.57_CD 18.60_CD 40.77_CD 38.61_CD 58.01_CD 59.31_CD 19.72_CD 12.04_CD 21.37_CD 15.99_CD 45.77_CD 46.50_CD 32.47_CD 24.18_CD 60.51_CD 22.15_CD 18.82_CD 47.03_CD indicate_VBP dissimilar_JJ terms_NNS of_IN the_DT corresponding_JJ FS_NNP ,_, References_NNP Aggarwal_NNP ,_, C._NNP C._NNP ,_, &_CC Zhai_NNP ,_, C._NNP -LRB-_-LRB- 2012_CD -RRB-_-RRB- ._.
A_DT survey_NN of_IN text_NN classification_NN algorithms_NNS ._.
In_IN Mining_NNP text_NN data_NNS -LRB-_-LRB- pp._FW 163-222_CD -RRB-_-RRB- ._.
Springer_NNP US_NNP ._.
Asuncion_NNP ,_, A._NN ,_, &_CC Newman_NNP ,_, D._NNP -LRB-_-LRB- 2007_CD -RRB-_-RRB- ._.
UCI_NNP machine_NN learning_VBG repository_NN ._.
Bermejo_NNP ,_, P._NNP ,_, Gámez_NNP ,_, J._NNP A._NNP ,_, &_CC Puerta_NNP ,_, J._NNP M._NNP -LRB-_-LRB- 2014_CD -RRB-_-RRB- ._.
Speeding_VBG up_RP incremental_JJ wrapper_NN feature_NN subset_NN selection_NN with_IN Naive_NNP Bayes_NNP classifier_NN ._.
Knowledge_NN -_: Based_VBN Systems_NNPS ,_, 55_CD ,_, 140-147_CD ._.
Platt_NNP ,_, J._NNP -LRB-_-LRB- 1999_CD -RRB-_-RRB- ._.
Fast_RB training_NN of_IN support_NN vector_NN machines_NNS using_VBG sequential_JJ minimal_JJ optimization_NN ._.
Advances_NNS in_IN kernel_NN methods_NNS --_: support_NN vector_NN learning_NN ,_, 3_CD ._.
Quinlan_NNP ,_, J._NNP R._NNP -LRB-_-LRB- 1986_CD -RRB-_-RRB- ._.
Induction_NNP of_IN decision_NN trees_NNS ._.
Machine_NN learning_NN ,_, 1_CD -LRB-_-LRB- 1_LS -RRB-_-RRB- ,_, 81-106_CD ._.
Sebastiani_NNP ,_, F._NNP -LRB-_-LRB- 2002_CD -RRB-_-RRB- ._.
Machine_NN learning_NN in_IN automated_JJ text_NN categorization_NN ._.
ACM_JJ computing_NN surveys_NNS ,_, 34_CD -LRB-_-LRB- 1_LS -RRB-_-RRB- ,_, 1-47_CD ._.
Taşcı_NNP ,_, Ş._NNP ,_, &_CC Güngör_NNP ,_, T._NNP -LRB-_-LRB- 2013_CD -RRB-_-RRB- ._.
Comparison_NN of_IN text_NN feature_NN selection_NN policies_NNS and_CC using_VBG an_DT adaptive_JJ framework_NN ._.
Expert_NNP Systems_NNPS with_IN Applications_NNS ,_, 40_CD -LRB-_-LRB- 12_CD -RRB-_-RRB- ,_, 4871-4886_CD ._.
Yan_NNP ,_, J._NNP ,_, Liu_NNP ,_, N._NNP ,_, Cheng_NNP ,_, Q._NNP ,_, ..._: &_CC Ma_NNP ,_, W._NNP Y._NNP -LRB-_-LRB- 2005_CD ,_, August_NNP -RRB-_-RRB- ._.
OCFS_NNP :_: optimal_JJ orthogonal_JJ centroid_JJ feature_NN selection_NN for_IN text_NN categorization_NN ._.
In_IN Proceedings_NNP of_IN the_DT 28th_JJ annual_JJ international_JJ ACM_NNP SIGIR_NNP conference_NN on_IN Research_NNP and_CC development_NN in_IN information_NN retrieval_NN -LRB-_-LRB- pp._FW 122-129_CD -RRB-_-RRB- ._.
ACM_NNP ._.
Yang_NNP ,_, J._NNP ,_, Liu_NNP ,_, Y._NNP ,_, Zhu_NNP ,_, X._NNP ,_, Liu_NNP ,_, Z._NNP ,_, &_CC Zhang_NNP ,_, X._NNP -LRB-_-LRB- 2012_CD -RRB-_-RRB- ._.
A_DT new_JJ feature_NN selection_NN based_VBN on_IN comprehensive_JJ measurement_NN both_DT in_IN inter-category_JJ and_CC intra_NN -_: category_NN for_IN text_NN categorization_NN ._.
Information_NNP Processing_NNP &_CC Management_NNP ,_, 48_CD -LRB-_-LRB- 4_LS -RRB-_-RRB- ,_, 741-754_CD ._.
Yang_NNP ,_, J._NNP ,_, Liu_NNP ,_, Z._NNP ,_, Qu_NNP ,_, Z._NNP ,_, &_CC Wang_NNP ,_, J._NNP -LRB-_-LRB- 2014_CD ,_, June_NNP -RRB-_-RRB- ._.
Feature_NN selection_NN method_NN based_VBN on_IN crossed_VBN centroid_NN for_IN text_NN categorization_NN ._.
In_IN Software_NNP Engineering_NNP ,_, Artificial_NNP Intelligence_NNP ,_, Networking_NNP and_CC Parallel/Distributed_NNP Computing_NNP -LRB-_-LRB- SNPD_NNP -RRB-_-RRB- ,_, 2014_CD 15th_JJ IEEE/ACIS_NNP International_NNP Conference_NNP on_IN -LRB-_-LRB- pp._FW 1-5_FW -RRB-_-RRB- ._.
IEEE_NNP ._.
Yang_NNP ,_, Y._NNP ,_, &_CC Pedersen_NNP ,_, J._NNP O._NNP -LRB-_-LRB- 1997_CD ,_, July_NNP -RRB-_-RRB- ._.
A_DT comparative_JJ study_NN on_IN feature_NN selection_NN in_IN text_NN categorization_NN ._.
In_IN ICML_NNP -LRB-_-LRB- Vol_NNP ._.
97_CD ,_, pp._SYM 412-420_CD -RRB-_-RRB- Fragoudis_NNPS ,_, D._NNP ,_, Meretakis_NNP ,_, D._NNP ,_, &_CC Likothanassis_NNP ,_, S._NNP -LRB-_-LRB- 2005_CD -RRB-_-RRB- ._.
Best_JJS terms_NNS :_: an_DT efficient_JJ feature-selection_NN algorithm_NN for_IN text_NN categorization_NN ._.
Knowledge_NN and_CC Information_NNP Systems_NNP ,_, 8_CD -LRB-_-LRB- 1_LS -RRB-_-RRB- ,_, 16-33_CD ._.
Gomez_NNP ,_, J._NNP C._NNP ,_, &_CC Moens_NNP ,_, M._NNP F._NNP -LRB-_-LRB- 2012_CD -RRB-_-RRB- ._.
PCA_NNP document_NN reconstruction_NN for_IN classification_NN ._.
Computational_NNP Statistics_NNPS Analysis_NNP ,_, 56_CD -LRB-_-LRB- 3_LS -RRB-_-RRB- ,_, 741-751_CD ._.
email_NN &_CC Data_NNP Gunal_NNP ,_, S._NNP ,_, &_CC Edizkan_NNP ,_, R._NNP -LRB-_-LRB- 2008_CD -RRB-_-RRB- ._.
Subspace_NNP based_VBN feature_NN selection_NN for_IN pattern_NN recognition_NN ._.
Information_NNP Sciences_NNP ,_, 178_CD -LRB-_-LRB- 19_CD -RRB-_-RRB- ,_, 3716-3726_CD ._.
Joachims_NNP ,_, T._NNP -LRB-_-LRB- 1996_CD -RRB-_-RRB- ._.
A_DT Probabilistic_NNP Analysis_NNP of_IN the_DT Rocchio_NNP Algorithm_NNP with_IN TFIDF_NNP for_IN Text_NNP Categorization_NNP -LRB-_-LRB- No_UH ._.
CMU-CS-96-118_NN -RRB-_-RRB- ._.
Joachims_NNP ,_, T._NNP -LRB-_-LRB- 1998_CD -RRB-_-RRB- ._.
Text_NN categorization_NN with_IN support_NN vector_NN machines_NNS :_: Learning_NNP with_IN many_JJ relevant_JJ features_NNS -LRB-_-LRB- pp._FW 137-142_CD -RRB-_-RRB- ._.
Springer_NNP Berlin_NNP Heidelberg_NNP ._.
Liu_NNP ,_, H._NNP ,_, &_CC Motoda_NNP ,_, H._NNP -LRB-_-LRB- Eds_NNP ._. -RRB-_-RRB- ._.
-LRB-_-LRB- 1998_CD -RRB-_-RRB- ._.
Feature_NN extraction_NN ,_, construction_NN and_CC selection_NN :_: A_DT data_NN mining_NN perspective_NN ._.
Springer_NNP Science_NNP &_CC Business_NNP Media_NNP ._.
Porter_NNP ,_, M._NNP F._NNP -LRB-_-LRB- 1980_CD -RRB-_-RRB- ._.
An_DT algorithm_NN for_IN suffix_NN stripping_VBG ._.
Program_NN ,_, 14_CD -LRB-_-LRB- 3_LS -RRB-_-RRB- ,_, 130-137_CD ._.
Bellman_NNP ,_, R._NNP ,_, -LRB-_-LRB- 1961_CD -RRB-_-RRB- ._.
Adaptive_JJ control_NN processes_NNS :_: a_DT guided_VBN tour_NN -LRB-_-LRB- Vol_NNP ._.
4_LS -RRB-_-RRB- ._.
Princeton_NNP :_: Princeton_NNP university_NN press_NN ._.
Chakraborti_NNP ,_, S._NNP ,_, Mukras_NNP ,_, R._NNP ,_, Lothian_NNP ,_, R._NNP ,_, Wiratunga_NNP ,_, N._NNP ,_, Watt_NNP ,_, S._NNP N._NNP ,_, &_CC Harper_NNP ,_, D._NNP J._NNP -LRB-_-LRB- 2007_CD ,_, January_NNP -RRB-_-RRB- ._.
Supervised_VBN Latent_NNP Semantic_NNP Indexing_NN Using_VBG Adaptive_NNP Sprinkling_NNP ._.
In_IN IJCAI_NNP -LRB-_-LRB- pp._FW 1582-1587_CD -RRB-_-RRB- ._.
Friedman_NNP ,_, J._NNP ,_, Hastie_NNP ,_, T._NNP ,_, &_CC Tibshirani_NNP ,_, R._NNP -LRB-_-LRB- 2001_CD -RRB-_-RRB- ._.
The_DT elements_NNS of_IN statistical_JJ learning_NN -LRB-_-LRB- Vol_NNP ._.
1_LS -RRB-_-RRB- ._.
Springer_NNP ,_, Berlin_NNP :_: Springer_NNP series_NN in_IN statistics_NNS Hall_NNP ,_, M._NNP ,_, Frank_NNP ,_, E._NNP ,_, Holmes_NNP ,_, G._NNP ,_, Pfahringer_NNP ,_, B._NNP ,_, Reutemann_NNP ,_, P._NNP ,_, &_CC Witten_NNP ,_, I._NNP H._NNP -LRB-_-LRB- 2009_CD -RRB-_-RRB- ._.
The_DT WEKA_NNP data_NNS mining_NN software_NN :_: an_DT update_VBP ._.
ACM_NNP SIGKDD_NNP explorations_VBZ newsletter_NN ,_, 11_CD -LRB-_-LRB- 1_LS -RRB-_-RRB- ,_, 10-18_CD ._.
Howland_NNP ,_, P._NNP ,_, &_CC Park_NNP ,_, H._NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- ._.
Generalizing_VBG discriminant_JJ analysis_NN using_VBG the_DT generalized_VBN singular_JJ value_NN decomposition_NN ._.
Pattern_NN Analysis_NN and_CC Machine_NN Intelligence_NNP ,_, IEEE_NNP Transactions_NNS on_IN ,_, 26_CD -LRB-_-LRB- 8_CD -RRB-_-RRB- ,_, 995-1006_CD ._.
